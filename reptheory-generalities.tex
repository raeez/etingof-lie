\documentclass[etingof-lie.tex]{subfiles}
\begin{document}
\section{Representation theory: generalities}
\subsection{Representation theory: general facts}

The first step in the representation theory of any objects (groups, algebras,
etc.) is usually proving some kind of Schur's lemma. There is one form of
Schur's lemma that holds almost tautologically: This is the form that claims
that every morphism between irreducible representations is either $0$ or an
isomorphism.\footnote{There are also variations on this assertion:
\par
\textbf{1)} Every morphism from an irreducible representation to a
representation is either $0$ or injective.
\par
\textbf{2)} Every morphism from a representation to an irreducible
representation is either $0$ or surjective.
\par
Both of these variations follow very easily from the definition of
``irreducible''.} However, the more often used form of Schur's lemma is a bit
different: It claims that, over an algebraically closed field, every
endomorphism of a finite-dimensional irreducible representation is a scalar
multiple of the identity map. This is usually proven using eigenvalues, and
this proof depends on the fact that eigenvalues exist; this (in general)
requires the irreducible representation to be \textit{finite-dimensional}.
Hence, it should not come as a surprise that this latter form of Schur's lemma
does not generally hold for infinite-dimensional representations. This makes
this lemma not particularly useful in the case of infinite-dimensional Lie
algebras. But we still can show the following version of Schur's lemma over
$\mathbb{C}$:

\begin{lemma}
[Dixmier's Lemma]\label{lem.dix}Let $A$ be an algebra over $\mathbb{C}$, and
let $V$ be an irreducible $A$-module of countable dimension. Then, any
$A$-module homomorphism $\phi:V\rightarrow V$ is a scalar multiple of the identity.
\end{lemma}

This lemma is called \textit{Dixmier's lemma}, and its proof is similar to the
famous proof of the Nullstellensatz over $\mathbb{C}$ using the uncountability
of $\mathbb{C}$.

\textit{Proof of Lemma \ref{lem.dix}.} Let $D=\operatorname*{End}%
\nolimits_{A}V$. Then, $D$ is a division algebra (in fact, the endomorphism
ring of an irreducible representation always is a division algebra).

For any nonzero $v\in V$, we have $Av=V$ (otherwise, $Av$ would be a nonzero
proper $A$-submodule of $V$, contradicting the fact that $V$ is irreducible
and thus does not have any such submodules). In other words, for any nonzero
$v\in V$, every element of $V$ can be written as $av$ for some $a\in A$. Thus,
for any nonzero $v\in V$, any element $\phi\in D$ is completely determined by
$\phi\left(  v\right)  $ (because $\phi\left(  av\right)  =a\phi\left(
v\right)  $ for every $a\in A$, so that the value $\phi\left(  v\right)  $
uniquely determines the value of $\phi\left(  av\right)  $ for every $a\in A$,
and thus (since we know that every element of $V$ can be written as $av$ for
some $a\in A$) every value of $\phi$ is uniquely determined). Thus, we have an
embedding of $D$ into $V$. Hence, $D$ is countably-dimensional (since $V$ is
countably-dimensional). But a countably-dimensional division algebra $D$ over
$\mathbb{C}$ must be $\mathbb{C}$ itself\footnote{\textit{Proof.} Indeed,
assume the contrary. So there exists some $\phi\in D$ not belonging to
$\mathbb{C}$. Then, $\phi$ is transcendental over $\mathbb{C}$, so that
$\mathbb{C}\left(  \phi\right)  \subseteq D$ is the field of rational
functions in one variable $\phi$ over $\mathbb{C}$. Now, $\mathbb{C}\left(
\phi\right)  $ contains the rational function $\dfrac{1}{\phi-\lambda}$ for
every $\lambda\in\mathbb{C}$, and these rational functions for varying
$\lambda$ are linearly independent. Since $\mathbb{C}$ is uncountable, we thus
have an uncountable linearly independent set of elements of $\mathbb{C}\left(
\phi\right)  $, contradicting the fact that $\mathbb{C}\left(  \phi\right)  $
is a subspace of the countably-dimensional space $D$, qed.}, so that
$D=\mathbb{C}$, and this is exactly what we wanted to show. Lemma
\ref{lem.dix} is proven.

Note that Lemma \ref{lem.dix} is a general fact, not particular to Lie
algebras; however, it is not as general as it seems: It really makes use of
the uncountability of $\mathbb{C}$, not just of the fact that $\mathbb{C}$ is
an algebraically closed field of characteristic $0$. It would be wrong if we
would replace $\mathbb{C}$ by (for instance) the algebraic closure of
$\mathbb{Q}$.

\begin{remark}
\label{rem.dix}Let $A$ be a countably-dimensional algebra over $\mathbb{C}$,
and let $V$ be an irreducible $A$-module. Then, $V$ itself is countably dimensional.
\end{remark}

\textit{Proof of Remark \ref{rem.dix}.} For any nonzero $v\in V$, we have
$Av=V$ (by the same argument as in the proof of Lemma \ref{lem.dix}), and thus
$\dim\left(  Av\right)  =\dim V$. Since $\dim\left(  Av\right)  \leq\dim A$,
we thus have $\dim V=\dim\left(  Av\right)  \leq\dim A$, so that $V$ has
countable dimension (since $A$ has countable dimension). This proves Remark
\ref{rem.dix}.

\begin{corollary}
\label{cor.dix2}Let $A$ be an algebra over $\mathbb{C}$, and let $V$ be an
irreducible $A$-module of countable dimension. Let $C$ be a central element of
$A$. Then, $C\mid_{V}$ is a scalar (i. e., a scalar multiple of the identity map).
\end{corollary}

\textit{Proof of Corollary \ref{cor.dix2}.} Since $C$ is central, the element
$C$ commutes with any element of $A$. Thus, $C\mid_{V}$ is an $A$-module
homomorphism, and hence (by Lemma \ref{lem.dix}, applied to $\phi=C\mid_{V}$)
a scalar multiple of the identity. This proves Corollary \ref{cor.dix2}.

\subsection{Representations of the Heisenberg algebra
\texorpdfstring{$\mathcal{A}$}{A}}

\subsubsection{General remarks}

Consider the oscillator algebra (aka Heisenberg algebra) $\mathcal{A}%
=\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\right\rangle +\left\langle
K\right\rangle $. Recall that%
\begin{align*}
\left[  a_{i},a_{j}\right]   &  =i\delta_{i,-j}K\ \ \ \ \ \ \ \ \ \ \text{for
any }i,j\in\mathbb{Z};\\
\left[  K,a_{i}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for any }%
i\in\mathbb{Z}.
\end{align*}


Let us try to classify the irreducible $\mathcal{A}$-modules.

Let $V$ be an irreducible $\mathcal{A}$-module. Then, $V$ is
countably-dimensional (by Remark \ref{rem.dix}, since $U\left(  \mathcal{A}%
\right)  $ is countably-dimensional), so that by Corollary \ref{cor.dix2}, the
endomorphism $K\mid_{V}$ is a scalar (because $K$ is a central element of
$\mathcal{A}$ and thus also a central element of $U\left(  \mathcal{A}\right)
$).

If $K\mid_{V}=0$, then $V$ is a module over the Lie algebra $\mathcal{A}%
\diagup\mathbb{C}K=\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\right\rangle $.
But since $\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\right\rangle $ is an
abelian Lie algebra, irreducible modules over $\left\langle a_{i}\ \mid
\ i\in\mathbb{Z}\right\rangle $ are $1$-dimensional (again by Corollary
\ref{cor.dix2}), so that $V$ must be $1$-dimensional in this case. Thus, the
case when $K\mid_{V}=0$ is not an interesting case.

Now consider the case when $K\mid_{V}=k\neq0$. Then, we can WLOG assume that
$k=1$, because the Lie algebra $\mathcal{A}$ has an automorphism sending $K$
to $\lambda K$ for any arbitrary $\lambda\neq0$ (this automorphism is given by
$a_{i}\mapsto\lambda a_{i}$ for $i>0$, and $a_{i}\mapsto a_{i}$ for $i\leq0$).

We are thus interested in irreducible representations $V$ of $\mathcal{A}$
satisfying $K\mid_{V}=1$. These are in an obvious 1-to-1 correspondence with
irreducible representations of $U\left(  \mathcal{A}\right)  \diagup\left(
K-1\right)  $.

\begin{proposition}
\label{prop.K-1}We have an algebra isomorphism%
\[
\xi:U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)  \rightarrow
D\left(  x_{1},x_{2},x_{3},...\right)  \otimes\mathbb{C}\left[  x_{0}\right]
,
\]
where $D\left(  x_{1},x_{2},x_{3},...\right)  $ is the algebra of differential
operators in the variables $x_{1}$, $x_{2}$, $x_{3}$, $...$ with polynomial
coefficients. This isomorphism is given by%
\begin{align*}
\xi\left(  a_{-i}\right)   &  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{i}\right)   &  =i\dfrac{\partial}{\partial x_{i}}%
\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{0}\right)   &  =x_{0}.
\end{align*}

\end{proposition}

Note that we are sloppy with notation here: Since $\xi$ is a homomorphism from
$U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)  $ (rather than
$U\left(  \mathcal{A}\right)  $), we should write $\xi\left(  \overline
{a_{-i}}\right)  $ instead of $\xi\left(  a_{-i}\right)  $, etc.. We are using
the same letters to denote elements of $U\left(  \mathcal{A}\right)  $ and
their residue classes in $U\left(  \mathcal{A}\right)  \diagup\left(
K-1\right)  $, and are relying on context to keep them apart. We hope that the
reader will forgive us this abuse of notation.

\textit{Proof of Proposition \ref{prop.K-1}.} It is clear\footnote{from the
universal property of the universal enveloping algebra, and the universal
property of the quotient algebra} that there exists a unique algebra
homomorphism $\xi:U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)
\rightarrow D\left(  x_{1},x_{2},x_{3},...\right)  $ satisfying%
\begin{align*}
\xi\left(  a_{-i}\right)   &  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{i}\right)   &  =i\dfrac{\partial}{\partial x_{i}}%
\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{0}\right)   &  =x_{0}.
\end{align*}
It is also clear that this $\xi$ is surjective (since all the generators
$x_{i}$, $\dfrac{\partial}{\partial x_{i}}$ and $x_{0}$ of the algebra
$D\left(  x_{1},x_{2},x_{3},...\right)  \otimes\mathbb{C}\left[  x_{0}\right]
$ are in its image).

In the following, a map $\varphi:A\rightarrow\mathbb{N}$ (where $A$ is some
set) is said to be \textit{finitely supported} if all but finitely many $a\in
A$ satisfy $\varphi\left(  a\right)  =0$. Sequences (finite, infinite, or
two-sided infinite) are considered as maps (from finite sets, $\mathbb{N}$ or
$\mathbb{Z}$, or occasionally other sets). Thus, a sequence is finitely
supported if and only if all but finitely many of its elements are zero.

If $A$ is a set, then $\mathbb{N}_{\operatorname*{fin}}^{A}$ will denote the
set of all finitely supported maps $A\rightarrow\mathbb{N}$.

By the easy part of the Poincar\'{e}-Birkhoff-Witt theorem (this is the part
which states that the increasing monomials \textit{span} the universal
enveloping algebra\footnote{The hard part says that these increasing monomials
are linearly independent.}), the family\footnote{Here, $\overset{\rightarrow
}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}}$ denotes the product
$...a_{-2}^{n_{-2}}a_{-1}^{n_{-1}}a_{0}^{n_{0}}a_{1}^{n_{1}}a_{2}^{n_{2}}...$.
(This product is infinite, but still has a value since only finitely many
$n_{i}$ are nonzero.)}%
\[
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}}\cdot
K^{m}\right)  _{\left(  ...,n_{-2},n_{-1},n_{0},n_{1},n_{2},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}},\ m\in\mathbb{N}}%
\]
is a spanning set of the vector space $U\left(  \mathcal{A}\right)  $. Hence,
the family
\[
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}%
}\right)  _{\left(  ...,n_{-2},n_{-1},n_{0},n_{1},n_{2},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}}}%
\]
is a spanning set of $U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)
$, and since this family maps to a linearly independent set under $\xi$ (this
is very easy to see), it follows that $\xi$ is injective. Thus, $\xi$ is an
isomorphism, so that Proposition \ref{prop.K-1} is proven.

\begin{definition}
\label{def.A0}Define a vector subspace $\mathcal{A}_{0}$ of $\mathcal{A}$ by
$\mathcal{A}_{0}=\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\diagdown\left\{
0\right\}  \right\rangle +\left\langle K\right\rangle $.
\end{definition}

\begin{proposition}
\label{prop.A0}This subspace $\mathcal{A}_{0}$ is a Lie subalgebra of
$\mathcal{A}$, and $\mathbb{C}a_{0}$ is also a Lie subalgebra of $\mathcal{A}%
$. We have $\mathcal{A}=\mathcal{A}_{0}\oplus\mathbb{C}a_{0}$ as Lie algebras.
Hence,%
\[
U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)  =U\left(
\mathcal{A}_{0}\oplus\mathbb{C}a_{0}\right)  \diagup\left(  K-1\right)
\cong\underbrace{\left(  U\left(  \mathcal{A}_{0}\right)  \diagup\left(
K-1\right)  \right)  }_{\cong D\left(  x_{1},x_{2},x_{3},...\right)  }%
\otimes\underbrace{\mathbb{C}\left[  a_{0}\right]  }_{\cong\mathbb{C}\left[
x_{0}\right]  }%
\]
(since $K\in\mathcal{A}_{0}$). Here, the isomorphism $U\left(  \mathcal{A}%
_{0}\right)  \diagup\left(  K-1\right)  \cong D\left(  x_{1},x_{2}%
,x_{3},...\right)  $ is defined as follows: In analogy to Proposition
\ref{prop.K-1}, we have an algebra isomorphism%
\[
\widetilde{\xi}:U\left(  \mathcal{A}_{0}\right)  \diagup\left(  K-1\right)
\rightarrow D\left(  x_{1},x_{2},x_{3},...\right)
\]
given by%
\begin{align*}
\widetilde{\xi}\left(  a_{-i}\right)   &  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for
}i\geq1;\\
\widetilde{\xi}\left(  a_{i}\right)   &  =i\dfrac{\partial}{\partial x_{i}%
}\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1.
\end{align*}

\end{proposition}

The proof of Proposition \ref{prop.A0} is analogous to that of Proposition
\ref{prop.K-1} (where it is not completely straightforward).

\subsubsection{The Fock space}

From Proposition \ref{prop.A0}, we know that
\begin{align*}
U\left(  \mathcal{A}_{0}\right)  \diagup\left(  K-1\right)  \cong D\left(
x_{1},x_{2},x_{3},...\right)  \subseteq\operatorname*{End}\left(
\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  \right)  .
\end{align*}
Hence, we have a $\mathbb{C}$-algebra homomorphism $U\left(  \mathcal{A}%
_{0}\right)  \rightarrow\operatorname*{End}\left(  \mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  \right)  $. This makes $\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  $ into a representation of the Lie algebra
$\mathcal{A}_{0}$. Let us state this as a corollary:

\begin{corollary}
\label{cor.fock}The Lie algebra $\mathcal{A}_{0}$ has a representation
$F=\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  $ which is given by
\begin{align*}
a_{-i}  &  \mapsto x_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1;\\
a_{i}  &  \mapsto i\dfrac{\partial}{\partial x_{i}}%
\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1,\\
K  &  \mapsto1
\end{align*}
(where ``$a_{-i}\mapsto x_{i}$'' is just shorthand for ``$a_{-i}\mapsto\left(
\text{multiplication by }x_{i}\right)  $''). For every $\mu\in\mathbb{C}$, we
can upgrade $F$ to a representation $F_{\mu}$ of $\mathcal{A}$ by adding the
condition that $a_{0}\mid_{F_{\mu}}=\mu\cdot\operatorname*{id}$.
\end{corollary}

\begin{definition}
\label{def.fock}The representation $F$ of $\mathcal{A}_{0}$ introduced in
Corollary \ref{cor.fock} is called the \textit{Fock module} or the
\textit{Fock representation}. For every $\mu\in\mathbb{C}$, the representation
$F_{\mu}$ of $\mathcal{A}$ introduced in Corollary \ref{cor.fock} will be
called the $\mu$\textit{-Fock representation} of $\mathcal{A}$. The vector
space $F$ itself is called the \textit{Fock space}.
\end{definition}

Let us now define some gradings to make these infinite-dimensional spaces more manageable:

\begin{definition}
\label{def.A.grad}Let us grade the vector space $\mathcal{A}$ by
$\mathcal{A}=\bigoplus\limits_{n\in\mathbb{Z}}\mathcal{A}\left[  n\right]  $,
where $\mathcal{A}\left[  n\right]  =\left\langle a_{n}\right\rangle $ for
$n\neq0$, and where $\mathcal{A}\left[  0\right]  =\left\langle a_{0}%
,K\right\rangle $.\ With this grading, we have $\left[  \mathcal{A}\left[
n\right]  ,\mathcal{A}\left[  m\right]  \right]  \subseteq\mathcal{A}\left[
n+m\right]  $ for all $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$. (In other words,
the Lie algebra $\mathcal{A}$ with the decomposition $\mathcal{A}%
=\bigoplus\limits_{n\in\mathbb{Z}}\mathcal{A}\left[  n\right]  $ is a
$\mathbb{Z}$-graded Lie algebra. The notion of a ``$\mathbb{Z}$-graded Lie
algebra'' that we have just used is defined in Definition \ref{def.gradLie}.)
\end{definition}

Note that we are denoting the $n$-th homogeneous component of $\mathcal{A}$ by
$\mathcal{A}\left[  n\right]  $ rather than $\mathcal{A}_{n}$, since otherwise
the notation $\mathcal{A}_{0}$ would have two different meanings.

\begin{definition}
\label{def.fock.grad}We grade the polynomial algebra $F$ by setting
$\deg\left(  x_{i}\right)  =-i$ for each $i$. Thus, $F=\bigoplus
\limits_{n\geq0}F\left[  -n\right]  $, where $F\left[  -n\right]  $ is the
space of polynomials of degree $-n$, where the degree is our degree defined by
$\deg\left(  x_{i}\right)  =-i$ (so that, for instance, $x_{1}^{2}+x_{2}$ is
homogeneous of degree $-2$). With this grading, $\dim\left(  F\left[
-n\right]  \right)  $ is the number $p\left(  n\right)  $ of all partitions of
$n$. Hence,%
\[
\sum\limits_{n\geq0}\dim\left(  F\left[  -n\right]  \right)  q^{n}%
=\sum\limits_{n\geq0}p\left(  n\right)  q^{n}=\dfrac{1}{\left(  1-q\right)
\left(  1-q^{2}\right)  \left(  1-q^{3}\right)  \cdots}=\dfrac{1}%
{\prod\limits_{i\geq1}\left(  1-q^{i}\right)  }%
\]
in the ring of power series $\mathbb{Z}\left[  \left[  q\right]  \right]  $.

We use the same grading for $F_{\mu}$ for every $\mu\in\mathbb{C}$. That is,
we define the grading on $F_{\mu}$ by $F_{\mu}\left[  n\right]  =F\left[
n\right]  $ for every $n\in\mathbb{Z}$.
\end{definition}

\begin{remark}
\label{rmk.fockgrad}Some people prefer to grade $F_{\mu}$ somewhat differently
from $F$: namely, they shift the grading for $F_{\mu}$ by $\dfrac{\mu^{2}}{2}%
$, so that $\deg1=-\dfrac{\mu^{2}}{2}$ in $F_{\mu}$, and generally $F_{\mu
}\left[  z\right]  =F\left[  \dfrac{\mu^{2}}{2}+z\right]  $ (as vector spaces)
for every $z\in\mathbb{C}$. This is a grading by complex numbers rather than
integers (in general). (The advantage of this grading is that we will
eventually find an operator whose eigenspace to the eigenvalue $n$ is $F_{\mu
}\left[  n\right]  =F\left[  \dfrac{\mu^{2}}{2}+n\right]  $ for every
$n\in\mathbb{C}$.)

With this grading, the equality $\sum\limits_{n\geq0}\dim\left(  F\left[
-n\right]  \right)  q^{n}=\dfrac{1}{\prod\limits_{i\geq1}\left(
1-q^{i}\right)  }$ rewrites as $\sum\limits_{n\in\mathbb{C}}\dim\left(
F_{\mu}\left[  -n\right]  \right)  q^{n+\dfrac{\mu^{2}}{2}}=\dfrac{q^{\mu^{2}%
}}{\prod\limits_{i\geq1}\left(  1-q^{i}\right)  }$, if we allow power series
with complex exponents. We define a ``power series'' $\operatorname*{ch}%
\left(  F_{\mu}\right)  $ by%
\[
\operatorname*{ch}\left(  F_{\mu}\right)  =\sum\limits_{n\in\mathbb{C}}%
\dim\left(  F_{\mu}\left[  -n\right]  \right)  q^{n+\dfrac{\mu^{2}}{2}}%
=\dfrac{q^{\mu^{2}}}{\prod\limits_{i\geq1}\left(  1-q^{i}\right)  }.
\]
But we will not use this grading; instead we will use the grading defined in
Definition \ref{def.fock.grad}.
\end{remark}

\begin{proposition}
\label{prop.F.irrep}The representation $F$ is an irreducible representation of
$\mathcal{A}_{0}$.
\end{proposition}

\begin{lemma}
\label{lem.F.P1=P}For every $P\in F$, we have
\[
P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot1=P\ \ \ \ \ \ \ \ \ \ \text{in
}F.
\]
(Here, the term $P\left(  a_{-1},a_{-2},a_{-3},...\right)  $ denotes the
evaluation of the polynomial $P$ at $\left(  x_{1},x_{2},x_{3},...\right)
=\left(  a_{-1},a_{-2},a_{-3},...\right)  $. This evaluation is a well-defined
element of $U\left(  \mathcal{A}_{0}\right)  $, since the elements $a_{-1}$,
$a_{-2}$, $a_{-3}$, $...$ of $U\left(  \mathcal{A}_{0}\right)  $ commute.)
\end{lemma}

\textit{Proof of Lemma \ref{lem.F.P1=P}.} For every $Q\in F$, let
$\operatorname*{mult}Q$ denote the map $F\rightarrow F,$ $R\mapsto QR$. (In
Proposition \ref{prop.K-1}, we abused notations and denoted this map simply by
$Q$; but we will not do this in this proof.) Then, by the definition of $\xi$,
we have $\xi\left(  a_{-i}\right)  =\operatorname*{mult}\left(  x_{i}\right)
$ for every $i\geq1$.

Since we have defined an endomorphism $\operatorname*{mult}Q\in
\operatorname*{End}F$ for every $Q\in F$, we thus obtain a map
$\operatorname*{mult}:F\rightarrow\operatorname*{End}F$. This map
$\operatorname*{mult}$ is an algebra homomorphism (since it describes the
action of $F$ on the $F$-module $F$).

Let $P\in F$. Since $\xi$ is an algebra homomorphism, and thus commutes with
polynomials, we have
\begin{align*}
&  \xi\left(  P\left(  a_{-1},a_{-2},a_{-3},...\right)  \right) \\
&  =P\left(  \xi\left(  a_{-1}\right)  ,\xi\left(  a_{-2}\right)  ,\xi\left(
a_{-3}\right)  ,...\right)  =P\left(  \operatorname*{mult}\left(
x_{1}\right)  ,\operatorname*{mult}\left(  x_{2}\right)  ,\operatorname*{mult}%
\left(  x_{3}\right)  ,...\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\xi\left(  a_{-i}\right)
=\operatorname*{mult}\left(  x_{i}\right)  \text{ for every }i\geq1\right) \\
&  =\operatorname*{mult}\left(  \underbrace{P\left(  x_{1},x_{2}%
,x_{3},...\right)  }_{=P}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\operatorname*{mult}\text{ is an algebra homomorphism,}\\
\text{and thus commutes with polynomials}%
\end{array}
\right) \\
&  =\operatorname*{mult}P.
\end{align*}
Thus,%
\[
P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot1=\left(  \operatorname*{mult}%
P\right)  \left(  1\right)  =P\cdot1=P.
\]
This proves Lemma \ref{lem.F.P1=P}.

\textit{Proof of Proposition \ref{prop.F.irrep}.} \textbf{1)} The
representation $F$ is generated by $1$ as a $U\left(  \mathcal{A}_{0}\right)
$-module (due to Lemma \ref{lem.F.P1=P}). In other words, $F=U\left(
\mathcal{A}_{0}\right)  \cdot1$.

\textbf{2)} Let us forget about the grading on $F$ which we defined in
Definition \ref{def.fock.grad}, and instead, once again, define a grading on
$F$ by $\deg\left(  x_{i}\right)  =1$ for every $i\in\left\{
1,2,3,...\right\}  $. Thus, the degree of a polynomial $P\in F$ with respect
to this grading is what is usually referred to as the degree of the polynomial
$P$.

\begin{verlong}
If $P\in F$ and if $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ is
a monomial in $P$ of degree $\deg P$, with $\alpha\neq0$, then $\dfrac
{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}%
!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...P=\alpha$%
\ \ \ \ \footnote{\textit{Proof.} Let $P\in F$. Let $\alpha\cdot x_{1}^{m_{1}%
}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ be a monomial in $P$ of degree $\deg P$, with
$\alpha\neq0$. Since the monomial $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}%
x_{3}^{m_{3}}...$ has degree $\deg P$, we have%
\[
\deg P=\deg\left(  \alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}%
}...\right)  =m_{1}+m_{2}+m_{3}+....
\]
\par
For every set $A$, define $\mathbb{N}_{\operatorname*{fin}}^{A}$ as in the
proof of Proposition \ref{prop.K-1}.
\par
Now, for every $\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$, let $\beta_{\left(
n_{1},n_{2},n_{3},...\right)  }$ be the coefficient of the polynomial $P$
before the monomial $x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...$. Then,
$\beta_{\left(  n_{1},n_{2},n_{3},...\right)  }=0$ for every $\left(
n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
1,2,3,...\right\}  }$ satisfying $n_{1}+n_{2}+n_{3}+...>\deg P$ (because for
every $\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ satisfying $n_{1}%
+n_{2}+n_{3}+...>\deg P$, the monomial $x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}%
^{n_{3}}...$ has degree $n_{1}+n_{2}+n_{3}+...>\deg P$, and thus the
coefficient of the polynomial $P$ before this monomial must be $0$). On the
other hand, $\beta_{\left(  m_{1},m_{2},m_{3},...\right)  }=\alpha$ (since
$\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ is a monomial in $P$,
and thus the coefficient of the polynomial $P$ before the monomial
$x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ is $\alpha$).
\par
On the other hand, recall that $\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}$ is the coefficient of the polynomial $P$ before the monomial $x_{1}^{n_{1}%
}x_{2}^{n_{2}}x_{3}^{n_{3}}...$ for every $\left(  n_{1},n_{2},n_{3}%
,...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}
}$. Hence,%
\begin{align*}
P  &  =\sum\limits_{\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }}\beta_{\left(
n_{1},n_{2},n_{3},...\right)  }x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P}}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...+\sum\limits_{\substack{\left(
n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
1,2,3,...\right\}  };\\n_{1}+n_{2}+n_{3}+...>\deg P}}\underbrace{\beta
_{\left(  n_{1},n_{2},n_{3},...\right)  }}_{\substack{=0\\\text{(since }%
n_{1}+n_{2}+n_{3}+...>\deg P\text{)}}}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}%
}...\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P}}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...+\underbrace{\sum
\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}+n_{2}%
+n_{3}+...>\deg P}}0x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...}_{=0}\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P}}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(
m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...+\underbrace{\beta_{\left(
m_{1},m_{2},m_{3},...\right)  }}_{=\alpha}x_{1}^{m_{1}}x_{2}^{m_{2}}%
x_{3}^{m_{3}}...\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(  m_{1},m_{2},m_{3}%
,...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}
}\text{ satisfies }m_{1}+m_{2}+m_{3}+...=\deg P\right) \\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(
m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...+\alpha x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}....
\end{align*}
Thus,%
\begin{align}
&  \dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}%
}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...P\nonumber\\
&  =\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}%
}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(  \sum
\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}+n_{2}%
+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(
m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...+\alpha x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...\right) \nonumber\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(
m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}%
}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(  x_{1}^{n_{1}}%
x_{2}^{n_{2}}x_{3}^{n_{3}}...\right)  +\alpha\underbrace{\dfrac{\partial
_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}%
\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(  x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...\right)  }_{=\dfrac{m_{1}!}{m_{1}!}\dfrac{m_{2}!}{m_{2}%
!}\dfrac{m_{3}!}{m_{3}!}...=1}\nonumber\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(
m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}%
}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(  x_{1}^{n_{1}}%
x_{2}^{n_{2}}x_{3}^{n_{3}}...\right)  +\alpha. \label{pf.F.irrep.long.1}%
\end{align}
\par
But now, let $\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ be a sequence
satisfying $n_{1}+n_{2}+n_{3}+...\leq\deg P$ and $\left(  n_{1},n_{2}%
,n_{3},...\right)  \neq\left(  m_{1},m_{2},m_{3},...\right)  $. Since
$n_{1}+n_{2}+n_{3}+...\leq\deg P=m_{1}+m_{2}+m_{3}+...$ but $\left(
n_{1},n_{2},n_{3},...\right)  \neq\left(  m_{1},m_{2},m_{3},...\right)  $, it
is clear that there exists at least one $\ell\in\left\{  1,2,3,...\right\}  $
satisfying $n_{\ell}<m_{\ell}$. Consider such an $\ell$. Since the
differential operators $\partial_{x_{1}}$, $\partial_{x_{2}}$, $\partial
_{x_{3}}$, $...$ commute, we have $\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}%
!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}%
}{m_{3}!}...=\left(  \prod\limits_{i\in\left\{  1,2,3,...\right\}
\setminus\left\{  \ell\right\}  }\dfrac{\partial_{x_{i}}^{m_{i}}}{m_{i}%
!}\right)  \circ\dfrac{\partial_{x_{\ell}}^{m_{\ell}}}{m_{\ell}!}$, so that%
\begin{align*}
\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}%
{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(  x_{1}^{n_{1}}%
x_{2}^{n_{2}}x_{3}^{n_{3}}...\right)   &  =\left(  \left(  \prod
\limits_{i\in\left\{  1,2,3,...\right\}  \setminus\left\{  \ell\right\}
}\dfrac{\partial_{x_{i}}^{m_{i}}}{m_{i}!}\right)  \circ\dfrac{\partial
_{x_{\ell}}^{m_{\ell}}}{m_{\ell}!}\right)  \left(  x_{1}^{n_{1}}x_{2}^{n_{2}%
}x_{3}^{n_{3}}...\right) \\
&  =\left(  \prod\limits_{i\in\left\{  1,2,3,...\right\}  \setminus\left\{
\ell\right\}  }\dfrac{\partial_{x_{i}}^{m_{i}}}{m_{i}!}\right)
\underbrace{\left(  \dfrac{\partial_{x_{\ell}}^{m_{\ell}}}{m_{\ell}!}\left(
x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...\right)  \right)  }%
_{\substack{=0\\\text{(since }n_{\ell}<m_{\ell}\text{)}}}\\
&  =\left(  \prod\limits_{i\in\left\{  1,2,3,...\right\}  \setminus\left\{
\ell\right\}  }\dfrac{\partial_{x_{i}}^{m_{i}}}{m_{i}!}\right)  \left(
0\right)  =0.
\end{align*}
\par
Now, forget that we fixed $\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$. We have thus
proven that every sequence $\left(  n_{1},n_{2},n_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ satisfying
$n_{1}+n_{2}+n_{3}+...\leq\deg P$ and $\left(  n_{1},n_{2},n_{3},...\right)
\neq\left(  m_{1},m_{2},m_{3},...\right)  $ must satisfy $\dfrac
{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}%
!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(  x_{1}^{n_{1}}x_{2}%
^{n_{2}}x_{3}^{n_{3}}...\right)  =0$. Hence, (\ref{pf.F.irrep.long.1}) becomes%
\begin{align*}
&  \dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}%
}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...P\\
&  =\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\n_{1}%
+n_{2}+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(
m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2},n_{3},...\right)
}\underbrace{\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}%
}^{m_{2}}}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...\left(
x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...\right)  }%
_{\substack{=0\\\text{(since }n_{1}+n_{2}+n_{3}+...\leq\deg P\\\text{and
}\left(  n_{1},n_{2},n_{3},...\right)  \neq\left(  m_{1},m_{2},m_{3}%
,...\right)  \text{)}}}+\alpha\\
&  =\underbrace{\sum\limits_{\substack{\left(  n_{1},n_{2},n_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }%
;\\n_{1}+n_{2}+n_{3}+...\leq\deg P;\\\left(  n_{1},n_{2},n_{3},...\right)
\neq\left(  m_{1},m_{2},m_{3},...\right)  }}\beta_{\left(  n_{1},n_{2}%
,n_{3},...\right)  }0}_{=0}+\alpha=\alpha,
\end{align*}
qed.}.
\end{verlong}

\begin{vershort}
If $P\in F$ and if $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ is
a monomial in $P$ of degree $\deg P$, with $\alpha\neq0$, then $\dfrac
{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}%
!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...P=\alpha$%
\ \ \ \ \footnote{\textit{Proof.} Let $P\in F$. Let $\alpha\cdot x_{1}^{m_{1}%
}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ be a monomial in $P$ of degree $\deg P$, with
$\alpha\neq0$.
\par
WLOG, no variable other than $x_{1}$, $x_{2}$, $...$, $x_{k}$ appears in $P$,
for some $k\in\mathbb{N}$. Thus, $x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}%
}...=x_{1}^{m_{1}}x_{2}^{m_{2}}...x_{k}^{m_{k}}$ and $\dfrac{\partial_{x_{1}%
}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}\dfrac
{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...=\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}%
!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}%
}{m_{k}!}$.
\par
Thus, $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}...x_{k}^{m_{k}}=\alpha\cdot
x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$ is a monomial in $P$ of degree
$\deg P$.
\par
When we apply the differential operator $\dfrac{\partial_{x_{1}}^{m_{1}}%
}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}%
}^{m_{k}}}{m_{k}!}$ to $P$, all monomials $\beta\cdot x_{1}^{n_{1}}%
x_{2}^{n_{2}}...x_{k}^{n_{k}}$ with $\left(  n_{\ell}<m_{\ell}\text{ for at
least one }\ell\in\left\{  1,2,...,k\right\}  \right)  $ are annihilated
(because if $n_{\ell}<m_{\ell}$ for some $\ell$, then $\dfrac{\partial_{x_{1}%
}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac
{\partial_{x_{k}}^{m_{k}}}{m_{k}!}\left(  \beta\cdot x_{1}^{n_{1}}x_{2}%
^{n_{2}}...x_{k}^{n_{k}}\right)  =0$). Hence, the only monomials in $P$ which
survive under this operator are monomials of the form $\beta\cdot x_{1}%
^{n_{1}}x_{2}^{n_{2}}...x_{k}^{n_{k}}$ with each $n_{\ell}$ being $\geq$ to
the corresponding $m_{\ell}$. But since $m_{1}+m_{2}+...+m_{k}=\deg P$
(because $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}...x_{k}^{m_{k}}$ is a
monomial of degree $\deg P$), the only such monomial in $P$ is $\alpha\cdot
x_{1}^{m_{1}}x_{2}^{m_{2}}...x_{k}^{m_{k}}$ (because for every other monomial
of the form $\beta\cdot x_{1}^{n_{1}}x_{2}^{n_{2}}...x_{k}^{n_{k}}$ with each
$n_{\ell}$ being $\geq$ to the corresponding $m_{\ell}$, the sum $n_{1}%
+n_{2}+...+n_{k}$ must be greater than $m_{1}+m_{2}+...+m_{k}=\deg P$, and
thus such a monomial cannot occur in $P$). Hence, the only monomial in $P$
which survives is the monomial $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}%
...x_{k}^{m_{k}}$. This monomial clearly gets mapped to $\alpha$ by the
differential operator $\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac
{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}}{m_{k}!}%
$. Thus, $\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}%
}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}}{m_{k}!}P=\alpha$. Since
$\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}%
}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}}{m_{k}!}=\dfrac{\partial_{x_{1}%
}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}\dfrac
{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...$, this rewrites as $\dfrac
{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}%
!}\dfrac{\partial_{x_{3}}^{m_{3}}}{m_{3}!}...P=\alpha$, qed.}.
\end{vershort}

Thus, for every nonzero $P\in F$, we have $1\in U\left(  \mathcal{A}%
_{0}\right)  \cdot P$\ \ \ \ \footnote{\textit{Proof.} Let $P\in F$ be
nonzero. Then, there exist a monomial $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...$ in $P$ of degree $P$ with $\alpha\neq0$. Consider such a
monomial. As shown above, we have $\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}%
!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}%
}{m_{3}!}...P=\alpha$. But we know that $a_{i}\in\mathcal{A}_{0}$ acts as
$i\dfrac{\partial}{\partial x_{i}}$ on $F$ for every $i\geq1$. Thus,
$\dfrac{1}{i}a_{i}\in\mathcal{A}_{0}$ acts as $\dfrac{\partial}{\partial
x_{i}}=\partial_{x_{i}}$ on $F$ for every $i\geq1$. Hence,%
\[
\dfrac{\left(  \dfrac{1}{1}a_{1}\right)  ^{m_{1}}}{m_{1}!}\dfrac{\left(
\dfrac{1}{2}a_{2}\right)  ^{m_{2}}}{m_{2}!}\dfrac{\left(  \dfrac{1}{3}%
a_{3}\right)  ^{m_{3}}}{m_{3}!}...P=\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}%
!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}\dfrac{\partial_{x_{3}}^{m_{3}}%
}{m_{3}!}...P=\alpha.
\]
Consequently,%
\[
\alpha=\dfrac{\left(  \dfrac{1}{1}a_{1}\right)  ^{m_{1}}}{m_{1}!}%
\dfrac{\left(  \dfrac{1}{2}a_{2}\right)  ^{m_{2}}}{m_{2}!}\dfrac{\left(
\dfrac{1}{3}a_{3}\right)  ^{m_{3}}}{m_{3}!}...P\in U\left(  \mathcal{A}%
_{0}\right)  \cdot P.
\]
Since $\alpha\neq0$, we can divide this relation by $\alpha$, and obtain
$1\in\dfrac{1}{\alpha}\cdot U\left(  \mathcal{A}_{0}\right)  \cdot P\subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot P$, qed.}. Combined with \textbf{1)},
this yields that for every nonzero $P\in F$, the representation $F$ is
generated by $P$ as a $U\left(  \mathcal{A}_{0}\right)  $-module (since
$F=U\left(  \mathcal{A}_{0}\right)  \cdot\underbrace{1}_{\in U\left(
\mathcal{A}_{0}\right)  \cdot P}\subseteq U\left(  \mathcal{A}_{0}\right)
\cdot U\left(  \mathcal{A}_{0}\right)  \cdot P=U\left(  \mathcal{A}%
_{0}\right)  \cdot P$). Consequently, $F$ is irreducible. Proposition
\ref{prop.F.irrep} is proven.

\begin{proposition}
\label{prop.V=F}Let $V$ be an irreducible $\mathcal{A}_{0}$-module on which
$K$ acts as $1$. Assume that for any $v\in V$, the space $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \cdot v$ is finite-dimensional, and the $a_{i}$
with $i>0$ act on it by nilpotent operators. Then, $V\cong F$ as
$\mathcal{A}_{0}$-modules.
\end{proposition}

Before we prove this, a simple lemma:

\begin{lemma}
\label{lem.V=F}Let $V$ be an $\mathcal{A}_{0}$-module. Let $u\in V$ be such
that $a_{i}u=0$ for all $i>0$, and such that $Ku=u$. Then, there exists a
homomorphism $\eta:F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that
$\eta\left(  1\right)  =u$. (This homomorphism $\eta$ is unique, although we
won't need this.)
\end{lemma}

We give two proofs of this lemma. The first one is conceptual and gives us a
glimpse into the more general theory (it proceeds by constructing an
$\mathcal{A}_{0}$-module $\operatorname*{Ind}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$, which is an example
of what we will later call a Verma highest-weight module in Definition
\ref{def.verma}). The second one is down-to-earth and proceeds by direct
construction and computation.

\textit{First proof of Lemma \ref{lem.V=F}.} Define a vector subspace
$\mathcal{A}_{0}^{+}$ of $\mathcal{A}_{0}$ by $\mathcal{A}_{0}^{+}%
=\left\langle a_{i}\ \mid\ i\text{ positive integer}\right\rangle $. It is
clear that the internal direct sum $\mathbb{C}K\oplus\mathcal{A}_{0}^{+}$ is
well-defined and an abelian Lie subalgebra of $\mathcal{A}_{0}$. We can make
$\mathbb{C}$ into an $\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
$-module by setting%
\begin{align*}
K\lambda &  =\lambda\ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in
\mathbb{C};\\
a_{i}\lambda &  =0\ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in
\mathbb{C}\text{ and every positive integer }i.
\end{align*}
Now, consider the $\mathcal{A}_{0}$-module $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}=U\left(  \mathcal{A}_{0}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }\mathbb{C}$. Denote the element
$1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\in
U\left(  \mathcal{A}_{0}\right)  \otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }\mathbb{C}$ of this module by $1$.

We will now show the following important property of this module:
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{For any }\mathcal{A}_{0}\text{-module }T\text{, and any }t\in T\text{
satisfying }\left(  a_{i}t=0\text{ for all }i>0\right)  \text{ and
}Kt=t\text{,}\\
\text{there exists a homomorphism }\overline{\eta}_{T,t}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow T\text{ of }\mathcal{A}_{0}\text{-modules such that
}\overline{\eta}_{T,t}\left(  1\right)  =t
\end{array}
\right)  . \label{lem.V=F.pf.A1}%
\end{equation}
Once this is proven, we will (by considering $\overline{\eta}_{F,1}$) show
that $\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}}\mathbb{C}\cong F$, so this property will translate into the
assertion of Lemma \ref{lem.V=F}.

\textit{Proof of (\ref{lem.V=F.pf.A1}).} Let $\tau:\mathbb{C}\rightarrow T$ be
the map which sends every $\lambda\in\mathbb{C}$ to $\lambda t\in T$. Then,
$\tau$ is $\mathbb{C}$-linear and satisfies%
\[
\tau\underbrace{\left(  K\lambda\right)  }_{=\lambda}=\tau\left(
\lambda\right)  =\lambda\underbrace{t}_{=Kt}=\lambda\cdot Kt=K\cdot
\underbrace{\lambda t}_{=\tau\left(  \lambda\right)  }=K\cdot\tau\left(
\lambda\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in\mathbb{C}%
\]
and%
\begin{align*}
\tau\underbrace{\left(  a_{i}\lambda\right)  }_{=0}  &  =\tau\left(  0\right)
=0=\lambda\cdot\underbrace{0}_{=a_{i}t}=\lambda\cdot a_{i}t=a_{i}%
\cdot\underbrace{\lambda t}_{=\tau\left(  \lambda\right)  }=a_{i}\tau\left(
\lambda\right) \\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in\mathbb{C}\text{ and every
positive integer }i\text{.}%
\end{align*}
Thus, $\tau$ is a $\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
$-module map. In other words, $\tau\in\operatorname*{Hom}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}\left(  \mathbb{C},\operatorname*{Res}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}T\right)  $.

By Frobenius reciprocity, we have%
\[
\operatorname*{Hom}\nolimits_{\mathcal{A}_{0}}\left(  \operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C},T\right)  \cong\operatorname*{Hom}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}\left(  \mathbb{C},\operatorname*{Res}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}T\right)  .
\]
The preimage of $\tau\in\operatorname*{Hom}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}\left(  \mathbb{C},\operatorname*{Res}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}T\right)  $
under this isomorphism is an $\mathcal{A}_{0}$-module map $\overline{\eta
}_{T,t}:\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}\rightarrow T$ such that
\begin{align*}
\overline{\eta}_{T,t}\underbrace{\left(  1\right)  }_{=1\otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1}  &  =\overline{\eta}%
_{T,t}\left(  1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
}1\right)  =1\underbrace{\tau\left(  1\right)  }_{=1t=t}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the proof of Frobenius reciprocity}%
\right) \\
&  =1t=t.
\end{align*}
Hence, there exists a homomorphism $\overline{\eta}_{T,t}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow T$ of $\mathcal{A}_{0}$-modules such that $\overline
{\eta}_{T,t}\left(  1\right)  =t$. This proves (\ref{lem.V=F.pf.A1}).

It is easy to see that the element $1\in F$ satisfies $\left(  a_{i}1=0\text{
for all }i>0\right)  $ and $K1=1$. Thus, (\ref{lem.V=F.pf.A1}) (applied to
$T=F$ and $t=1$) yields that there exists a homomorphism $\overline{\eta
}_{F,1}:\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}\rightarrow F$ of $\mathcal{A}_{0}$-modules such
that $\overline{\eta}_{F,1}\left(  1\right)  =1$. This homomorphism
$\overline{\eta}_{F,1}$ is surjective, since
\begin{align*}
F  &  =U\left(  \mathcal{A}_{0}\right)  \cdot\underbrace{1}_{=\overline{\eta
}_{F,1}\left(  1\right)  }\ \ \ \ \ \ \ \ \ \ \left(  \text{as proven in the
proof of Proposition \ref{prop.F.irrep}}\right) \\
&  =U\left(  \mathcal{A}_{0}\right)  \cdot\overline{\eta}_{F,1}\left(
1\right)  =\overline{\eta}_{F,1}\left(  U\left(  \mathcal{A}_{0}\right)
\cdot1\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\overline{\eta}%
_{F,1}\text{ is an }\mathcal{A}_{0}\text{-module map}\right) \\
&  \subseteq\operatorname{Im}\overline{\eta}_{F,1}.
\end{align*}


Now we will prove that this homomorphism $\overline{\eta}_{F,1}$ is injective.

In the following, a map $\varphi:A\rightarrow\mathbb{N}$ (where $A$ is any
set) is said to be \textit{finitely supported} if all but finitely many $a\in
A$ satisfy $\varphi\left(  a\right)  =0$. Sequences (finite, infinite, or
two-sided infinite) are considered as maps (from finite sets, $\mathbb{N}$ or
$\mathbb{Z}$, or occasionally other sets). Thus, a sequence is finitely
supported if and only if all but finitely many of its elements are zero.

If $A$ is a set, then $\mathbb{N}_{\operatorname*{fin}}^{A}$ will denote the
set of all finitely supported maps $A\rightarrow\mathbb{N}$.

By the easy part of the Poincar\'{e}-Birkhoff-Witt theorem (this is the part
which states that the increasing monomials \textit{span} the universal
enveloping algebra), the family\footnote{Here, $\overset{\rightarrow
}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}$
denotes the product $...a_{-2}^{n_{-2}}a_{-1}^{n_{-1}}a_{1}^{n_{1}}%
a_{2}^{n_{2}}...$. (This product is infinite, but still has a value since only
finitely many $n_{i}$ are nonzero.)}%
\[
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\cdot K^{m}\right)  _{\left(  ...,n_{-2}%
,n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  },\ m\in\mathbb{N}}%
\]
is a spanning set of the vector space $U\left(  \mathcal{A}_{0}\right)  $.

Hence, the family%
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\cdot K^{m}\right)  \otimes
_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  },\ m\in\mathbb{N}}%
\]
is a spanning set of the vector space $U\left(  \mathcal{A}_{0}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }%
\mathbb{C}=\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}$.

Let us first notice that this family is redundant: Each of its elements is
contained in the smaller family%
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  }}.
\]
\footnote{This is because any sequence $\left(  ...,n_{-2},n_{-1},n_{1}%
,n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}%
\diagdown\left\{  0\right\}  }$ and any $m\in\mathbb{N}$ satisfy%
\begin{align*}
&  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\cdot K^{m}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown
\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }\underbrace{\left(  K^{m}1\right)
}_{\substack{=1\\\text{(by repeated application of }K1=1\text{)}%
}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }K^{m}\in U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  \right) \\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown
\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1.
\end{align*}
} Hence, this smaller family is also a spanning set of the vector space
$\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}$.

This smaller family is still redundant: Every of its elements corresponding to
a sequence $\left(  ...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{  0\right\}  }$
satisfying $n_{1}+n_{2}+n_{3}+...>0$ is zero\footnote{\textit{Proof.} Let
$\left(  ...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{  0\right\}  }$ be a
sequence satisfying $n_{1}+n_{2}+n_{3}+...>0$. Then, the sequence $\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  $ is finitely supported (as it is an
element of $\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{
0\right\}  }$), so that only finitely many $n_{i}$ are nonzero.
\par
There exists some positive integer $\ell$ satisfying $n_{\ell}>0$ (since
$n_{1}+n_{2}+n_{3}+...>0$). Let $j$ be the greatest such $\ell$ (this is
well-defined, since only finitely many $n_{i}$ are nonzero).
\par
Since $j$ is the greatest positive integer $\ell$ satisfying $n_{\ell}>0$, it
is clear that $j$ is the greatest integer $\ell$ satisfying $n_{\ell}>0$. In
other words, $a_{j}^{n_{j}}$ is the rightmost factor in the product
$\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}}$ which is
not equal to $1$. Thus,%
\[
\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{  0\right\}
}}a_{i}^{n_{i}}=\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  \diagdown\left\{  j\right\}  }}a_{i}^{n_{i}}%
\cdot\underbrace{a_{j}^{n_{j}}}_{\substack{=a_{j}^{n_{j}-1}a_{j}\\\text{(since
}n_{j}>0\text{)}}}=\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  \diagdown\left\{  j\right\}  }}a_{i}^{n_{i}}\cdot
a_{j}^{n_{j}-1}a_{j},
\]
so that%
\begin{align*}
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }1  &  =\left(  \overset{\rightarrow
}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{  0\right\}  \diagdown\left\{
j\right\}  }}a_{i}^{n_{i}}\cdot a_{j}^{n_{j}-1}a_{j}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\\
&  =\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  \diagdown\left\{  j\right\}  }}a_{i}^{n_{i}}\cdot a_{j}^{n_{j}%
-1}\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
}\underbrace{a_{j}1}_{\substack{=0\\\text{(since }j>0\text{, so that}%
\\a_{j}1=j\dfrac{\partial}{\partial x_{j}}1=0\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }a_{j}\in U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  \right) \\
&  =0.
\end{align*}
We have thus proven that every sequence $\left(  ...,n_{-2},n_{-1},n_{1}%
,n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}%
\diagdown\left\{  0\right\}  }$ satisfying $n_{1}+n_{2}+n_{3}+...>0$ satisfies
$\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }1=0$, qed.}, and zero elements in a spanning set
are automatically redundant. Hence, we can replace this smaller family by the
even smaller family%
\begin{align*}
&  \left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  }\text{; we do \textit{not} have
}n_{1}+n_{2}+n_{3}+...>0}\\
&  =\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  }\text{; }n_{1}=n_{2}=n_{3}=...=0}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the condition }\left(  \text{we do \textit{not} have }n_{1}%
+n_{2}+n_{3}+...>0\right) \\
\text{is equivalent to the condition }\left(  n_{1}=n_{2}=n_{3}=...=0\right)
\\
\text{(because }n_{i}\in\mathbb{N}\text{ for all }i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  \text{)}%
\end{array}
\right)  ,
\end{align*}
and we still have a spanning set of the vector space $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$.

Clearly, sequences $\left(  ...,n_{-2},n_{-1},n_{1},n_{2},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{  0\right\}  }$
satisfying $n_{1}=n_{2}=n_{3}=...=0$ are in 1-to-1 correspondence with
sequences $\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$. Hence, we can
reindex the above family as follows:
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}.
\]
So we have proven that the family%
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}%
\]
is a spanning set of the vector space $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$.
But the map $\overline{\eta}_{F,1}$ sends this family to%
\begin{align*}
&  \left(  \overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow
}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
\right)  _{\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }}\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}x_{-i}^{n_{i}}\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}%
\end{align*}
\footnote{\textit{Proof.} Let $\left(  ...,n_{-2},n_{-1}\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$ be
arbitrary. Then,%
\begin{align*}
&  \overline{\eta}_{F,1}\left(  \underbrace{\left(  \overset{\rightarrow
}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1}_{=\left(
\overset{\rightarrow}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}%
a_{i}^{n_{i}}\right)  \left(  1\otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }1\right)  }\right) \\
&  =\overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow}{\prod
\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \left(
1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
\right) \\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \overline{\eta}_{F,1}%
\underbrace{\left(  1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}%
^{+}\right)  }1\right)  }_{=1}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\overline{\eta}_{F,1}\text{ is an }\mathcal{A}_{0}\text{-module map}\right)
\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \underbrace{\overline{\eta
}_{F,1}\left(  1\right)  }_{=1}=\left(  \overset{\rightarrow}{\prod
\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  1=\left(
\overset{\rightarrow}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }%
}x_{-i}^{n_{i}}\right)  1\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{because each }a_{i}\text{ with negative
}i\text{ acts on }F\text{ by multiplication with }x_{-i}\right) \\
&  =\overset{\rightarrow}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }%
}x_{-i}^{n_{i}}=\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }%
x_{-i}^{n_{i}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }F\text{ is
commutative}\right)  .
\end{align*}
Now forget that we fixed $\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$. We thus have shown
that every $\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$ satisfies
$\overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow}{\prod
\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
=\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }x_{-i}^{n_{i}}$. Thus,%
\begin{align*}
&  \left(  \overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow
}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
\right)  _{\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }}\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}x_{-i}^{n_{i}}\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }},
\end{align*}
qed.}. Since the family $\left(  \overset{\rightarrow}{\prod\limits_{i\in
\left\{  ...,-3,-2,-1\right\}  }}x_{-i}^{n_{i}}\right)  _{\left(
...,n_{-2},n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}$ is a basis of the vector space $F$ (in fact, this
family consists of all monomials of the polynomial ring $\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  =F$), we thus conclude that $\overline{\eta
}_{F,1}$ sends a spanning family of the vector space $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$
to a basis of the vector space $F$. Thus, $\overline{\eta}_{F,1}$ must be
injective\footnote{Here we are using the following trivial fact from linear
algebra: If a linear map $\varphi:V\rightarrow W$ sends a spanning family of
the vector space $V$ to a basis of the vector space $W$ (as families, not just
as sets), then this map $\varphi$ must be injective.}.

Altogether, we now know that $\overline{\eta}_{F,1}$ is a surjective and
injective $\mathcal{A}_{0}$-module map. Thus, $\overline{\eta}_{F,1}$ is an
isomorphism of $\mathcal{A}_{0}$-modules.

Now, apply (\ref{lem.V=F.pf.A1}) to $T=V$ and $t=u$. This yields that there
exists a homomorphism $\overline{\eta}_{V,u}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow V$ of $\mathcal{A}_{0}$-modules such that $\overline
{\eta}_{V,u}\left(  1\right)  =u$.

Now, the composition $\overline{\eta}_{V,u}\circ\overline{\eta}_{F,1}^{-1}$ is
a homomorphism $F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that
\[
\left(  \overline{\eta}_{V,u}\circ\overline{\eta}_{F,1}^{-1}\right)  \left(
1\right)  =\overline{\eta}_{V,u}\underbrace{\left(  \overline{\eta}_{F,1}%
^{-1}\left(  1\right)  \right)  }_{\substack{=1\\\text{(since }\overline{\eta
}_{F,1}\left(  1\right)  =1\text{)}}}=\overline{\eta}_{V,u}\left(  1\right)
=u.
\]
Thus, there exists a homomorphism $\eta:F\rightarrow V$ of $\mathcal{A}_{0}%
$-modules such that $\eta\left(  1\right)  =u$ (namely, $\eta=\overline{\eta
}_{V,u}\circ\overline{\eta}_{F,1}^{-1}$). This proves Lemma \ref{lem.V=F}.

\textit{Second proof of Lemma \ref{lem.V=F}.} Let $\eta$ be the map
$F\rightarrow V$ which sends every polynomial $P\in F=\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  $ to $P\left(  a_{-1},a_{-2},a_{-3},...\right)
\cdot u\in V$.\ \ \ \ \footnote{Note that the term $P\left(  a_{-1}%
,a_{-2},a_{-3},...\right)  $ denotes the evaluation of the polynomial $P$ at
$\left(  x_{1},x_{2},x_{3},...\right)  =\left(  a_{-1},a_{-2},a_{-3}%
,...\right)  $. This evaluation is a well-defined element of $U\left(
\mathcal{A}_{0}\right)  $, since the elements $a_{-1}$, $a_{-2}$, $a_{-3}$,
$...$ of $U\left(  \mathcal{A}_{0}\right)  $ commute.} This map $\eta$ is
clearly $\mathbb{C}$-linear, and satisfies $\eta\left(  F\right)  \subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot u$. In order to prove that $\eta$ is an
$\mathcal{A}_{0}$-module homomorphism, we must prove that
\begin{equation}
\eta\left(  a_{i}P\right)  =a_{i}\eta\left(  P\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }i\in\mathbb{Z}\diagdown\left\{
0\right\}  \text{ and }P\in F \label{lem.V=F.pf.1}%
\end{equation}
and that%
\begin{equation}
\eta\left(  KP\right)  =K\eta\left(  P\right)  \ \ \ \ \ \ \ \ \ \ \text{for
every }P\in F. \label{lem.V=F.pf.2}%
\end{equation}


First we show that%
\begin{equation}
Kv=v\ \ \ \ \ \ \ \ \ \ \text{for every }v\in U\left(  \mathcal{A}_{0}\right)
\cdot u. \label{lem.V=F.pf.3}%
\end{equation}


\textit{Proof of (\ref{lem.V=F.pf.3}).} Since $K$ lies in the center of the
Lie algebra $\mathcal{A}_{0}$, it is clear that $K$ lies in the center of the
universal enveloping algebra $U\left(  \mathcal{A}_{0}\right)  $. Thus,
$Kx=xK$ for every $x\in U\left(  \mathcal{A}_{0}\right)  $.

Now let $v\in U\left(  \mathcal{A}_{0}\right)  \cdot u$. Then, there exists
some $x\in U\left(  \mathcal{A}_{0}\right)  $ such that $v=xu$. Thus,
$Kv=Kxu=x\underbrace{Ku}_{=u}=xu=v$. This proves (\ref{lem.V=F.pf.3}).

\textit{Proof of (\ref{lem.V=F.pf.2}).} Since $K$ acts as the identity on $F$,
we have $KP=P$ for every $P\in F$. Thus, for every $P\in F$, we have%
\[
\eta\left(  KP\right)  =\eta\left(  P\right)  =K\eta\left(  P\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since (\ref{lem.V=F.pf.3}) (applied to }v=\eta\left(  P\right)  \text{)
yields }K\eta\left(  P\right)  =\eta\left(  P\right) \\
\text{(because }\eta\left(  P\right)  \in\eta\left(  F\right)  \subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot u\text{)}%
\end{array}
\right)  .
\]
This proves (\ref{lem.V=F.pf.2}).

\textit{Proof of (\ref{lem.V=F.pf.1}).} Let $i\in\mathbb{Z}\diagdown\left\{
0\right\}  $. If $i<0$, then (\ref{lem.V=F.pf.1}) is pretty much obvious
(because in this case, $a_{i}$ acts as $x_{-i}$ on $F$, so that $a_{i}%
P=x_{-i}P$ and thus%
\[
\eta\left(  a_{i}P\right)  =\eta\left(  x_{-i}P\right)  =\left(
x_{-i}P\right)  \left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u=a_{i}%
\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u}_{=\eta\left(
P\right)  }=a_{i}\eta\left(  P\right)
\]
for every $P\in F$). Hence, from now on, we can WLOG assume that $i$ is not
$<0$. Assume this. Then, $i\geq0$, so that $i>0$ (since $i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  $).

In order to prove the equality (\ref{lem.V=F.pf.1}) for all $P\in F$, it is
enough to prove it for the case when $P$ is a monomial of the form
$x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{m}}$ for some $m\in\mathbb{N}$ and some
$\left(  \ell_{1},\ell_{2},...,\ell_{m}\right)  \in\left\{  1,2,3,...\right\}
^{m}$.\ \ \ \ \footnote{This is because such monomials generate $F$ as a
$\mathbb{C}$-vector space, and because the equality (\ref{lem.V=F.pf.1}) is
linear in $P$.} In other words, in order to prove the equality
(\ref{lem.V=F.pf.1}), it is enough to prove that%
\begin{equation}
\eta\left(  a_{i}\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{m}}\right)
\right)  =a_{i}\eta\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{m}}\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }m\in\mathbb{N}\text{ and every }\left(
\ell_{1},\ell_{2},...,\ell_{m}\right)  \in\left\{  1,2,3,...\right\}  ^{m}.
\label{lem.V=F.pf.4}%
\end{equation}


Thus, let us now prove (\ref{lem.V=F.pf.4}). In fact, we are going to prove
(\ref{lem.V=F.pf.4}) by induction over $m$. The induction base is very easy
(using $a_{i}1=i\dfrac{\partial}{\partial x_{i}}1=0$ and $a_{i}u=0$) and thus
left to the reader. For the induction step, fix some positive $M\in\mathbb{N}%
$, and assume that (\ref{lem.V=F.pf.4}) is already proven for $m=M-1$. Our
task is now to prove (\ref{lem.V=F.pf.4}) for $m=M$.

So let $\left(  \ell_{1},\ell_{2},...,\ell_{M}\right)  \in\left\{
1,2,3,...\right\}  ^{M}$ be arbitrary. Denote by $Q$ the polynomial
$x_{\ell_{2}}x_{\ell_{3}}...x_{\ell_{M}}$. Then, $x_{\ell_{1}}Q=x_{\ell_{1}%
}x_{\ell_{2}}x_{\ell_{3}}...x_{\ell_{M}}=x_{\ell_{1}}x_{\ell_{2}}%
...x_{\ell_{M}}$.

Since (\ref{lem.V=F.pf.4}) is already proven for $m=M-1$, we can apply
(\ref{lem.V=F.pf.4}) to $M-1$ and $\left(  \ell_{2},\ell_{3},...,\ell
_{M}\right)  $ instead of $m$ and $\left(  \ell_{1},\ell_{2},...,\ell
_{m}\right)  $. We obtain $\eta\left(  a_{i}\left(  x_{\ell_{2}}x_{\ell_{3}%
}...x_{\ell_{M}}\right)  \right)  =a_{i}\eta$ $\left(  x_{\ell_{2}}x_{\ell
_{3}}...x_{\ell_{M}}\right)  $. Since $x_{\ell_{2}}x_{\ell_{3}}...x_{\ell_{M}%
}=Q$, this rewrites as $\eta\left(  a_{i}Q\right)  =a_{i}\eta\left(  Q\right)
$.

Since any $x\in\mathcal{A}_{0}$ and $y\in\mathcal{A}_{0}$ satisfy
$xy=yx+\left[  x,y\right]  $ (by the definition of $U\left(  \mathcal{A}%
_{0}\right)  $), we have%
\[
a_{i}a_{-\ell_{1}}=a_{-\ell_{1}}a_{i}+\underbrace{\left[  a_{i},a_{-\ell_{1}%
}\right]  }_{=i\delta_{i,-\left(  -\ell_{1}\right)  }K}=a_{-\ell_{1}}%
a_{i}+i\underbrace{\delta_{i,-\left(  -\ell_{1}\right)  }}_{=\delta
_{i,\ell_{1}}}K=a_{-\ell_{1}}a_{i}+i\delta_{i,\ell_{1}}K.
\]


On the other hand, by the definition of $\eta$, every $P\in F$ satisfies the
two equalities $\eta\left(  P\right)  =P\left(  a_{-1},a_{-2},a_{-3}%
,...\right)  \cdot u$ and%
\begin{align}
\eta\left(  x_{\ell_{1}}P\right)   &  =\underbrace{\left(  x_{\ell_{1}%
}P\right)  \left(  a_{-1},a_{-2},a_{-3},...\right)  }_{=a_{-\ell_{1}}\cdot
P\left(  a_{-1},a_{-2},a_{-3},...\right)  }\cdot u=a_{-\ell_{1}}%
\cdot\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u}%
_{=\eta\left(  P\right)  }\nonumber\\
&  =a_{-\ell_{1}}\cdot\eta\left(  P\right)  . \label{lem.V=F.pf.5}%
\end{align}


Since $a_{i}$ acts on $F$ as $i\dfrac{\partial}{\partial x_{i}}$, we have
$a_{i}\left(  x_{\ell_{1}}Q\right)  =i\dfrac{\partial}{\partial x_{i}}\left(
x_{\ell_{1}}Q\right)  $ and $a_{i}Q=i\dfrac{\partial}{\partial x_{i}}Q$. Now,%
\begin{align*}
a_{i}\left(  \underbrace{x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}}}%
_{=x_{\ell_{1}}Q}\right)   &  =a_{i}\left(  x_{\ell_{1}}Q\right)
=i\dfrac{\partial}{\partial x_{i}}\left(  x_{\ell_{1}}Q\right)  =i\left(
\left(  \dfrac{\partial}{\partial x_{i}}x_{\ell_{1}}\right)  Q+x_{\ell_{1}%
}\left(  \dfrac{\partial}{\partial x_{i}}Q\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the Leibniz rule}\right) \\
&  =i\underbrace{\left(  \dfrac{\partial}{\partial x_{i}}x_{\ell_{1}}\right)
}_{=\delta_{i,\ell_{1}}}Q+x_{\ell_{1}}\cdot\underbrace{i\dfrac{\partial
}{\partial x_{i}}Q}_{=a_{i}Q}=i\delta_{i,\ell_{1}}Q+x_{\ell_{1}}\cdot
a_{i}Q=x_{\ell_{1}}\cdot a_{i}Q+i\delta_{i,\ell_{1}}Q,
\end{align*}
so that%
\begin{align*}
\eta\left(  a_{i}\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}}\right)
\right)   &  =\eta\left(  x_{\ell_{1}}\cdot a_{i}Q+i\delta_{i,\ell_{1}%
}Q\right)  =\underbrace{\eta\left(  x_{\ell_{1}}\cdot a_{i}Q\right)
}_{\substack{=a_{-\ell_{1}}\cdot\eta\left(  a_{i}Q\right)  \\\text{(by
(\ref{lem.V=F.pf.5}), applied to }P=a_{i}Q\text{)}}}+i\delta_{i,\ell_{1}}%
\eta\left(  Q\right) \\
&  =a_{-\ell_{1}}\cdot\underbrace{\eta\left(  a_{i}Q\right)  }_{=a_{i}%
\eta\left(  Q\right)  }+i\delta_{i,\ell_{1}}\eta\left(  Q\right)
=a_{-\ell_{1}}\cdot a_{i}\eta\left(  Q\right)  +i\delta_{i,\ell_{1}}%
\eta\left(  Q\right)  .
\end{align*}
Compared to%
\begin{align*}
a_{i}\eta\left(  \underbrace{x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}}%
}_{=x_{\ell_{1}}Q}\right)   &  =a_{i}\underbrace{\eta\left(  x_{\ell_{1}%
}Q\right)  }_{\substack{=a_{-\ell_{1}}\cdot\eta\left(  Q\right)  \\\text{(by
(\ref{lem.V=F.pf.5}), applied to }P=Q\text{)}}}=\underbrace{a_{i}a_{-\ell_{1}%
}}_{=a_{-\ell_{1}}a_{i}+i\delta_{i,\ell_{1}}K}\cdot\eta\left(  Q\right) \\
&  =\left(  a_{-\ell_{1}}a_{i}+i\delta_{i,\ell_{1}}K\right)  \cdot\eta\left(
Q\right)  =a_{-\ell_{1}}\cdot a_{i}\eta\left(  Q\right)  +i\delta_{i,\ell_{1}%
}\underbrace{K\eta\left(  Q\right)  }_{\substack{=\eta\left(  Q\right)
\\\text{(by (\ref{lem.V=F.pf.3}), applied to }v=\eta\left(  Q\right)
\\\text{(since }\eta\left(  Q\right)  \in\eta\left(  F\right)  \subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot u\text{))}}}\\
&  =a_{-\ell_{1}}\cdot a_{i}\eta\left(  Q\right)  +i\delta_{i,\ell_{1}}%
\eta\left(  Q\right)  ,
\end{align*}
this yields $\eta\left(  a_{i}\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}%
}\right)  \right)  =a_{i}\eta\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}%
}\right)  $. Since we have proven this for every $\left(  \ell_{1},\ell
_{2},...,\ell_{M}\right)  \in\left\{  1,2,3,...\right\}  ^{M}$, we have thus
proven (\ref{lem.V=F.pf.4}) for $m=M$. This completes the induction step, and
thus the induction proof of (\ref{lem.V=F.pf.4}) is complete. As we have seen
above, this proves (\ref{lem.V=F.pf.1}).

From (\ref{lem.V=F.pf.1}) and (\ref{lem.V=F.pf.2}), it is clear that $\eta$ is
$\mathcal{A}_{0}$-linear (since $\mathcal{A}_{0}$ is spanned by the $a_{i}$
for $i\in\mathbb{Z}\diagdown\left\{  0\right\}  $ and $K$). Since $\eta\left(
1\right)  =u$ is obvious, this proves Lemma \ref{lem.V=F}.

\textit{Proof of Proposition \ref{prop.V=F}.} Pick some nonzero vector $v\in
V$. Let $W=\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \cdot v$. Then, by
the condition, we have $\dim W<\infty$, and $a_{i}:W\rightarrow W$ are
commuting nilpotent operators\footnote{Of course, when we write $a_{i}%
:W\rightarrow W$, we don't mean the elements $a_{i}$ of $\mathcal{A}_{0}$
themselves, but their actions on $W$.}. Hence, $\bigcap\limits_{i\geq
1}\operatorname*{Ker}a_{i}\neq0\ \ \ \ $\footnote{Here, we are using the
following linear-algebraic fact:
\par
If $T$ is a nonzero finite-dimensional vector space over an algebraically
closed field, and if $b_{1}$, $b_{2}$, $b_{3}$, $...$ are commuting linear
maps $T\rightarrow T$, then there exists a nonzero common eigenvector of
$b_{1}$, $b_{2}$, $b_{3}$, $...$. If $b_{1}$, $b_{2}$, $b_{3}$, $...$ are
nilpotent, this yields $\bigcap\limits_{i\geq1}\operatorname*{Ker}b_{i}\neq0$
(since any eigenvector of a nilpotent map must lie in its kernel).}. Hence,
there exists some nonzero $u\in\bigcap\limits_{i\geq1}\operatorname*{Ker}%
a_{i}$. Pick such a $u$. Then, $a_{i}u=0$ for all $i>0$, and $Ku=u$ (since $K$
acts as $1$ on $V$). Thus, there exists a homomorphism $\eta:F\rightarrow V$
of $\mathcal{A}_{0}$-modules such that $\eta\left(  1\right)  =u$ (by Lemma
\ref{lem.V=F}). Since both $F$ and $V$ are irreducible and $\eta\neq0$, this
yields that $\eta$ is an isomorphism. This proves Proposition \ref{prop.V=F}.

\subsubsection{Classification of
\texorpdfstring{$\mathcal{A}_{0}$}{A0}-modules with locally nilpotent action
of
\texorpdfstring{$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $}{C[a1,a2,a3,...]}}%


\begin{proposition}
\label{prop.V=F(X)U}Let $V$ be any $\mathcal{A}_{0}$-module having a locally
nilpotent action of $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $. (Here,
we say that the $\mathcal{A}_{0}$-module $V$ has a \textit{locally nilpotent
action of$\mathbb{\ }$}$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ if
for any $v\in V$, the space $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]
\cdot v$ is finite-dimensional, and the $a_{i}$ with $i>0$ act on it by
nilpotent operators.) Assume that $K$ acts as $1$ on $V$. Assume that for
every $v\in V$, there exists some $N\in\mathbb{N}$ such that for every $n\geq
N$, we have $a_{n}v=0$. Then, $V\cong F\otimes U$ as $\mathcal{A}_{0}$-modules
for some vector space $U$. (The vector space $U$ is not supposed to carry any
$\mathcal{A}_{0}$-module structure.)
\end{proposition}

\begin{remark}
From Proposition \ref{prop.V=F(X)U}, we cannot remove the condition that for
every $v\in V$, there exists some $N\in\mathbb{N}$ such that for every $n\geq
N$, we have $a_{n}v=0$. In fact, here is a counterexample of how Proposition
\ref{prop.V=F(X)U} can fail without this condition:

Let $V$ be the representation $\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]
\left[  y\right]  \diagup\left(  y^{2}\right)  $ of $\mathcal{A}_{0}$ given
by
\begin{align*}
a_{-i}  &  \mapsto x_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1;\\
a_{i}  &  \mapsto i\dfrac{\partial}{\partial x_{i}}%
+y\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1,\\
K  &  \mapsto1
\end{align*}
(where we are being sloppy and abbreviating the residue class $\overline{y}%
\in\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  \left[  y\right]
\diagup\left(  y^{2}\right)  $ by $y$, and similarly all other residue
classes). We have an exact sequence%
\[%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%0 \ar[r] & F \ar[r]^i & V \ar[r]^{\pi} & F \ar[r] & 0
%}}}%
%BeginExpansion
\xymatrix{
0 \ar[r] & F \ar[r]^i & V \ar[r]^{\pi} & F \ar[r] & 0
}%
%EndExpansion
\]
of $\mathcal{A}_{0}$-modules, where the map $i:F\rightarrow V$ is given by%
\[
i\left(  P\right)  =yP\ \ \ \ \ \ \ \ \ \ \text{for every }p\in F=\mathbb{C}%
\left[  x_{1},x_{2},x_{3},...\right]  ,
\]
and the map $\pi:V\rightarrow F$ is the canonical projection $V\rightarrow
V\diagup\left(  y\right)  \cong F$. Thus, $V$ is an extension of $F$ by $F$.
It is easily seen that $V$ has a locally nilpotent action of$\ \mathbb{C}%
\left[  a_{1},a_{2},a_{3},...\right]  $. But $V$ is not isomorphic to
$F\otimes U$ as $\mathcal{A}_{0}$-modules for any vector space $U$, since
there is a vector $v\in V$ satisfying $V=U\left(  \mathcal{A}_{0}\right)
\cdot v$ (for example, $v=1$), whereas there is no vector $v\in F\otimes U$
satisfying $F\otimes U=U\left(  \mathcal{A}_{0}\right)  \cdot v$ if $\dim
U>1$, and the case $\dim U\leq1$ is easily ruled out (in this case, $\dim U$
would have to be $1$, so that $V$ would be $\cong F$ and thus irreducible, and
thus the homomorphisms $i$ and $\pi$ would have to be isomorphisms, which is absurd).
\end{remark}

Before we prove Proposition \ref{prop.V=F(X)U}, we need to define the notion
of complete coflags:

\begin{definition}
Let $k$ be a field. Let $V$ be a $k$-vector space. Let $W$ be a vector
subspace of $V$. Assume that $\dim\left(  V\diagup W\right)  <\infty$. Then, a
\textbf{complete coflag from }$V$ \textbf{to }$W$ will mean a sequence
$\left(  V_{0},V_{1},...,V_{N}\right)  $ of vector subspaces of $V$ (with $N$
being an integer) satisfying the following conditions:

- We have $V_{0}\supseteq V_{1}\supseteq...\supseteq V_{N}$.

- Every $i\in\left\{  0,1,...,N\right\}  $ satisfies $\dim\left(  V\diagup
V_{i}\right)  =i$.

- We have $V_{0}=V$ and $V_{N}=W$.

(Note that the condition $V_{0}=V$ is superfluous (since it follows from the
condition that every $i\in\left\{  0,1,...,N\right\}  $ satisfies $\dim\left(
V\diagup V_{i}\right)  =i$), but has been given for the sake of intuition.)

We will also denote the complete coflag $\left(  V_{0},V_{1},...,V_{N}\right)
$ by $V=V_{0}\supseteq V_{1}\supseteq...\supseteq V_{N}=W$.
\end{definition}

It is clear that if $k$ is a field, $V$ is a $k$-vector space, and $W$ is a
vector subspace of $V$ satisfying $\dim\left(  V\diagup W\right)  <\infty$,
then a complete coflag from $V$ to $W$ exists.\footnote{In fact, it is known
that the finite-dimensional vector space $V\diagup W$ has a complete flag
$\left(  F_{0},F_{1},...,F_{N}\right)  $; now, if we let $p$ be the canonical
projection $V\rightarrow V\diagup W$, then $\left(  p^{-1}\left(
F_{N}\right)  ,p^{-1}\left(  F_{N-1}\right)  ,...,p^{-1}\left(  F_{0}\right)
\right)  $ is easily seen to be a complete coflag from $V$ to $W$.}

\begin{definition}
Let $k$ be a field. Let $V$ be a $k$-algebra. Let $W$ be a vector subspace of
$V$. Let $\mathfrak{i}$ be an ideal of $V$. Then, an $\mathfrak{i}%
$\textbf{-coflag from }$V$\textbf{ to }$W$ means a complete coflag $\left(
V_{0},V_{1},...,V_{N}\right)  $ from $V$ to $W$ such that
\[
\text{every }i\in\left\{  0,1,...,N-1\right\}  \text{ satisfies }%
\mathfrak{i}\cdot V_{i}\subseteq V_{i+1}.
\]

\end{definition}

\begin{lemma}
\label{lem.V=F(X)U.coflags}Let $k$ be a field. Let $B$ be a commutative
$k$-algebra. Let $I$ be an ideal of $B$ such that the $k$-vector space
$B\diagup I$ is finite-dimensional. Let $\mathfrak{i}$ be an ideal of $B$. Let
$M\in\mathbb{N}$. Then, there exists an $\mathfrak{i}$-coflag from $B$ to
$\mathfrak{i}^{M}+I$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.V=F(X)U.coflags}.} We will prove Lemma
\ref{lem.V=F(X)U.coflags} by induction over $M$:

\textit{Induction base:} Lemma \ref{lem.V=F(X)U.coflags} is trivial in the
case when $M=0$, because $\underbrace{\mathfrak{i}^{0}}_{=B}+I=B+I=B$. This
completes the induction base.

\textit{Induction base:} Let $m\in\mathbb{N}$. Assume that Lemma
\ref{lem.V=F(X)U.coflags} is proven in the case when $M=m$. We now must prove
Lemma \ref{lem.V=F(X)U.coflags} in the case when $M=m+1$.

Since Lemma \ref{lem.V=F(X)U.coflags} is proven in the case when $M=m$, there
exists an $\mathfrak{i}$-coflag $\left(  J_{0},J_{1},...,J_{K}\right)  $ from
$B$ to $\mathfrak{i}^{m}+I$. This $\mathfrak{i}$-coflag clearly is a complete
coflag from $B$ to $\mathfrak{i}^{m}+I$.

Since
\begin{align*}
\dim\left(  \left(  \mathfrak{i}^{m}+I\right)  \diagup\left(  \mathfrak{i}%
^{m+1}+I\right)  \right)   &  \leq\dim\left(  B\diagup\left(  \mathfrak{i}%
^{m+1}+I\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{because }\left(  \mathfrak{i}%
^{m}+I\right)  \diagup\left(  \mathfrak{i}^{m+1}+I\right)  \text{ injects into
}B\diagup\left(  \mathfrak{i}^{m+1}+I\right)  \right) \\
&  \leq\dim\left(  B\diagup I\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}B\diagup\left(  \mathfrak{i}^{m+1}+I\right)  \text{ is a quotient of
}B\diagup I\right) \\
&  <\infty\ \ \ \ \ \ \ \ \ \ \left(  \text{since }B\diagup I\text{ is
finite-dimensional}\right)  ,
\end{align*}
there exists a complete coflag $\left(  U_{0},U_{1},...,U_{P}\right)  $ from
$\mathfrak{i}^{m}+I$ to $\mathfrak{i}^{m+1}+I$.

Since $\left(  U_{0},U_{1},...,U_{P}\right)  $ is a complete coflag from
$\mathfrak{i}^{m}+I$ to $\mathfrak{i}^{m+1}+I$, we have $U_{0}=\mathfrak{i}%
^{m}+I$, and each of the vector spaces $U_{0}$, $U_{1}$, $...$, $U_{P}$
contains $\mathfrak{i}^{m+1}+I$ as a subspace.

Also, every $i\in\left\{  0,1,...,P\right\}  $ satisfies $U_{i}\subseteq
\mathfrak{i}^{m}+I$ (again since $\left(  U_{0},U_{1},...,U_{P}\right)  $ is a
complete coflag from $\mathfrak{i}^{m}+I$ to $\mathfrak{i}^{m+1}+I$).

Since $\left(  J_{0},J_{1},...,J_{K}\right)  $ is a complete coflag from $B$
to $\mathfrak{i}^{m}+I$, while $\left(  U_{0},U_{1},...,U_{P}\right)  $ is a
complete coflag from $\mathfrak{i}^{m}+I$ to $\mathfrak{i}^{m+1}+I$, it is
clear that
\[
\left(  J_{0},J_{1},...,J_{K},U_{1},U_{2},...,U_{P}\right)  =\left(
J_{0},J_{1},...,J_{K-1},U_{0},U_{1},...,U_{P}\right)
\]
is a complete coflag from $B$ to $\mathfrak{i}^{m+1}+I$. We now will prove
that this complete coflag
\[
\left(  J_{0},J_{1},...,J_{K},U_{1},U_{2},...,U_{P}\right)  =\left(
J_{0},J_{1},...,J_{K-1},U_{0},U_{1},...,U_{P}\right)
\]
actually is an $\mathfrak{i}$-coflag.

In order to prove this, we must show the following two assertions:

\textit{Assertion 1:} Every $i\in\left\{  0,1,...,K-1\right\}  $ satisfies
$\mathfrak{i}\cdot J_{i}\subseteq J_{i+1}$.

\textit{Assertion 2:} Every $i\in\left\{  0,1,...,P-1\right\}  $ satisfies
$\mathfrak{i}\cdot U_{i}\subseteq U_{i+1}$.

Assertion 1 follows directly from the fact that $\left(  J_{0},J_{1}%
,...,J_{K}\right)  $ is an $\mathfrak{i}$-coflag.

Assertion 2 follows from the fact that $\mathfrak{i}\cdot\underbrace{U_{i}%
}_{\subseteq\mathfrak{i}^{m}+I}\subseteq\mathfrak{i}\cdot\left(
\mathfrak{i}^{m}+I\right)  \subseteq\underbrace{\mathfrak{i}\cdot
\mathfrak{i}^{m}}_{=\mathfrak{i}^{m+1}}+\underbrace{\mathfrak{i}\cdot
I}_{\substack{\subseteq I\\\text{(since }I\text{ is an ideal)}}}\subseteq
\mathfrak{i}^{m+1}+I\subseteq U_{i+1}$ (because we know that each of the
vector spaces $U_{0}$, $U_{1}$, $...$, $U_{P}$ contains $\mathfrak{i}^{m+1}+I$
as a subspace, so that (in particular) $\mathfrak{i}^{m+1}+I\subseteq U_{i+1}$).

Hence, both Assertions 1 and 2 are proven, and we conclude that
\[
\left(  J_{0},J_{1},...,J_{K},U_{1},U_{2},...,U_{P}\right)  =\left(
J_{0},J_{1},...,J_{K-1},U_{0},U_{1},...,U_{P}\right)
\]
is an $\mathfrak{i}$-coflag. This is clearly an $\mathfrak{i}$-coflag from $B$
to $\mathfrak{i}^{m+1}+I$. Thus, there exists an $\mathfrak{i}$-coflag from
$B$ to $\mathfrak{i}^{m+1}+I$. This proves Lemma \ref{lem.V=F(X)U.coflags} in
the case when $M=m+1$. The induction step is complete, and with it the proof
of Lemma \ref{lem.V=F(X)U.coflags}.

\textit{Proof of Proposition \ref{prop.V=F(X)U}.} Let $v\in V$ be arbitrary.
Let $I_{v}\subseteq\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ be the
annihilator of $v$. Then, the canonical $\mathbb{C}$-algebra map
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \rightarrow
\operatorname*{End}\left(  \mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]
\cdot v\right)  $ (this map comes from the action of the $\mathbb{C}$-algebra
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ on $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \cdot v$) gives rise to an \textit{injective}
map $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}%
\rightarrow\operatorname*{End}\left(  \mathbb{C}\left[  a_{1},a_{2}%
,a_{3},...\right]  \cdot v\right)  $. Since this map is injective, we have
$\dim\left(  \mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup
I_{v}\right)  \leq\dim\left(  \operatorname*{End}\left(  \mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \cdot v\right)  \right)  <\infty$ (since
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \cdot v$ is
finite-dimensional). In other words, the vector space $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$ is finite-dimensional.

Let $W$ be the $\mathcal{A}_{0}$-submodule of $V$ generated by $v$. In other
words, let $W=U\left(  \mathcal{A}_{0}\right)  \cdot v$. Then, $W$ is a
quotient of $U\left(  \mathcal{A}_{0}\right)  $ (as an $\mathcal{A}_{0}%
$-module). Since $K$ acts as $1$ on $W$, it follows that $W$ is a quotient of
$U\left(  \mathcal{A}_{0}\right)  \diagup\left(  K-1\right)  \cong D\left(
x_{1},x_{2},x_{3},...\right)  $. Since $I_{v}$ annihilates $v$, it follows
that $W$ is a quotient of $D\left(  x_{1},x_{2},...\right)  \diagup\left(
D\left(  x_{1},x_{2},...\right)  I_{v}\right)  $. Let us denote the
$\mathcal{A}_{0}$-module $D\left(  x_{1},x_{2},...\right)  \diagup\left(
D\left(  x_{1},x_{2},...\right)  I_{v}\right)  $ by $\widetilde{W}$.

We now will prove that $\widetilde{W}$ is a finite-length $\mathcal{A}_{0}%
$-module with all composition factors isomorphic to $F$.\ \ \ \ \footnote{We
can even prove that there are exactly $\dim\left(  \mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \diagup I_{v}\right)  $ composition factors.}

Let $\mathfrak{i}$ be the ideal $\left(  a_{1},a_{2},a_{3},...\right)  $ of
the commutative algebra $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $.

Since $I_{v}$ is an ideal of the commutative algebra $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  $, the quotient $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  \diagup I_{v}$ is an algebra. For every
$q\in\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $, let $\overline{q}$ be
the projection of $q$ onto the quotient algebra $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  \diagup I_{v}$. Let also $\overline{\mathfrak{i}}$ be
the projection of the ideal $\mathfrak{i}$ onto the quotient algebra
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$. Clearly,
$\overline{\mathfrak{i}}=\left(  \overline{a_{1}},\overline{a_{2}}%
,\overline{a_{3}},...\right)  $.

For every $j>0$, there exists some $i\in\mathbb{N}$ such that $a_{j}^{i}v=0$
(since $V$ has a locally nilpotent action of $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  $). Hence, for every $j>0$, the element
$\overline{a_{j}}$ of $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup
I_{v}$ is nilpotent (because there exists some $i\in\mathbb{N}$ such that
$a_{j}^{i}v=0$, and thus this $i$ satisfies $a_{j}^{i}\in I_{v}$, so that
$\overline{a_{j}}^{i}=0$). Hence, the ideal $\overline{\mathfrak{i}}$ is
generated by nilpotent generators (since $\overline{\mathfrak{i}}=\left(
\overline{a_{1}},\overline{a_{2}},\overline{a_{3}},...\right)  $). Since we
also know that $\overline{\mathfrak{i}}$ is finitely generated (since
$\overline{\mathfrak{i}}$ is an ideal of the finite-dimensional algebra
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$), it follows
that $\overline{\mathfrak{i}}$ is generated by \textit{finitely many}
nilpotent generators. But if an ideal of a commutative ring is generated by
finitely many nilpotent generators, it must be nilpotent. Thus, $\overline
{\mathfrak{i}}$ is nilpotent. In other words, there exists some $M\in
\mathbb{N}$ such that $\overline{\mathfrak{i}}^{M}=0$. Consider this $M$.
Since $\overline{\mathfrak{i}}^{M}=0$, we have $\mathfrak{i}^{M}\subseteq
I_{v}$ and thus $\mathfrak{i}^{M}+I_{v}=I_{v}$.

Now, Lemma \ref{lem.V=F(X)U.coflags} (applied to $k=\mathbb{C}$,
$B=\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ and $I=I_{v}$) yields
that there exists an $\mathfrak{i}$-coflag from $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  $ to $\mathfrak{i}^{M}+I_{v}$. Denote this
$\mathfrak{i}$-coflag by $\left(  J_{0},J_{1},...,J_{N}\right)  $. Since
$\mathfrak{i}^{M}+I_{v}=I_{v}$, this $\mathfrak{i}$-coflag $\left(
J_{0},J_{1},...,J_{N}\right)  $ thus is an $\mathfrak{i}$-coflag from
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ to $I_{v}$. Thus, $\left(
J_{0},J_{1},...,J_{N}\right)  $ is a complete coflag from $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  $ to $I_{v}$. In other words:

\begin{itemize}
\item We have $J_{0}\supseteq J_{1}\supseteq...\supseteq J_{N}$.

\item Every $i\in\left\{  0,1,...,N\right\}  $ satisfies $\dim\left(
\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup J_{i}\right)  =i$.

\item We have $J_{0}=\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ and
$J_{N}=I_{v}$.
\end{itemize}

Besides, since $\left(  J_{0},J_{1},...,J_{N}\right)  $ is an $\mathfrak{i}%
$-coflag, we have%
\begin{equation}
\mathfrak{i}\cdot J_{i}\subseteq J_{i+1}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\left\{  0,1,...,N-1\right\}  . \label{prop.V=F(X)U.pf.2}%
\end{equation}


For every $i\in\left\{  0,1,...,N\right\}  $, let $D_{i}=D\left(  x_{1}%
,x_{2},...\right)  \cdot J_{i}$. Then,%
\[
D_{0}=D\left(  x_{1},x_{2},...\right)  \cdot\underbrace{J_{0}}_{=\mathbb{C}%
\left[  a_{1},a_{2},a_{3},...\right]  }=D\left(  x_{1},x_{2},...\right)
\]
and%
\[
D_{N}=D\left(  x_{1},x_{2},...\right)  \cdot\underbrace{J_{N}}_{=I_{v}%
}=D\left(  x_{1},x_{2},...\right)  \cdot I_{v}.
\]
Hence, $D_{0}\diagup D_{N}=D\left(  x_{1},x_{2},...\right)  \diagup\left(
D\left(  x_{1},x_{2},...\right)  I_{v}\right)  =\widetilde{W}$.

Now, we are going to prove that%
\begin{equation}
D_{i}\diagup D_{i+1}\cong F\text{ or }D_{i}\diagup D_{i+1}%
=0\ \ \ \ \ \ \ \ \ \ \text{for every }i\in\left\{  0,1,...,N-1\right\}
\label{prop.V=F(X)U.pf.3}%
\end{equation}
(where $\cong$ means isomorphism of $\mathcal{A}_{0}$-modules).

\textit{Proof of (\ref{prop.V=F(X)U.pf.3}).} Let $i\in\left\{
0,1,...,N-1\right\}  $. Since $\dim\left(  \mathbb{C}\left[  a_{1},a_{2}%
,a_{3},...\right]  \diagup J_{i}\right)  =i$ and $\dim\left(  \mathbb{C}%
\left[  a_{1},a_{2},a_{3},...\right]  \diagup J_{i+1}\right)  =i+1$, there
exists some $u\in J_{i}$ such that $J_{i}=u+J_{i+1}$. Consider this $u$. By
abuse of notation, we also use the letter $u$ to denote the element $1\cdot
u\in D\left(  x_{1},x_{2},...\right)  \cdot J_{i}=D_{i}$. Then,
\begin{align*}
D_{i}  &  =D\left(  x_{1},x_{2},...\right)  \cdot\underbrace{J_{i}%
}_{=u+J_{i+1}}=D\left(  x_{1},x_{2},...\right)  \cdot\left(  u+J_{i+1}\right)
\\
&  =D\left(  x_{1},x_{2},...\right)  \cdot u+\underbrace{D\left(  x_{1}%
,x_{2},...\right)  \cdot J_{i+1}}_{=D_{i+1}}=D\left(  x_{1},x_{2},...\right)
\cdot u+D_{i+1}.
\end{align*}
Thus,
\[
D_{i}\diagup D_{i+1}=D\left(  x_{1},x_{2},...\right)  \cdot u^{\prime},
\]
where $u^{\prime}$ denotes the residue class of $u\in D_{i}$ modulo $D_{i+1}$.
For every $j>0$, we have $\underbrace{a_{j}}_{\in\mathfrak{i}}\underbrace{u}%
_{\in J_{i}}\in\mathfrak{i}\cdot J_{i}\subseteq J_{i+1}$ (by
(\ref{prop.V=F(X)U.pf.2})) and thus $a_{j}u\in D\left(  x_{1},x_{2}%
,...\right)  \cdot J_{i+1}=D_{i+1}$. In other words, for every $j>0$, we have
$a_{j}u^{\prime}=0$. Also, it is pretty clear that $Ku^{\prime}=u^{\prime}$.
Thus, Lemma \ref{lem.V=F} (applied to $D_{i}\diagup D_{i+1}$ and $u^{\prime}$
instead of $V$ and $u$) yields that there exists a homomorphism $\eta
:F\rightarrow D_{i}\diagup D_{i+1}$ of $\mathcal{A}_{0}$-modules such that
$\eta\left(  1\right)  =u^{\prime}$. This homomorphism $\eta$ must be
surjective\footnote{since its image is $\eta\left(  \underbrace{F}_{=D\left(
x_{1},x_{2},...\right)  \cdot1}\right)  =D\left(  x_{1},x_{2},...\right)
\cdot\underbrace{\eta\left(  1\right)  }_{=u^{\prime}}=D\left(  x_{1}%
,x_{2},...\right)  \cdot u^{\prime}=D_{i}\diagup D_{i+1}$}, and thus
$D_{i}\diagup D_{i+1}$ is a factor module of $F$. Since $F$ is irreducible,
this yields that $D_{i}\diagup D_{i+1}\cong F$ or $D_{i}\diagup D_{i+1}=0$.
This proves (\ref{prop.V=F(X)U.pf.3}).

Now, clearly, the $\mathcal{A}_{0}$-module $\widetilde{W}=D_{0}\diagup D_{N}$
is filtered by the $\mathcal{A}_{0}$-modules $D_{i}\diagup D_{N}$ for
$i\in\left\{  0,1,...,N\right\}  $. Due to (\ref{prop.V=F(X)U.pf.3}), the
subquotients of this filtration are all $\cong F$ or $=0$, so that
$\widetilde{W}$ is a finite-length $\mathcal{A}_{0}$-module with all
composition factors isomorphic to $F$ (since $F$ is irreducible).

Since $W$ is a quotient module of $\widetilde{W}$, this yields that $W$ must
also be a finite-length $\mathcal{A}_{0}$-module with all composition factors
isomorphic to $F$.

Now forget that we fixed $v$. We have thus shown that for every $v\in V$, the
$\mathcal{A}_{0}$-submodule $U\left(  \mathcal{A}_{0}\right)  \cdot v$ of $V$
(this submodule is what we called $W$) is a finite-length module with
composition factors isomorphic to $F$.

By the assumption (that for every $v\in V$, there exists some $N\in\mathbb{N}$
such that for every $n\geq N$, we have $a_{n}v=0$), we can define an action of
$E=\sum\limits_{i>0}a_{-i}a_{i}\in\widehat{\mathcal{A}}$ (the so-called
\textit{Euler field}) on $V$. Note that $E$ acts on $V$ in a locally finite
way (this means that for any $v\in V$, the space $\mathbb{C}\left[  E\right]
\cdot v$ is finite-dimensional)\footnote{\textit{Proof.} Notice that $E$ acts
on $F$ as $\sum\limits_{i>0}ix_{i}\dfrac{\partial}{\partial x_{i}}$, and thus
$E$ acts on $F$ in a locally finite way (since the differential operator
$\sum\limits_{i>0}ix_{i}\dfrac{\partial}{\partial x_{i}}$ preserves the
degrees of polynomials), and thus also on $V$ (because for every $v\in V$, the
$\mathcal{A}_{0}$-submodule $U\left(  \mathcal{A}_{0}\right)  \cdot v$ of $V$
is a finite-length module with composition factors isomorphic to $F$).}. Now,
let us notice that the eigenvalues of the map $E\mid_{V}:V\rightarrow V$ (this
is the action of $E$ on $V$) are nonnegative
integers.\footnote{\textit{Proof.} Let $\rho$ be an eigenvalue of $E\mid_{V}$.
Then, there exists some nonzero eigenvector $v\in V$ to the eigenvalue $\rho$.
Consider this $v$. Clearly, $\rho$ must thus also be an eigenvalue of
$E\mid_{U\left(  \mathcal{A}_{0}\right)  \cdot v}$ (because $v$ is a nonzero
eigenvector of $E\mid_{V}$ to the eigenvalue $\rho$ and lies in $U\left(
\mathcal{A}_{0}\right)  \cdot v$). But the eigenvalues of $E\mid_{U\left(
\mathcal{A}_{0}\right)  \cdot v}$ are nonnegative integers (since we know that
the $\mathcal{A}_{0}$-submodule $U\left(  \mathcal{A}_{0}\right)  \cdot v$ of
$V$ is a finite-length module with composition factors isomorphic to $F$, and
we can easily check that the eigenvalues of $E\mid_{F}$ are nonnegative
integers). Hence, $\rho$ is a nonnegative integer. We have thus shown that
every eigenvalue of $E\mid_{V}$ is a nonnegative integer, qed.} Hence, we can
write $V$ as $V=\bigoplus\limits_{j\geq0}V\left[  j\right]  $, where $V\left[
j\right]  $ is the generalized eigenspace of $E\mid_{V}$ with eigenvalue $j$
for every $j\in\mathbb{N}$.

If some $v\in V$ satisfies $a_{i}v=0$ for all $i>0$, then $Ev=0$ and thus
$v\in V\left[  0\right]  $.

Conversely, if $v\in V\left[  0\right]  $, then $a_{i}v=0$ for all
$i>0$.\ \ \ \ \footnote{\textit{Proof.} Let $v\in V\left[  0\right]  $. Let
$j$ be positive.
\par
It is easy to check that $a_{-i}a_{i}a_{j}=a_{j}a_{-i}a_{i}-i\delta_{i,j}%
a_{i}$ for any positive $i$ (here, we use that $j>0$). Since $E=\sum
\limits_{i>0}a_{-i}a_{i}$, we have%
\begin{align*}
Ea_{j}  &  =\sum\limits_{i>0}\underbrace{a_{-i}a_{i}a_{j}}_{=a_{j}a_{-i}%
a_{i}-i\delta_{i,j}a_{i}}=\sum\limits_{i>0}\left(  a_{j}a_{-i}a_{i}%
-i\delta_{i,j}a_{i}\right) \\
&  =a_{j}\underbrace{\sum\limits_{i>0}a_{-i}a_{i}}_{=E}-\underbrace{\sum
\limits_{i>0}i\delta_{i,j}a_{i}}_{=ja_{j}}=a_{j}E-ja_{j},
\end{align*}
so that $\left(  E+j\right)  a_{j}=a_{j}E$. This yields (by induction over
$m$) that $\left(  E+j\right)  ^{m}a_{j}=a_{j}E^{m}$ for every $m\in
\mathbb{N}$.
\par
Now, since $v\in V\left[  0\right]  =\left(  \text{generalized eigenspace of
}E\mid_{V}\text{ with eigenvalue }0\right)  $, there exists an $m\in
\mathbb{N}$ such that $E^{m}v=0$. Consider this $m$. Then, from $\left(
E+j\right)  ^{m}a_{j}=a_{j}E^{m}$, we obtain $\left(  E+j\right)  ^{m}%
a_{j}v=a_{j}E^{m}v=0$, so that
\[
a_{j}v\in\left(  \text{generalized eigenspace of }E\mid_{V}\text{ with
eigenvalue }-j\right)  =0
\]
(because the eigenvalues of the map $E\mid_{V}:V\rightarrow V$ are nonnegative
integers, whereas $-j$ is not). In other words, $a_{j}v=0$.
\par
We have thus proven that $a_{j}v=0$ for every positive $j$. In other words,
$a_{i}v=0$ for all $i>0$, qed.}

So we conclude that $V\left[  0\right]  =\operatorname*{Ker}E=\bigcap
\limits_{i\geq1}\operatorname*{Ker}a_{i}$.

Now, $F\otimes V\left[  0\right]  $ is an $\mathcal{A}_{0}$-module (where
$\mathcal{A}_{0}$ acts only on the $F$ tensorand, where $V\left[  0\right]  $
is considered just as a vector space). We will now construct an isomorphism
$F\otimes V\left[  0\right]  \rightarrow V$ of $\mathcal{A}_{0}$-modules. This
will prove Proposition \ref{prop.V=F(X)U}.

For every $v\in V\left[  0\right]  $, there exists a homomorphism $\eta
_{v}:F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that $\eta_{v}\left(
1\right)  =v$ (according to Lemma \ref{lem.V=F}, applied to $v$ instead of $u$
(since $a_{i}v=0$ for all $i>0$ and $Kv=v$)). Consider these homomorphisms
$\eta_{v}$ for various $v$. Clearly, every $v\in V\left[  0\right]  $ and
$P\in F$ satisfy%
\begin{align*}
\eta_{v}\left(  P\right)   &  =\eta_{v}\left(  P\left(  a_{-1},a_{-2}%
,a_{-3},...\right)  \cdot1\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}P=P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot1\right) \\
&  =P\left(  a_{-1},a_{-2},a_{-3},...\right)  \underbrace{\eta_{v}\left(
1\right)  }_{=v}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\eta_{v}\text{ is an
}\mathcal{A}_{0}\text{-module map}\right) \\
&  =P\left(  a_{-1},a_{-2},a_{-3},...\right)  v.
\end{align*}
Hence, we can define a $\mathbb{C}$-linear map $\rho:F\otimes V\left[
0\right]  \rightarrow V$ by%
\[
\rho\left(  P\otimes v\right)  =\eta_{v}\left(  P\right)  =P\left(
a_{-1},a_{-2},a_{-3},...\right)  v\ \ \ \ \ \ \ \ \ \ \text{for any }P\in
F\text{ and }v\in V\left[  0\right]  .
\]
This map $\rho$ is an $\mathcal{A}_{0}$-module map (because $\eta_{v}$ is an
$\mathcal{A}_{0}$-module map for every $v\in V\left[  0\right]  $).

The restriction of the map $\rho$ to the subspace $\mathbb{C}\cdot1\otimes
V\left[  0\right]  $ of $F\otimes V\left[  0\right]  $ is injective (since it
maps every $1\otimes v$ to $v$). Hence, the map $\rho$ is
injective\footnote{This follows from the following general
representation-theoretical fact (applied to $A=U\left(  \mathcal{A}%
_{0}\right)  $, $I=F$, $R=V\left[  0\right]  $, $S=V$, $i=1$ and $\phi=\rho$):
\par
Let $A$ be a $\mathbb{C}$-algebra. Let $I$ be an irreducible $A$-module, and
let $S$ be an $A$-module. Let $R$ be a vector space. Let $i\in I$ be nonzero.
Let $\phi:I\otimes R\rightarrow S$ be an $A$-module homomorphism such that the
restriction of $\phi$ to $\mathbb{C}i\otimes R$ is injective. Then, $\phi$ is
injective.}. Also, considering the quotient $\mathcal{A}_{0}$-module
$V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  $, we notice that
$E\mid_{V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  }$ has only
strictly positive eigenvalues (since $\rho\left(  F\otimes V\left[  0\right]
\right)  \supseteq V\left[  0\right]  $, so that all eigenvectors of
$E\mid_{V}$ to eigenvalue $0$ have been killed when factoring modulo
$\rho\left(  F\otimes V\left[  0\right]  \right)  $), and thus $V\diagup
\rho\left(  F\otimes V\left[  0\right]  \right)  =0$%
\ \ \ \ \footnote{\textit{Proof.} Assume the contrary. Then, $V\diagup
\rho\left(  F\otimes V\left[  0\right]  \right)  \neq0$. Thus, there exists
some nonzero $w\in V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  $.
Write $w$ as $\overline{v}$, where $v$ is an element of $V$ and $\overline{v}$
denotes the residue class of $v$ modulo $\rho\left(  F\otimes V\left[
0\right]  \right)  $. As we know, the $\mathcal{A}_{0}$-submodule $U\left(
\mathcal{A}_{0}\right)  \cdot v$ of $V$ is a finite-length module with
composition factors isomorphic to $F$. Thus, the $\mathcal{A}_{0}$-module
$U\left(  \mathcal{A}_{0}\right)  \cdot w$ (being a quotient module of
$U\left(  \mathcal{A}_{0}\right)  \cdot v$) must also be a finite-length
module with composition factors isomorphic to $F$. Hence, there exists a
submodule of $U\left(  \mathcal{A}_{0}\right)  \cdot w$ isomorphic to $F$
(since $w\neq0$ and thus $U\left(  \mathcal{A}_{0}\right)  \cdot w\neq0$).
This submodule contains a nonzero eigenvector of $E$ to eigenvalue $0$
(because $F$ contains a nonzero eigenvector of $E$ to eigenvalue $0$, namely
$1$). This is a contradiction to the fact that $E\mid_{V\diagup\rho\left(
F\otimes V\left[  0\right]  \right)  }$ has only strictly positive
eigenvalues. This contradiction shows that our assumption was wrong, so we do
have $V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  =0$, qed.}. In
other words, $V=\rho\left(  F\otimes V\left[  0\right]  \right)  $, so that
$\rho$ is surjective. Since $\rho$ is an injective and surjective
$\mathcal{A}_{0}$-module map, we conclude that $\rho$ is an $\mathcal{A}_{0}%
$-module isomorphism. Thus, $V\cong F\otimes V\left[  0\right]  $ as
$\mathcal{A}_{0}$-modules. This proves Proposition \ref{prop.V=F(X)U}.

\subsubsection{Remark on \texorpdfstring{$\mathcal{A}$}{A}-modules}

We will not use this until much later, but here is an analogue of Lemma
\ref{lem.V=F} for $\mathcal{A}$ instead of $\mathcal{A}_{0}$:

\begin{lemma}
\label{lem.V=F.A}Let $V$ be an $\mathcal{A}$-module. Let $\mu\in\mathbb{C}$.
Let $u\in V$ be such that $a_{i}u=0$ for all $i>0$, such that $a_{0}u=\mu u$,
and such that $Ku=u$. Then, there exists a homomorphism $\eta:F_{\mu
}\rightarrow V$ of $\mathcal{A}$-modules such that $\eta\left(  1\right)  =u$.
(This homomorphism $\eta$ is unique, although we won't need this.)
\end{lemma}

\textit{Proof of Lemma \ref{lem.V=F.A}.} Let $\eta$ be the map $F\rightarrow
V$ which sends every polynomial $P\in F=\mathbb{C}\left[  x_{1},x_{2}%
,x_{3},...\right]  $ to $P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u\in
V$.\ \ \ \ \footnote{Note that the term $P\left(  a_{-1},a_{-2},a_{-3}%
,...\right)  $ denotes the evaluation of the polynomial $P$ at $\left(
x_{1},x_{2},x_{3},...\right)  =\left(  a_{-1},a_{-2},a_{-3},...\right)  $.
This evaluation is a well-defined element of $U\left(  \mathcal{A}_{0}\right)
$, since the elements $a_{-1}$, $a_{-2}$, $a_{-3}$, $...$ of $U\left(
\mathcal{A}_{0}\right)  $ commute.} Just as in the Second proof of Lemma
\ref{lem.V=F}, we can show that $\eta$ is an $\mathcal{A}_{0}$-module
homomorphism $F\rightarrow V$ such that $\eta\left(  1\right)  =u$. We are now
going to prove that this $\eta$ is also a homomorphism $F_{\mu}\rightarrow V$
of $\mathcal{A}$-modules. Clearly, in order to prove this, it is enough to
show that $\eta\left(  a_{0}P\right)  =a_{0}\eta\left(  P\right)  $ for all
$P\in F_{\mu}$.

Let $P\in F_{\mu}$. Since $a_{0}$ acts as multiplication by $\mu$ on $F_{\mu}%
$, we have $a_{0}P=\mu P$.

On the other hand, by the definition of $\eta$, we have $\eta\left(  P\right)
=P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u$, so that%
\begin{align*}
a_{0}\eta\left(  P\right)   &  =a_{0}P\left(  a_{-1},a_{-2},a_{-3},...\right)
\cdot u=P\left(  a_{-1},a_{-2},a_{-3},...\right)  a_{0}\cdot u\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }a_{0}\text{ lies in the center of }\mathcal{A}\text{, and thus in
the center of }U\left(  \mathcal{A}\right)  \text{,}\\
\text{and thus }a_{0}P\left(  a_{-1},a_{-2},a_{-3},...\right)  =P\left(
a_{-1},a_{-2},a_{-3},...\right)  a_{0}%
\end{array}
\right) \\
&  =P\left(  a_{-1},a_{-2},a_{-3},...\right)  \underbrace{a_{0}u}_{=\mu u}%
=\mu\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u}%
_{=\eta\left(  P\right)  }=\mu\eta\left(  P\right) \\
&  =\eta\left(  \underbrace{\mu P}_{=a_{0}P}\right)  =\eta\left(
a_{0}P\right)  .
\end{align*}
Thus, we have shown that $\eta\left(  a_{0}P\right)  =a_{0}\eta\left(
P\right)  $ for all $P\in F_{\mu}$. This completes the proof of Lemma
\ref{lem.V=F.A}.

\subsubsection{A rescaled version of the Fock space}

Here is a statement very similar to Corollary \ref{cor.fock}:

\begin{corollary}
\label{cor.focktilde}The Lie algebra $\mathcal{A}_{0}$ has a representation
$\widetilde{F}=\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  $ which is
given by
\begin{align*}
a_{-i}  &  \mapsto ix_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1;\\
a_{i}  &  \mapsto\dfrac{\partial}{\partial x_{i}}\ \ \ \ \ \ \ \ \ \ \text{for
every }i\geq1,\\
K  &  \mapsto1
\end{align*}
(where ``$a_{-i}\mapsto ix_{i}$'' is just shorthand for ``$a_{-i}%
\mapsto\left(  \text{multiplication by }ix_{i}\right)  $''). For every $\mu
\in\mathbb{C}$, we can upgrade $\widetilde{F}$ to a representation
$\widetilde{F}_{\mu}$ of $\mathcal{A}$ by adding the condition that $a_{0}%
\mid_{\widetilde{F}_{\mu}}=\mu\cdot\operatorname*{id}$.
\end{corollary}

Note that the $\mathcal{A}_{0}$-module structure on $\widetilde{F}$ differs
from that on $F$ by a different choice of ``where to put the $i$ factor'': in
$F$ it is in the action of $a_{i}$, while in $\widetilde{F}$ it is in the
action of $a_{-i}$ (where $i\geq1$).

\begin{definition}
\label{def.focktilde}The representation $\widetilde{F}$ of $\mathcal{A}_{0}$
introduced in Corollary \ref{cor.focktilde} will be called the
\textit{rescaled Fock module} or the \textit{rescaled Fock representation}.
For every $\mu\in\mathbb{C}$, the representation $\widetilde{F}_{\mu}$ of
$\mathcal{A}$ introduced in Corollary \ref{cor.focktilde} will be called the
\textit{rescaled }$\mu$\textit{-Fock representation} of $\mathcal{A}$. The
vector space $\widetilde{F}$ itself, of course, is the same as the vector
space $F$ of Corollary \ref{cor.fock}, and thus we simply call it the Fock space.
\end{definition}

\begin{proposition}
\label{prop.resc}Let $\operatorname*{resc}:\mathbb{C}\left[  x_{1},x_{2}%
,x_{3},...\right]  \rightarrow\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]
$ be the $\mathbb{C}$-algebra homomorphism which sends $x_{i}$ to $ix_{i}$ for
every $i\in\left\{  1,2,3,...\right\}  $. (This homomorphism exists and is
unique by the universal property of the polynomial algebra. It is clear that
$\operatorname*{resc}$ multiplies every monomial by some scalar.)

\textbf{(a)} Then, $\operatorname*{resc}$ is an $\mathcal{A}_{0}$-module
isomorphism $F\rightarrow\widetilde{F}$. Thus, $F\cong\widetilde{F}$ as
$\mathcal{A}_{0}$-modules.

\textbf{(b)} Let $\mu\in\mathbb{C}$. Then, $\operatorname*{resc}$ is an
$\mathcal{A}$-module isomorphism $F_{\mu}\rightarrow\widetilde{F}_{\mu}$.
Thus, $F_{\mu}\cong\widetilde{F}_{\mu}$ as $\mathcal{A}$-modules.
\end{proposition}

Corollary \ref{cor.focktilde} and Proposition \ref{prop.resc} are both very
easy to prove: It is best to prove Proposition \ref{prop.resc} first (without
yet knowing that $\widetilde{F}$ and $\widetilde{F}_{\mu}$ are really an
$\mathcal{A}_{0}$-module and an $\mathcal{A}$-module, respectively), and then
use it to derive Corollary \ref{cor.focktilde} from Corollary \ref{cor.fock}
by means of $\operatorname*{resc}$. We leave all details to the reader.

The modules $\widetilde{F}$ and $F$ aren't that much different: They are
isomorphic by an isomorphism which has diagonal form with respect to the
monomial bases (due to Proposition \ref{prop.resc}). Nevertheless, it pays off
to use different notations for them so as not to let confusion arise. We are
going to work with $F$ most of the time, except when $\widetilde{F}$ is easier
to handle.

\subsubsection{An involution on \texorpdfstring{$\mathcal{A}$}{A} and a
bilinear form on the Fock space}

The following fact is extremely easy to prove:

\begin{proposition}
\label{prop.A.omega}Define a $\mathbb{C}$-linear map $\omega:\mathcal{A}%
\rightarrow\mathcal{A}$ by setting
\begin{align*}
\omega\left(  K\right)   &  =-K\ \ \ \ \ \ \ \ \ \ \text{and}\\
\omega\left(  a_{i}\right)   &  =-a_{-i}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\mathbb{Z}.
\end{align*}
Then, $\omega$ is an automorphism of the Lie algebra $\mathcal{A}$. Also,
$\omega$ is an involution (this means that $\omega^{2}=\operatorname*{id}$).
Moreover, $\omega\left(  \mathcal{A}\left[  i\right]  \right)  =\mathcal{A}%
\left[  -i\right]  $ for all $i\in\mathbb{Z}$. Finally, $\omega\mid
_{\mathcal{A}\left[  0\right]  }=-\operatorname*{id}$.
\end{proposition}

Now, let us make a few conventions:

\begin{Convention}
\label{conv.fin}In the following, a map $\varphi:A\rightarrow\mathbb{N}$
(where $A$ is some set) is said to be \textit{finitely supported} if all but
finitely many $a\in A$ satisfy $\varphi\left(  a\right)  =0$. Sequences
(finite, infinite, or two-sided infinite) are considered as maps (from finite
sets, $\mathbb{N}$ or $\mathbb{Z}$, or occasionally other sets). Thus, a
sequence is finitely supported if and only if all but finitely many of its
elements are zero.

If $A$ is a set, then $\mathbb{N}_{\operatorname*{fin}}^{A}$ will denote the
set of all finitely supported maps $A\rightarrow\mathbb{N}$.
\end{Convention}

\begin{proposition}
\label{prop.A.contravariantform}Define a $\mathbb{C}$-bilinear form $\left(
\cdot,\cdot\right)  :F\times F\rightarrow\mathbb{C}$ by setting%
\begin{align*}
\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...,x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...\right)   &  =\prod\limits_{i=1}^{\infty}\delta_{n_{i},m_{i}%
}\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}}\cdot\prod\limits_{i=1}^{\infty
}n_{i}!\\
&  \ \ \ \ \ \ \ \ \ \ \left.
\begin{array}
[c]{c}%
\text{for all sequences }\left(  n_{1},n_{2},n_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }\\
\text{and }\left(  m_{1},m_{2},m_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }%
\end{array}
\right.  .
\end{align*}
(This is well-defined, because each of the infinite products $\prod
\limits_{i=1}^{\infty}\delta_{n_{i},m_{i}}$, $\prod\limits_{i=1}^{\infty
}i^{n_{i}}$ and $\prod\limits_{i=1}^{\infty}n_{i}!$ has only finitely many
terms distinct from $1$, and thus is well-defined.)

\textbf{(a)} This form $\left(  \cdot,\cdot\right)  $ is symmetric and nondegenerate.

\textbf{(b)} Every polynomial $P\in F=\mathbb{C}\left[  x_{1},x_{2}%
,x_{3},...\right]  $ satisfies $\left(  1,P\right)  =P\left(
0,0,0,...\right)  $.

\textbf{(c)} Let $\mu\in\mathbb{C}$. Any $x\in\mathcal{A}$, $P\in F_{\mu}$ and
$Q\in F_{\mu}$ satisfy $\left(  xP,Q\right)  =-\left(  P,\omega\left(
x\right)  Q\right)  $, where $xP$ and $\omega\left(  x\right)  Q$ are
evaluated in the $\mathcal{A}$-module $F_{\mu}$.

\textbf{(d)} Let $\mu\in\mathbb{C}$. Any $x\in\mathcal{A}$, $P\in F_{\mu}$ and
$Q\in F_{\mu}$ satisfy $\left(  P,xQ\right)  =-\left(  \omega\left(  x\right)
P,Q\right)  $, where $xQ$ and $\omega\left(  x\right)  P$ are evaluated in the
$\mathcal{A}$-module $F_{\mu}$.

\textbf{(e)} Let $\mu\in\mathbb{C}$. Any $x\in\mathcal{A}$, $P\in
\widetilde{F}_{\mu}$ and $Q\in\widetilde{F}_{\mu}$ satisfy $\left(
xP,Q\right)  =-\left(  P,\omega\left(  x\right)  Q\right)  $, where $xP$ and
$\omega\left(  x\right)  Q$ are evaluated in the $\mathcal{A}$-module
$\widetilde{F}_{\mu}$.

\textbf{(f)} Let $\mu\in\mathbb{C}$. Any $x\in\mathcal{A}$, $P\in
\widetilde{F}_{\mu}$ and $Q\in\widetilde{F}_{\mu}$ satisfy $\left(
P,xQ\right)  =-\left(  \omega\left(  x\right)  P,Q\right)  $, where $xQ$ and
$\omega\left(  x\right)  P$ are evaluated in the $\mathcal{A}$-module
$\widetilde{F}_{\mu}$.
\end{proposition}

We are going to put the form $\left(  \cdot,\cdot\right)  $ from this
proposition into a broader context in Proposition \ref{prop.invol.A}; indeed,
we will see that it is an example of a contravariant form on a Verma module of
a Lie algebra with involution. (``Contravariant'' means that $\left(
av,w\right)  =-\left(  v,\omega\left(  a\right)  w\right)  $ and $\left(
v,aw\right)  =-\left(  \omega\left(  a\right)  v,w\right)  $ for all $a$ in
the Lie algebra and $v$ and $w$ in the module. In the case of our form
$\left(  \cdot,\cdot\right)  $, the contravariantness of the form follows from
Proposition \ref{prop.A.contravariantform} \textbf{(c)} and \textbf{(d)}.)

\textit{Proof of Proposition \ref{prop.A.contravariantform}.} \textbf{(a)} For
any sequences $\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ and $\left(
m_{1},m_{2},m_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
1,2,3,...\right\}  }$, we have%
\[
\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...,x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...\right)  =\prod\limits_{i=1}^{\infty}\delta_{n_{i},m_{i}%
}\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}}\cdot\prod\limits_{i=1}^{\infty
}n_{i}!
\]
and%
\[
\left(  x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...,x_{1}^{n_{1}}x_{2}^{n_{2}%
}x_{3}^{n_{3}}...\right)  =\prod\limits_{i=1}^{\infty}\delta_{m_{i},n_{i}%
}\cdot\prod\limits_{i=1}^{\infty}i^{m_{i}}\cdot\prod\limits_{i=1}^{\infty
}m_{i}!.
\]
These two terms are equal in the case when $\left(  n_{1},n_{2},n_{3}%
,...\right)  \neq\left(  m_{1},m_{2},m_{3},...\right)  $ (because in this
case, they are both $0$ due to the presence of the $\prod\limits_{i=1}%
^{\infty}\delta_{n_{i},m_{i}}$ and $\prod\limits_{i=1}^{\infty}\delta
_{m_{i},n_{i}}$ factors), and are clearly equal in the case when $\left(
n_{1},n_{2},n_{3},...\right)  =\left(  m_{1},m_{2},m_{3},...\right)  $ as
well. Hence, these two terms are always equal. In other words, any sequences
$\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\left\{  1,2,3,...\right\}  }$ and $\left(  m_{1},m_{2},m_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ satisfy
\[
\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...,x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...\right)  =\left(  x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}%
}...,x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...\right)  .
\]
This proves that the form $\left(  \cdot,\cdot\right)  $ is symmetric.

The space $F=\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  $ has a basis
consisting of monomials. With respect to this basis, the form $\left(
\cdot,\cdot\right)  $ is represented by a diagonal matrix (because whenever
$\left(  n_{1},n_{2},n_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\left\{  1,2,3,...\right\}  }$ and $\left(  m_{1},m_{2},m_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ are
distinct, we have
\[
\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...,x_{1}^{m_{1}}x_{2}^{m_{2}%
}x_{3}^{m_{3}}...\right)  =\underbrace{\prod\limits_{i=1}^{\infty}%
\delta_{n_{i},m_{i}}}_{\substack{=0\\\text{(since }\left(  n_{1},n_{2}%
,n_{3},...\right)  \neq\left(  m_{1},m_{2},m_{3},...\right)  \text{)}}%
}\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}}\cdot\prod\limits_{i=1}^{\infty
}n_{i}!=0
\]
), whose diagonal entries are all nonzero (since every $\left(  n_{1}%
,n_{2},n_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
1,2,3,...\right\}  }$ satisfies%
\[
\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...,x_{1}^{n_{1}}x_{2}^{n_{2}%
}x_{3}^{n_{3}}...\right)  =\prod\limits_{i=1}^{\infty}\underbrace{\delta
_{n_{i},n_{i}}}_{=1}\cdot\prod\limits_{i=1}^{\infty}\underbrace{i^{n_{i}}%
}_{\neq0}\cdot\prod\limits_{i=1}^{\infty}\underbrace{n_{i}!}_{\neq0}\neq0
\]
). Hence, this form is nondegenerate. Proposition
\ref{prop.A.contravariantform} \textbf{(a)} is proven.

\textbf{(b)} We must prove that every polynomial $P\in F=\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  $ satisfies $\left(  1,P\right)  =P\left(
0,0,0,...\right)  $. In order to show this, it is enough to check that every
\textbf{monomial} $P\in F=\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  $
satisfies $\left(  1,P\right)  =P\left(  0,0,0,...\right)  $ (because the
equation $\left(  1,P\right)  =P\left(  0,0,0,...\right)  $ is linear in $P$,
and because the monomials span $F$). In other words, we must check that every
$\left(  m_{1},m_{2},m_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\left\{  1,2,3,...\right\}  }$ satisfies $\left(  1,x_{1}^{m_{1}}%
x_{2}^{m_{2}}x_{3}^{m_{3}}...\right)  =\left(  x_{1}^{m_{1}}x_{2}^{m_{2}}%
x_{3}^{m_{3}}...\right)  \left(  0,0,0,...\right)  $. But this is easy:%
\begin{align*}
\left(  \underbrace{1}_{=x_{1}^{0}x_{2}^{0}x_{3}^{0}...},x_{1}^{m_{1}}%
x_{2}^{m_{2}}x_{3}^{m_{3}}...\right)   &  =\left(  x_{1}^{0}x_{2}^{0}x_{3}%
^{0}...,x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...\right)  =\prod
\limits_{i=1}^{\infty}\underbrace{\delta_{0,m_{i}}}_{=0^{m_{i}}}\cdot
\prod\limits_{i=1}^{\infty}\underbrace{i^{0}}_{=1}\cdot\prod\limits_{i=1}%
^{\infty}\underbrace{0!}_{=1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\left(  \cdot
,\cdot\right)  \right) \\
&  =\prod\limits_{i=1}^{\infty}0^{m_{i}}=0^{m_{1}}0^{m_{2}}0^{m_{3}%
}...=\left(  x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...\right)  \left(
0,0,0,...\right)  ,
\end{align*}
qed. Proposition \ref{prop.A.contravariantform} \textbf{(b)} is proven.

\textbf{(c)} We must prove that any $x\in\mathcal{A}$, $P\in F_{\mu}$ and
$Q\in F_{\mu}$ satisfy $\left(  xP,Q\right)  =-\left(  P,\omega\left(
x\right)  Q\right)  $. Since this equation is linear in each of $x$, $P$ and
$Q$, we can WLOG assume that $x$ is an element of the basis $\left\{
a_{n}\ \mid\ n\in\mathbb{Z}\right\}  \cup\left\{  K\right\}  $ of
$\mathcal{A}$ and that $P$ and $Q$ are monomials (since monomials span $F$).
So let us assume this.

Since $x$ is an element of the basis $\left\{  a_{n}\ \mid\ n\in
\mathbb{Z}\right\}  \cup\left\{  K\right\}  $ of $\mathcal{A}$, we have either
$x=a_{j}$ for some $j\in\mathbb{Z}$, or $x=K$. Since the latter case is
trivial (in fact, when $x=K$, then%
\[
\left(  xP,Q\right)  =\left(  KP,Q\right)  =\left(  P,Q\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }K\text{ acts as }1\text{ on }F_{\mu
}\text{, so that }KP=P\right)
\]
and%
\begin{align*}
-\left(  P,\omega\left(  \underbrace{x}_{=K}\right)  Q\right)   &  =-\left(
P,\underbrace{\omega\left(  K\right)  }_{=-K}Q\right)  =-\left(  P,-KQ\right)
=\left(  P,KQ\right)  =\left(  P,Q\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }K\text{ acts as }1\text{ on
}F_{\mu}\text{, so that }KQ=Q\right)  ,
\end{align*}
so that $\left(  xP,Q\right)  =-\left(  P,\omega\left(  x\right)  Q\right)  $
is proven), we can WLOG assume that we are in the former case, i. e., that
$x=a_{j}$ for some $j\in\mathbb{Z}$. Assume this, and consider this $j$.

Since $P$ is a monomial, there exists a $\left(  n_{1},n_{2},n_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ such that
$P=x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...$. Consider this $\left(
n_{1},n_{2},n_{3},...\right)  $.

Since $Q$ is a monomial, there exists a $\left(  m_{1},m_{2},m_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }$ such that
$Q=x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$. Consider this $\left(
m_{1},m_{2},m_{3},...\right)  $.

We must prove that $\left(  xP,Q\right)  =-\left(  P,\omega\left(  x\right)
Q\right)  $. Since $\left(  xP,Q\right)  =\left(  a_{j}P,Q\right)  $ (because
$x=a_{j}$) and $-\left(  P,\omega\left(  x\right)  Q\right)  =\left(
P,a_{-j}Q\right)  $ (because $-\left(  P,\omega\left(  \underbrace{x}_{=a_{j}%
}\right)  Q\right)  =-\left(  P,\underbrace{\omega\left(  a_{j}\right)
}_{=-a_{-j}}Q\right)  =-\left(  P,-a_{-j}Q\right)  =\left(  P,a_{-j}Q\right)
$), this rewrites as $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $.
Hence, we must only prove that $\left(  a_{j}P,Q\right)  =\left(
P,a_{-j}Q\right)  $.

We will distinguish between three cases:

\textit{Case 1:} We have $j\geq1$.

\textit{Case 2:} We have $j=0$.

\textit{Case 3:} We have $j\leq-1$.

First, let us consider Case 1. In this case, by the definition of $F_{\mu}$,
we know that $a_{j}$ acts on $F_{\mu}$ as $j\dfrac{\partial}{\partial x_{j}}$,
whereas $a_{-j}$ acts on $F_{\mu}$ as multiplication by $x_{j}$. Hence,
$a_{j}P=j\dfrac{\partial}{\partial x_{j}}P$ and $a_{-j}Q=x_{j}Q$.

Since $Q=x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...$, we have $x_{j}%
Q=x_{1}^{m_{1}^{\prime}}x_{2}^{m_{2}^{\prime}}x_{3}^{m_{3}^{\prime}}...$,
where the sequence $\left(  m_{1}^{\prime},m_{2}^{\prime},m_{3}^{\prime
},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}
}$ is defined by%
\[
m_{i}^{\prime}=\left\{
\begin{array}
[c]{c}%
m_{i},\ \ \ \ \ \ \ \ \ \ \text{if }i\neq j;\\
m_{i}+1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j
\end{array}
\right.  \ \ \ \ \ \ \ \ \ \ \text{for every }i\in\left\{  1,2,3,...\right\}
.
\]
Note that this definition immediately yields $m_{j}^{\prime}=m_{j}+1\geq1$, so
that $\delta_{0,m_{j}^{\prime}}=0$.

As a consequence of the definition of $\left(  m_{1}^{\prime},m_{2}^{\prime
},m_{3}^{\prime},...\right)  $, we have $m_{i}^{\prime}-m_{i}=\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }i\neq j;\\
1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j
\end{array}
\right.  $ for every $i\in\left\{  1,2,3,...\right\}  $.

Now, $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $ is easily proven
when $n_{j}=0$\ \ \ \ \footnote{\textit{Proof.} Assume that $n_{j}=0$. Then,
$P=x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...$ is a monomial that does not
involve the indeterminate $x_{j}$; hence, $\dfrac{\partial}{\partial x_{j}%
}P=0$, so that $a_{j}P=j\underbrace{\dfrac{\partial}{\partial x_{j}}P}_{=0}%
=0$, and thus $\left(  a_{j}P,Q\right)  =\left(  0,Q\right)  =0$. On the other
hand, since $n_{j}=0$, we have $\delta_{n_{j},m_{j}^{\prime}}=\delta
_{0,m_{j}^{\prime}}=0$ and thus $\prod\limits_{i=1}^{\infty}\delta
_{n_{i},m_{i}^{\prime}}=0$ (since the product $\prod\limits_{i=1}^{\infty
}\delta_{n_{i},m_{i}^{\prime}}$ contains the factor $\delta_{n_{j}%
,m_{j}^{\prime}}$). Now, since $P=x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...$
and $a_{-j}Q=x_{j}Q=x_{1}^{m_{1}^{\prime}}x_{2}^{m_{2}^{\prime}}x_{3}%
^{m_{3}^{\prime}}...$, we have%
\begin{align*}
\left(  P,a_{-j}Q\right)   &  =\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}%
}...,x_{1}^{m_{1}^{\prime}}x_{2}^{m_{2}^{\prime}}x_{3}^{m_{3}^{\prime}%
}...\right) \\
&  =\underbrace{\prod\limits_{i=1}^{\infty}\delta_{n_{i},m_{i}^{\prime}}}%
_{=0}\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}}\cdot\prod\limits_{i=1}^{\infty
}n_{i}!\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\left(
\cdot,\cdot\right)  \right) \\
&  =0=\left(  a_{j}P,Q\right)  .
\end{align*}
Hence, $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $ is proven when
$n_{j}=0$.}. Hence, for the remaining part of Case 1, we can WLOG assume that
$n_{j}\neq0$. Let us assume this. Then, $n_{j}\geq1$. Hence, since
$P=x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...$, we have $\dfrac{\partial
}{\partial x_{j}}P=n_{j}x_{1}^{n_{1}^{\prime}}x_{2}^{n_{2}^{\prime}}%
x_{3}^{n_{3}^{\prime}}...$, where the sequence $\left(  n_{1}^{\prime}%
,n_{2}^{\prime},n_{3}^{\prime},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\left\{  1,2,3,...\right\}  }$ is defined by%
\[
n_{i}^{\prime}=\left\{
\begin{array}
[c]{c}%
n_{i},\ \ \ \ \ \ \ \ \ \ \text{if }i\neq j;\\
n_{i}-1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j
\end{array}
\right.  \ \ \ \ \ \ \ \ \ \ \text{for every }i\in\left\{  1,2,3,...\right\}
.
\]
From this definition, it is clear that the sequence $\left(  n_{1}^{\prime
},n_{2}^{\prime},n_{3}^{\prime},...\right)  $ differs from the sequence
$\left(  n_{1},n_{2},n_{3},...\right)  $ only in the $j$-th term. Hence, the
product $\prod\limits_{i=1}^{\infty}i^{n_{i}^{\prime}}$ differs from the
product $\prod\limits_{i=1}^{\infty}i^{n_{i}}$ only in the $j$-th factor.
Thus,%
\begin{align*}
\dfrac{\prod\limits_{i=1}^{\infty}i^{n_{i}}}{\prod\limits_{i=1}^{\infty
}i^{n_{i}^{\prime}}}  &  =\dfrac{j^{n_{j}}}{j^{n_{j}^{\prime}}}=\dfrac
{j^{n_{j}}}{j^{n_{j}-1}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }n_{j}%
^{\prime}=n_{j}-1\text{ by the definition of }\left(  n_{1}^{\prime}%
,n_{2}^{\prime},n_{3}^{\prime},...\right)  \right) \\
&  =j,
\end{align*}
so that $\prod\limits_{i=1}^{\infty}i^{n_{i}}=j\prod\limits_{i=1}^{\infty
}i^{n_{i}^{\prime}}$. A similar argument (using the products $\prod
\limits_{i=1}^{\infty}n_{i}^{\prime}$ and $\prod\limits_{i=1}^{\infty}n_{i}$
instead of the products $\prod\limits_{i=1}^{\infty}i^{n_{i}^{\prime}}$ and
$\prod\limits_{i=1}^{\infty}i^{n_{i}}$) shows that $\prod\limits_{i=1}%
^{\infty}n_{i}!=n_{j}\prod\limits_{i=1}^{\infty}n_{i}^{\prime}!$.

As a consequence of the definition of $\left(  n_{1}^{\prime},n_{2}^{\prime
},n_{3}^{\prime},...\right)  $, we have $n_{i}-n_{i}^{\prime}=\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }i\neq j;\\
1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j
\end{array}
\right.  $ for every $i\in\left\{  1,2,3,...\right\}  $. Thus, every
$i\in\left\{  1,2,3,...\right\}  $ satisfies%
\[
n_{i}-n_{i}^{\prime}=\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }i\neq j;\\
1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j
\end{array}
\right.  =m_{i}^{\prime}-m_{i},
\]
so that $n_{i}-m_{i}^{\prime}=n_{i}^{\prime}-m_{i}$, so that $\delta
_{n_{i}-m_{i}^{\prime},0}=\delta_{n_{i}^{\prime}-m_{i},0}$.

Now, since $P=x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}}...$ and $a_{-j}%
Q=x_{j}Q=x_{1}^{m_{1}^{\prime}}x_{2}^{m_{2}^{\prime}}x_{3}^{m_{3}^{\prime}%
}...$, we have%
\begin{align*}
\left(  P,a_{-j}Q\right)   &  =\left(  x_{1}^{n_{1}}x_{2}^{n_{2}}x_{3}^{n_{3}%
}...,x_{1}^{m_{1}^{\prime}}x_{2}^{m_{2}^{\prime}}x_{3}^{m_{3}^{\prime}%
}...\right) \\
&  =\prod\limits_{i=1}^{\infty}\underbrace{\delta_{n_{i},m_{i}^{\prime}}%
}_{=\delta_{n_{i}-m_{i}^{\prime},0}=\delta_{n_{i}^{\prime}-m_{i},0}%
=\delta_{n_{i}^{\prime},m_{i}}}\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}}%
\cdot\prod\limits_{i=1}^{\infty}n_{i}!\ \ \ \ \ \ \ \ \ \ \left(  \text{by the
definition of }\left(  \cdot,\cdot\right)  \right) \\
&  =\prod\limits_{i=1}^{\infty}\delta_{n_{i}^{\prime},m_{i}}\cdot
\underbrace{\prod\limits_{i=1}^{\infty}i^{n_{i}}}_{=j\prod\limits_{i=1}%
^{\infty}i^{n_{i}^{\prime}}}\cdot\underbrace{\prod\limits_{i=1}^{\infty}%
n_{i}!}_{=n_{j}\prod\limits_{i=1}^{\infty}n_{i}^{\prime}!}=jn_{j}\cdot
\prod\limits_{i=1}^{\infty}\delta_{n_{i}^{\prime},m_{i}}\cdot\prod
\limits_{i=1}^{\infty}i^{n_{i}^{\prime}}\cdot\prod\limits_{i=1}^{\infty}%
n_{i}^{\prime}!.
\end{align*}
Compared with%
\begin{align*}
\left(  a_{j}P,Q\right)   &  =\left(  jn_{j}x_{1}^{n_{1}^{\prime}}x_{2}%
^{n_{2}^{\prime}}x_{3}^{n_{3}^{\prime}}...,x_{1}^{m_{1}}x_{2}^{m_{2}}%
x_{3}^{m_{3}}...\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }a_{j}P=j\underbrace{\dfrac
{\partial}{\partial x_{j}}P}_{=n_{j}x_{1}^{n_{1}^{\prime}}x_{2}^{n_{2}%
^{\prime}}x_{3}^{n_{3}^{\prime}}...}=jn_{j}x_{1}^{n_{1}^{\prime}}x_{2}%
^{n_{2}^{\prime}}x_{3}^{n_{3}^{\prime}}...\text{ and }Q=x_{1}^{m_{1}}%
x_{2}^{m_{2}}x_{3}^{m_{3}}...\right) \\
&  =jn_{j}\underbrace{\left(  x_{1}^{n_{1}^{\prime}}x_{2}^{n_{2}^{\prime}%
}x_{3}^{n_{3}^{\prime}}...,x_{1}^{m_{1}}x_{2}^{m_{2}}x_{3}^{m_{3}}...\right)
}_{\substack{=\prod\limits_{i=1}^{\infty}\delta_{n_{i}^{\prime},m_{i}}%
\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}^{\prime}}\cdot\prod\limits_{i=1}%
^{\infty}n_{i}^{\prime}!\\\text{(by the definition of }\left(  \cdot
,\cdot\right)  \text{)}}}=jn_{j}\cdot\prod\limits_{i=1}^{\infty}\delta
_{n_{i}^{\prime},m_{i}}\cdot\prod\limits_{i=1}^{\infty}i^{n_{i}^{\prime}}%
\cdot\prod\limits_{i=1}^{\infty}n_{i}^{\prime}!,
\end{align*}
this yields $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $. Thus,
$\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $ is proven in Case 1. In
other words, we have shown that%
\begin{equation}
\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)
\ \ \ \ \ \ \ \ \ \ \text{for every integer }j\geq1\text{ and any monomials
}P\text{ and }Q\text{.} \label{pf.A.contravariantform.1}%
\end{equation}


In Case 2, proving $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $ is
trivial (since $a_{0}$ acts on $F_{\mu}$ as $\mu\cdot\operatorname*{id}$).

Now, let us consider Case 3. In this case, $j\leq-1$, so that $-j\geq1$. Thus,
(\ref{pf.A.contravariantform.1}) (applied to $-j$, $Q$ and $P$ instead of $j$,
$P$ and $Q$) yields $\left(  a_{-j}Q,P\right)  =\left(  Q,a_{-\left(
-j\right)  }P\right)  $. Now, since $\left(  \cdot,\cdot\right)  $ is
symmetric, we have $\left(  a_{j}P,Q\right)  =\left(  Q,\underbrace{a_{j}%
}_{=a_{-\left(  -j\right)  }}P\right)  =\left(  Q,a_{-\left(  -j\right)
}P\right)  =\left(  a_{-j}Q,P\right)  =\left(  P,a_{-j}Q\right)  $ (again
since $\left(  \cdot,\cdot\right)  $ is symmetric). Thus, $\left(
a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $ is proven in Case 3.

We have now proven $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $ is
each of the cases 1, 2 and 3. Since no other cases can occur, this completes
the proof of $\left(  a_{j}P,Q\right)  =\left(  P,a_{-j}Q\right)  $. As we
have explained above, this proves Proposition \ref{prop.A.contravariantform}
\textbf{(c)}.

\textbf{(d)} Let $x\in\mathcal{A}$, $P\in F_{\mu}$ and $Q\in F_{\mu}$. Since
the form $\left(  \cdot,\cdot\right)  $ is symmetric, we have $\left(
P,xQ\right)  =\left(  xQ,P\right)  $ and $\left(  \omega\left(  x\right)
P,Q\right)  =\left(  Q,\omega\left(  x\right)  P\right)  $. Proposition
\ref{prop.A.contravariantform} \textbf{(c)} (applied to $P$ and $Q$ instead of
$Q$ and $P$) yields $\left(  xQ,P\right)  =-\left(  Q,\omega\left(  x\right)
P\right)  $. Thus, $\left(  P,xQ\right)  =\left(  xQ,P\right)
=-\underbrace{\left(  Q,\omega\left(  x\right)  P\right)  }_{=\left(
\omega\left(  x\right)  P,Q\right)  }=-\left(  \omega\left(  x\right)
P,Q\right)  $. This proves Proposition \ref{prop.A.contravariantform}
\textbf{(d)}.

\textbf{(e)} and \textbf{(f)} The proofs of Proposition
\ref{prop.A.contravariantform} \textbf{(e)} and \textbf{(f)} are analogous to
those of Proposition \ref{prop.A.contravariantform} \textbf{(c)} and
\textbf{(d)}, respectively, and thus will be omitted.

\subsection{Representations of the Virasoro algebra
\texorpdfstring{$\operatorname*{Vir}$}{Vir}}

We now come to the Virasoro algebra $\operatorname*{Vir}$. First, some notations:

\begin{definition}
\textbf{(a)} The notion ``\textit{Virasoro module}'' will be a synonym for
``$\operatorname*{Vir}$-module''. Similarly, ``Virasoro action'' means
``$\operatorname*{Vir}$-action''.

\textbf{(b)} Let $c\in\mathbb{C}$. A $\operatorname*{Vir}$-module $M$ is said
to have \textit{central charge }$c$ if and only if the element $C$ of
$\operatorname*{Vir}$ acts as $c\cdot\operatorname*{id}$ on $M$.
\end{definition}

Note that not every $\operatorname*{Vir}$-module has a central charge (and the
zero module has infinitely many central charges), but Corollary \ref{cor.dix2}
yields that every irreducible $\operatorname*{Vir}$-module of countable
dimension has a (unique) central charge.

There are lots and lots of Virasoro modules in mathematics, and we will
encounter them as this course progresses; the more complicated among them will
require us to introduce a lot of machinery like Verma modules, semiinfinite
wedges and affine Lie algebras. For now, we define one of the simplest
families of representations of $\operatorname*{Vir}$: the ``chargeless''
$\operatorname*{Vir}$-modules $V_{\alpha,\beta}$ parametrized by pairs of
complex numbers $\left(  \alpha,\beta\right)  $.

\begin{proposition}
\label{prop.Vab.1}Let $\alpha\in\mathbb{C}$ and $\beta\in\mathbb{C}$. Let
$V_{\alpha,\beta}$ be the vector space of formal expressions of the form
$gt^{\alpha}\left(  dt\right)  ^{\beta}$ with $g\in\mathbb{C}\left[
t,t^{-1}\right]  $ (where $\mathbb{C}\left[  t,t^{-1}\right]  $ is the ring of
Laurent polynomials in the variable $t$). (Formally, this vector space
$V_{\alpha,\beta}$ is defined to be a copy of the $\mathbb{C}$-vector space
$\mathbb{C}\left[  t,t^{-1}\right]  $, but in which the element corresponding
to any $g\in\mathbb{C}\left[  t,t^{-1}\right]  $ is denoted by $gt^{\alpha
}\left(  dt\right)  ^{\beta}$. For a geometric intuition, the elements of
$V_{\alpha,\beta}$ can be seen as ``tensor fields'' of rank $\beta$ and
branching $\alpha$ on the punctured complex plane $\mathbb{C}^{\times}$.)

\textbf{(a)} The formula
\begin{equation}
f\partial\rightharpoonup\left(  gt^{\alpha}\left(  dt\right)  ^{\beta}\right)
=\left(  fg^{\prime}+\alpha t^{-1}fg+\beta f^{\prime}g\right)  t^{\alpha
}\left(  dt\right)  ^{\beta} \label{ex1.1.1}%
\end{equation}
defines an action of $W$ on $V_{\alpha,\beta}$. Thus, $V_{\alpha,\beta}$
becomes a $\operatorname*{Vir}$-module with $C$ acting as $0$. (In other
words, $V_{\alpha,\beta}$ becomes a $\operatorname*{Vir}$-module with central
charge $0$.)

\textbf{(b)} For every $k\in\mathbb{Z}$, let $v_{k}=t^{-k+\alpha}\left(
dt\right)  ^{\beta}\in V_{\alpha,\beta}$. Here, for any $\ell\in\mathbb{Z}$,
the term $t^{\ell+\alpha}\left(  dt\right)  ^{\beta}$ denotes $t^{\ell
}t^{\alpha}\left(  dt\right)  ^{\beta}$. Then,%
\begin{equation}
L_{m}v_{k}=\left(  k-\alpha-\beta\left(  m+1\right)  \right)  v_{k-m}%
\ \ \ \ \ \ \ \ \ \ \text{for every }m\in\mathbb{Z}\text{ and }k\in\mathbb{Z}.
\label{ex1.1.2.var}%
\end{equation}

\end{proposition}

Note that Proposition \ref{prop.Vab.1} was Homework Set 1 exercise 1, but the
notation $v_{k}$ had a slightly different meaning in Homework Set 1 exercise 1
than it has here.

The proof of this proposition consists of straightforward computations. We
give it for the sake of completeness, slightly simplifying the calculation by
introducing auxiliary functions.

\textit{Proof of Proposition \ref{prop.Vab.1}.} \textbf{(a)} In order to prove
Proposition \ref{prop.Vab.1} \textbf{(a)}, we must show that the formula
(\ref{ex1.1.1}) defines an action of $W$ on $V_{\alpha,\beta}$.

It is clear that $\left(  fg^{\prime}+\alpha t^{-1}fg+\beta f^{\prime
}g\right)  t^{\alpha}\left(  dt\right)  ^{\beta}$ depends linearly on each of
$f$ and $g$. Hence, we must only prove that, with the definition
(\ref{ex1.1.1}), we have
\begin{equation}
\left[  f\partial,g\partial\right]  \rightharpoonup\left(  ht^{\alpha}\left(
dt\right)  ^{\beta}\right)  =f\partial\rightharpoonup\left(  g\partial
\rightharpoonup\left(  ht^{\alpha}\left(  dt\right)  ^{\beta}\right)  \right)
-g\partial\rightharpoonup\left(  f\partial\rightharpoonup\left(  ht^{\alpha
}\left(  dt\right)  ^{\beta}\right)  \right)  \label{sol1.1.1}%
\end{equation}
for any Laurent polynomials $f$, $g$ and $h$ in $\mathbb{C}\left[
t,t^{-1}\right]  $.

So let $f$, $g$ and $h$ be any three Laurent polynomials in $\mathbb{C}\left[
t,t^{-1}\right]  $. Denote by $p$ the Laurent polynomial $h^{\prime}+\alpha
t^{-1}h$. Denote by $q$ the Laurent polynomial $fg^{\prime}-gf^{\prime}$.
Then,\footnote{In the following computations, terms like $f\left(  u\right)  $
(where $u$ is a subterm, usually a complicated one) have to be understood as
$f\cdot u$ (the product of $f$ with $u$) and not as $f\left(  u\right)  $ (the
Laurent polynomial $f$ applied to $u$).}%
\begin{equation}
f\left(  g^{\prime}h\right)  ^{\prime}-g\left(  f^{\prime}h\right)  ^{\prime
}=q^{\prime}h+qh^{\prime} \label{sol1.1.fgh}%
\end{equation}
\footnote{\textit{Proof of (\ref{sol1.1.fgh}):} Since $q=fg^{\prime
}-gf^{\prime}$, we have $qh=\left(  fg^{\prime}-gf^{\prime}\right)
h=fg^{\prime}h-gf^{\prime}h=f\left(  g^{\prime}h\right)  -g\left(  f^{\prime
}h\right)  $, so that%
\begin{align*}
\left(  qh\right)  ^{\prime}  &  =\left(  f\left(  g^{\prime}h\right)
-g\left(  f^{\prime}h\right)  \right)  ^{\prime}=\underbrace{\left(  f\left(
g^{\prime}h\right)  \right)  ^{\prime}}_{\substack{=f^{\prime}\left(
g^{\prime}h\right)  +f\left(  g^{\prime}h\right)  ^{\prime}\\\text{(by the
Leibniz rule)}}}-\underbrace{\left(  g\left(  f^{\prime}h\right)  \right)
^{\prime}}_{\substack{=g^{\prime}\left(  f^{\prime}h\right)  +g\left(
f^{\prime}h\right)  ^{\prime}\\\text{(by the Leibniz rule)}}}\\
&  =\underbrace{f^{\prime}\left(  g^{\prime}h\right)  }_{=f^{\prime}g^{\prime
}h}+f\left(  g^{\prime}h\right)  ^{\prime}-\underbrace{g^{\prime}\left(
f^{\prime}h\right)  }_{=f^{\prime}g^{\prime}h}-g\left(  f^{\prime}h\right)
^{\prime}\\
&  =f^{\prime}g^{\prime}h+f\left(  g^{\prime}h\right)  ^{\prime}-f^{\prime
}g^{\prime}h-g\left(  f^{\prime}h\right)  ^{\prime}=f\left(  g^{\prime
}h\right)  ^{\prime}-g\left(  f^{\prime}h\right)  ^{\prime}.
\end{align*}
Since $\left(  qh\right)  ^{\prime}=q^{\prime}h+qh^{\prime}$ (by the Leibniz
rule), this rewrites as $q^{\prime}h+qh^{\prime}=f\left(  g^{\prime}h\right)
^{\prime}-g\left(  f^{\prime}h\right)  ^{\prime}$. This proves
(\ref{sol1.1.fgh}).} and%
\begin{align}
&  f\underbrace{\left(  gp\right)  ^{\prime}}_{\substack{=g^{\prime
}p+gp^{\prime}\\\text{(by the Leibniz rule)}}}-g\underbrace{\left(  fp\right)
^{\prime}}_{\substack{=f^{\prime}p+fp^{\prime}\\\text{(by the Leibniz rule)}%
}}\nonumber\\
&  =\underbrace{f\left(  g^{\prime}p+gp^{\prime}\right)  }_{=fg^{\prime
}p+fgp^{\prime}}-\underbrace{g\left(  f^{\prime}p+fp^{\prime}\right)
}_{=gf^{\prime}p+gfp^{\prime}=gf^{\prime}p+fgp^{\prime}}\nonumber\\
&  =fg^{\prime}p+fgp^{\prime}-gf^{\prime}p-fgp^{\prime}=fg^{\prime
}p-gf^{\prime}p=\underbrace{\left(  fg^{\prime}-gf^{\prime}\right)  }%
_{=q}p=qp. \label{sol1.1.fgh2}%
\end{align}


Also,%
\begin{align*}
\underbrace{\left[  f\partial,g\partial\right]  }_{=\left(  fg^{\prime
}-gf^{\prime}\right)  \partial}\rightharpoonup\left(  ht^{\alpha}\left(
dt\right)  ^{\beta}\right)   &  =\underbrace{\left(  fg^{\prime}-gf^{\prime
}\right)  }_{=q}\partial\rightharpoonup\left(  ht^{\alpha}\left(  dt\right)
^{\beta}\right)  =q\partial\rightharpoonup\left(  ht^{\alpha}\left(
dt\right)  ^{\beta}\right) \\
&  =\left(  \underbrace{qh^{\prime}+\alpha t^{-1}qh}_{\substack{=q\left(
h^{\prime}+\alpha t^{-1}h\right)  =qp\\\text{(since }h^{\prime}+\alpha
t^{-1}h=p\text{)}}}+\beta q^{\prime}h\right)  t^{\alpha}\left(  dt\right)
^{\beta}=\left(  qp+\beta q^{\prime}h\right)  t^{\alpha}\left(  dt\right)
^{\beta}.
\end{align*}
Moreover, $gh^{\prime}+\alpha t^{-1}gh=g\underbrace{\left(  h^{\prime}+\alpha
t^{-1}h\right)  }_{=p}=gp$, and
\[
g\partial\rightharpoonup\left(  ht^{\alpha}\left(  dt\right)  ^{\beta}\right)
=\left(  \underbrace{gh^{\prime}+\alpha t^{-1}gh}_{=gp}+\beta g^{\prime
}h\right)  t^{\alpha}\left(  dt\right)  ^{\beta}=\left(  gp+\beta g^{\prime
}h\right)  t^{\alpha}\left(  dt\right)  ^{\beta},
\]
so that%
\begin{align}
&  f\partial\rightharpoonup\underbrace{\left(  g\partial\rightharpoonup\left(
ht^{\alpha}\left(  dt\right)  ^{\beta}\right)  \right)  }_{=\left(  gp+\beta
g^{\prime}h\right)  t^{\alpha}\left(  dt\right)  ^{\beta}}\nonumber\\
&  =f\partial\rightharpoonup\left(  \left(  gp+\beta g^{\prime}h\right)
t^{\alpha}\left(  dt\right)  ^{\beta}\right) \nonumber\\
&  =\left(  f\underbrace{\left(  gp+\beta g^{\prime}h\right)  ^{\prime}%
}_{=\left(  gp\right)  ^{\prime}+\beta\left(  g^{\prime}h\right)  ^{\prime}%
}+\underbrace{\alpha t^{-1}f\left(  gp+\beta g^{\prime}h\right)  }_{=\alpha
t^{-1}fgp+\alpha\beta t^{-1}fg^{\prime}h}+\underbrace{\beta f^{\prime}\left(
gp+\beta g^{\prime}h\right)  }_{=\beta f^{\prime}gp+\beta^{2}f^{\prime
}g^{\prime}h}\right)  t^{\alpha}\left(  dt\right)  ^{\beta}\nonumber\\
&  =\left(  \underbrace{f\left(  \left(  gp\right)  ^{\prime}+\beta\left(
g^{\prime}h\right)  ^{\prime}\right)  }_{=f\left(  gp\right)  ^{\prime}+\beta
f\left(  g^{\prime}h\right)  ^{\prime}}+\alpha t^{-1}fgp+\alpha\beta
t^{-1}fg^{\prime}h+\beta f^{\prime}gp+\beta^{2}f^{\prime}g^{\prime}h\right)
t^{\alpha}\left(  dt\right)  ^{\beta}\nonumber\\
&  =\left(  f\left(  gp\right)  ^{\prime}+\beta f\left(  g^{\prime}h\right)
^{\prime}+\alpha t^{-1}fgp+\alpha\beta t^{-1}fg^{\prime}h+\beta f^{\prime
}gp+\beta^{2}f^{\prime}g^{\prime}h\right)  t^{\alpha}\left(  dt\right)
^{\beta}. \label{sol1.1.2.var}%
\end{align}


Since the roles of $f$ and $g$ in our situation are symmetric, we can
interchange $f$ and $g$ in (\ref{sol1.1.2.var}), and obtain%
\begin{align}
&  g\partial\rightharpoonup\left(  f\partial\rightharpoonup\left(  ht^{\alpha
}\left(  dt\right)  ^{\beta}\right)  \right) \nonumber\\
&  =\left(  g\left(  fp\right)  ^{\prime}+\beta g\left(  f^{\prime}h\right)
^{\prime}+\alpha t^{-1}gfp+\alpha\beta t^{-1}gf^{\prime}h+\beta g^{\prime
}fp+\beta^{2}g^{\prime}f^{\prime}h\right)  t^{\alpha}\left(  dt\right)
^{\beta}\nonumber\\
&  =\left(  g\left(  fp\right)  ^{\prime}+\beta g\left(  f^{\prime}h\right)
^{\prime}+\alpha t^{-1}fgp+\alpha\beta t^{-1}gf^{\prime}h+\beta g^{\prime
}fp+\beta^{2}f^{\prime}g^{\prime}h\right)  t^{\alpha}\left(  dt\right)
^{\beta}. \label{sol1.1.3}%
\end{align}


Thus,%
\begin{align*}
&  \underbrace{f\partial\rightharpoonup\left(  g\partial\rightharpoonup\left(
ht^{\alpha}\left(  dt\right)  ^{\beta}\right)  \right)  }_{\substack{=\left(
f\left(  gp\right)  ^{\prime}+\beta f\left(  g^{\prime}h\right)  ^{\prime
}+\alpha t^{-1}fgp+\alpha\beta t^{-1}fg^{\prime}h+\beta f^{\prime}gp+\beta
^{2}f^{\prime}g^{\prime}h\right)  t^{\alpha}\left(  dt\right)  ^{\beta
}\\\text{(by (\ref{sol1.1.2.var}))}}}\\
&  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ -\underbrace{g\partial
\rightharpoonup\left(  f\partial\rightharpoonup\left(  ht^{\alpha}\left(
dt\right)  ^{\beta}\right)  \right)  }_{\substack{=\left(  g\left(  fp\right)
^{\prime}+\beta g\left(  f^{\prime}h\right)  ^{\prime}+\alpha t^{-1}%
fgp+\alpha\beta t^{-1}gf^{\prime}h+\beta g^{\prime}fp+\beta^{2}f^{\prime
}g^{\prime}h\right)  t^{\alpha}\left(  dt\right)  ^{\beta}\\\text{(by
(\ref{sol1.1.3}))}}}\\
&  =\left(  f\left(  gp\right)  ^{\prime}+\beta f\left(  g^{\prime}h\right)
^{\prime}+\alpha t^{-1}fgp+\alpha\beta t^{-1}fg^{\prime}h+\beta f^{\prime
}gp+\beta^{2}f^{\prime}g^{\prime}h\right)  t^{\alpha}\left(  dt\right)
^{\beta}\\
&  \ \ \ \ \ \ \ \ \ \ -\left(  g\left(  fp\right)  ^{\prime}+\beta g\left(
f^{\prime}h\right)  ^{\prime}+\alpha t^{-1}fgp+\alpha\beta t^{-1}gf^{\prime
}h+\beta g^{\prime}fp+\beta^{2}f^{\prime}g^{\prime}h\right)  t^{\alpha}\left(
dt\right)  ^{\beta}\\
&  =\left(  \left(  f\left(  gp\right)  ^{\prime}+\beta f\left(  g^{\prime
}h\right)  ^{\prime}+\alpha t^{-1}fgp+\alpha\beta t^{-1}fg^{\prime}h+\beta
f^{\prime}gp+\beta^{2}f^{\prime}g^{\prime}h\right)  \right. \\
&  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left.  -\left(  g\left(
fp\right)  ^{\prime}+\beta g\left(  f^{\prime}h\right)  ^{\prime}+\alpha
t^{-1}fgp+\alpha\beta t^{-1}gf^{\prime}h+\beta g^{\prime}fp+\beta^{2}%
f^{\prime}g^{\prime}h\right)  \right)  t^{\alpha}\left(  dt\right)  ^{\beta}\\
&  =\left(  \underbrace{f\left(  gp\right)  ^{\prime}-g\left(  fp\right)
^{\prime}}_{\substack{=qp\\\text{(by (\ref{sol1.1.fgh2}))}}}+\underbrace{\beta
f\left(  g^{\prime}h\right)  ^{\prime}-\beta g\left(  f^{\prime}h\right)
^{\prime}}_{=\beta\left(  f\left(  g^{\prime}h\right)  ^{\prime}-g\left(
f^{\prime}h\right)  ^{\prime}\right)  }+\underbrace{\alpha\beta t^{-1}%
fg^{\prime}h-\alpha\beta t^{-1}gf^{\prime}h}_{=\alpha\beta t^{-1}\left(
fg^{\prime}-gf^{\prime}\right)  h}+\underbrace{\beta f^{\prime}gp-\beta
g^{\prime}fp}_{=\beta\left(  f^{\prime}g-g^{\prime}f\right)  p}\right) \\
&  \ \ \ \ \ \ \ \ \ \ t^{\alpha}\left(  dt\right)  ^{\beta}\\
&  =\left(  qp+\beta\underbrace{\left(  f\left(  g^{\prime}h\right)  ^{\prime
}-g\left(  f^{\prime}h\right)  ^{\prime}\right)  }_{\substack{=q^{\prime
}h+qh^{\prime}\\\text{(by (\ref{sol1.1.fgh}))}}}+\alpha\beta t^{-1}%
\underbrace{\left(  fg^{\prime}-gf^{\prime}\right)  }_{=q}h+\beta
\underbrace{\left(  f^{\prime}g-g^{\prime}f\right)  }%
_{\substack{=-q\\\text{(since }q=fg^{\prime}-gf^{\prime}=g^{\prime}%
f-f^{\prime}g\text{)}}}p\right)  t^{\alpha}\left(  dt\right)  ^{\beta}\\
&  =\left(  qp+\underbrace{\beta\left(  q^{\prime}h+qh^{\prime}\right)
}_{=\beta q^{\prime}h+\beta qh^{\prime}}+\alpha\beta t^{-1}%
qh+\underbrace{\beta\left(  -q\right)  p}_{=-\beta qp}\right)  t^{\alpha
}\left(  dt\right)  ^{\beta}\\
&  =\left(  qp+\beta q^{\prime}h+\underbrace{\beta qh^{\prime}+\alpha\beta
t^{-1}qh}_{=\beta q\left(  h^{\prime}+\alpha t^{-1}h\right)  }-\beta
qp\right)  t^{\alpha}\left(  dt\right)  ^{\beta}\\
&  =\left(  qp+\beta q^{\prime}h+\beta q\underbrace{\left(  h^{\prime}+\alpha
t^{-1}h\right)  }_{=p}-\beta qp\right)  t^{\alpha}\left(  dt\right)  ^{\beta
}\\
&  =\left(  qp+\beta q^{\prime}h+\underbrace{\beta qp-\beta qp}_{=0}\right)
t^{\alpha}\left(  dt\right)  ^{\beta}=\left(  qp+\beta q^{\prime}h\right)
t^{\alpha}\left(  dt\right)  ^{\beta}=\left[  f\partial,g\partial\right]
\rightharpoonup\left(  ht^{\alpha}\left(  dt\right)  ^{\beta}\right)  .
\end{align*}


Thus, (\ref{sol1.1.1}) is proven for any Laurent polynomials $f$, $g$ and $h$.
This proves that the formula (\ref{ex1.1.1}) defines an action of $W$ on
$V_{\alpha,\beta}$. Hence, $V_{\alpha,\beta}$ becomes a $W$-module, i. e., a
$\operatorname*{Vir}$-module with $C$ acting as $0$. (In other words,
$V_{\alpha,\beta}$ becomes a $\operatorname*{Vir}$-module with central charge
$0$.) This proves Proposition \ref{prop.Vab.1} \textbf{(a)}.

\textbf{(b)} We only need to prove (\ref{ex1.1.2.var}).

Let $m\in\mathbb{Z}$ and $k\in\mathbb{Z}$. Then, $v_{k}=t^{-k+\alpha}\left(
dt\right)  ^{\beta}=t^{-k}t^{\alpha}\left(  dt\right)  ^{\beta}$ and
$v_{k-m}=t^{-\left(  k-m\right)  +\alpha}\left(  dt\right)  ^{\beta}%
=t^{m-k}t^{\alpha}\left(  dt\right)  ^{\beta}$. Thus,%
\begin{align*}
&  \underbrace{L_{m}}_{=-t^{m+1}\partial}\rightharpoonup\underbrace{v_{k}%
}_{=t^{-k}t^{\alpha}\left(  dt\right)  ^{\beta}}\\
&  =\left(  -t^{m+1}\partial\right)  \rightharpoonup\left(  t^{-k}t^{\alpha
}\left(  dt\right)  ^{\beta}\right) \\
&  =\left(  -t^{m+1}\underbrace{\left(  t^{-k}\right)  ^{\prime}}%
_{=-kt^{-k-1}}+\underbrace{\alpha t^{-1}\left(  -t^{m+1}\right)  t^{-k}%
}_{=-\alpha t^{-1}t^{m+1}t^{-k}}+\beta\underbrace{\left(  -t^{m+1}\right)
^{\prime}}_{=-\left(  m+1\right)  t^{m}}t^{-k}\right)  t^{\alpha}\left(
dt\right)  ^{\beta}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{ex1.1.1}), applied to
}f=-t^{m+1}\text{ and }g=t^{-k}\right) \\
&  =\left(  -\left(  -k\right)  \underbrace{t^{m+1}t^{-k-1}}_{=t^{m-k}}%
-\alpha\underbrace{t^{-1}t^{m+1}t^{-k}}_{=t^{\left(  -1\right)  +\left(
m+1\right)  +\left(  -k\right)  }=t^{m-k}}+\beta\left(  -\left(  m+1\right)
\right)  \underbrace{t^{m}t^{-k}}_{=t^{m-k}}\right)  t^{\alpha}\left(
dt\right)  ^{\beta}\\
&  =\left(  kt^{m-k}-\alpha t^{m-k}+\beta\left(  -\left(  m+1\right)  \right)
t^{m-k}\right)  t^{\alpha}\left(  dt\right)  ^{\beta}\\
&  =\underbrace{\left(  k-\alpha+\beta\left(  -\left(  m+1\right)  \right)
\right)  }_{=k-\alpha-\left(  m+1\right)  \beta}\underbrace{t^{m-k}t^{\alpha
}\left(  dt\right)  ^{\beta}}_{=v_{k-m}}=\left(  k-\alpha-\left(  m+1\right)
\beta\right)  v_{k-m}.
\end{align*}
This proves (\ref{ex1.1.2.var}). Proposition \ref{prop.Vab.1} \textbf{(b)} is proven.

The representations $V_{\alpha,\beta}$ are not all pairwise non-isomorphic,
but there are still uncountably many non-isomorphic ones among them. More precisely:

\begin{proposition}
\label{prop.Vab.iso}\textbf{(a)} For every $\ell\in\mathbb{Z}$, $\alpha
\in\mathbb{C}$ and $\beta\in\mathbb{C}$, the $\mathbb{C}$-linear map%
\begin{align*}
V_{\alpha,\beta}  &  \rightarrow V_{\alpha+\ell,\beta},\\
gt^{\alpha}\left(  dt\right)  ^{\beta}  &  \mapsto\left(  gt^{-\ell}\right)
t^{\alpha+\ell}\left(  dt\right)  ^{\beta}%
\end{align*}
is an isomorphism of $\operatorname*{Vir}$-modules. (This map sends $v_{k}$ to
$v_{k+\ell}$ for every $k\in\mathbb{Z}$.)

\textbf{(b)} For every $\alpha\in\mathbb{C}$, the $\mathbb{C}$-linear map%
\begin{align*}
V_{\alpha,0}  &  \rightarrow V_{\alpha-1,1},\\
gt^{\alpha}\left(  dt\right)  ^{0}  &  \mapsto\left(  -g^{\prime}t-\alpha
g\right)  t^{\alpha-1}\left(  dt\right)  ^{1}%
\end{align*}
is a homomorphism of $\operatorname*{Vir}$-modules. (This map sends $v_{k}$ to
$\left(  k-\alpha\right)  v_{k}$ for every $k\in\mathbb{Z}$.) If $\alpha
\notin\mathbb{Z}$, then this map is an isomorphism.

\textbf{(c)} Let $\left(  \alpha,\beta,\alpha^{\prime},\beta^{\prime}\right)
\in\mathbb{C}^{4}$. Then, $V_{\alpha,\beta}\cong V_{\alpha^{\prime}%
,\beta^{\prime}}$ as $\operatorname*{Vir}$-modules if and only if either
$\left(  \beta=\beta^{\prime}\text{ and }\alpha-\alpha^{\prime}\in
\mathbb{Z}\right)  $ or $\left(  \beta=0\text{, }\beta^{\prime}=1\text{,
}\alpha-\alpha^{\prime}\in\mathbb{Z}\text{ and }\alpha\notin\mathbb{Z}\right)
$ or $\left(  \beta=1\text{, }\beta^{\prime}=0\text{, }\alpha-\alpha^{\prime
}\in\mathbb{Z}\text{ and }\alpha\notin\mathbb{Z}\right)  $.
\end{proposition}

\textit{Proof of Proposition \ref{prop.Vab.iso} (sketched).} \textbf{(a)} and
\textbf{(b)} Very easy and left to the reader.

\textbf{(c)} The $\Longleftarrow$ direction is handled by parts \textbf{(a)}
and \textbf{(b)}.

$\Longrightarrow:$ Assume that $V_{\alpha,\beta}\cong V_{\alpha^{\prime}%
,\beta^{\prime}}$ as $\operatorname*{Vir}$-modules. We must prove that either
$\left(  \beta=\beta^{\prime}\text{ and }\alpha-\alpha^{\prime}\in
\mathbb{Z}\right)  $ or $\left(  \beta=0\text{, }\beta^{\prime}=1\text{,
}\alpha-\alpha^{\prime}\in\mathbb{Z}\text{ and }\alpha\notin\mathbb{Z}\right)
$ or $\left(  \beta=1\text{, }\beta^{\prime}=0\text{, }\alpha-\alpha^{\prime
}\in\mathbb{Z}\text{ and }\alpha\notin\mathbb{Z}\right)  $.

Let $\Phi$ be the $\operatorname*{Vir}$-module isomorphism $V_{\alpha,\beta
}\rightarrow V_{\alpha^{\prime},\beta^{\prime}}$.

Applying (\ref{ex1.1.2.var}) to $m=0$, we obtain%
\begin{equation}
L_{0}v_{k}=\left(  k-\alpha-\beta\right)  v_{k}\text{ in }V_{\alpha,\beta
}\ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{Z}. \label{pf.Vab.iso.1}%
\end{equation}
Hence, $L_{0}$ acts on $V_{\alpha,\beta}$ as a diagonal matrix with
eigenvalues $k-\alpha-\beta$ for all $k\in\mathbb{Z}$, each eigenvalue
appearing exactly once. Similarly, applying (\ref{ex1.1.2.var}) to $0$ and
$\left(  \alpha^{\prime},\beta^{\prime}\right)  $ instead of $m$ and $\left(
\alpha,\beta\right)  $, we obtain%
\begin{equation}
L_{0}v_{k}=\left(  k-\alpha^{\prime}-\beta^{\prime}\right)  v_{k}\text{ in
}V_{\alpha^{\prime},\beta^{\prime}}\ \ \ \ \ \ \ \ \ \ \text{for every }%
k\in\mathbb{Z}. \label{pf.Vab.iso.2}%
\end{equation}
Thus, $L_{0}$ acts on $V_{\alpha^{\prime},\beta^{\prime}}$ as a diagonal
matrix with eigenvalues $k-\alpha^{\prime}-\beta^{\prime}$ for all
$k\in\mathbb{Z}$, each eigenvalue appearing exactly once.

But since $V_{\alpha,\beta}\cong V_{\alpha^{\prime},\beta^{\prime}}$ as
$\operatorname*{Vir}$-modules, the eigenvalues of $L_{0}$ acting on
$V_{\alpha,\beta}$ must be the same as the eigenvalues of $L_{0}$ acting on
$V_{\alpha^{\prime},\beta^{\prime}}$. In other words,%
\[
\left\{  k-\alpha-\beta\ \mid\ k\in\mathbb{Z}\right\}  =\left\{
k-\alpha^{\prime}-\beta^{\prime}\ \mid\ k\in\mathbb{Z}\right\}
\]
(because we know that the eigenvalues of $L_{0}$ acting on $V_{\alpha,\beta}$
are $k-\alpha-\beta$ for all $k\in\mathbb{Z}$, while the eigenvalues of
$L_{0}$ acting on $V_{\alpha^{\prime},\beta^{\prime}}$ are $k-\alpha^{\prime
}-\beta^{\prime}$ for all $k\in\mathbb{Z}$). Hence, $\left(  \alpha
+\beta\right)  -\left(  \alpha^{\prime}+\beta^{\prime}\right)  \in\mathbb{Z}$.
Since we can shift $\alpha$ by an arbitrary integer without changing the
isomorphism class of $V_{\alpha,\beta}$ (due to part \textbf{(a)}), we can
thus WLOG assume that $\alpha+\beta=\alpha^{\prime}+\beta^{\prime}$.

Let us once again look at the equality (\ref{pf.Vab.iso.1}). This equality
tells us that, for each $k\in\mathbb{Z}$, the vector $v_{k}$ is the unique (up
to scaling) eigenvector of the operator $L_{0}$ with eigenvalue $k-\alpha
-\beta$ in $V_{\alpha,\beta}$. The isomorphism $\Phi$ (being
$\operatorname*{Vir}$-linear) must map this vector $v_{k}$ to an eigenvector
of the operator $L_{0}$ with eigenvalue $k-\alpha-\beta$ in $V_{\alpha
^{\prime},\beta^{\prime}}$. Since $\alpha+\beta=\alpha^{\prime}+\beta^{\prime
}$, this eigenvalue equals $k-\alpha^{\prime}-\beta^{\prime}$. But (due to
(\ref{pf.Vab.iso.2})) the unique (up to scaling) eigenvector of the operator
$L_{0}$ with eigenvalue $k-\alpha^{\prime}-\beta^{\prime}$ in $V_{\alpha
^{\prime},\beta^{\prime}}$ is $v_{k}$. Hence, $\Phi\left(  v_{k}\right)  $
must equal $v_{k}$ up to scaling, i. e., there exists a nonzero complex number
$\lambda_{k}$ such that $\Phi\left(  v_{k}\right)  =\lambda_{k}v_{k}$.

Now, let $m\in\mathbb{Z}$ and $k\in\mathbb{Z}$. Then, in $V_{\alpha,\beta}$,
we have%
\[
L_{m}v_{k}=\left(  k-\alpha-\beta\left(  m+1\right)  \right)  v_{k-m},
\]
so that%
\begin{align*}
\Phi\left(  L_{m}v_{k}\right)   &  =\Phi\left(  \left(  k-\alpha-\beta\left(
m+1\right)  \right)  v_{k-m}\right)  =\left(  k-\alpha-\beta\left(
m+1\right)  \right)  \underbrace{\Phi\left(  v_{k-m}\right)  }_{=\lambda
_{k-m}v_{k-m}}\\
&  =\lambda_{k-m}\left(  k-\alpha-\beta\left(  m+1\right)  \right)  v_{k-m}%
\end{align*}
in $V_{\alpha^{\prime},\beta^{\prime}}$. Compared with%
\begin{align*}
\Phi\left(  L_{m}v_{k}\right)   &  =L_{m}\underbrace{\Phi\left(  v_{k}\right)
}_{=\lambda_{k}v_{k}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\Phi\text{ is
}\operatorname*{Vir}\text{-linear}\right) \\
&  =\lambda_{k}\underbrace{L_{m}v_{k}}_{=\left(  k-\alpha^{\prime}%
-\beta^{\prime}\left(  m+1\right)  \right)  v_{k-m}}=\lambda_{k}\left(
k-\alpha^{\prime}-\beta^{\prime}\left(  m+1\right)  \right)  v_{k-m}%
\end{align*}
in $V_{\alpha^{\prime},\beta^{\prime}}$, this yields%
\[
\lambda_{k-m}\left(  k-\alpha-\beta\left(  m+1\right)  \right)  v_{k-m}%
=\lambda_{k}\left(  k-\alpha^{\prime}-\beta^{\prime}\left(  m+1\right)
\right)  v_{k-m}.
\]
Since $v_{k-m}\neq0$, this yields%
\begin{equation}
\lambda_{k-m}\left(  k-\alpha-\beta\left(  m+1\right)  \right)  =\lambda
_{k}\left(  k-\alpha^{\prime}-\beta^{\prime}\left(  m+1\right)  \right)  .
\label{pf.Vab.iso.5a}%
\end{equation}


Now, any $m\in\mathbb{Z}$, $k\in\mathbb{Z}$ and $n\in\mathbb{Z}$ satisfy%
\begin{equation}
\lambda_{k-\left(  n+m\right)  }\left(  k-\alpha-\beta\left(  m+1\right)
\right)  =\lambda_{k}\left(  k-\alpha^{\prime}-\beta^{\prime}\left(
n+m+1\right)  \right)  \label{pf.Vab.iso.5b}%
\end{equation}
(by (\ref{pf.Vab.iso.5a}), applied to $n+m$ instead of $m$) and%
\begin{equation}
\lambda_{k-m-n}\left(  k-m-\alpha-\beta\left(  n+1\right)  \right)
=\lambda_{k-m}\left(  k-m-\alpha^{\prime}-\beta^{\prime}\left(  n+1\right)
\right)  \label{pf.Vab.iso.5c}%
\end{equation}
(by (\ref{pf.Vab.iso.5a}), applied to $k-m$ and $n$ instead of $k$ and $m$).
Hence, any $m\in\mathbb{Z}$, $k\in\mathbb{Z}$ and $n\in\mathbb{Z}$ satisfy
\begin{align*}
&  \lambda_{k}\lambda_{k-m}\lambda_{k-m-n}\cdot\left(  k-\alpha^{\prime}%
-\beta^{\prime}\left(  n+m+1\right)  \right)  \cdot\left(  k-\alpha
-\beta\left(  m+1\right)  \right)  \cdot\left(  k-m-\alpha-\beta\left(
n+1\right)  \right) \\
&  =\underbrace{\lambda_{k}\left(  k-\alpha^{\prime}-\beta^{\prime}\left(
n+m+1\right)  \right)  }_{\substack{=\lambda_{k-\left(  n+m\right)  }\left(
k-\alpha-\beta\left(  m+1\right)  \right)  \\\text{(by (\ref{pf.Vab.iso.5b}%
))}}}\cdot\underbrace{\lambda_{k-m}\left(  k-\alpha-\beta\left(  m+1\right)
\right)  }_{\substack{=\lambda_{k}\left(  k-\alpha^{\prime}-\beta^{\prime
}\left(  m+1\right)  \right)  \\\text{(by (\ref{pf.Vab.iso.5a}))}}%
}\cdot\underbrace{\lambda_{k-m-n}\left(  k-m-\alpha-\beta\left(  n+1\right)
\right)  }_{\substack{=\lambda_{k-m}\left(  k-m-\alpha^{\prime}-\beta^{\prime
}\left(  n+1\right)  \right)  \\\text{(by (\ref{pf.Vab.iso.5c}))}}}\\
&  =\lambda_{k-\left(  n+m\right)  }\left(  k-\alpha-\beta\left(  m+1\right)
\right)  \cdot\lambda_{k}\left(  k-\alpha^{\prime}-\beta^{\prime}\left(
m+1\right)  \right)  \cdot\lambda_{k-m}\left(  k-m-\alpha^{\prime}%
-\beta^{\prime}\left(  n+1\right)  \right) \\
&  =\lambda_{k}\lambda_{k-m}\underbrace{\lambda_{k-\left(  n+m\right)  }%
}_{=\lambda_{k-m-n}}\cdot\left(  k-\alpha-\beta\left(  n+m+1\right)  \right)
\cdot\left(  k-\alpha^{\prime}-\beta^{\prime}\left(  m+1\right)  \right)
\cdot\left(  k-m-\alpha^{\prime}-\beta^{\prime}\left(  n+1\right)  \right) \\
&  =\lambda_{k}\lambda_{k-m}\lambda_{k-m-n}\cdot\left(  k-\alpha-\beta\left(
n+m+1\right)  \right)  \cdot\left(  k-\alpha^{\prime}-\beta^{\prime}\left(
m+1\right)  \right)  \cdot\left(  k-m-\alpha^{\prime}-\beta^{\prime}\left(
n+1\right)  \right)  .
\end{align*}
We can divide this equality by $\lambda_{k}\lambda_{k-m}\lambda_{k-m-n}$
(since $\lambda_{i}\neq0$ for every $i\in\mathbb{Z}$, and therefore we have
$\lambda_{k}\lambda_{k-m}\lambda_{k-m-n}\neq0$), and thus obtain that any
$m\in\mathbb{Z}$, $k\in\mathbb{Z}$ and $n\in\mathbb{Z}$ satisfy
\begin{align*}
&  \left(  k-\alpha^{\prime}-\beta^{\prime}\left(  n+m+1\right)  \right)
\cdot\left(  k-\alpha-\beta\left(  m+1\right)  \right)  \cdot\left(
k-m-\alpha-\beta\left(  n+1\right)  \right) \\
&  =\left(  k-\alpha-\beta\left(  n+m+1\right)  \right)  \cdot\left(
k-\alpha^{\prime}-\beta^{\prime}\left(  m+1\right)  \right)  \cdot\left(
k-m-\alpha^{\prime}-\beta^{\prime}\left(  n+1\right)  \right)  .
\end{align*}
Since $\mathbb{Z}^{3}$ is Zariski-dense in $\mathbb{C}^{3}$, this yields that
\begin{align*}
&  \left(  X-\alpha^{\prime}-\beta^{\prime}\left(  Y+Z+1\right)  \right)
\cdot\left(  X-\alpha-\beta\left(  Z+1\right)  \right)  \cdot\left(
X-Z-\alpha-\beta\left(  Y+1\right)  \right) \\
&  =\left(  X-\alpha-\beta\left(  Y+Z+1\right)  \right)  \cdot\left(
X-\alpha^{\prime}-\beta^{\prime}\left(  Z+1\right)  \right)  \cdot\left(
X-Z-\alpha^{\prime}-\beta^{\prime}\left(  Y+1\right)  \right)  .
\end{align*}
holds as a polynomial identity in the polynomial ring $\mathbb{C}\left[
X,Y,Z\right]  $.

If we compare coefficients before $XYZ$ in this polynomial identity, we get an
equation which easily simplifies to $\left(  \beta-\beta^{\prime}\right)
\left(  \beta+\beta^{\prime}-1\right)  =0$. If we compare coefficients before
$YZ^{2}$ in the same identity, we similarly obtain $\beta\beta^{\prime}\left(
\beta-\beta^{\prime}\right)  =0$.

If $\beta=\beta^{\prime}$, then $\alpha=\alpha^{\prime}$ (since $\alpha
+\beta=\alpha^{\prime}+\beta^{\prime}$), and thus we are done. Hence, let us
assume that $\beta\neq\beta^{\prime}$ for the rest of this proof. Then,
$\left(  \beta-\beta^{\prime}\right)  \left(  \beta+\beta^{\prime}-1\right)
=0$ simplifies to $\beta+\beta^{\prime}-1=0$, and $\beta\beta^{\prime}\left(
\beta-\beta^{\prime}\right)  =0$ simplifies to $\beta\beta^{\prime}=0$.
Combining these two equations, we see that either $\left(  \beta=0\text{ and
}\beta^{\prime}=1\right)  $ or $\left(  \beta=1\text{ and }\beta^{\prime
}=0\right)  $. Assume WLOG that $\left(  \beta=0\text{ and }\beta^{\prime
}=1\right)  $ (otherwise, just switch $\left(  \alpha,\beta\right)  $ with
$\left(  \alpha^{\prime},\beta^{\prime}\right)  $). From $\alpha+\beta
=\alpha^{\prime}+\beta^{\prime}$, we obtain $\alpha-\alpha^{\prime
}=\underbrace{\beta^{\prime}}_{=1}-\underbrace{\beta}_{=0}=1\in\mathbb{Z}$. If
we are able to prove that $\alpha\notin\mathbb{Z}$, then we can conclude that
$\left(  \beta=0\text{, }\beta^{\prime}=1\text{, }\alpha-\alpha^{\prime}%
\in\mathbb{Z}\text{ and }\alpha\notin\mathbb{Z}\right)  $, and thus we are
done. So let us show that $\alpha\notin\mathbb{Z}$.

In fact, assume the opposite. Then, $\alpha\in\mathbb{Z}$, so that $v_{\alpha
}$ is well-defined in $V_{\alpha,\beta}$ and in $V_{\alpha^{\prime}%
,\beta^{\prime}}$. Then, (\ref{ex1.1.2.var}) yields that every $m\in
\mathbb{Z}$ satisfies
\[
L_{m}v_{\alpha}=\left(  \underbrace{\alpha-\alpha}_{=0}-\underbrace{\beta
}_{=0}\left(  m+1\right)  \right)  v_{\alpha-m}=0\text{ in }V_{\alpha,\beta}.
\]
Thus, every $m\in\mathbb{Z}$ satisfies $\Phi\left(  L_{m}v_{\alpha}\right)
=\Phi\left(  0\right)  =0$, so that $0=\Phi\left(  L_{m}v_{\alpha}\right)
=L_{m}\underbrace{\Phi\left(  v_{\alpha}\right)  }_{=\lambda_{\alpha}%
v_{\alpha}}=\lambda_{\alpha}L_{m}v_{\alpha}$ in $V_{\alpha^{\prime}%
,\beta^{\prime}}$, and thus $0=L_{m}v_{\alpha}$ in $V_{\alpha^{\prime}%
,\beta^{\prime}}$ (since $\lambda_{\alpha}\neq0$). But since
(\ref{ex1.1.2.var}) yields%
\[
L_{m}v_{\alpha}=\left(  \alpha-\alpha^{\prime}-\underbrace{\beta^{\prime}%
}_{=1}\left(  m+1\right)  \right)  \underbrace{v_{\alpha-\alpha}}_{=v_{0}%
}=\left(  \alpha-\alpha^{\prime}-\left(  m+1\right)  \right)  v_{0}\text{ in
}V_{\alpha^{\prime},\beta^{\prime}},
\]
this rewrites as $0=\left(  \alpha-\alpha^{\prime}-\left(  m+1\right)
\right)  v_{0}$, so that $0=\alpha-\alpha^{\prime}-\left(  m+1\right)  $. But
this cannot hold for every $m\in\mathbb{Z}$. This contradiction shows that our
assumption (that $\alpha\in\mathbb{Z}$) was wrong. Thus, $\alpha
\notin\mathbb{Z}$, and our proof of the $\Longrightarrow$ direction is finally
done. Proposition \ref{prop.Vab.iso} \textbf{(c)} is finally proven.

Proving Proposition \ref{prop.Vab.iso} was one part of Homework Set 1 exercise
2; the other was the following:

\begin{proposition}
\label{prop.Vab.irr}Let $\alpha\in\mathbb{C}$ and $\beta\in\mathbb{C}$. Then,
the $\operatorname*{Vir}$-module $V_{\alpha,\beta}$ is not irreducible if and
only if $\left(  \alpha\in\mathbb{Z}\text{ and }\beta\in\left\{  0,1\right\}
\right)  $.
\end{proposition}

We will not prove this; the interested reader is referred to Proposition 1.1
in \S 1.2 of Kac-Raina.

\begin{remark}
\label{rmk.Vab.adj}Consider the $\operatorname*{Vir}$-module
$\operatorname*{Vir}$ (with the adjoint action). Since $\left\langle
C\right\rangle $ is a $\operatorname*{Vir}$-submodule of $\operatorname*{Vir}%
$, we obtain a $\operatorname*{Vir}$-module $\operatorname*{Vir}%
\diagup\left\langle C\right\rangle $. This $\operatorname*{Vir}$-module is
isomorphic to $V_{1,-1}$. More precisely, the $\mathbb{C}$-linear map%
\begin{align*}
\operatorname*{Vir}\diagup\left\langle C\right\rangle  &  \rightarrow
V_{1,-1},\\
\overline{L_{n}}  &  \mapsto v_{-n}%
\end{align*}
is a $\operatorname*{Vir}$-module isomorphism. Thus, $\operatorname*{Vir}%
\diagup\left\langle C\right\rangle \cong V_{1,-1}\cong V_{\alpha,-1}$ as
$\operatorname*{Vir}$-modules for every $\alpha\in\mathbb{Z}$ (because of
Proposition \ref{prop.Vab.iso} \textbf{(a)}).
\end{remark}

\subsection{Some consequences of Poincar\'{e}-Birkhoff-Witt}

We will now spend some time with generalities on Lie algebras and their
universal enveloping algebras. These generalities will be applied later, and
while these applications could be substituted by concrete computations, it
appears to me that it is better for the sake of clarity to do them generally
in here.

\begin{proposition}
\label{prop.U(X)U}Let $k$ be a field. Let $\mathfrak{c}$ be a $k$-Lie algebra.
Let $\mathfrak{a}$ and $\mathfrak{b}$ be two Lie subalgebras of $\mathfrak{c}$
such that $\mathfrak{a}+\mathfrak{b}=\mathfrak{c}$. Notice that $\mathfrak{a}%
\cap\mathfrak{b}$ is also a Lie subalgebra of $\mathfrak{c}$.

Let $\rho:U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  \rightarrow U\left(
\mathfrak{c}\right)  $ be the $k$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\beta\right)  =\alpha\beta\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in
U\left(  \mathfrak{a}\right)  \text{ and }\beta\in U\left(  \mathfrak{b}%
\right)
\]
(this is clearly well-defined). Then, $\rho$ is an isomorphism of filtered
vector spaces, of left $U\left(  \mathfrak{a}\right)  $-modules and of right
$U\left(  \mathfrak{b}\right)  $-modules.
\end{proposition}

\begin{corollary}
\label{cor.U(X)U}Let $k$ be a field. Let $\mathfrak{c}$ be a $k$-Lie algebra.
Let $\mathfrak{a}$ and $\mathfrak{b}$ be two Lie subalgebras of $\mathfrak{c}$
such that $\mathfrak{a}\oplus\mathfrak{b}=\mathfrak{c}$ (as vector spaces, not
necessarily as Lie algebras). Let $\rho:U\left(  \mathfrak{a}\right)
\otimes_{k}U\left(  \mathfrak{b}\right)  \rightarrow U\left(  \mathfrak{c}%
\right)  $ be the $k$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes\beta\right)  =\alpha\beta
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in U\left(  \mathfrak{a}\right)
\text{ and }\beta\in U\left(  \mathfrak{b}\right)
\]
(this is clearly well-defined). Then, $\rho$ is an isomorphism of filtered
vector spaces, of left $U\left(  \mathfrak{a}\right)  $-modules and of right
$U\left(  \mathfrak{b}\right)  $-modules.
\end{corollary}

We give two proofs of Proposition \ref{prop.U(X)U}. They are very similar
(both use the Poincar\'{e}-Birkhoff-Witt theorem, albeit different versions
thereof). The first is more conceptual (and more general), while the second is
more down-to-earth.

\textit{First proof of Proposition \ref{prop.U(X)U}.} For any Lie algebra
$\mathfrak{u}$, we have a $k$-algebra homomorphism $\operatorname*{PBW}%
\nolimits_{\mathfrak{u}}:S\left(  \mathfrak{u}\right)  \rightarrow
\operatorname*{gr}\left(  U\left(  \mathfrak{u}\right)  \right)  $ which sends
$u_{1}u_{2}...u_{\ell}$ to $\overline{u_{1}u_{2}...u_{\ell}}\in
\operatorname*{gr}\nolimits_{\ell}\left(  U\left(  \mathfrak{u}\right)
\right)  $ for every $\ell\in\mathbb{N}$ and every $u_{1},u_{2},...,u_{\ell
}\in\mathfrak{u}$. This homomorphism $\operatorname*{PBW}%
\nolimits_{\mathfrak{u}}$ is an isomorphism due to the
Poincar\'{e}-Birkhoff-Witt theorem.

\begin{verlong}
It is rather clear that $\operatorname*{gr}\left(  U\left(  \mathfrak{a}%
\right)  \right)  $ and $\operatorname*{gr}\left(  U\left(  \mathfrak{b}%
\right)  \right)  $ are $\operatorname*{gr}\left(  U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  \right)  $-modules (since $U\left(  \mathfrak{a}%
\right)  $ and $U\left(  \mathfrak{b}\right)  $ are filtered $U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  $-modules)
\end{verlong}

We can define a $k$-algebra homomorphism $f:\operatorname*{gr}\left(  U\left(
\mathfrak{a}\right)  \right)  \otimes_{\operatorname*{gr}\left(  U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \right)  }\operatorname*{gr}\left(
U\left(  \mathfrak{b}\right)  \right)  \rightarrow\operatorname*{gr}\left(
U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  \right)  $ by
\[
f\left(  \overline{u}\otimes_{\operatorname*{gr}\left(  U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \right)  }\overline{v}\right)
=\overline{u\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }v}%
\in\operatorname*{gr}\nolimits_{k+\ell}\left(  U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \right)
\]
for any $k\in\mathbb{N}$, any $\ell\in\mathbb{N}$, any $u\in U_{\leq k}\left(
\mathfrak{a}\right)  $ and $v\in U_{\leq\ell}\left(  \mathfrak{b}\right)  $.
This $f$ is easily seen to be well-defined. Moreover, $f$ is
surjective\footnote{To show this, either notice that the image of $f$ contains
a generating set of $\operatorname*{gr}\left(  U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \right)  $ (because the definition of $f$ easily rewrites
as
\par%
\[
f\left(  \overline{\alpha_{1}\alpha_{2}...\alpha_{k}}\otimes
_{\operatorname*{gr}\left(  U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
\right)  }\overline{\beta_{1}\beta_{2}...\beta_{\ell}}\right)  =\overline
{\alpha_{1}\alpha_{2}...\alpha_{k}\otimes_{U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }\beta_{1}\beta_{2}...\beta_{\ell}}\in
\operatorname*{gr}\nolimits_{k+\ell}\left(  U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \right)
\]
for any $k\in\mathbb{N}$, any $\ell\in\mathbb{N}$, any $\alpha_{1},\alpha
_{2},...,\alpha_{k}\in\mathfrak{a}$ and $\beta_{1},\beta_{2},...,\beta_{\ell
}\in\mathfrak{b}$), or prove the more general fact that for any $\mathbb{Z}%
_{+}$-filtered algebra $A$, any filtered right $A$-module $M$ and any filtered
left $A$-module $N$, the canonical map%
\begin{align*}
\operatorname*{gr}\left(  M\right)  \otimes_{\operatorname*{gr}\left(
A\right)  }\operatorname*{gr}\left(  N\right)   &  \rightarrow
\operatorname*{gr}\left(  M\otimes_{A}N\right)  ,\\
\overline{\mu}\otimes_{\operatorname*{gr}\left(  A\right)  }\overline{\nu}  &
\mapsto\overline{\mu\otimes_{A}\nu}\in\operatorname*{gr}\nolimits_{m+n}\left(
M\otimes_{A}N\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{for all }\mu\in
M_{m}\text{ and }\nu\in N_{n}\text{, for all }m,n\in\mathbb{N}\right)
\end{align*}
is well-defined and surjective (this is easy to prove).}.

It is easy to see that the isomorphisms $\operatorname*{PBW}%
\nolimits_{\mathfrak{a}}:S\left(  \mathfrak{a}\right)  \rightarrow
\operatorname*{gr}\left(  U\left(  \mathfrak{a}\right)  \right)  $,
$\operatorname*{PBW}\nolimits_{\mathfrak{b}}:S\left(  \mathfrak{b}\right)
\rightarrow\operatorname*{gr}\left(  U\left(  \mathfrak{b}\right)  \right)  $
and $\operatorname*{PBW}\nolimits_{\mathfrak{a}\cap\mathfrak{b}}:S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \rightarrow\operatorname*{gr}\left(
U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  \right)  $ are ``compatible''
with each other in the sense that the diagrams%
\[%
%TCIMACRO{\TeXButton{X}{\xycs{12pc}
%\xymatrix{
%S\left(\fraka\right) \otimes S\left(\fraka\cap\frakb\right) \ar[r]^-{\text
%{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\fraka\right)}
%\ar[d]_{\PBW_{\fraka}\otimes\PBW_{\fraka\cap\frakb}}^{\cong} & S\left
%(\fraka\right) \ar[d]_{\PBW_{\fraka}}^{\cong} \\
%\gr\left(U\left(\fraka\right)\right) \otimes\gr\left(U\left(\fraka\cap
%\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
%\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\fraka\right)\right)}
%& \gr\left(U\left(\fraka\right)\right)
%}}}%
%BeginExpansion
\xycs{12pc}
\xymatrix{
S\left(\fraka\right) \otimes S\left(\fraka\cap\frakb\right) \ar[r]^-{\text
{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\fraka\right)}
\ar[d]_{\PBW_{\fraka}\otimes\PBW_{\fraka\cap\frakb}}^{\cong} & S\left
(\fraka\right) \ar[d]_{\PBW_{\fraka}}^{\cong} \\
\gr\left(U\left(\fraka\right)\right) \otimes\gr\left(U\left(\fraka\cap
\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\fraka\right)\right)}
& \gr\left(U\left(\fraka\right)\right)
}%
%EndExpansion
\]
and%
\[%
%TCIMACRO{\TeXButton{X}{\xycs{12pc}
%\xymatrix{
%S\left(\fraka\cap\frakb\right) \otimes S\left(\frakb\right) \ar[r]^-{\text
%{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\frakb\right)}
%\ar[d]_{\PBW_{\fraka\cap\frakb}\otimes\PBW_{\frakb}}^{\cong} & S\left
%(\frakb\right) \ar[d]_{\PBW_{\frakb}}^{\cong} \\
%\gr\left(U\left(\fraka\cap\frakb\right)\right) \otimes\gr\left(U\left
%(\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
%\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\frakb\right)\right)}
%& \gr\left(U\left(\frakb\right)\right)
%}}}%
%BeginExpansion
\xycs{12pc}
\xymatrix{
S\left(\fraka\cap\frakb\right) \otimes S\left(\frakb\right) \ar[r]^-{\text
{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\frakb\right)}
\ar[d]_{\PBW_{\fraka\cap\frakb}\otimes\PBW_{\frakb}}^{\cong} & S\left
(\frakb\right) \ar[d]_{\PBW_{\frakb}}^{\cong} \\
\gr\left(U\left(\fraka\cap\frakb\right)\right) \otimes\gr\left(U\left
(\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\frakb\right)\right)}
& \gr\left(U\left(\frakb\right)\right)
}%
%EndExpansion
\]
commute\footnote{This is pretty easy to see from the definition of
$\operatorname*{PBW}\nolimits_{\mathfrak{u}}$.}. Hence, they give rise to an
isomorphism%
\begin{align*}
S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)   &  \rightarrow
\operatorname*{gr}\left(  U\left(  \mathfrak{a}\right)  \right)
\otimes_{\operatorname*{gr}\left(  U\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  \right)  }\operatorname*{gr}\left(  U\left(  \mathfrak{b}\right)
\right)  ,\\
\alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }\beta &
\mapsto\left(  \operatorname*{PBW}\nolimits_{\mathfrak{a}}\alpha\right)
\otimes_{\operatorname*{gr}\left(  U\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  \right)  }\left(  \operatorname*{PBW}\nolimits_{\mathfrak{b}}%
\beta\right)  .
\end{align*}
Denote this isomorphism by $\left(  \operatorname*{PBW}\nolimits_{\mathfrak{a}%
}\right)  \otimes_{\operatorname*{PBW}\nolimits_{\mathfrak{a}\cap\mathfrak{b}%
}}\left(  \operatorname*{PBW}\nolimits_{\mathfrak{b}}\right)  $.

Finally, let $\sigma:S\left(  \mathfrak{a}\right)  \otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)
\rightarrow S\left(  \mathfrak{c}\right)  $ be the vector space homomorphism
defined by%
\[
\sigma\left(  \alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\beta\right)  =\alpha\beta\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in
S\left(  \mathfrak{a}\right)  \text{ and }\beta\in S\left(  \mathfrak{b}%
\right)  .
\]
This $\sigma$ is rather obviously an algebra homomorphism. Now, it is easy to
see that $\sigma$ is an algebra isomorphism\footnote{\textit{First proof that
}$\sigma$\textit{ is an algebra isomorphism:} Since every subspace of a vector
space has a complementary subspace, we can find a $k$-vector subspace
$\mathfrak{d}$ of $\mathfrak{a}$ such that $\mathfrak{a}=\mathfrak{d}%
\oplus\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $. Consider such a
$\mathfrak{d}$.
\par
Since $\mathfrak{a}=\mathfrak{d}\oplus\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  =\mathfrak{d}+\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $, the
fact that $\mathfrak{c}=\mathfrak{a}+\mathfrak{b}$ rewrites as $\mathfrak{c}%
=\mathfrak{d}+\underbrace{\left(  \mathfrak{a}\cap\mathfrak{b}\right)
+\mathfrak{b}}_{\substack{=\mathfrak{b}\\\text{(since }\mathfrak{a}%
\cap\mathfrak{b}\subseteq\mathfrak{b}\text{)}}}=\mathfrak{d}+\mathfrak{b}$.
Combined with $\underbrace{\mathfrak{d}}_{\substack{=\mathfrak{d}%
\cap\mathfrak{a}\\\text{(since }\mathfrak{d}\subseteq\mathfrak{a}\text{)}%
}}\cap\mathfrak{b}\subseteq\mathfrak{d}\cap\mathfrak{a}\cap\mathfrak{b}=0$
(since $\mathfrak{d}\oplus\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $ is a
well-defined internal direct sum), this yields $\mathfrak{c}=\mathfrak{d}%
\oplus\mathfrak{b}$.
\par
Recall a known fact from multilinear algebra: Any two $k$-vector spaces $U$
and $V$ satisfy $S\left(  U\oplus V\right)  \cong S\left(  U\right)
\otimes_{k}S\left(  V\right)  $ by the canonical algebra isomorphism. Hence,
$S\left(  \mathfrak{d}\oplus\mathfrak{b}\right)  \cong S\left(  \mathfrak{d}%
\right)  \otimes_{k}S\left(  \mathfrak{b}\right)  $.
\par
But $\mathfrak{a}=\mathfrak{d}\oplus\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  $ yields $S\left(  \mathfrak{a}\right)  =S\left(  \mathfrak{d}%
\oplus\left(  \mathfrak{a}\cap\mathfrak{b}\right)  \right)  \cong S\left(
\mathfrak{d}\right)  \otimes_{k}S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
$ (by the above-quoted fact that any two $k$-vector spaces $U$ and $V$ satisfy
$S\left(  U\oplus V\right)  \cong S\left(  U\right)  \otimes_{k}S\left(
V\right)  $ by the canonical algebra isomorphism). Hence,%
\begin{align*}
S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)   &  \cong\left(  S\left(
\mathfrak{d}\right)  \otimes_{k}S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
\right)  \otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }S\left(
\mathfrak{b}\right) \\
&  \cong S\left(  \mathfrak{d}\right)  \otimes_{k}\underbrace{\left(  S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)  \right)  }_{\cong
S\left(  \mathfrak{b}\right)  }\cong S\left(  \mathfrak{d}\right)  \otimes
_{k}S\left(  \mathfrak{b}\right)  \cong S\left(  \underbrace{\mathfrak{d}%
\oplus\mathfrak{b}}_{=\mathfrak{c}}\right)  =S\left(  \mathfrak{c}\right)  .
\end{align*}
Thus we have constructed an algebra isomorphism $S\left(  \mathfrak{a}\right)
\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }S\left(
\mathfrak{b}\right)  \rightarrow S\left(  \mathfrak{c}\right)  $. If we track
down what happens to elements of $\mathfrak{d}$, $\mathfrak{a}\cap
\mathfrak{b}$ and $\mathfrak{b}$ under this isomorphism, we notice that they
just get sent to themselves, so this isomorphism must coincide with $\sigma$
(because if two algebra homomorphisms from the same algebra coincide on a set
of generators of said algebra, then these two algebra homomorphisms must be
identical). Thus, $\sigma$ is an algebra isomorphism, qed.
\par
\textit{Second proof that }$\sigma$\textit{ is an algebra isomorphism:} Define
a map $\tau:\mathfrak{c}\rightarrow S\left(  \mathfrak{a}\right)
\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }S\left(
\mathfrak{b}\right)  $ as follows: For every $c\in\mathfrak{c}$, let
$\tau\left(  c\right)  $ be $a\otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }1+1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  }b$, where we have written $c$ in the form $c=a+b$ with
$a\in\mathfrak{a}$ and $b\in\mathfrak{b}$ (in fact, we can write $c$ this way,
because $\mathfrak{c}=\mathfrak{a}+\mathfrak{b}$). This map $\tau$ is
well-defined, because the value of $a\otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }1+1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  }b$ depends only on $c$ and not on the exact values of $a$ and $b$ in
the decomposition $c=a+b$. (In fact, if $c=a+b$ and $c=a^{\prime}+b^{\prime}$
are two different ways to decompose $c$ into a sum of an element of
$\mathfrak{a}$ with an element of $\mathfrak{b}$, then $a+b=c=a^{\prime
}+b^{\prime}$, so that $a-a^{\prime}=b^{\prime}-b$, thus $a-a^{\prime}%
\in\mathfrak{a}\cap\mathfrak{b}$ (because $a-a^{\prime}\in\mathfrak{a}$ and
$a-a^{\prime}=b^{\prime}-b\in\mathfrak{b}$), so that%
\begin{align*}
&  \underbrace{a}_{=a^{\prime}+\left(  a-a^{\prime}\right)  }\otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }1+1\otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }b\\
&  =\left(  a^{\prime}+\left(  a-a^{\prime}\right)  \right)  \otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }1+1\otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }b\\
&  =a^{\prime}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}1+\underbrace{\left(  a-a^{\prime}\right)  \otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }1}_{\substack{=1\otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }\left(  a-a^{\prime}\right)  \\\text{(since
}a-a^{\prime}\in\mathfrak{a}\cap\mathfrak{b}\subseteq S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  \text{)}}}+1\otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }b\\
&  =a^{\prime}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}1+1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }%
\underbrace{\left(  a-a^{\prime}\right)  }_{=b^{\prime}-b}+1\otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }b\\
&  =a^{\prime}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}1+\underbrace{1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\left(  b^{\prime}-b\right)  +1\otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }b}_{=1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  }\left(  \left(  b^{\prime}-b\right)  +b\right)  }\\
&  =a^{\prime}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}1+1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }%
\underbrace{\left(  \left(  b^{\prime}-b\right)  +b\right)  }_{=b^{\prime}%
}=a^{\prime}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }%
1+1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }b^{\prime}.
\end{align*}
)
\par
It is also easy to see that $\tau$ is a linear map. Thus, by the universal
property of the symmetric algebra, the map $\tau:\mathfrak{c}\rightarrow
S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)  $ gives rise to a
$k$-algebra homomorphism $\widehat{\tau}:S\left(  \mathfrak{c}\right)
\rightarrow S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)  $ that lifts $\tau$.
\par
Any $\alpha\in\mathfrak{a}$ satisfies%
\begin{align*}
\left(  \widehat{\tau}\circ\sigma\right)  \left(  \alpha\otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }1\right)   &  =\widehat{\tau}\left(
\underbrace{\sigma\left(  \alpha\otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }1\right)  }_{\substack{=\alpha1\\\text{(by the
definition of }\sigma\text{)}}}\right)  =\widehat{\tau}\left(  \alpha1\right)
=\widehat{\tau}\left(  \alpha\right)  =\tau\left(  \alpha\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widehat{\tau}\text{ lifts }%
\tau\right) \\
&  =\alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }%
1+1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }0\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by the definition of }\tau\text{, since }\alpha=\alpha+0\text{ is a
decomposition of}\\
\text{ }\alpha\text{ into a sum of an element of }\mathfrak{a}\text{ with an
element of }\mathfrak{b}%
\end{array}
\right) \\
&  =\alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }1.
\end{align*}
In other words, the map $\widehat{\tau}\circ\sigma$ fixes all tensors of the
form $\alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }1$ with
$\alpha\in\mathfrak{a}$. Similarly, the map $\widehat{\tau}\circ\sigma$ fixes
all tensors of the form $1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  }\beta$ with $\beta\in\mathfrak{b}$. Combining the previous two
sentences, we conclude that the map map $\widehat{\tau}\circ\sigma$ fixes all
elements of the set $\left\{  \alpha\otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }1\ \mid\ \alpha\in\mathfrak{a}\right\}  \cup\left\{
1\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }\beta\ \mid\ \beta
\in\mathfrak{b}\right\}  $. Thus, there is a generating set of the $k$-algebra
$S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)  $ such that the map
$\widehat{\tau}\circ\sigma$ fixes all elements of this set (because $\left\{
\alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }1\ \mid
\ \alpha\in\mathfrak{a}\right\}  \cup\left\{  1\otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }\beta\ \mid\ \beta\in\mathfrak{b}%
\right\}  $ is a generating set of the $k$-algebra $S\left(  \mathfrak{a}%
\right)  \otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }S\left(
\mathfrak{b}\right)  $). Since this map $\widehat{\tau}\circ\sigma$ is a
$k$-algebra homomorphism (because $\widehat{\tau}$ and $\sigma$ are
$k$-algebra homomorphisms), this yields that the map $\widehat{\tau}%
\circ\sigma$ is the identity (since a $k$-algebra homomorphism which fixes a
generating set of its domain must be the identity). In other words, we have
shown that $\widehat{\tau}\circ\sigma=\operatorname*{id}$. A slightly
different but similarly simple argument shows that $\sigma\circ\widehat{\tau
}=\operatorname*{id}$. Combining $\sigma\circ\widehat{\tau}=\operatorname*{id}%
$ with $\widehat{\tau}\circ\sigma=\operatorname*{id}$, we conclude that
$\widehat{\tau}$ is an inverse to $\sigma$, so that $\sigma$ is an algebra
isomorphism, qed.}.

Now, it is easy to see (by elementwise checking) that the diagram%
\[%
%TCIMACRO{\TeXButton{X}{\xymatrixcolsep{11pc}
%\xymatrix{
%\gr\left(U\left(\fraka\right)\right) \otimes_{\gr\left(U\left(\fraka\cap
%\frakb\right)\right)} \gr\left(U\left(\frakb\right)\right) \ar[d]^{f}
%& S\left(\fraka\right) \otimes_{S\left(\fraka\cap\frakb\right)} S\left
%(\frakb\right) \ar[l]_-{\left(\PBW_{\fraka}\right) \otimes_{\PBW_{\fraka
%\cap\frakb}} \left(\PBW_{\frakb}\right)}^{\cong} \ar[d]_{\cong}^{\sigma} \\
%\gr\left(U\left(\fraka\right) \otimes_{U\left(\fraka\cap\frakb\right)}
%U\left(\frakb\right)\right) \ar[dr]_{\gr\rho} & S\left(\frakc\right
%) \ar[d]^{\PBW_{\frakc}}_{\cong} \\
%& \gr\left(U\left(\frakc\right)\right)
%}}}%
%BeginExpansion
\xymatrixcolsep{11pc}
\xymatrix{
\gr\left(U\left(\fraka\right)\right) \otimes_{\gr\left(U\left(\fraka\cap
\frakb\right)\right)} \gr\left(U\left(\frakb\right)\right) \ar[d]^{f}
& S\left(\fraka\right) \otimes_{S\left(\fraka\cap\frakb\right)} S\left
(\frakb\right) \ar[l]_-{\left(\PBW_{\fraka}\right) \otimes_{\PBW_{\fraka
\cap\frakb}} \left(\PBW_{\frakb}\right)}^{\cong} \ar[d]_{\cong}^{\sigma} \\
\gr\left(U\left(\fraka\right) \otimes_{U\left(\fraka\cap\frakb\right)}
U\left(\frakb\right)\right) \ar[dr]_{\gr\rho} & S\left(\frakc\right
) \ar[d]^{\PBW_{\frakc}}_{\cong} \\
& \gr\left(U\left(\frakc\right)\right)
}%
%EndExpansion
\]
is commutative.\footnote{In fact, if we follow the pure tensor $\alpha
_{1}\alpha_{2}...\alpha_{k}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  }\beta_{1}\beta_{2}...\beta_{\ell}$ (with $k\in\mathbb{N}$, $\ell
\in\mathbb{N}$, $\alpha_{1},\alpha_{2},...,\alpha_{k}\in\mathfrak{a}$ and
$\beta_{1},\beta_{2},...,\beta_{\ell}\in\mathfrak{b}$) through this diagram,
we get $\overline{\alpha_{1}\alpha_{2}...\alpha_{k}\beta_{1}\beta_{2}%
...\beta_{\ell}}\in\operatorname*{gr}\nolimits_{k+\ell}\left(  U\left(
\mathfrak{c}\right)  \right)  $ both ways.} Hence, $\left(  \operatorname*{gr}%
\rho\right)  \circ f$ is an isomorphism, so that $f$ is injective. Since $f$
is also surjective, this yields that $f$ is an isomorphism. Thus,
$\operatorname*{gr}\rho$ is an isomorphism (since $\left(  \operatorname*{gr}%
\rho\right)  \circ f$ is an isomorphism). Since $\rho$ is a filtered map and
$\operatorname*{gr}\rho$ is an isomorphism, it follows that $\rho$ is an
isomorphism of filtered vector spaces. Hence, $\rho$ is an isomorphism of
filtered vector spaces, of left $U\left(  \mathfrak{a}\right)  $-modules and
of right $U\left(  \mathfrak{b}\right)  $-modules (since it is clear that
$\rho$ is a homomorphism of $U\left(  \mathfrak{a}\right)  $-left modules and
of $U\left(  \mathfrak{b}\right)  $-right modules). This proves Proposition
\ref{prop.U(X)U}.

\textit{Second proof of Proposition \ref{prop.U(X)U}.} Let $\left(
z_{i}\right)  _{i\in I}$ be a basis of the $k$-vector space $\mathfrak{a}%
\cap\mathfrak{b}$. We extend this basis to a basis $\left(  z_{i}\right)
_{i\in I}\cup\left(  x_{j}\right)  _{j\in J}$ of the $k$-vector space
$\mathfrak{a}$ and to a basis $\left(  z_{i}\right)  _{i\in I}\cup\left(
y_{\ell}\right)  _{\ell\in L}$ of the $k$-vector space $\mathfrak{b}$. Then,
$\left(  z_{i}\right)  _{i\in I}\cup\left(  x_{j}\right)  _{j\in J}\cup\left(
y_{\ell}\right)  _{\ell\in L}$ is a basis of the $k$-vector space
$\mathfrak{c}$. We endow this basis with a total ordering in such a way that
every $x_{j}$ is smaller than every $z_{i}$, and that every $z_{i}$ is smaller
than every $y_{\ell}$. By the Poincar\'{e}-Birkhoff-Witt theorem, we have a
basis of $U\left(  \mathfrak{c}\right)  $ consisting of increasing products of
elements of the basis $\left(  z_{i}\right)  _{i\in I}\cup\left(
x_{j}\right)  _{j\in J}\cup\left(  y_{\ell}\right)  _{\ell\in L}$. On the
other hand, again by the Poincar\'{e}-Birkhoff-Witt theorem, we have a basis
of $U\left(  \mathfrak{a}\right)  $ consisting of increasing products of
elements of the basis $\left(  z_{i}\right)  _{i\in I}\cup\left(
x_{j}\right)  _{j\in J}$. Note that the $z_{i}$ accumulate at the right end of
these products, while the $x_{j}$ accumulate at the left end (because we
defined the total ordering in such a way that every $x_{j}$ is smaller than
every $z_{i}$). Hence, $U\left(  \mathfrak{a}\right)  $ is a free right
$U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $-module, with a basis (over
$U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $, not over $k$) consisting of
increasing products of elements of the basis $\left(  x_{j}\right)  _{j\in J}%
$. Combined with the fact that $U\left(  \mathfrak{b}\right)  $ is a free
$k$-vector space with a basis consisting of increasing products of elements of
the basis $\left(  z_{i}\right)  _{i\in I}\cup\left(  y_{\ell}\right)
_{\ell\in L}$ (again by Poincar\'{e}-Birkhoff-Witt), this yields that
$U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  $ is a free $k$-vector
space with a basis consisting of tensors of the form%
\begin{align*}
&  \left(  \text{some increasing product of elements of the basis }\left(
x_{j}\right)  _{j\in J}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\left(  \text{some increasing product of elements of the basis }\left(
z_{i}\right)  _{i\in I}\cup\left(  y_{\ell}\right)  _{\ell\in L}\right)  .
\end{align*}
The map $\rho$ clearly maps such terms bijectively into increasing products of
elements of the basis $\left(  z_{i}\right)  _{i\in I}\cup\left(
x_{j}\right)  _{j\in J}\cup\left(  y_{\ell}\right)  _{\ell\in L}$. Hence,
$\rho$ maps a basis of $U\left(  \mathfrak{a}\right)  \otimes_{U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  $
bijectively to a basis of $U\left(  \mathfrak{c}\right)  $. Thus, $\rho$ is an
isomorphism of vector spaces. Moreover, since both of our bases were
filtered\footnote{A basis $\mathcal{B}$ of a filtered vector space $V$ is said
to be \textit{filtered} if for every $n\in\mathbb{N}$, the subfamily of
$\mathcal{B}$ consisting of those elements of $\mathcal{B}$ lying in the
$n$-th filtration of $V$ is a basis of the $n$-th filtration of $V$.}, and
$\rho$ respects this filtration on the bases, we can even conclude that $\rho$
is an isomorphism of filtered vector spaces. Since it is clear that $\rho$ is
a homomorphism of $U\left(  \mathfrak{a}\right)  $-left modules and of
$U\left(  \mathfrak{b}\right)  $-right modules, it follows that $\rho$ is an
isomorphism of filtered vector spaces, of left $U\left(  \mathfrak{a}\right)
$-modules and of right $U\left(  \mathfrak{b}\right)  $-modules. This proves
Proposition \ref{prop.U(X)U}.

\textit{Proof of Corollary \ref{cor.U(X)U}.} Corollary \ref{cor.U(X)U}
immediately follows from Proposition \ref{prop.U(X)U} (since $\mathfrak{a}%
\oplus\mathfrak{b}=\mathfrak{c}$ yields $\mathfrak{a}\cap\mathfrak{b}=0$, thus
$U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  =U\left(  0\right)  =k$).

\begin{remark}
\label{rmk.U(X)U}While we have required $k$ to be a field in Proposition
\ref{prop.U(X)U} and Corollary \ref{cor.U(X)U}, these two results hold in more
general situations as well. For instance, Proposition \ref{prop.U(X)U} holds
whenever $k$ is a commutative ring, as long as $\mathfrak{a}$, $\mathfrak{b}$
and $\mathfrak{a}\cap\mathfrak{b}$ are free $k$-modules, and $\mathfrak{a}%
\cap\mathfrak{b}$ is a direct summand of $\mathfrak{a}$ as a $k$-module. In
fact, the first proof of Proposition \ref{prop.U(X)U} works in this situation
(because the Poincar\'{e}-Birkhoff-Witt theorem holds for free modules). In a
more restrictive situation (namely, when $\mathfrak{a}\cap\mathfrak{b}$ is a
free $k$-module, and a direct summand of each of $\mathfrak{a}$ and
$\mathfrak{b}$, with the other two summands also being free), the second proof
of Proposition \ref{prop.U(X)U} works as well. As for Corollary
\ref{cor.U(X)U}, it holds whenever $k$ is a commutative ring, as long as
$\mathfrak{a}$ and $\mathfrak{b}$ are free $k$-modules.

This generality is more than enough for most applications of Proposition
\ref{prop.U(X)U} and Corollary \ref{cor.U(X)U}. Yet we can go even further
using the appropriate generalizations of the Poincar\'{e}-Birkhoff-Witt
theorem (for these, see, e. g., P. J. Higgins, \textit{Baer Invariants and the
Birkhoff-Witt theorem}, J. of Alg. 11, pp. 469-482, (1969), \newline%
\texttt{\url{http://www.sciencedirect.com/science/article/pii/0021869369900866}
}).
\end{remark}

\subsection{\texorpdfstring{$\mathbb{Z}$}{Z}-graded Lie algebras and Verma
modules}

\subsubsection{\texorpdfstring{$\mathbb{Z}$}{Z}-graded Lie algebras}

Let us show some general results about representations of $\mathbb{Z}$-graded
Lie algebras -- particularly of \textit{nondegenerate} $\mathbb{Z}$-graded Lie
algebras. This is a notion that encompasses many of the concrete Lie algebras
that we want to study (among others, $\mathcal{A}$, $\mathcal{A}_{0}$, $W$ and
$\operatorname*{Vir}$), and thus by proving the properties of nondegenerate
$\mathbb{Z}$-graded Lie algebras now we can avoid proving them separately in
many different cases.

\begin{definition}
\label{def.gradLie}A $\mathbb{Z}$\textit{-graded Lie algebra} is a Lie algebra
$\mathfrak{g}$ with a decomposition $\mathfrak{g}=\bigoplus\limits_{n\in
\mathbb{Z}}\mathfrak{g}_{n}$ (as a vector space) such that $\left[
\mathfrak{g}_{n},\mathfrak{g}_{m}\right]  \subseteq\mathfrak{g}_{n+m}$ for all
$n,m\in\mathbb{Z}$. The family $\left(  \mathfrak{g}_{n}\right)
_{n\in\mathbb{Z}}$ is called the \textit{grading} of this $\mathbb{Z}$-graded
Lie algebra.\footnotemark
\end{definition}

\footnotetext{\textbf{Warning:} Some algebraists use the words ``$\mathbb{Z}%
$-graded Lie algebra'' to denote a $\mathbb{Z}$-graded Lie \textbf{super}%
algebra, where the even homogeneous components constitute the even part and
the odd homogeneous components constitute the odd part. This is \textbf{not}
how we understand the notion of a ``$\mathbb{Z}$-graded Lie algebra'' here. In
particular, for us, a $\mathbb{Z}$-graded Lie algebra $\mathfrak{g}$ should
satisfy $\left[  x,x\right]  =0$ for all $x\in\mathfrak{g}$ (not just for $x$
lying in even homogeneous components).} Of course, every $\mathbb{Z}$-graded
Lie algebra automatically is a $\mathbb{Z}$-graded vector space (by way of
forgetting the Lie bracket and only keeping the grading). Note that if
$\mathfrak{g}=\bigoplus\limits_{n\in\mathbb{Z}}\mathfrak{g}_{n}$ is a
$\mathbb{Z}$-graded Lie algebra, then $\bigoplus\limits_{n<0}\mathfrak{g}_{n}%
$, $\mathfrak{g}_{0}$ and $\bigoplus\limits_{n>0}\mathfrak{g}_{n}$ are Lie
subalgebras of $\mathfrak{g}$.

\begin{example}
We defined a grading on the Heisenberg algebra $\mathcal{A}$ in Definition
\ref{def.A.grad}. This makes $\mathcal{A}$ into a $\mathbb{Z}$-graded Lie
algebra. Also, $\mathcal{A}_{0}$ is a $\mathbb{Z}$-graded Lie subalgebra of
$\mathcal{A}$.
\end{example}

\begin{example}
We make the Witt algebra $W$ into a $\mathbb{Z}$-graded Lie algebra by using
the grading $\left(  W\left[  n\right]  \right)  _{n\in\mathbb{Z}}$, where
$W\left[  n\right]  =\left\langle L_{n}\right\rangle $ for every
$n\in\mathbb{Z}$.

We make the Virasoro algebra $\operatorname*{Vir}$ into a $\mathbb{Z}$-graded
Lie algebra by using the grading $\left(  \operatorname*{Vir}\left[  n\right]
\right)  _{n\in\mathbb{Z}}$, where $\operatorname*{Vir}\left[  n\right]
=\left\{
\begin{array}
[c]{l}%
\left\langle L_{n}\right\rangle ,\ \ \ \ \ \ \ \ \ \ \text{if }n\neq0;\\
\left\langle L_{0},C\right\rangle ,\ \ \ \ \ \ \ \ \ \ \text{if }n=0
\end{array}
\right.  $ for every $n\in\mathbb{Z}$.
\end{example}

\begin{definition}
\label{def.gradLienondeg}A $\mathbb{Z}$-graded Lie algebra $\mathfrak{g}%
=\bigoplus\limits_{n\in\mathbb{Z}}\mathfrak{g}_{n}$ is said to be
\textit{nondegenerate} if

\textbf{(1)} the vector space $\mathfrak{g}_{n}$ is finite-dimensional for
every $n\in\mathbb{Z}$;

\textbf{(2)} the Lie algebra $\mathfrak{g}_{0}$ is abelian;

\textbf{(3)} for every positive integer $n$, for generic $\lambda
\in\mathfrak{g}_{0}^{\ast}$, the bilinear form $\mathfrak{g}_{n}%
\times\mathfrak{g}_{-n}\rightarrow\mathbb{C},\ \left(  a,b\right)
\mapsto\lambda\left(  \left[  a,b\right]  \right)  $ is nondegenerate.
(``Generic $\lambda$'' means ``$\lambda$ lying in some dense open subset of
$\mathfrak{g}_{0}^{\ast}$ with respect to the Zariski topology''. This subset
can depend on $n$.)
\end{definition}

Note that condition \textbf{(3)} in Definition \ref{def.gradLienondeg} implies
that $\dim\left(  \mathfrak{g}_{n}\right)  =\dim\left(  \mathfrak{g}%
_{-n}\right)  $ for all $n\in\mathbb{Z}$.

Here are some examples:

\begin{proposition}
The $\mathbb{Z}$-graded Lie algebras $\mathcal{A}$, $\mathcal{A}_{0}$, $W$ and
$\operatorname*{Vir}$ are nondegenerate (with the gradings defined above).
\end{proposition}

\begin{proposition}
\label{prop.grad.g}Let $\mathfrak{g}$ be a finite-dimensional simple Lie
algebra. The following is a reasonable (although non-canonical) way to define
a grading on $\mathfrak{g}$:

Using a Cartan subalgebra and the roots of $\mathfrak{g}$, we can present the
Lie algebra $\mathfrak{g}$ as a Lie algebra with generators $e_{1}$, $e_{2}$,
$...$, $e_{m}$, $f_{1}$, $f_{2}$, $...$, $f_{m}$, $h_{1}$, $h_{2}$, $...$,
$h_{m}$ (the so-called Chevalley generators) and some relations (among them
the Serre relations). Then, we can define a grading on $\mathfrak{g}$ by
setting
\[
\deg\left(  e_{i}\right)  =1,\ \ \ \ \ \ \ \ \ \ \deg\left(  f_{i}\right)
=-1\ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ \deg\left(  h_{i}\right)
=0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{  1,2,...,m\right\}  ,
\]
and extending this grading in such a way that $\mathfrak{g}$ becomes a graded
Lie algebra. This grading is non-canonical, but it makes $\mathfrak{g}$ into a
nondegenerate graded Lie algebra.
\end{proposition}

\begin{proposition}
\label{prop.grad.ghat.simple}If $\mathfrak{g}$ is a finite-dimensional simple
Lie algebra, then the loop algebra $\mathfrak{g}\left[  t,t^{-1}\right]  $ and
the affine Kac-Moody algebra $\widehat{\mathfrak{g}}=\mathfrak{g}\left[
t,t^{-1}\right]  \oplus\mathbb{C}K$ can be graded as follows:

Fix Chevalley generators for $\mathfrak{g}$ and grade $\mathfrak{g}$ as in
Proposition \ref{prop.grad.g}. Now let $\theta$ be the maximal root of
$\mathfrak{g}$, i. e., the highest weight of the adjoint representation of
$\mathfrak{g}$. Let $e_{\theta}$ and $f_{\theta}$ be the root elements
corresponding to $\theta$. The \textit{Coxeter number} of $\mathfrak{g}$ is
defined as $\deg\left(  e_{\theta}\right)  +1$, and denoted by $h$. Now let us
grade $\widehat{\mathfrak{g}}$ by setting $\deg K=0$ and $\deg\left(
at^{m}\right)  =\deg a+mh$ for every homogeneous $a\in\mathfrak{g}$ and every
$m\in\mathbb{Z}$. This grading satisfies $\deg\left(  f_{\theta}t\right)  =1$
and $\deg\left(  e_{\theta}t^{-1}\right)  =-1$. Moreover, the map
$\mathfrak{g}\left[  t,t^{-1}\right]  \rightarrow\mathfrak{g}\left[
t,t^{-1}\right]  ,\ x\mapsto xt$ is homogeneous of degree $h$; this is often
informally stated as ``$\deg t=h$'' (although $t$ itself is not an element of
$\widehat{\mathfrak{g}}$). It is easy to see that the elements of
$\widehat{\mathfrak{g}}$ of positive degree span $\mathfrak{n}_{+}\oplus
t\mathfrak{g}\left[  t\right]  $.

The graded Lie algebra $\widehat{\mathfrak{g}}$ is nondegenerate. The loop
algebra $\mathfrak{g}\left[  t,t^{-1}\right]  $, however, is not (with the
grading defined in the same way).
\end{proposition}

If $\mathfrak{g}$ is a $\mathbb{Z}$-graded Lie algebra, we can write%
\[
\mathfrak{g}=\bigoplus\limits_{n\in\mathbb{Z}}\mathfrak{g}_{n}=\bigoplus
\limits_{n<0}\mathfrak{g}_{n}\oplus\mathfrak{g}_{0}\oplus\bigoplus
\limits_{n>0}\mathfrak{g}_{n}.
\]
We denote $\bigoplus\limits_{n<0}\mathfrak{g}_{n}$ by $\mathfrak{n}_{-}$ and
we denote $\bigoplus\limits_{n>0}\mathfrak{g}_{n}$ by $\mathfrak{n}_{+}$. We
also denote $\mathfrak{g}_{0}$ by $\mathfrak{h}$. Then, $\mathfrak{n}_{-}$,
$\mathfrak{n}_{+}$ and $\mathfrak{h}$ are Lie subalgebras of $\mathfrak{g}$,
and the above decomposition rewrites as $\mathfrak{g}=\mathfrak{n}_{-}%
\oplus\mathfrak{h}\oplus\mathfrak{n}_{+}$ (but this is, of course, not a
direct sum of Lie algebras). This is called the \textit{triangular
decomposition} of $\mathfrak{g}$.

It is easy to see that when $\mathfrak{g}$ is a $\mathbb{Z}$-graded Lie
algebra, the universal enveloping algebra $U\left(  \mathfrak{g}\right)  $
canonically becomes a $\mathbb{Z}$-graded algebra.\footnote{In fact, $U\left(
\mathfrak{g}\right)  $ is defined as the quotient of the tensor algebra
$T\left(  \mathfrak{g}\right)  $ by a certain ideal. When $\mathfrak{g}$ is a
$\mathbb{Z}$-graded Lie algebra, this ideal is generated by homogeneous
elements, and thus is a graded ideal.}

\subsubsection{\texorpdfstring{$\mathbb{Z}$}{Z}-graded modules}

\begin{definition}
\label{def.liesubspace}Let $\mathfrak{g}$ be a Lie algebra over a field $k$.
Let $M$ be a $\mathfrak{g}$-module. Let $U$ be a vector subspace of
$\mathfrak{g}$. Let $N$ be a vector subspace of $M$. Then, $U\rightharpoonup
N$ will denote the $k$-linear span of all elements of the form
$u\rightharpoonup n$ with $u\in U$ and $n\in N$. (Notice that this notation is
analogous to the notation $\left[  U,N\right]  $ which is defined if $U$ and
$N$ are both subspaces of $\mathfrak{g}$.)
\end{definition}

\begin{definition}
\label{def.gradLie.mod}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra
with grading $\left(  \mathfrak{g}_{n}\right)  _{n\in\mathbb{Z}}$. A
$\mathbb{Z}$\textit{-graded $\mathfrak{g}$-module} means a $\mathbb{Z}$-graded
vector space $M$ equipped with a $\mathfrak{g}$-module structure such that any
$i\in\mathbb{Z}$ and $j\in\mathbb{Z}$ satisfy $\mathfrak{g}_{i}\rightharpoonup
M_{j}\subseteq M_{i+j}$, where $\left(  M_{n}\right)  _{n\in\mathbb{Z}}$
denotes the grading of $M$.
\end{definition}

The reader can easily check that when $\mathfrak{g}$ is a $\mathbb{Z}$-graded
Lie algebra, and $M$ is a $\mathbb{Z}$-graded $\mathfrak{g}$-module, then $M$
canonically becomes a $\mathbb{Z}$-graded $U\left(  \mathfrak{g}\right)
$-module (by taking the canonical $U\left(  \mathfrak{g}\right)  $-module
structure on $M$ and the given $\mathbb{Z}$-grading on $M$).

Examples of $\mathbb{Z}$-graded $\mathfrak{g}$-modules for various Lie
algebras $\mathfrak{g}$ are easy to get by. For example, when $\mathfrak{g}$
is a $\mathbb{Z}$-graded Lie algebra, then the adjoint representation
$\mathfrak{g}$ itself is a $\mathbb{Z}$-graded $\mathfrak{g}$-module. For two
more interesting examples:

\begin{example}
The action of the Heisenberg algebra $\mathcal{A}$ on the $\mu$-Fock
representation $F_{\mu}$ makes $F_{\mu}$ into a $\mathbb{Z}$-graded
$\mathcal{A}$-module (i. e., it maps $\mathcal{A}\left[  i\right]  \otimes
F_{\mu}\left[  j\right]  $ to $F_{\mu}\left[  i+j\right]  $ for all
$i\in\mathbb{Z}$ and $j\in\mathbb{Z}$). Here, we are using the $\mathbb{Z}%
$-grading on $F_{\mu}$ defined in Definition \ref{def.fock.grad}. (If we would
use the alternative $\mathbb{Z}$-grading on $F_{\mu}$ defined in Remark
\ref{rmk.fockgrad}, then the action of $\mathcal{A}$ on $F_{\mu}$ would still
make $F_{\mu}$ into a $\mathbb{Z}$-graded $\mathcal{A}$-module.)

The action of $\mathcal{A}_{0}$ on the Fock module $F$ makes $F$ into a
$\mathbb{Z}$-graded $\mathcal{A}_{0}$-module.
\end{example}

\begin{example}
Let $\alpha\in\mathbb{C}$ and $\beta\in\mathbb{C}$. The $\operatorname*{Vir}%
$-module $V_{\alpha,\beta}$ defined in Proposition \ref{prop.Vab.1} becomes a
$\mathbb{Z}$-graded $\operatorname*{Vir}$-module by means of the grading
$\left(  V_{\alpha,\beta}\left[  n\right]  \right)  _{n\in\mathbb{Z}}$, where
$V_{\alpha,\beta}\left[  n\right]  =\left\langle v_{-n}\right\rangle $ for
every $n\in\mathbb{Z}$.
\end{example}

Let us formulate a graded analogue of Lemma \ref{lem.V=F}:

\begin{lemma}
\label{lem.V=F.gr}Let $V$ be a $\mathbb{Z}$-graded $\mathcal{A}_{0}$-module
with grading $\left(  V\left[  n\right]  \right)  _{n\in\mathbb{Z}}$. Let
$u\in V\left[  0\right]  $ be such that $a_{i}u=0$ for all $i>0$, and such
that $Ku=u$. Then, there exists a $\mathbb{Z}$-graded homomorphism
$\eta:F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that $\eta\left(
1\right)  =u$. (This homomorphism $\eta$ is unique, although we won't need this.)
\end{lemma}

\textit{Proof of Lemma \ref{lem.V=F.gr}.} Let $\eta$ be the map $F\rightarrow
V$ which sends every polynomial $P\in F=\mathbb{C}\left[  x_{1},x_{2}%
,x_{3},...\right]  $ to $P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u\in
V$.\ \ \ \ \footnote{Note that the term $P\left(  a_{-1},a_{-2},a_{-3}%
,...\right)  $ denotes the evaluation of the polynomial $P$ at $\left(
x_{1},x_{2},x_{3},...\right)  =\left(  a_{-1},a_{-2},a_{-3},...\right)  $.
This evaluation is a well-defined element of $U\left(  \mathcal{A}_{0}\right)
$, since the elements $a_{-1}$, $a_{-2}$, $a_{-3}$, $...$ of $U\left(
\mathcal{A}_{0}\right)  $ commute.} Just as in the Second proof of Lemma
\ref{lem.V=F}, we can show that $\eta$ is an $\mathcal{A}_{0}$-module
homomorphism $F\rightarrow V$ such that $\eta\left(  1\right)  =u$. Hence, in
order to finish the proof of Lemma \ref{lem.V=F.gr}, we only need to check
that $\eta$ is a $\mathbb{Z}$-graded map.

If $A$ is a set, then $\mathbb{N}_{\operatorname*{fin}}^{A}$ will denote the
set of all finitely supported maps $A\rightarrow\mathbb{N}$.

Let $n\in\mathbb{Z}$ and $P\in F\left[  n\right]  $. Then, we can write the
polynomial $P$ in the form
\begin{equation}
P=\sum\limits_{\substack{\left(  i_{1},i_{2},i_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\1i_{1}%
+2i_{2}+3i_{3}+...=-n}}\lambda_{\left(  i_{1},i_{2},i_{3},...\right)  }%
x_{1}^{i_{1}}x_{2}^{i_{2}}x_{3}^{i_{3}}... \label{pf.V=F.gr.P}%
\end{equation}
for some scalars $\lambda_{\left(  i_{1},i_{2},i_{3},...\right)  }%
\in\mathbb{C}$. Consider these $\lambda_{\left(  i_{1},i_{2},i_{3},...\right)
}$. From (\ref{pf.V=F.gr.P}), it follows that%
\begin{align*}
P\left(  a_{-1},a_{-2},a_{-3},...\right)   &  =\sum\limits_{\substack{\left(
i_{1},i_{2},i_{3},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
1,2,3,...\right\}  };\\1i_{1}+2i_{2}+3i_{3}+...=-n}}\lambda_{\left(
i_{1},i_{2},i_{3},...\right)  }\underbrace{a_{-1}^{i_{1}}a_{-2}^{i_{2}}%
a_{-3}^{i_{3}}...}_{\substack{\in U\left(  \mathcal{A}_{0}\right)  \left[
i_{1}\left(  -1\right)  +i_{2}\left(  -2\right)  +i_{3}\left(  -3\right)
+...\right]  \\\text{(since every positive integer }k\text{ satisfies}%
\\a_{-k}\in\mathcal{A}_{0}\left[  -k\right]  \subseteq U\left(  \mathcal{A}%
_{0}\right)  \left[  -k\right]  \text{ and thus }a_{-k}^{i_{k}}\in U\left(
\mathcal{A}_{0}\right)  \left[  i_{k}\left(  -k\right)  \right]  \text{)}}}\\
&  \in\sum\limits_{\substack{\left(  i_{1},i_{2},i_{3},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  }%
;\\1i_{1}+2i_{2}+3i_{3}+...=-n}}\lambda_{\left(  i_{1},i_{2},i_{3},...\right)
}U\left(  \mathcal{A}_{0}\right)  \left[  \underbrace{i_{1}\left(  -1\right)
+i_{2}\left(  -2\right)  +i_{3}\left(  -3\right)  +...}_{\substack{=-\left(
1i_{1}+2i_{2}+3i_{3}+...\right)  =n\\\text{(since }1i_{1}+2i_{2}%
+3i_{3}+...=-n\text{)}}}\right] \\
&  =\sum\limits_{\substack{\left(  i_{1},i_{2},i_{3},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  1,2,3,...\right\}  };\\1i_{1}%
+2i_{2}+3i_{3}+...=-n}}\lambda_{\left(  i_{1},i_{2},i_{3},...\right)
}U\left(  \mathcal{A}_{0}\right)  \left[  n\right]  \subseteq U\left(
\mathcal{A}_{0}\right)  \left[  n\right]
\end{align*}
(since $U\left(  \mathcal{A}_{0}\right)  \left[  n\right]  $ is a vector
space). By the definition of $\eta$, we have%
\[
\eta\left(  P\right)  =\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)
}_{\in U\left(  \mathcal{A}_{0}\right)  \left[  n\right]  }\cdot
\underbrace{u}_{\in V\left[  0\right]  }\in U\left(  \mathcal{A}_{0}\right)
\left[  n\right]  \cdot V\left[  0\right]  \subseteq V\left[  n\right]
\]
(since $V$ is a $\mathbb{Z}$-graded $\mathcal{A}_{0}$-module and thus a
$\mathbb{Z}$-graded $U\left(  \mathcal{A}_{0}\right)  $-module). Now forget
that we fixed $n$ and $P$. We have thus shown that every $n\in\mathbb{Z}$ and
$P\in F\left[  n\right]  $ satisfy $\eta\left(  P\right)  \subseteq V\left[
n\right]  $. In other words, every $n\in\mathbb{Z}$ satisfies $\eta\left(
F\left[  n\right]  \right)  \subseteq V\left[  n\right]  $. In other words,
$\eta$ is $\mathbb{Z}$-graded. This proves Lemma \ref{lem.V=F.gr}.

And here is a graded analogue of Lemma \ref{lem.V=F.A}:

\begin{lemma}
\label{lem.V=F.A.gr}Let $V$ be a graded $\mathcal{A}$-module with grading
$\left(  V\left[  n\right]  \right)  _{n\in\mathbb{Z}}$. Let $\mu\in
\mathbb{C}$. Let $u\in V\left[  0\right]  $ be such that $a_{i}u=0$ for all
$i>0$, such that $a_{0}u=\mu u$, and such that $Ku=u$. Then, there exists a
$\mathbb{Z}$-graded homomorphism $\eta:F_{\mu}\rightarrow V$ of $\mathcal{A}%
$-modules such that $\eta\left(  1\right)  =u$. (This homomorphism $\eta$ is
unique, although we won't need this.)
\end{lemma}

The proof of Lemma \ref{lem.V=F.A.gr} is completely analogous to that of Lemma
\ref{lem.V=F.gr}, but this time using Lemma \ref{lem.V=F.A} instead of Lemma
\ref{lem.V=F}.

\subsubsection{Verma modules}

\begin{definition}
\label{def.verma}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra (not
necessarily nondegenerate). Let us work with the notations introduced above.
Let $\lambda\in\mathfrak{h}^{\ast}$.

Let $\mathbb{C}_{\lambda}$ denote the $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{+}\right)  $-module which, as a $\mathbb{C}$-vector space, is
the free vector space with basis $\left(  v_{\lambda}^{+}\right)  $ (thus, a
$1$-dimensional vector space), and whose $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{+}\right)  $-action is given by%
\begin{align*}
hv_{\lambda}^{+}  &  =\lambda\left(  h\right)  v_{\lambda}^{+}%
\ \ \ \ \ \ \ \ \ \ \text{for every }h\in\mathfrak{h};\\
\mathfrak{n}_{+}v_{\lambda}^{+}  &  =0.
\end{align*}


The \textit{Verma highest-weight module }$M_{\lambda}^{+}$ \textit{of
}$\left(  \mathfrak{g},\lambda\right)  $ is defined by%
\[
M_{\lambda}^{+}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{\lambda}.
\]
The element $1\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
}v_{\lambda}^{+}$ of $M_{\lambda}^{+}$ will still be denoted by $v_{\lambda
}^{+}$ by abuse of notation, and will be called the \textit{defining vector}
of $M_{\lambda}^{+}$. Since $U\left(  \mathfrak{g}\right)  $ and
$\mathbb{C}_{\lambda}$ are graded $U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  $-modules, their tensor product $U\left(  \mathfrak{g}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}%
_{\lambda}=M_{\lambda}^{+}$ becomes graded as well.

Let $\mathbb{C}_{\lambda}$ denote the $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{-}\right)  $-module which, as a $\mathbb{C}$-vector space, is
the free vector space with basis $\left(  v_{\lambda}^{-}\right)  $ (thus, a
$1$-dimensional vector space), and whose $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{-}\right)  $-action is given by%
\begin{align*}
hv_{\lambda}^{-}  &  =\lambda\left(  h\right)  v_{\lambda}^{-}%
\ \ \ \ \ \ \ \ \ \ \text{for every }h\in\mathfrak{h};\\
\mathfrak{n}_{-}v_{\lambda}^{-}  &  =0.
\end{align*}
(Note that we denote this $\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)
$-module by $\mathbb{C}_{\lambda}$, although we already have denoted an
$\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  $-module by $\mathbb{C}%
_{\lambda}$. This is ambiguous, but misunderstandings are unlikely to occur
since these modules are modules over different Lie algebras, and their
restrictions to $\mathfrak{h}$ are identical.)

The \textit{Verma lowest-weight module }$M_{\lambda}^{-}$ \textit{of }$\left(
\mathfrak{g},\lambda\right)  $ is defined by%
\[
M_{\lambda}^{-}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}_{\lambda}.
\]
The element $1\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)
}v_{\lambda}^{-}$ of $M_{\lambda}^{-}$ will still be denoted by $v_{\lambda
}^{-}$ by abuse of notation, and will be called the \textit{defining vector}
of $M_{\lambda}^{-}$. Since $U\left(  \mathfrak{g}\right)  $ and
$\mathbb{C}_{\lambda}$ are graded $U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{-}\right)  $-modules, their tensor product $U\left(  \mathfrak{g}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}%
_{\lambda}=M_{\lambda}^{-}$ becomes graded as well.
\end{definition}

We notice some easy facts about these modules:

\begin{proposition}
\label{prop.verma1}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra
(not necessarily nondegenerate). Let us work with the notations introduced
above. Let $\lambda\in\mathfrak{h}^{\ast}$.

\textbf{(a)} As a graded $\mathfrak{n}_{-}$-module, $M_{\lambda}^{+}=U\left(
\mathfrak{n}_{-}\right)  v_{\lambda}^{+}$; more precisely, there exists a
graded $\mathfrak{n}_{-}$-module isomorphism $U\left(  \mathfrak{n}%
_{-}\right)  \otimes\mathbb{C}_{\lambda}\rightarrow M_{\lambda}^{+}$ which
sends every $x\otimes t\in U\left(  \mathfrak{n}_{-}\right)  \otimes
\mathbb{C}_{\lambda}$ to $xtv_{\lambda}^{+}$. The Verma module $M_{\lambda
}^{+}$ is concentrated in nonpositive degrees:%
\[
M_{\lambda}^{+}=\bigoplus\limits_{n\geq0}M_{\lambda}^{+}\left[  -n\right]
;\ \ \ \ \ \ \ \ \ \ M_{\lambda}^{+}\left[  -n\right]  =U\left(
\mathfrak{n}_{-}\right)  \left[  -n\right]  v_{\lambda}^{+}%
\ \ \ \ \ \ \ \ \ \ \text{for every }n\geq0.
\]
Also, if $\dim\mathfrak{g}_{j}<\infty$ for all $j\leq-1$, we have%
\[
\sum\limits_{n\geq0}\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)
q^{n}=\dfrac{1}{\prod\limits_{j\leq-1}\left(  1-q^{-j}\right)  ^{\dim
\mathfrak{g}_{j}}}.
\]


\textbf{(b)} As a graded $\mathfrak{n}_{+}$-module, $M_{\lambda}^{-}=U\left(
\mathfrak{n}_{+}\right)  v_{\lambda}^{-}$; more precisely, there exists a
graded $\mathfrak{n}_{+}$-module isomorphism $U\left(  \mathfrak{n}%
_{+}\right)  \otimes\mathbb{C}_{\lambda}\rightarrow M_{\lambda}^{-}$ which
sends every $x\otimes t\in U\left(  \mathfrak{n}_{+}\right)  \otimes
\mathbb{C}_{\lambda}$ to $xtv_{\lambda}^{-}$. The Verma module $M_{\lambda
}^{-}$ is concentrated in nonnegative degrees:%
\[
M_{\lambda}^{-}=\bigoplus\limits_{n\geq0}M_{\lambda}^{-}\left[  n\right]
;\ \ \ \ \ \ \ \ \ \ M_{\lambda}^{-}\left[  n\right]  =U\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  v_{\lambda}^{-}\ \ \ \ \ \ \ \ \ \ \text{for
every }n\geq0.
\]
Also, if $\dim\mathfrak{g}_{j}<\infty$ for all $j\geq1$, we have%
\[
\sum\limits_{n\geq0}\dim\left(  M_{\lambda}^{-}\left[  n\right]  \right)
q^{n}=\dfrac{1}{\prod\limits_{j\geq1}\left(  1-q^{j}\right)  ^{\dim
\mathfrak{g}_{j}}}.
\]

\end{proposition}

\textit{Proof of Proposition \ref{prop.verma1}.} \textbf{(a)} Let
$\rho:U\left(  \mathfrak{n}_{-}\right)  \otimes_{\mathbb{C}}U\left(
\mathfrak{h}\oplus\mathfrak{n}_{+}\right)  \rightarrow U\left(  \mathfrak{g}%
\right)  $ be the $\mathbb{C}$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes\beta\right)  =\alpha\beta
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in U\left(  \mathfrak{n}_{-}\right)
\text{ and }\beta\in U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
\]
(this is clearly well-defined). By Corollary \ref{cor.U(X)U} (applied to
$\mathfrak{a}=\mathfrak{n}_{-}$, $\mathfrak{b}=\mathfrak{h}\oplus
\mathfrak{n}_{+}$ and $\mathfrak{c}=\mathfrak{g}$), this $\rho$ is an
isomorphism of filtered\footnote{Filtered by the usual filtration on the
universal enveloping algebra of a Lie algebra. This filtration does not take
into account the grading on $\mathfrak{n}_{-}$, $\mathfrak{h}\oplus
\mathfrak{n}_{+}$ and $\mathfrak{g}$.} vector spaces, of left $U\left(
\mathfrak{n}_{-}\right)  $-modules and of right $U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  $-modules. Also, it is a graded linear
map\footnote{Here we \textit{do} take into account the grading on
$\mathfrak{n}_{-}$, $\mathfrak{h}\oplus\mathfrak{n}_{+}$ and $\mathfrak{g}$.}
(this is clear from its definition), and thus an isomorphism of graded vector
spaces (because if a vector space isomorphism of graded vector spaces is a
graded linear map, then it must be an isomorphism of graded vector
spaces\footnote{If you are wondering why this statement is more than a
blatantly obvious tautology, let me add some clarifications:
\par
A \textit{graded linear map} is a morphism in the category of graded vector
spaces. What I am stating here is that if a vector space isomorphism between
graded vector spaces is at the same time a morphism in the category of graded
vector spaces, then it must be an \textit{isomorphism} in the category of
graded vector spaces. This is very easy to show, but not a self-evident
tautology. In fact, the analogous assertion about filtered vector spaces (i.
e., the assertion that if a vector space isomorphism between filtered vector
spaces is at the same time a morphism in the category of filtered vector
spaces, then it must be an \textit{isomorphism} in the category of filtered
vector spaces) is wrong.}). Altogether, $\rho$ is an isomorphism of graded
filtered vector spaces, of left $U\left(  \mathfrak{n}_{-}\right)  $-modules
and of right $U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  $-modules.
Hence,%
\begin{align*}
M_{\lambda}^{+}  &  =\underbrace{U\left(  \mathfrak{g}\right)  }%
_{\substack{\cong U\left(  \mathfrak{n}_{-}\right)  \otimes_{\mathbb{C}%
}U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  \\\text{(by the
isomorphism }\rho\text{)}}}\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  }\mathbb{C}_{\lambda}\cong\left(  U\left(  \mathfrak{n}%
_{-}\right)  \otimes_{\mathbb{C}}U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  \right)  \otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  }\mathbb{C}_{\lambda}\\
&  \cong U\left(  \mathfrak{n}_{-}\right)  \otimes_{\mathbb{C}}%
\underbrace{\left(  U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}%
_{\lambda}\right)  }_{\cong\mathbb{C}_{\lambda}}\cong U\left(  \mathfrak{n}%
_{-}\right)  \otimes\mathbb{C}_{\lambda}\ \ \ \ \ \ \ \ \ \ \text{as graded
}U\left(  \mathfrak{n}_{-}\right)  \text{-modules.}%
\end{align*}
This gives us a graded $\mathfrak{n}_{-}$-module isomorphism $U\left(
\mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}\rightarrow M_{\lambda
}^{+}$ which is easily seen to send every $x\otimes t\in U\left(
\mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}$ to $xtv_{\lambda}^{+}$.
Hence, $M_{\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)  v_{\lambda}^{+}$.
Since $\mathfrak{n}_{-}$ is concentrated in negative degrees, it is clear that
$U\left(  \mathfrak{n}_{-}\right)  $ is concentrated in nonpositive degrees.
Hence, $U\left(  \mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}$ is
concentrated in nonpositive degrees, and thus the same holds for $M_{\lambda
}^{+}$ (since $M_{\lambda}^{+}\cong U\left(  \mathfrak{n}_{-}\right)
\otimes\mathbb{C}_{\lambda}$ as graded $U\left(  \mathfrak{n}_{-}\right)
$-modules). In other words, $M_{\lambda}^{+}=\bigoplus\limits_{n\geq
0}M_{\lambda}^{+}\left[  -n\right]  $.

Since the isomorphism $U\left(  \mathfrak{n}_{-}\right)  \otimes
\mathbb{C}_{\lambda}\rightarrow M_{\lambda}^{+}$ which sends every $x\otimes
t\in U\left(  \mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}$ to
$xtv_{\lambda}^{+}$ is graded, it sends $U\left(  \mathfrak{n}_{-}\right)
\left[  -n\right]  \otimes\mathbb{C}_{\lambda}=\left(  U\left(  \mathfrak{n}%
_{-}\right)  \otimes\mathbb{C}_{\lambda}\right)  \left[  -n\right]  $ to
$M_{\lambda}^{+}\left[  -n\right]  $ for every $n\geq0$. Thus, $M_{\lambda
}^{+}\left[  -n\right]  =U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]
v_{\lambda}^{+}$ for every $n\geq0$. Hence,
\begin{align*}
\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)   &  =\dim\left(
U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  v_{\lambda}^{+}\right)
=\dim\left(  U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \right)
=\dim\left(  S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because }U\left(  \mathfrak{n}_{-}\right)  \cong S\left(  \mathfrak{n}%
_{-}\right)  \text{ as graded vector spaces}\\
\text{(by the Poincar\'{e}-Birkhoff-Witt theorem)}%
\end{array}
\right)
\end{align*}
for every $n\geq0$. Hence, if $\dim\mathfrak{g}_{j}<\infty$ for all $j\leq-1$,
then%
\[
\sum\limits_{n\geq0}\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)
q^{n}=\sum\limits_{n\geq0}\dim\left(  S\left(  \mathfrak{n}_{-}\right)
\left[  -n\right]  \right)  q^{n}=\dfrac{1}{\prod\limits_{j\leq-1}\left(
1-q^{-j}\right)  ^{\dim\left(  \left(  \mathfrak{n}_{-}\right)  _{j}\right)
}}=\dfrac{1}{\prod\limits_{j\leq-1}\left(  1-q^{-j}\right)  ^{\dim
\mathfrak{g}_{j}}}.
\]
This proves Proposition \ref{prop.verma1} \textbf{(a)}.

\textbf{(b)} The proof of part \textbf{(b)} is analogous to that of
\textbf{(a)}.

This proves Proposition \ref{prop.verma1}.

We have already encountered an example of a Verma highest-weight module:

\begin{proposition}
\label{prop.fockverma}Let $\mathfrak{g}$ be the Lie algebra $\mathcal{A}_{0}$.
Consider the Fock module $F$ over the Lie algebra $\mathcal{A}_{0}$. Then,
there is a canonical isomorphism $M_{1}^{+}\rightarrow F$ of $\mathcal{A}_{0}%
$-modules (where $1$ is the element of $\mathfrak{h}^{\ast}$ which sends $K$
to $1$) which sends $v_{1}^{+}\in M_{1}^{+}$ to $1\in F$.
\end{proposition}

\textit{First proof of Proposition \ref{prop.fockverma}.} As we showed in the
First proof of Lemma \ref{lem.V=F}, there exists a homomorphism $\overline
{\eta}_{F,1}:\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}%
_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}\rightarrow F$ of $\mathcal{A}_{0}%
$-modules such that $\overline{\eta}_{F,1}\left(  1\right)  =1$. In the same
proof, we also showed that this $\overline{\eta}_{F,1}$ is an isomorphism. We
thus have an isomorphism $\overline{\eta}_{F,1}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow F$ of $\mathcal{A}_{0}$-modules such that $\overline
{\eta}_{F,1}\left(  1\right)  =1$. Since%
\begin{align*}
\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}  &  =U\left(  \mathcal{A}_{0}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }%
\mathbb{C}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathcal{A}_{0}=\mathfrak{g}%
\text{, }\mathbb{C}K=\mathfrak{h}\text{, }\mathcal{A}_{0}^{+}=\mathfrak{n}%
_{+}\text{ and }\mathbb{C}=\mathbb{C}_{1}\right) \\
&  =M_{1}^{+},
\end{align*}
and since the element $1$ of $\operatorname*{Ind}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$ is exactly the
element $v_{1}^{+}$ of $M_{1}^{+}$, this rewrites as follows: We have an
isomorphism $\overline{\eta}_{F,1}:M_{1}^{+}\rightarrow F$ of $\mathcal{A}%
_{0}$-modules such that $\overline{\eta}_{F,1}\left(  v_{1}^{+}\right)  =1$.
This proves Proposition \ref{prop.fockverma}.

\textit{Second proof of Proposition \ref{prop.fockverma}.} It is clear from
the definition of $v_{1}^{+}$ that $a_{i}v_{1}^{+}=0$ for all $i>0$, and that
$Kv_{1}^{+}=v_{1}^{+}$. Applying Lemma \ref{lem.V=F} to $u=v_{1}^{+}$ and
$V=M_{1}^{+}$, we thus conclude that there exists a homomorphism
$\eta:F\rightarrow M_{1}^{+}$ of $\mathcal{A}_{0}$-modules such that
$\eta\left(  1\right)  =v_{1}^{+}$.

On the other hand, since $M_{1}^{+}=U\left(  \mathfrak{g}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{1}$
(by the definition of $M_{1}^{+}$), we can define an $U\left(  \mathfrak{g}%
\right)  $-module homomorphism%
\[
M_{1}^{+}\rightarrow F,\ \ \ \ \ \ \ \ \ \ \alpha\otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }z\mapsto\alpha z.
\]
Since $\mathfrak{g}=\mathcal{A}_{0}$, this is an $U\left(  \mathcal{A}%
_{0}\right)  $-module homomorphism, i. e., an $\mathcal{A}_{0}$-module
homomorphism. Denote this homomorphism by $\xi$. We are going to prove that
$\eta$ and $\xi$ are mutually inverse.

Since $v_{1}^{+}=1\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
}1$, we have%
\begin{align*}
\xi\left(  v_{1}^{+}\right)   &  =\xi\left(  1\otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }1\right)  =1\cdot1\ \ \ \ \ \ \ \ \ \ \left(
\text{by the definition of }\xi\right) \\
&  =1.
\end{align*}
Since $v_{1}^{+}=\eta\left(  1\right)  $, this rewrites as $\xi\left(
\eta\left(  1\right)  \right)  =1$. In other words, $\left(  \xi\circ
\eta\right)  \left(  1\right)  =1$. Since the vector $1$ generates the
$\mathcal{A}_{0}$-module $F$ (because Lemma \ref{lem.F.P1=P} yields
$P=\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)  }_{\in U\left(
\mathcal{A}_{0}\right)  }\cdot1\in U\left(  \mathcal{A}_{0}\right)  \cdot1$
for every $P\in F$), this yields that the $\mathcal{A}_{0}$-module
homomorphisms $\xi\circ\eta:F\rightarrow F$ and $\operatorname*{id}%
:F\rightarrow F$ are equal on a generating set of the $\mathcal{A}_{0}$-module
$F$. Thus, $\xi\circ\eta=\operatorname*{id}$.

Also, $\left(  \eta\circ\xi\right)  \left(  v_{1}^{+}\right)  =\eta\left(
\underbrace{\xi\left(  v_{1}^{+}\right)  }_{=1}\right)  =\eta\left(  1\right)
=v_{1}^{+}$. Since the vector $v_{1}^{+}$ generates $M_{1}^{+}$ as an
$\mathcal{A}_{0}$-module (because $M_{1}^{+}=U\left(  \mathfrak{g}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}%
_{1}=U\left(  \mathcal{A}_{0}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{1}$), this yields that the
$\mathcal{A}_{0}$-module homomorphisms $\eta\circ\xi:M_{1}^{+}\rightarrow
M_{1}^{+}$ and $\operatorname*{id}:M_{1}^{+}\rightarrow M_{1}^{+}$ are equal
on a generating set of the $\mathcal{A}_{0}$-module $M_{1}^{+}$. Thus,
$\eta\circ\xi=\operatorname*{id}$.

Since $\eta\circ\xi=\operatorname*{id}$ and $\xi\circ\eta=\operatorname*{id}$,
the maps $\xi$ and $\eta$ are mutually inverse, so that $\xi$ is an
isomorphism $M_{1}^{+}\rightarrow F$ of $\mathcal{A}_{0}$-modules. We know
that $\xi$ sends $v_{1}^{+}$ to $\xi\left(  v_{1}^{+}\right)  =1$. Thus, there
is a canonical isomorphism $M_{1}^{+}\rightarrow F$ of $\mathcal{A}_{0}%
$-modules which sends $v_{1}^{+}\in M_{1}^{+}$ to $1\in F$. Proposition
\ref{prop.fockverma} is proven.

In analogy to the Second proof of Proposition \ref{prop.fockverma}, we can show:

\begin{proposition}
\label{prop.fockverma.A}Let $\mathfrak{g}$ be the Lie algebra $\mathcal{A}$.
Let $\mu\in\mathbb{C}$. Consider the $\mu$-Fock module $F_{\mu}$ over the Lie
algebra $\mathcal{A}$. Then, there is a canonical isomorphism $M_{1,\mu}%
^{+}\rightarrow F_{\mu}$ of $\mathcal{A}$-modules (where $\left(
1,\mu\right)  $ is the element of $\mathfrak{h}^{\ast}$ which sends $K$ to $1$
and $a_{0}$ to $\mu$) which sends $v_{1,\mu}^{+}\in M_{1,\mu}^{+}$ to $1\in
F_{\mu}$.
\end{proposition}

\subsubsection{Degree-\texorpdfstring{$0$}{0} forms}

We introduce another simple notion:

\begin{definition}
\label{def.deg0}Let $V$ and $W$ be two $\mathbb{Z}$-graded vector spaces over
a field $k$. Let $\beta:V\times W\rightarrow k$ be a $k$-bilinear form. We say
that the $k$-bilinear form $\beta$ \textit{has degree }$0$ (or, equivalently,
is a \textit{degree-}$0$ bilinear form) if and only if it satisfies%
\[
\left(  \beta\left(  V_{n}\times W_{m}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for
all }\left(  n,m\right)  \in\mathbb{Z}^{2}\text{ satisfying }n+m\neq0\right)
.
\]
(Here, $V_{n}$ denotes the $n$-th homogeneous component of $V$, and $W_{m}$
denotes the $m$-th homogeneous component of $W$.)
\end{definition}

It is straightforward to see the following characterization of degree-$0$
bilinear forms:

\begin{remark}
\label{rmk.deg0}Let $V$ and $W$ be two $\mathbb{Z}$-graded vector spaces over
a field $k$. Let $\beta:V\times W\rightarrow k$ be a $k$-bilinear form. Let
$B$ be the linear map $V\otimes W\rightarrow k$ induced by the $k$-bilinear
map $V\times W\rightarrow k$ using the universal property of the tensor
product. Consider $V\otimes W$ as a $\mathbb{Z}$-graded vector space (in the
usual way in which one defines a grading on the tensor product of two
$\mathbb{Z}$-graded vector spaces), and consider $k$ as a $\mathbb{Z}$-graded
vector space (by letting the whole field $k$ live in degree $0$).

Then, $\beta$ has degree $0$ if and only if $B$ is a graded map.
\end{remark}

\begin{verlong}
\textit{Proof of Remark \ref{rmk.deg0}.} For every $i\in\mathbb{Z}$ and every
$\mathbb{Z}$-graded vector space $U$, we denote by $U_{i}$ the $i$-th
homogeneous component of $U$. This is consistent with the use of the notations
$V_{n}$ and $W_{m}$ in Definition \ref{def.deg0}.

We know that $B$ is the linear map $V\otimes W\rightarrow k$ induced by the
$k$-bilinear map $V\times W\rightarrow k$ using the universal property of the
tensor product. Hence, any $a\in V$ and $b\in W$ satisfy%
\begin{equation}
B\left(  a\otimes b\right)  =\beta\left(  a,b\right)  . \label{pf.deg0.Bb}%
\end{equation}


We are going to prove the following two assertions:

\textit{Assertion \ref{rmk.deg0}.1:} If $\beta$ has degree $0$, then $B$ is a
graded map.

\textit{Assertion \ref{rmk.deg0}.2:} If $B$ is a graded map, then $\beta$ has
degree $0$.

\textit{Proof of Assertion \ref{rmk.deg0}.1:} Assume that $\beta$ has degree
$0$. Therefore,%
\begin{equation}
\left(  \beta\left(  V_{n}\times W_{m}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for
all }\left(  n,m\right)  \in\mathbb{Z}^{2}\text{ satisfying }n+m\neq0\right)
\label{pf.deg0.1.1}%
\end{equation}
(because Definition \ref{def.deg0} states that $\beta$ has degree $0$ if and
only if it satisfies (\ref{pf.deg0.1.1})).

Now, let $\left(  n,m\right)  \in\mathbb{Z}^{2}$ be such that $n+m\neq0$. Let
$u\in V_{n}\otimes W_{m}$.

Since $u$ is a tensor in $V_{n}\otimes W_{m}$, we can write $u$ in the form
$u=\sum\limits_{i=1}^{n}\lambda_{i}a_{i}\otimes b_{i}$ for some $n\in
\mathbb{N}$, some elements $\lambda_{1}$, $\lambda_{2}$, $...$, $\lambda_{n}$
of $k$, some elements $a_{1}$, $a_{2}$, $...$, $a_{n}$ of $V_{n}$ and some
elements $b_{1}$, $b_{2}$, $...$, $b_{n}$ of $W_{m}$. Consider this $n$, these
$\lambda_{1}$, $\lambda_{2}$, $...$, $\lambda_{n}$, these $a_{1}$, $a_{2}$,
$...$, $a_{n}$, and these $b_{1}$, $b_{2}$, $...$, $b_{n}$. Since
$u=\sum\limits_{i=1}^{n}\lambda_{i}a_{i}\otimes b_{i}$, we have%
\begin{align*}
B\left(  u\right)   &  =B\left(  \sum\limits_{i=1}^{n}\lambda_{i}a_{i}\otimes
b_{i}\right)  =\sum\limits_{i=1}^{n}\lambda_{i}\underbrace{B\left(
a_{i}\otimes b_{i}\right)  }_{\substack{=\beta\left(  a_{i},b_{i}\right)
\\\text{(by (\ref{pf.deg0.Bb}), applied}\\\text{to }a=a_{i}\text{ and }%
b=b_{i}\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }B\text{ is
}k\text{-linear}\right) \\
&  =\sum\limits_{i=1}^{n}\lambda_{i}\underbrace{\beta\left(  a_{i}%
,b_{i}\right)  }_{\substack{\in\beta\left(  V_{n}\times W_{m}\right)
\\\text{(since }a_{i}\in V_{n}\text{ and }b_{i}\in W_{m}\text{)}}}\in
\sum\limits_{i=1}^{n}\lambda_{i}\underbrace{\beta\left(  V_{n}\times
W_{m}\right)  }_{\substack{=0\\\text{(by (\ref{pf.deg0.1.1}))}}}=\sum
\limits_{i=1}^{n}\lambda_{i}0=0.
\end{align*}
In other words, $B\left(  u\right)  =0$.

Now forget that we fixed $u$. We thus have shown that every $u\in V_{n}\otimes
W_{m}$ satisfies $B\left(  u\right)  =0$. In other words, $B\left(
V_{n}\otimes W_{m}\right)  =0$.

Now forget that we fixed $\left(  n,m\right)  $. We thus have shown that
\begin{equation}
\text{every }\left(  n,m\right)  \in\mathbb{Z}^{2}\text{ such that }%
n+m\neq0\text{ satisfies }B\left(  V_{n}\otimes W_{m}\right)  =0\text{.}
\label{pf.deg0.1.3}%
\end{equation}


Now, every $N\in\mathbb{Z}$ satisfies%
\begin{align}
\left(  V\otimes W\right)  _{N}  &  =\bigoplus\limits_{i\in\mathbb{Z}}%
V_{i}\otimes W_{N-i}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the grading on the
tensor product }V\otimes W\right) \nonumber\\
&  =\sum\limits_{i\in\mathbb{Z}}V_{i}\otimes W_{N-i} \label{pf.deg0.1.4a}%
\end{align}
(since direct sums are sums). Hence, for every nonzero $N\in\mathbb{Z}$, we
have%
\begin{align}
B\left(  \left(  V\otimes W\right)  _{N}\right)   &  =B\left(  \sum
\limits_{i\in\mathbb{Z}}V_{i}\otimes W_{N-i}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.deg0.1.4a})}\right) \nonumber\\
&  =\sum\limits_{i\in\mathbb{Z}}\underbrace{B\left(  V_{i}\otimes
W_{N-i}\right)  }_{\substack{=0\\\text{(by (\ref{pf.deg0.1.3}) (applied to
}\left(  n,m\right)  =\left(  i,N-i\right)  \text{)}\\\text{(since }i+\left(
N-i\right)  =N\neq0\text{))}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }B\text{
is }k\text{-linear}\right) \nonumber\\
&  =\sum\limits_{i\in\mathbb{Z}}0=0. \label{pf.deg0.1.5}%
\end{align}


It is now clear that every $N\in\mathbb{Z}$ satisfies $B\left(  \left(
V\otimes W\right)  _{N}\right)  \subseteq k_{N}$%
\ \ \ \ \footnote{\textit{Proof.} Let $N\in\mathbb{Z}$. We have to prove that
$B\left(  \left(  V\otimes W\right)  _{N}\right)  \subseteq k_{N}$. But
$k_{0}=k$ (by the definition of the grading on $k$) and thus $B\left(  \left(
V\otimes W\right)  _{0}\right)  \subseteq k=k_{0}$. Hence, $B\left(  \left(
V\otimes W\right)  _{N}\right)  \subseteq k_{N}$ is obvious when $N=0$. Hence,
for the rest of this proof, we can WLOG assume that we don't have $N=0$.
Assume this. Thus, $N\neq0$. Hence, (\ref{pf.deg0.1.5}) yields $B\left(
\left(  V\otimes W\right)  _{N}\right)  =0\subseteq k_{N}$, qed.}. In other
words, $B$ is a graded map. This proves Assertion \ref{rmk.deg0}.1.

\textit{Proof of Assertion \ref{rmk.deg0}.2:} Assume that $B$ is a graded map.
Now, let $\left(  n,m\right)  \in\mathbb{Z}^{2}$ be such that $n+m\neq0$. Let
$a\in V_{n}$ and $b\in W_{m}$.

By the definition of the grading on $k$, we have $k_{i}=0$ for all nonzero
$i\in\mathbb{Z}$. Applying this to $i=n+m$, we obtain $k_{n+m}=0$.

By the definition of the grading on the tensor product $V\otimes W$, we have
\begin{align}
\left(  V\otimes W\right)  _{n+m}  &  =\bigoplus\limits_{i\in\mathbb{Z}}%
V_{i}\otimes W_{n+m-i}\supseteq V_{n}\otimes\underbrace{W_{n+m-n}}_{=W_{m}%
}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because }V_{n}\otimes W_{n+m-n}\text{ is an addend of the direct sum}\\
\bigoplus\limits_{i\in\mathbb{Z}}V_{i}\otimes W_{n+m-i}\text{ (namely, the
addend for }i=n\text{)}%
\end{array}
\right) \nonumber\\
&  =V_{n}\otimes W_{m}. \label{pf.deg0.2.1}%
\end{align}


But%
\begin{align*}
\beta\left(  a,b\right)   &  =B\left(  \underbrace{a}_{\in V_{n}}%
\otimes\underbrace{b}_{\in W_{m}}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.deg0.Bb})}\right) \\
&  \in B\left(  \underbrace{V_{n}\otimes W_{m}}_{\substack{\subseteq\left(
V\otimes W\right)  _{n+m}\\\text{(by (\ref{pf.deg0.2.1}))}}}\right)  \subseteq
B\left(  \left(  V\otimes W\right)  _{n+m}\right) \\
&  \subseteq k_{n+m}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }B\text{ is a
graded map}\right) \\
&  =0,
\end{align*}
so that $\beta\left(  a,b\right)  =0$.

Now, forget that we fixed $a$ and $b$. We thus have shown that $\beta\left(
a,b\right)  =0$ for every $a\in V_{n}$ and $b\in W_{m}$. In other words,
$\beta\left(  a,b\right)  =0$ for every $\left(  a,b\right)  \in V_{n}\times
W_{m}$. In other words, $\beta\left(  V_{n}\times W_{m}\right)  =0$.

Now, forget that we fixed $n$ and $m$. We thus have shown that%
\begin{equation}
\left(  \beta\left(  V_{n}\times W_{m}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for
all }\left(  n,m\right)  \in\mathbb{Z}^{2}\text{ satisfying }n+m\neq0\right)
. \label{pf.deg0.2.3}%
\end{equation}
In other words, $\beta$ has degree $0$ (because Definition \ref{def.deg0}
states that $\beta$ has degree $0$ if and only if it satisfies
(\ref{pf.deg0.2.3})). This proves Assertion \ref{rmk.deg0}.2. Now, both
Assertion \ref{rmk.deg0}.1 and Assertion \ref{rmk.deg0}.2 are proven.
Combining these two assertions, we conclude that $\beta$ has degree $0$ if and
only if $B$ is a graded map. This proves Remark \ref{rmk.deg0}.
\end{verlong}

\subsection{\label{subsect.invform}The invariant bilinear form on Verma
modules}

\subsubsection{The invariant bilinear form}

The study of the Verma modules rests on a $\mathfrak{g}$-bilinear form which
connects a highest-weight Verma module with a lowest-weight Verma module for
the opposite weight. First, let us prove its existence and basic properties:

\begin{proposition}
\label{prop.invform}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra,
and $\lambda\in\mathfrak{h}^{\ast}$.

\textbf{(a)} There exists a unique $\mathfrak{g}$-invariant bilinear form
$M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ satisfying
$\left(  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  =1$ (where we denote this
bilinear form by $\left(  \cdot,\cdot\right)  $).

\textbf{(b)} This form has degree $0$. (This means that if we consider this
bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ as
a linear map $M_{\lambda}^{+}\otimes M_{-\lambda}^{-}\rightarrow\mathbb{C}$,
then it is a graded map, where $M_{\lambda}^{+}\otimes M_{-\lambda}^{-}$ is
graded as a tensor product of graded vector spaces, and $\mathbb{C}$ is
concentrated in degree $0$.)

\textbf{(c)} Every $\mathfrak{g}$-invariant bilinear form $M_{\lambda}%
^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ is a scalar multiple of this
form $\left(  \cdot,\cdot\right)  $.
\end{proposition}

\begin{remark}
\label{rmk.invform.1}Proposition \ref{prop.invform} still holds when the
ground field $\mathbb{C}$ is replaced by a commutative ring $k$, as long as
some rather weak conditions hold (for instance, it is enough that
$\mathfrak{n}_{-}$, $\mathfrak{n}_{+}$ and $\mathfrak{h}$ are free $k$-modules).
\end{remark}

\begin{definition}
\label{def.invform}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra,
and $\lambda\in\mathfrak{h}^{\ast}$. According to Proposition
\ref{prop.invform} \textbf{(a)}, there exists a unique $\mathfrak{g}%
$-invariant bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  =1$ (where we denote this bilinear form by $\left(  \cdot
,\cdot\right)  $). This form is going to be denoted by $\left(  \cdot
,\cdot\right)  _{\lambda}$ (to stress its dependency on $\lambda$). (Later we
will also denote this form by $\left(  \cdot,\cdot\right)  _{\lambda
}^{\mathfrak{g}}$ to point out its dependency on both $\lambda$ and
$\mathfrak{g}$.)
\end{definition}

To prove Proposition \ref{prop.invform}, we recall two facts about modules
over Lie algebras:

\begin{lemma}
\label{lem.pushpull}Let $\mathfrak{a}$ be a Lie algebra, and let
$\mathfrak{b}$ be a Lie subalgebra of $\mathfrak{a}$. Let $V$ be a
$\mathfrak{b}$-module, and $W$ be an $\mathfrak{a}$-module. Then, $\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\cong\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $ as $\mathfrak{a}$-modules (where the $W$ on the right
hand side is to be understood as $\operatorname*{Res}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}W$). More precisely, there exists a canonical $\mathfrak{a}%
$-module isomorphism $\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}V\right)  \otimes W\rightarrow\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  $ which maps
$\left(  1\otimes_{U\left(  \mathfrak{b}\right)  }v\right)  \otimes w$ to
$1\otimes_{U\left(  \mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all
$v\in V$ and $w\in W$.
\end{lemma}

\begin{lemma}
\label{lem.IndRes}Let $\mathfrak{c}$ be a Lie algebra. Let $\mathfrak{a}$ and
$\mathfrak{b}$ be two Lie subalgebras of $\mathfrak{c}$ such that
$\mathfrak{a}+\mathfrak{b}=\mathfrak{c}$. Notice that $\mathfrak{a}%
\cap\mathfrak{b}$ is also a Lie subalgebra of $\mathfrak{c}$. Let $N$ be a
$\mathfrak{b}$-module. Then, $\operatorname*{Ind}\nolimits_{\mathfrak{a}%
\cap\mathfrak{b}}^{\mathfrak{a}}\left(  \operatorname*{Res}%
\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{b}}N\right)
\cong\operatorname*{Res}\nolimits_{\mathfrak{a}}^{\mathfrak{c}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{c}}N\right)  $ as
$\mathfrak{a}$-modules.
\end{lemma}

We will give two proofs of Lemma \ref{lem.pushpull}: one which is direct and
uses Hopf algebras; the other which is more elementary but less direct.

\textit{First proof of Lemma \ref{lem.pushpull}.} Remember that $U\left(
\mathfrak{a}\right)  $ is a Hopf algebra (a cocommutative one, actually; but
we won't use this). Let us denote its antipode by $S$ and use sumfree Sweedler notation.

Recalling that $\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}%
}V=U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{b}\right)  }V$
and $\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  =U\left(  \mathfrak{a}\right)  \otimes_{U\left(
\mathfrak{b}\right)  }\left(  V\otimes W\right)  $, we define a $\mathbb{C}%
$-linear map $\phi:\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}V\right)  \otimes W\rightarrow\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  $ by
$\left(  \alpha\otimes_{U\left(  \mathfrak{b}\right)  }v\right)  \otimes
w\mapsto\alpha_{\left(  1\right)  }\otimes_{U\left(  \mathfrak{b}\right)
}\left(  v\otimes S\left(  \alpha_{\left(  2\right)  }\right)  w\right)  $.
This map is easily checked to be well-defined and $\mathfrak{a}$-linear. Also,
we define a $\mathbb{C}$-linear map $\psi:\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)
\rightarrow\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}%
}V\right)  \otimes W$ by $\alpha\otimes_{U\left(  \mathfrak{b}\right)
}\left(  v\otimes w\right)  \mapsto\left(  \alpha_{\left(  1\right)  }%
\otimes_{U\left(  \mathfrak{b}\right)  }v\right)  \otimes\alpha_{\left(
2\right)  }w$. This map is easily checked to be well-defined. It is also easy
to see that $\phi\circ\psi=\operatorname*{id}$ and $\psi\circ\phi
=\operatorname*{id}$. Hence, $\phi$ and $\psi$ are mutually inverse
isomorphisms between the $\mathfrak{a}$-modules $\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W$ and
$\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $. This proves that $\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W\cong%
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $ as $\mathfrak{a}$-modules. Moreover, the isomorphism $\phi:\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\rightarrow\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $ is canonical and maps $\left(  1\otimes_{U\left(
\mathfrak{b}\right)  }v\right)  \otimes w$ to $1\otimes_{U\left(
\mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all $v\in V$ and $w\in
W$. In other words, Lemma \ref{lem.pushpull} is proven.

\textit{Second proof of Lemma \ref{lem.pushpull}.} For every $\mathfrak{a}%
$-module $Y$, we have%
\begin{align*}
&  \operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W,Y\right) \\
&  =\left(  \underbrace{\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)
\otimes W,Y\right)  }_{\cong\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}%
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
}\right)  ^{\mathfrak{a}}\\
&  \cong\left(  \operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}%
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
\right)  ^{\mathfrak{a}}=\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}%
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{b}}\left(
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right) \\
&  =\left(  \underbrace{\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
}_{\cong\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  V\otimes W,Y\right)
}\right)  ^{\mathfrak{b}}\cong\left(  \operatorname*{Hom}\nolimits_{\mathbb{C}%
}\left(  V\otimes W,Y\right)  \right)  ^{\mathfrak{b}}\\
&  =\operatorname*{Hom}\nolimits_{\mathfrak{b}}\left(  V\otimes W,Y\right)
\cong\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  ,Y\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right)  .
\end{align*}
Since this isomorphism is canonical, it gives us a natural isomorphism between
the functors $\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W,-\right)  $ and $\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  ,-\right)  $. By Yoneda's lemma, this yields that $\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\cong\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $ as $\mathfrak{a}$-modules. It is also rather clear that
the $\mathfrak{a}$-module isomorphism $\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W\rightarrow
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $ we have just obtained is canonical.

In order to check that this isomorphism maps $\left(  1\otimes_{U\left(
\mathfrak{b}\right)  }v\right)  \otimes w$ to $1\otimes_{U\left(
\mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all $v\in V$ and $w\in
W$, we must retrace the proof of Yoneda's lemma. This proof proceeds by
evaluating the natural isomorphism $\operatorname*{Hom}\nolimits_{\mathfrak{a}%
}\left(  \left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}%
}V\right)  \otimes W,-\right)  \rightarrow\operatorname*{Hom}%
\nolimits_{\mathfrak{a}}\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}\left(  V\otimes W\right)  ,-\right)  $ at the object
$\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $, thus obtaining an isomorphism%
\[
\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W,\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  \right)
\rightarrow\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  ,\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  \right)  ,
\]
and taking the preimage of $\operatorname*{id}\in\operatorname*{Hom}%
\nolimits_{\mathfrak{a}}\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}\left(  V\otimes W\right)  ,\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  \right)  $
under this isomorphism. This preimage is our isomorphism $\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\rightarrow\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $. Checking that this maps $\left(  1\otimes_{U\left(
\mathfrak{b}\right)  }v\right)  \otimes w$ to $1\otimes_{U\left(
\mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all $v\in V$ and $w\in
W$ is a matter of routine now, and left to the reader. Lemma
\ref{lem.pushpull} is thus proven.

\textit{Proof of Lemma \ref{lem.IndRes}.} Let $\rho:U\left(  \mathfrak{a}%
\right)  \otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \rightarrow U\left(  \mathfrak{c}\right)  $ be the
$\mathbb{C}$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\beta\right)  =\alpha\beta\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in
U\left(  \mathfrak{a}\right)  \text{ and }\beta\in U\left(  \mathfrak{b}%
\right)
\]
(this is clearly well-defined). By Proposition \ref{prop.U(X)U}, this map
$\rho$ is an isomorphism of left $U\left(  \mathfrak{a}\right)  $-modules and
of right $U\left(  \mathfrak{b}\right)  $-modules. Hence, $U\left(
\mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}U\left(  \mathfrak{b}\right)  \cong U\left(  \mathfrak{c}\right)  $ as left
$U\left(  \mathfrak{a}\right)  $-modules and simultaneously right $U\left(
\mathfrak{b}\right)  $-modules. Now,%
\begin{align*}
\operatorname*{Ind}\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{a}%
}\left(  \operatorname*{Res}\nolimits_{\mathfrak{a}\cap\mathfrak{b}%
}^{\mathfrak{b}}\underbrace{N}_{\cong U\left(  \mathfrak{b}\right)
\otimes_{U\left(  \mathfrak{b}\right)  }N}\right)   &  \cong%
\operatorname*{Ind}\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{a}%
}\left(  \underbrace{\operatorname*{Res}\nolimits_{\mathfrak{a}\cap
\mathfrak{b}}^{\mathfrak{b}}\left(  U\left(  \mathfrak{b}\right)
\otimes_{U\left(  \mathfrak{b}\right)  }N\right)  }_{\substack{=U\left(
\mathfrak{b}\right)  \otimes_{U\left(  \mathfrak{b}\right)  }N\\\text{(as a
}U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  \text{-module)}}}\right) \\
&  =\operatorname*{Ind}\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{a}%
}\left(  U\left(  \mathfrak{b}\right)  \otimes_{U\left(  \mathfrak{b}\right)
}N\right)  =U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }\left(  U\left(  \mathfrak{b}\right)  \otimes
_{U\left(  \mathfrak{b}\right)  }N\right) \\
&  \cong\underbrace{\left(  U\left(  \mathfrak{a}\right)  \otimes_{U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  \right)
}_{\cong U\left(  \mathfrak{c}\right)  }\otimes_{U\left(  \mathfrak{b}\right)
}N\cong U\left(  \mathfrak{c}\right)  \otimes_{U\left(  \mathfrak{b}\right)
}N\\
&  =\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{c}}%
N=\operatorname*{Res}\nolimits_{\mathfrak{a}}^{\mathfrak{c}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{c}}N\right)
\ \ \ \ \ \ \ \ \ \ \text{as }\mathfrak{a}\text{-modules.}%
\end{align*}
This proves Lemma \ref{lem.IndRes}.

\textit{Proof of Proposition \ref{prop.invform}.} We have $M_{\lambda}%
^{+}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{\lambda}=\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\mathbb{C}%
_{\lambda}$. Thus,%
\begin{align*}
&  \operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+}\otimes
M_{-\lambda}^{-},\mathbb{C}\right) \\
&  =\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  \underbrace{\left(
\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}^{\mathfrak{g}}\mathbb{C}_{\lambda}\right)  \otimes M_{-\lambda}^{-}%
}_{\substack{\cong\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus
\mathfrak{n}_{+}}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes
M_{-\lambda}^{-}\right)  \\\text{(by Lemma \ref{lem.pushpull})}}%
},\mathbb{C}\right)  \cong\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes M_{-\lambda}^{-}\right)
,\mathbb{C}\right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}\left(  \mathbb{C}_{\lambda}\otimes\underbrace{M_{-\lambda}^{-}%
}_{\substack{=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}_{-\lambda}\\=\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\mathbb{C}%
_{-\lambda}}},\mathbb{C}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
Frobenius reciprocity}\right) \\
&  =\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(
\underbrace{\mathbb{C}_{\lambda}\otimes\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\mathbb{C}%
_{-\lambda}\right)  }_{\substack{\cong\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\left(
\mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right)  \\\text{(by Lemma
\ref{lem.pushpull})}}},\mathbb{C}\right)  \cong\operatorname*{Hom}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\left(
\mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right)  ,\mathbb{C}\right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}\left(  \operatorname*{Ind}\nolimits_{\mathfrak{h}}^{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}\left(  \mathbb{C}_{\lambda}\otimes\mathbb{C}%
_{-\lambda}\right)  ,\mathbb{C}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since Lemma \ref{lem.IndRes} (applied to }\mathfrak{c}=\mathfrak{g}%
\text{, }\mathfrak{a}=\mathfrak{h}\oplus\mathfrak{n}_{+}\text{, }%
\mathfrak{b}=\mathfrak{h}\oplus\mathfrak{n}_{-}\text{ and }N=\mathbb{C}%
_{\lambda}\otimes\mathbb{C}_{-\lambda}\text{)}\\
\text{yields }\operatorname*{Ind}\nolimits_{\mathfrak{h}}^{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}\left(  \operatorname*{Res}\nolimits_{\mathfrak{h}%
}^{\mathfrak{h}\oplus\mathfrak{n}_{-}}\left(  \mathbb{C}_{\lambda}%
\otimes\mathbb{C}_{-\lambda}\right)  \right)  \cong\operatorname*{Res}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}%
}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda
}\right)  \right)  \text{,}\\
\text{which rewrites as }\operatorname*{Ind}\nolimits_{\mathfrak{h}%
}^{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(  \mathbb{C}_{\lambda}%
\otimes\mathbb{C}_{-\lambda}\right)  \cong\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\left(
\mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right) \\
\text{ (since we are suppressing the }\operatorname*{Res}\text{ functors),}\\
\text{ so that }\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus
\mathfrak{n}_{-}}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes
\mathbb{C}_{-\lambda}\right)  \cong\operatorname*{Ind}\nolimits_{\mathfrak{h}%
}^{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(  \mathbb{C}_{\lambda}%
\otimes\mathbb{C}_{-\lambda}\right)  \text{ (as }\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  \text{-modules)}%
\end{array}
\right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}}\left(  \mathbb{C}%
_{\lambda}\otimes\mathbb{C}_{-\lambda},\mathbb{C}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right) \\
&  \cong\mathbb{C}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathbb{C}%
_{\lambda}\otimes\mathbb{C}_{-\lambda}\cong\mathbb{C}\text{ as }%
\mathfrak{h}\text{-modules (this is easy to see)}\right)  .
\end{align*}
This isomorphism $\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(
M_{\lambda}^{+}\otimes M_{-\lambda}^{-},\mathbb{C}\right)  \rightarrow
\mathbb{C}$ is easily seen to map every $\mathfrak{g}$-invariant bilinear form
$\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda}%
^{-}\rightarrow\mathbb{C}$ (seen as a linear map $M_{\lambda}^{+}\otimes
M_{-\lambda}^{-}\rightarrow\mathbb{C}$) to the value $\left(  v_{\lambda}%
^{+},v_{-\lambda}^{-}\right)  $. Hence, there exists a unique $\mathfrak{g}%
$-invariant bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  =1$ (where we denote this bilinear form by $\left(  \cdot
,\cdot\right)  $), and every other $\mathfrak{g}$-invariant bilinear form
$M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ must be a scalar
multiple of this one. This proves Proposition \ref{prop.invform} \textbf{(a)}
and \textbf{(c)}.

Now, for the proof of \textbf{(b)}: Denote by $\left(  \cdot,\cdot\right)  $
the unique $\mathfrak{g}$-invariant bilinear form $M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}%
^{+},v_{-\lambda}^{-}\right)  =1$. Let us now prove that this bilinear form is
of degree $0$:

Consider the antipode $S:U\left(  \mathfrak{g}\right)  \rightarrow U\left(
\mathfrak{g}\right)  $ of the Hopf algebra $U\left(  \mathfrak{g}\right)  $.
This $S$ is a graded algebra antiautomorphism satisfying $S\left(  x\right)
=-x$ for every $x\in\mathfrak{g}$. It can be explicitly described by
\[
S\left(  x_{1}x_{2}...x_{m}\right)  =\left(  -1\right)  ^{m}x_{m}%
x_{m-1}...x_{1}\ \ \ \ \ \ \ \ \ \ \text{for all }m\in\mathbb{N}\text{ and
}x_{1},x_{2},...,x_{m}\in\mathfrak{g}.
\]


We can easily see by induction (using the $\mathfrak{g}$-invariance of the
bilinear form $\left(  \cdot,\cdot\right)  $) that $\left(  v,aw\right)
=\left(  S\left(  a\right)  v,w\right)  $ for all $v\in M_{\lambda}^{+}$ and
$w\in M_{-\lambda}^{-}$ and $a\in U\left(  \mathfrak{g}\right)  $. In
particular,%
\[
\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  =\left(  S\left(  b\right)
av_{\lambda}^{+},v_{-\lambda}^{-}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}a\in U\left(  \mathfrak{g}\right)  \text{ and }b\in U\left(  \mathfrak{g}%
\right)  .
\]
Thus, $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  =\left(  S\left(
b\right)  av_{\lambda}^{+},v_{-\lambda}^{-}\right)  =0$ whenever $a$ and $b$
are homogeneous elements of $U\left(  \mathfrak{g}\right)  $ satisfying $\deg
b>-\deg a$ (this is because any two homogeneous elements $a$ and $b$ of
$U\left(  \mathfrak{g}\right)  $ satisfying $\deg b>-\deg a$ satisfy $S\left(
b\right)  av_{\lambda}^{+}=0$\ \ \ \ \footnote{\textit{Proof.} Let $a$ and $b$
be homogeneous elements of $U\left(  \mathfrak{g}\right)  $ satisfying $\deg
b>-\deg a$. Then, $\deg b+\deg a>0$, and thus the element $S\left(  b\right)
av_{\lambda}^{+}$ of $M_{\lambda}^{+}$ is a homogeneous element of positive
degree (since $\deg v_{\lambda}^{+}=0$), but the only homogeneous element of
$M_{\lambda}^{+}$ of positive degree is $0$ (since $M_{\lambda}^{+}$ is
concentrated in nonpositive degrees), so that $S\left(  b\right)  av_{\lambda
}^{+}=0$.}). In other words, whenever $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$
are integers satisfying $m>-n$, we have $\left(  av_{\lambda}^{+}%
,bv_{-\lambda}^{-}\right)  =0$ for every $a\in U\left(  \mathfrak{g}\right)
\left[  n\right]  $ and $b\in U\left(  \mathfrak{g}\right)  \left[  m\right]
$. Since $M_{\lambda}^{+}\left[  n\right]  =\left\{  av_{\lambda}^{+}%
\ \mid\ a\in U\left(  \mathfrak{g}\right)  \left[  n\right]  \right\}  $ and
$M_{-\lambda}^{-}\left[  m\right]  =\left\{  bv_{-\lambda}^{-}\ \mid\ b\in
U\left(  \mathfrak{g}\right)  \left[  m\right]  \right\}  $, this rewrites as
follows: Whenever $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ are integers
satisfying $m>-n$, we have $\left(  M_{\lambda}^{+}\left[  n\right]
,M_{-\lambda}^{-}\left[  m\right]  \right)  =0$.

Similarly, using the formula $\left(  av,w\right)  =\left(  v,S\left(
a\right)  w\right)  $ (which holds for all $v\in M_{\lambda}^{+}$ and $w\in
M_{-\lambda}^{-}$ and $a\in U\left(  \mathfrak{g}\right)  $), we can show that
whenever $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ are integers satisfying $m<-n$,
we have $\left(  M_{\lambda}^{+}\left[  n\right]  ,M_{-\lambda}^{-}\left[
m\right]  \right)  =0$.

Thus we have $\left(  M_{\lambda}^{+}\left[  n\right]  ,M_{-\lambda}%
^{-}\left[  m\right]  \right)  =0$ whenever $m>-n$ and whenever $m<-n$. Hence,
$\left(  M_{\lambda}^{+}\left[  n\right]  ,M_{-\lambda}^{-}\left[  m\right]
\right)  $ can only be nonzero when $m=-n$. In other words, the form $\left(
\cdot,\cdot\right)  $ has degree $0$. This proves Proposition
\ref{prop.invform}. In this proof, we have not used any properties of
$\mathbb{C}$ other than being a commutative ring over which $\mathfrak{n}_{-}%
$, $\mathfrak{n}_{+}$ and $\mathfrak{h}$ are free modules (the latter was only
used for applying consequences of Poincar\'{e}-Birkhoff-Witt); we thus have
also verified Remark \ref{rmk.invform.1}.

\subsubsection{Generic nondegeneracy: Statement of the fact}

We will later (Theorem \ref{thm.verma}) see that the bilinear form $\left(
\cdot,\cdot\right)  _{\lambda}:M_{\lambda}^{+}\times M_{-\lambda}%
^{-}\rightarrow\mathbb{C}$ is nondegenerate if and only if the $\mathfrak{g}%
$-module $M_{\lambda}^{+}$ is irreducible. This makes the question of when the
form $\left(  \cdot,\cdot\right)  _{\lambda}$ is nondegenerate an important
question to study. It can, in many concrete cases, be answered by
combinatorial computations. But let us first give a general result about how
it is nondegenerate ``if $\lambda$ is in sufficiently general position'':

\begin{theorem}
\label{thm.invformnondeg}Assume that $\mathfrak{g}$ is a nondegenerate
$\mathbb{Z}$-graded Lie algebra.

Let $\left(  \cdot,\cdot\right)  $ be the form $\left(  \cdot,\cdot\right)
_{\lambda}:M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$. (In
other words, let $\left(  \cdot,\cdot\right)  $ be the unique $\mathfrak{g}%
$-invariant bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  =1$. Such a form exists and is unique by Proposition
\ref{prop.invform} \textbf{(a)}.)

In every degree, the form $\left(  \cdot,\cdot\right)  $ is nondegenerate for
generic $\lambda$. More precisely: For every $n\in\mathbb{N}$, the restriction
of the form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda
}^{-}\rightarrow\mathbb{C}$ to $M_{\lambda}^{+}\left[  -n\right]  \times
M_{-\lambda}^{-}\left[  n\right]  $ is nondegenerate for generic $\lambda$.

(What ``generic $\lambda$'' means here may depend on the degree. Thus, we
cannot claim that ``for generic $\lambda$, the form $\left(  \cdot
,\cdot\right)  $ is nondegenerate in every degree''!)
\end{theorem}

The proof of this theorem will occupy the rest of Section
\ref{subsect.invform}. While the statement of Theorem \ref{thm.invformnondeg}
itself will never be used in this text, the proof involves several useful
ideas and provides good examples of how to work with Verma modules
computationally; moreover, the main auxiliary result (Proposition
\ref{prop.det.US}) will be used later in the text.

\textbf{[Note: The below proof has been written at nighttime and not been
checked for mistakes. It also has not been checked for redundancies and
readability.]}

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: Casting bilinear
forms on coinvariant spaces}

Before we start with the proof, a general fact from representation theory:

\begin{lemma}
\label{lem.bilform}Let $k$ be a field, and let $G$ be a finite group. Let
$\Lambda\in k\left[  G\right]  $ be the element $\sum\limits_{g\in G}g$.

Let $V$ and $W$ be representations of $G$ over $k$. Let $B:V\times
W\rightarrow k$ be a $G$-invariant bilinear form.

\textbf{(a)} Then, there exists one and only one bilinear form $B^{\prime
}:V_{G}\times W_{G}\rightarrow k$ satisfying%
\[
B^{\prime}\left(  \overline{v},\overline{w}\right)  =B\left(  \Lambda
v,w\right)  =B\left(  v,\Lambda w\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}v\in V\text{ and }w\in W\text{.}%
\]
(Here, $\overline{v}$ denotes the projection of $v$ onto $V_{G}$, and
$\overline{w}$ denotes the projection of $w$ onto $W_{G}$.)

\textbf{(b)} Assume that $\left\vert G\right\vert $ is invertible in $k$ (in
other words, assume that $\operatorname*{char}k$ is either $0$ or coprime to
$\left\vert G\right\vert $). If the form $B$ is nondegenerate, then the form
$B^{\prime}$ constructed in Lemma \ref{lem.bilform} \textbf{(a)} is
nondegenerate, too.
\end{lemma}

\textit{Proof of Lemma \ref{lem.bilform}.} Every $h\in G$ satisfies%
\begin{align*}
h\Lambda &  =h\sum\limits_{g\in G}g\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\Lambda=\sum\limits_{g\in G}g\right) \\
&  =\sum\limits_{g\in G}hg=\sum\limits_{i\in G}i\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we substituted }i\text{ for }hg\text{ in the sum, since the map}\\
G\rightarrow G,\ g\mapsto hg\text{ is a bijection}%
\end{array}
\right) \\
&  =\sum\limits_{g\in G}g=\Lambda
\end{align*}
and similarly $\Lambda h=\Lambda$.

Also,%
\begin{align*}
\sum\limits_{g\in G}g^{-1}  &  =\sum\limits_{g\in G}%
g\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we substituted }g\text{ for }g^{-1}\text{ in the sum, since the
map}\\
G\rightarrow G,\ g\mapsto g^{-1}\text{ is a bijection}%
\end{array}
\right) \\
&  =\Lambda.
\end{align*}


We further notice that the group $G$ acts trivially on the $G$-modules $k$ and
$W_{G}$ (this follows from the definitions of these modules), and thus $G$
acts trivially on $\operatorname*{Hom}\left(  W_{G},k\right)  $ as well.

For every $v\in V$, the map%
\[
W\rightarrow k,\ \ \ \ \ \ \ \ \ \ w\mapsto B\left(  \Lambda v,w\right)
\]
is clearly $G$-equivariant (since it maps $hw$ to%
\begin{align*}
B\left(  \underbrace{\Lambda}_{=h\Lambda}v,hw\right)   &  =B\left(  h\Lambda
v,hw\right)  =B\left(  \Lambda v,w\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }B\text{ is }G\text{-invariant}\right) \\
&  =hB\left(  \Lambda v,w\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}G\text{ acts trivially on }k\right)
\end{align*}
for every $h\in G$ and $w\in W$), and thus descends to a map%
\[
W_{G}\rightarrow k_{G},\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto\overline
{B\left(  \Lambda v,w\right)  }.
\]
Hence, we have obtained a map%
\[
V\rightarrow\operatorname*{Hom}\left(  W_{G},k_{G}\right)
,\ \ \ \ \ \ \ \ \ \ v\mapsto\left(  \overline{w}\mapsto\overline{B\left(
\Lambda v,w\right)  }\right)  .
\]
Since $k_{G}=k$ (because $G$ acts trivially on $k$), this rewrites as a map%
\[
V\rightarrow\operatorname*{Hom}\left(  W_{G},k\right)
,\ \ \ \ \ \ \ \ \ \ v\mapsto\left(  \overline{w}\mapsto B\left(  \Lambda
v,w\right)  \right)  .
\]


This map, too, is $G$-equivariant (since it maps $hv$ to the map%
\begin{align*}
&  \left(  W_{G}\rightarrow k,\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto B\left(
\underbrace{\Lambda h}_{=\Lambda}v,w\right)  \right) \\
&  =\left(  W_{G}\rightarrow k,\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto
B\left(  \Lambda v,w\right)  \right)  =h\left(  W_{G}\rightarrow
k,\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto B\left(  \Lambda v,w\right)  \right)
\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }G\text{ acts trivially on
}\operatorname*{Hom}\left(  W_{G},k\right)  \right)
\end{align*}
for every $h\in G$ and $v\in V$). Thus, it descends to a map%
\[
V_{G}\rightarrow\left(  \operatorname*{Hom}\left(  W_{G},k\right)  \right)
_{G},\ \ \ \ \ \ \ \ \ \ \overline{v}\mapsto\overline{\left(  \overline
{w}\mapsto B\left(  \Lambda v,w\right)  \right)  }.
\]
Since $\left(  \operatorname*{Hom}\left(  W_{G},k\right)  \right)
_{G}=\operatorname*{Hom}\left(  W_{G},k\right)  $ (because $G$ acts trivially
on $\operatorname*{Hom}\left(  W_{G},k\right)  $), this rewrites as a map%
\[
V_{G}\rightarrow\operatorname*{Hom}\left(  W_{G},k\right)
,\ \ \ \ \ \ \ \ \ \ \overline{v}\mapsto\left(  \overline{w}\mapsto B\left(
\Lambda v,w\right)  \right)  .
\]


This map can be rewritten as a bilinear form $V_{G}\times W_{G}\rightarrow k$
which maps $\left(  \overline{v},\overline{w}\right)  $ to $B\left(  \Lambda
v,w\right)  $ for all $v\in V$ and $w\in W$. Since
\begin{align*}
B\left(  \Lambda v,w\right)   &  =B\left(  \sum\limits_{g\in G}gv,w\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\Lambda=\sum\limits_{g\in G}g\right)
\\
&  =\sum\limits_{g\in G}B\left(  gv,\underbrace{w}_{=gg^{-1}w}\right)
=\sum\limits_{g\in G}\underbrace{B\left(  gv,gg^{-1}w\right)  }%
_{\substack{=B\left(  v,g^{-1}w\right)  \\\text{(since }B\text{ is
}G\text{-invariant)}}}=\sum\limits_{g\in G}B\left(  v,g^{-1}w\right) \\
&  =B\left(  v,\underbrace{\sum\limits_{g\in G}g^{-1}}_{=\Lambda}w\right)
=B\left(  v,\Lambda w\right)
\end{align*}
for all $v\in V$ and $w\in W$, we have thus proven that there exists a
bilinear form $B^{\prime}:V_{G}\times W_{G}\rightarrow k$ satisfying%
\[
B^{\prime}\left(  \overline{v},\overline{w}\right)  =B\left(  \Lambda
v,w\right)  =B\left(  v,\Lambda w\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}v\in V\text{ and }w\in W\text{.}%
\]
The uniqueness of such a form is self-evident. This proves Lemma
\ref{lem.bilform} \textbf{(a)}.

\textbf{(b)} Assume that $\left\vert G\right\vert $ is invertible in $k$.
Assume that the form $B$ is nondegenerate. Consider the form $B^{\prime}$
constructed in Lemma \ref{lem.bilform} \textbf{(a)}.

Let $p\in V_{G}$ be such that $B^{\prime}\left(  p,W_{G}\right)  =0$. Since
$p\in V_{G}$, there exists some $v\in V$ such that $p=\overline{v}$. Consider
this $v$. Then, every $w\in W$ satisfies $B\left(  \Lambda v,w\right)  =0$
(since $B\left(  \Lambda v,w\right)  =B^{\prime}\left(  \underbrace{\overline
{v}}_{=p},\underbrace{\overline{w}}_{\in W_{G}}\right)  \in B^{\prime}\left(
p,W_{G}\right)  =0$). Hence, $\Lambda v=0$ (since $B$ is nondegenerate).

But since the projection of $V$ to $V_{G}$ is a $G$-module map, we have
\begin{align*}
\overline{\Lambda v}  &  =\Lambda\overline{v}=\sum\limits_{g\in G}%
\underbrace{g\overline{v}}_{\substack{=\overline{v}\\\text{(since }G\text{
acts}\\\text{trivially on }V_{G}\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }\Lambda=\sum\limits_{g\in G}g\right) \\
&  =\sum\limits_{g\in G}\overline{v}=\left\vert G\right\vert \overline{v}.
\end{align*}
Since $\left\vert G\right\vert $ is invertible in $k$, this yields
$\overline{v}=\dfrac{1}{\left\vert G\right\vert }\overline{\Lambda v}=0$
(since $\Lambda v=0$), so that $p=\overline{v}=0$.

We have thus shown that every $p\in V_{G}$ such that $B^{\prime}\left(
p,W_{G}\right)  =0$ must satisfy $p=0$. In other words, the form $B^{\prime}$
is nondegenerate. Lemma \ref{lem.bilform} \textbf{(b)} is proven.

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: The form
\texorpdfstring{$\left(\cdot,\cdot\right)  _{\lambda}^{\circ}$}{induced
by lambda on the k-th symmetric power}}

Let us formulate some standing assumptions:

\begin{Convention}
From now on until the end of Section \ref{subsect.invform}, we let
$\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra, and let $\lambda
\in\mathfrak{h}^{\ast}$. We also require that $\mathfrak{g}_{0}$ is abelian
(this is condition \textbf{(2)} of Definition \ref{def.gradLienondeg}), but we
do \textit{not} require $\mathfrak{g}$ to be nondegenerate (unless we
explicitly state this).
\end{Convention}

As vector spaces, $M_{\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)
v_{\lambda}^{+}\cong U\left(  \mathfrak{n}_{-}\right)  $ (where the
isomorphism maps $v_{\lambda}^{+}$ to $1$) and $M_{-\lambda}^{-}=U\left(
\mathfrak{n}_{+}\right)  v_{-\lambda}^{-}\cong U\left(  \mathfrak{n}%
_{+}\right)  $ (where the isomorphism maps $v_{-\lambda}^{-}$ to $1$). Thus,
the bilinear form $\left(  \cdot,\cdot\right)  =\left(  \cdot,\cdot\right)
_{\lambda}:M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$
corresponds to a bilinear form $U\left(  \mathfrak{n}_{-}\right)  \times
U\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$.

For every $n\in\mathbb{N}$, let $\left(  \cdot,\cdot\right)  _{\lambda,n}$
denote the restriction of our form $\left(  \cdot,\cdot\right)  =\left(
\cdot,\cdot\right)  _{\lambda}:M_{\lambda}^{+}\times M_{-\lambda}%
^{-}\rightarrow\mathbb{C}$ to $M_{\lambda}^{+}\left[  -n\right]  \times
M_{-\lambda}^{-}\left[  n\right]  $. In order to prove Theorem
\ref{thm.invformnondeg}, it is enough to prove that for every $n\in\mathbb{N}%
$, when $\mathfrak{g}$ is nondegenerate, this form $\left(  \cdot
,\cdot\right)  _{\lambda,n}$ is nondegenerate for generic $\lambda$.

We now introduce a $\mathbb{C}$-bilinear form, which will turn out to be, in
some sense, the ``highest term'' of the form $\left(  \cdot,\cdot\right)  $
with respect to $\lambda$ (what this exactly means will be explained in
Proposition \ref{prop.det.US}).

\begin{proposition}
\label{prop.lambda_k}For every $k\in\mathbb{N}$, there exists one and only one
$\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)
\times S^{k}\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ by
\begin{align}
\lambda_{k}\left(  \alpha_{1}\alpha_{2}...\alpha_{k},\beta_{1}\beta
_{2}...\beta_{k}\right)   &  =\sum\limits_{\sigma\in S_{k}}\lambda\left(
\left[  \alpha_{1},\beta_{\sigma\left(  1\right)  }\right]  \right)
\lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  \alpha_{k},\beta_{\sigma\left(  k\right)
}\right]  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for all }\alpha_{1},\alpha_{2},...,\alpha_{k}%
\in\mathfrak{n}_{-}\text{ and }\beta_{1},\beta_{2},...,\beta_{k}%
\in\mathfrak{n}_{+}. \label{thm.invformnondeg.pf.lambda}%
\end{align}

\end{proposition}

Here, we are using the following convention:

\begin{Convention}
From now on until the end of Section \ref{subsect.invform}, the map
$\lambda:\mathfrak{g}_{0}\rightarrow\mathbb{C}$ is extended to a linear map
$\lambda:\mathfrak{g}\rightarrow\mathbb{C}$ by composing it with the canonical
projection $\mathfrak{g}\rightarrow\mathfrak{g}_{0}$.
\end{Convention}

\textit{First proof of Proposition \ref{prop.lambda_k} (sketched).} Let
$k\in\mathbb{N}$. The value of
\[
\sum\limits_{\sigma\in S_{k}}\lambda\left(  \left[  \alpha_{1},\beta
_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[  \alpha
_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{k},\beta_{\sigma\left(  k\right)  }\right]  \right)
\]
depends linearly on each of the $\alpha_{1},\alpha_{2},...,\alpha_{k}$ and
$\beta_{1},\beta_{2},...,\beta_{k}$, and is invariant under any permutation of
the $\alpha_{1},\alpha_{2},...,\alpha_{k}$ and under any permutation of the
$\beta_{1},\beta_{2},...,\beta_{k}$ (as is easily checked). This readily shows
that we can indeed define a $\mathbb{C}$-bilinear form $\lambda_{k}%
:S^{k}\left(  \mathfrak{n}_{-}\right)  \times S^{k}\left(  \mathfrak{n}%
_{+}\right)  \rightarrow\mathbb{C}$ by (\ref{thm.invformnondeg.pf.lambda}).
This proves Proposition \ref{prop.lambda_k}.

\textit{Second proof of Proposition \ref{prop.lambda_k}.} Let $G=S_{k}$. Let
$\Lambda\in\mathbb{C}\left[  G\right]  $ be the element $\sum\limits_{g\in
S_{k}}g=\sum\limits_{\sigma\in S_{k}}\sigma=\sum\limits_{\sigma\in S_{k}%
}\sigma^{-1}$. Let $V$ and $W$ be the canonical representations $\mathfrak{n}%
_{-}^{\otimes k}$ and $\mathfrak{n}_{+}^{\otimes k}$ of $S_{k}$ (where $S_{k}$
acts by permuting the tensorands). Let $B:V\times W\rightarrow\mathbb{C}$ be
the $\mathbb{C}$-bilinear form defined as the $k$-th tensor power of the
$\mathbb{C}$-bilinear form $\mathfrak{n}_{-}\times\mathfrak{n}_{+}%
\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)  \mapsto\lambda\left(
\left[  \alpha,\beta\right]  \right)  $. It is easy to see that this form is
$S_{k}$-invariant (in fact, more generally, the $k$-th tensor power of any
bilinear form is $S_{k}$-invariant). Thus, Lemma \ref{lem.bilform}
\textbf{(a)} (applied to $\mathbb{C}$ instead of $k$) yields that there exists
one and only one bilinear form $B^{\prime}:V_{G}\times W_{G}\rightarrow
\mathbb{C}$ satisfying%
\begin{equation}
B^{\prime}\left(  \overline{v},\overline{w}\right)  =B\left(  \Lambda
v,w\right)  =B\left(  v,\Lambda w\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}v\in V\text{ and }w\in W \label{thm.invformnondeg.pf.B'}%
\end{equation}
(where $\overline{v}$ denotes the projection of $v$ onto $V_{G}=V_{S_{k}%
}=S^{k}\left(  \mathfrak{n}_{-}\right)  $, and $\overline{w}$ denotes the
projection of $w$ onto $W_{G}=W_{S_{k}}=S^{k}\left(  \mathfrak{n}_{+}\right)
$). Consider this form $B^{\prime}$. All $\alpha_{1},\alpha_{2},...,\alpha
_{k}\in\mathfrak{n}_{-}$ and $\beta_{1},\beta_{2},...,\beta_{k}\in
\mathfrak{n}_{+}$ satisfy%
\begin{align*}
&  B^{\prime}\left(  \alpha_{1}\alpha_{2}...\alpha_{k},\beta_{1}\beta
_{2}...\beta_{k}\right) \\
&  =B^{\prime}\left(  \overline{\alpha_{1}\otimes\alpha_{2}\otimes
...\otimes\alpha_{k}},\overline{\beta_{1}\otimes\beta_{2}\otimes
...\otimes\beta_{k}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\alpha_{1}\alpha_{2}...\alpha
_{k}=\overline{\alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}}\text{
and }\beta_{1}\beta_{2}...\beta_{k}=\overline{\beta_{1}\otimes\beta_{2}%
\otimes...\otimes\beta_{k}}\right) \\
&  =B\left(  \alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}%
,\Lambda\left(  \beta_{1}\otimes\beta_{2}\otimes...\otimes\beta_{k}\right)
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{thm.invformnondeg.pf.B'}),
applied to }v=\alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}\text{ and
}w=\beta_{1}\otimes\beta_{2}\otimes...\otimes\beta_{k}\right) \\
&  =B\left(  \alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}%
,\sum\limits_{\sigma\in S_{k}}\beta_{\sigma\left(  1\right)  }\otimes
\beta_{\sigma\left(  2\right)  }\otimes...\otimes\beta_{\sigma\left(
k\right)  }\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\Lambda=\sum\limits_{\sigma\in S_{k}}\sigma^{-1}\text{ yields
}\Lambda\left(  \beta_{1}\otimes\beta_{2}\otimes...\otimes\beta_{k}\right)
=\sum\limits_{\sigma\in S_{k}}\underbrace{\sigma^{-1}\left(  \beta_{1}%
\otimes\beta_{2}\otimes...\otimes\beta_{k}\right)  }_{=\beta_{\sigma\left(
1\right)  }\otimes\beta_{\sigma\left(  2\right)  }\otimes...\otimes
\beta_{\sigma\left(  k\right)  }}\\
=\sum\limits_{\sigma\in S_{k}}\beta_{\sigma\left(  1\right)  }\otimes
\beta_{\sigma\left(  2\right)  }\otimes...\otimes\beta_{\sigma\left(
k\right)  }%
\end{array}
\right) \\
&  =\sum\limits_{\sigma\in S_{k}}\underbrace{B\left(  \alpha_{1}\otimes
\alpha_{2}\otimes...\otimes\alpha_{k},\beta_{\sigma\left(  1\right)  }%
\otimes\beta_{\sigma\left(  2\right)  }\otimes...\otimes\beta_{\sigma\left(
k\right)  }\right)  }_{\substack{=\lambda\left(  \left[  \alpha_{1}%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{k},\beta_{\sigma\left(  k\right)  }\right]  \right)
\\\text{(since }B\text{ is the }k\text{-th tensor power of the }%
\mathbb{C}\text{-bilinear form }\mathfrak{n}_{-}\times\mathfrak{n}%
_{+}\rightarrow\mathbb{C},\ \left(  \alpha,\beta\right)  \mapsto\lambda\left(
\left[  \alpha,\beta\right]  \right)  \text{)}}}\\
&  =\sum\limits_{\sigma\in S_{k}}\lambda\left(  \left[  \alpha_{1}%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{k},\beta_{\sigma\left(  k\right)  }\right]  \right)  .
\end{align*}
Thus, there exists a $\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(
\mathfrak{n}_{-}\right)  \times S^{k}\left(  \mathfrak{n}_{+}\right)
\rightarrow\mathbb{C}$ satisfying (\ref{thm.invformnondeg.pf.lambda}) (namely,
$B^{\prime}$). On the other hand, there exists \textbf{at most one
}$\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)
\times S^{k}\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ satisfying
(\ref{thm.invformnondeg.pf.lambda})\ \ \ \ \footnote{\textit{Proof.} The
vector space $S^{k}\left(  \mathfrak{n}_{-}\right)  $ is spanned by products
of the form $\alpha_{1}\alpha_{2}...\alpha_{k}$ with $\alpha_{1},\alpha
_{2},...,\alpha_{k}\in\mathfrak{n}_{-}$, whereas the vector space
$S^{k}\left(  \mathfrak{n}_{+}\right)  $ is spanned by products of the form
$\beta_{1}\beta_{2}...\beta_{k}$ with $\beta_{1},\beta_{2},...,\beta_{k}%
\in\mathfrak{n}_{+}$. Hence, the equation (\ref{thm.invformnondeg.pf.lambda})
makes it possible to compute the value of $\lambda_{k}\left(  A,B\right)  $
for any $A\in S^{k}\left(  \mathfrak{n}_{-}\right)  $ and $B\in S^{k}\left(
\mathfrak{n}_{+}\right)  $. Thus, the equation
(\ref{thm.invformnondeg.pf.lambda}) uniquely determines $\lambda_{k}$. In
other words, there exists at most one $\mathbb{C}$-bilinear form $\lambda
_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)  \times S^{k}\left(  \mathfrak{n}%
_{+}\right)  \rightarrow\mathbb{C}$ satisfying
(\ref{thm.invformnondeg.pf.lambda}).}. Hence, we can indeed define a
$\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)
\times S^{k}\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ by
(\ref{thm.invformnondeg.pf.lambda}). And, moreover,%
\begin{equation}
\text{this form }\lambda_{k}\text{ is the form }B^{\prime}\text{ satisfying
(\ref{thm.invformnondeg.pf.B'}).} \label{thm.invformnondeg.pf.B'=l_k}%
\end{equation}
Proposition \ref{prop.lambda_k} is thus proven.

\begin{definition}
\label{def.lambda_k}For every $k\in\mathbb{N}$, let $\lambda_{k}:S^{k}\left(
\mathfrak{n}_{-}\right)  \times S^{k}\left(  \mathfrak{n}_{+}\right)
\rightarrow\mathbb{C}$ be the $\mathbb{C}$-bilinear form whose existence and
uniqueness is guaranteed by Proposition \ref{prop.lambda_k}. These forms can
be added together, resulting in a bilinear form $\bigoplus\limits_{k\geq
0}\lambda_{k}:S\left(  \mathfrak{n}_{-}\right)  \times S\left(  \mathfrak{n}%
_{+}\right)  \rightarrow\mathbb{C}$. It is very easy to see that this form is
of degree $0$ (where the grading on $S\left(  \mathfrak{n}_{-}\right)  $ and
$S\left(  \mathfrak{n}_{+}\right)  $ is not the one that gives the $k$-th
symmetric power the degree $k$ for every $k\in\mathbb{N}$, but is the one
induced by the grading on $\mathfrak{n}_{-}$ and $\mathfrak{n}_{+}$). Denote
this form by $\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$.
\end{definition}

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: Generic nondegeneracy
of \texorpdfstring{$\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$}{the
form induced by lambda on the symmetric power}}

\begin{lemma}
\label{lem.lambda_k}Let $\lambda\in\mathfrak{h}^{\ast}$ be such that the
$\mathbb{C}$-bilinear form $\mathfrak{n}_{-}\times\mathfrak{n}_{+}%
\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)  \mapsto\lambda\left(
\left[  \alpha,\beta\right]  \right)  $ is nondegenerate. Then, the form
$\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$ is nondegenerate.
\end{lemma}

\textit{Proof of Lemma \ref{lem.lambda_k}.} Let $k\in\mathbb{N}$. Introduce
the same notations as in the Second proof of Proposition \ref{prop.lambda_k}.

The $\mathbb{C}$-bilinear form $\mathfrak{n}_{-}\times\mathfrak{n}%
_{+}\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)  \mapsto
\lambda\left(  \left[  \alpha,\beta\right]  \right)  $ is nondegenerate. Thus,
the $k$-th tensor power of this form is also nondegenerate (since all tensor
powers of a nondegenerate form are always nondegenerate). But the $k$-th
tensor power of this form is $B$. Thus, $B$ is nondegenerate. Hence, Lemma
\ref{lem.bilform} \textbf{(b)} yields that the form $B^{\prime}$ is
nondegenerate. Due to (\ref{thm.invformnondeg.pf.B'=l_k}), this yields that
the form $\lambda_{k}$ is nondegenerate.

Forget that we fixed $k$. We thus have shown that for every $k\in\mathbb{N}$,
the form $\lambda_{k}$ is nondegenerate. Thus, the direct sum $\bigoplus
\limits_{k\geq0}\lambda_{k}$ of these forms is also nondegenerate. Since
$\bigoplus\limits_{k\geq0}\lambda_{k}=\left(  \cdot,\cdot\right)  _{\lambda
}^{\circ}$, this yields that $\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$
is nondegenerate. This proves Lemma \ref{lem.lambda_k}.

For every $n\in\mathbb{N}$, define $\left(  \cdot,\cdot\right)  _{\lambda
,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \times
S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  \rightarrow\mathbb{C}$ to
be the restriction of this form $\left(  \cdot,\cdot\right)  _{\lambda}%
^{\circ}=\bigoplus\limits_{k\geq0}\lambda_{k}:S\left(  \mathfrak{n}%
_{-}\right)  \times S\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$
to $S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \times S\left(
\mathfrak{n}_{+}\right)  \left[  n\right]  $. We now need the following
strengthening of Lemma \ref{lem.lambda_k}:

\begin{lemma}
\label{lem.lambda_k.2}Let $n\in\mathbb{N}$ and $\lambda\in\mathfrak{h}^{\ast}$
be such that the bilinear form%
\[
\mathfrak{g}_{-k}\times\mathfrak{g}_{k}\rightarrow\mathbb{C}%
,\ \ \ \ \ \ \ \ \ \ \left(  a,b\right)  \mapsto\lambda\left(  \left[
a,b\right]  \right)
\]
is nondegenerate for every $k\in\left\{  1,2,...,n\right\}  $. Then, the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ must also be nondegenerate.
\end{lemma}

\textit{Proof of Lemma \ref{lem.lambda_k.2}.} For Lemma \ref{lem.lambda_k} to
hold, we did not need $\mathfrak{g}$ to be a graded Lie algebra; we only
needed that $\mathfrak{g}$ is a graded vector space with a well-defined
bilinear map $\left[  \cdot,\cdot\right]  :\mathfrak{g}_{-k}\times
\mathfrak{g}_{k}\rightarrow\mathfrak{g}_{0}$ for every positive integer $k$.
This is a rather weak condition, and holds not only for $\mathfrak{g}$, but
also for the graded subspace $\mathfrak{g}_{-n}\oplus\mathfrak{g}_{-n+1}%
\oplus...\oplus\mathfrak{g}_{n}$ of $\mathfrak{g}$. Denote this graded
subspace $\mathfrak{g}_{-n}\oplus\mathfrak{g}_{-n+1}\oplus...\oplus
\mathfrak{g}_{n}$ by $\mathfrak{g}^{\prime}$, and let $\mathfrak{n}%
_{-}^{\prime}\oplus\mathfrak{h}^{\prime}\oplus\mathfrak{n}_{+}^{\prime}$ be
its triangular decomposition (thus, $\mathfrak{n}_{-}^{\prime}=\mathfrak{g}%
_{-n}\oplus\mathfrak{g}_{-n+1}\oplus...\oplus\mathfrak{g}_{-1}$,
$\mathfrak{h}^{\prime}=\mathfrak{g}_{0}=\mathfrak{h}$ and $\mathfrak{n}%
_{+}^{\prime}=\mathfrak{g}_{1}\oplus\mathfrak{g}_{2}\oplus...\oplus
\mathfrak{g}_{n}$). The $\mathbb{C}$-bilinear form $\mathfrak{n}_{-}^{\prime
}\times\mathfrak{n}_{+}^{\prime}\rightarrow\mathbb{C},$ $\left(  \alpha
,\beta\right)  \mapsto\lambda\left(  \left[  \alpha,\beta\right]  \right)  $
is nondegenerate (because the bilinear form $\mathfrak{g}_{-k}\times
\mathfrak{g}_{k}\rightarrow\mathbb{C},\ \left(  a,b\right)  \mapsto
\lambda\left(  \left[  a,b\right]  \right)  $ is nondegenerate for every
$k\in\left\{  1,2,...,n\right\}  $). Hence, by Lemma \ref{lem.lambda_k}, the
form $\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$ \textit{defined for
}$\mathfrak{g}^{\prime}$ \textit{instead of }$\mathfrak{g}$ is nondegenerate.
Since this form is of degree $0$, the restriction $\left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}$ of this form to $S\left(  \mathfrak{n}_{-}^{\prime
}\right)  \left[  -n\right]  \times S\left(  \mathfrak{n}_{+}^{\prime}\right)
\left[  n\right]  $ must also be nondegenerate\footnote{This is because if $V$
and $W$ are two graded vector spaces, and $\phi:V\times W\rightarrow
\mathbb{C}$ is a nondegenerate bilinear form of degree $0$, then for every
$n\in\mathbb{Z}$, the restriction of $\phi$ to $V\left[  -n\right]  \times
W\left[  n\right]  $ must also be nondegenerate.}. But since $S\left(
\mathfrak{n}_{+}^{\prime}\right)  \left[  n\right]  =S\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  $\ \ \ \ \footnote{\textit{Proof.} Since
$\mathfrak{n}_{+}=\sum\limits_{i\geq1}\mathfrak{g}_{i}$, we have $S\left(
\mathfrak{n}_{+}\right)  =\sum\limits_{k\in\mathbb{N}}\sum
\limits_{\substack{\left(  i_{1},i_{2},...,i_{k}\right)  \in\mathbb{N}%
^{k};\\\text{each }i_{j}\geq1}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}%
}...\mathfrak{g}_{i_{k}}$ and thus%
\[
S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  =\sum\limits_{k\in
\mathbb{N}}\sum\limits_{\substack{\left(  i_{1},i_{2},...,i_{k}\right)
\in\mathbb{N}^{k};\\\text{each }i_{j}\geq1;\\i_{1}+i_{2}+...+i_{k}%
=n}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}}%
\]
(since $\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}%
}\subseteq S\left(  \mathfrak{n}_{+}\right)  \left[  i_{1}+i_{2}%
+...+i_{k}\right]  $ for all $\left(  i_{1},i_{2},...,i_{k}\right)
\in\mathbb{N}^{k}$). Similarly,%
\[
S\left(  \mathfrak{n}_{+}^{\prime}\right)  \left[  n\right]  =\sum
\limits_{k\in\mathbb{N}}\sum\limits_{\substack{\left(  i_{1},i_{2}%
,...,i_{k}\right)  \in\mathbb{N}^{k};\\\text{each }i_{j}\geq1;\\\text{each
}\left\vert i_{j}\right\vert \leq n;\\i_{1}+i_{2}+...+i_{k}=n}}\mathfrak{g}%
_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}}%
\]
(because $\mathfrak{g}^{\prime}$ is obtained from $\mathfrak{g}$ by removing
all $\mathfrak{g}_{i}$ with $\left\vert i\right\vert >n$). Thus,%
\begin{align*}
S\left(  \mathfrak{n}_{+}^{\prime}\right)  \left[  n\right]   &
=\sum\limits_{k\in\mathbb{N}}\sum\limits_{\substack{\left(  i_{1}%
,i_{2},...,i_{k}\right)  \in\mathbb{N}^{k};\\\text{each }i_{j}\geq
1;\\\text{each }\left\vert i_{j}\right\vert \leq n;\\i_{1}+i_{2}+...+i_{k}%
=n}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}}%
=\sum\limits_{k\in\mathbb{N}}\sum\limits_{\substack{\left(  i_{1}%
,i_{2},...,i_{k}\right)  \in\mathbb{N}^{k};\\\text{each }i_{j}\geq
1;\\i_{1}+i_{2}+...+i_{k}=n}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}%
}...\mathfrak{g}_{i_{k}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we removed the condition }\left(  \text{each }\left\vert
i_{j}\right\vert \leq n\right)  \text{, because it was redundant}\\
\text{(since every }\left(  i_{1},i_{2},...,i_{k}\right)  \in\mathbb{N}%
^{k}\text{ satisfying }i_{1}+i_{2}+...+i_{k}=n\text{ automatically}\\
\text{satisfies }\left(  \text{each }\left\vert i_{j}\right\vert \leq
n\right)  \text{)}%
\end{array}
\right) \\
&  =S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  ,
\end{align*}
qed.} and $S\left(  \mathfrak{n}_{-}^{\prime}\right)  \left[  -n\right]
=S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  $\ \ \ \ \footnote{for
analogous reasons}, this restriction is exactly our form $\left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)  \left[
-n\right]  \times S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]
\rightarrow\mathbb{C}$ (in fact, the form is clearly given by the same
formula). Thus we have shown that our form $\left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]
\times S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  \rightarrow
\mathbb{C}$ is nondegenerate. Lemma \ref{lem.lambda_k.2} is proven.

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}:
\texorpdfstring{$\left(  \cdot ,\cdot\right)  _{\lambda}^{\circ}$}{the form
induced by lambda} is the ``highest term'' of \texorpdfstring{$\left(
\cdot,\cdot\right)  _{\lambda}$}{the invariant bilinear form}}

Before we go on, let us sketch the direction in which we want to go. We want
to study how, for a fixed $n\in\mathbb{N}$, the form $\left(  \cdot
,\cdot\right)  _{\lambda,n}$ changes with $\lambda$. If $V$ and $W$ are two
finite-dimensional vector spaces \textbf{of the same dimension}, and if we
have chosen bases for these two vector spaces $V$ and $W$, then we can
represent every bilinear form $V\times W\rightarrow\mathbb{C}$ as a square
matrix with respect to these two bases, and the bilinear form is nondegenerate
if and only if this matrix has nonzero determinant. This suggests that we
study how the determinant $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $ of the form $\left(  \cdot,\cdot\right)  _{\lambda,n}$
with respect to some bases of $M_{\lambda}^{+}\left[  -n\right]  $ and
$M_{-\lambda}^{-}\left[  n\right]  $ changes with $\lambda$ (and, in
particular, show that this determinant is nonzero for generic $\lambda$ when
$\mathfrak{g}$ is nondegenerate). Of course, speaking of this determinant
$\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)  $ only makes
sense when the bases of $M_{\lambda}^{+}\left[  -n\right]  $ and $M_{-\lambda
}^{-}\left[  n\right]  $ have the same size (since only square matrices have
determinants), but this is automatically satisfied if we have $\dim\left(
\mathfrak{g}_{n}\right)  =\dim\left(  \mathfrak{g}_{-n}\right)  $ for every
integer $n>0$ (this condition is automatically satisfied when $\mathfrak{g}$
is a nondegenerate $\mathbb{Z}$-graded Lie algebra, but of course not only then).

Unfortunately, the spaces $M_{\lambda}^{+}\left[  -n\right]  $ and
$M_{-\lambda}^{-}\left[  n\right]  $ themselves change with $\lambda$. Thus,
if we want to pick some bases of $M_{\lambda}^{+}\left[  -n\right]  $ and
$M_{-\lambda}^{-}\left[  n\right]  $ for all $\lambda\in\mathfrak{h}^{\ast}$,
we have to pick new bases \textbf{for every }$\lambda$. If we just pick these
bases randomly, then the determinant $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $ can change very unpredictably (because the determinant
depends on the choice of bases). Thus, if we want to say something interesting
about how $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)  $
changes with $\lambda$, then we should specify a reasonable choice of bases
for all $\lambda$. Fortunately, this is not difficult: It is enough to choose
Poincar\'{e}-Birkhoff-Witt bases for $U\left(  \mathfrak{n}_{-}\right)
\left[  -n\right]  $ and $U\left(  \mathfrak{n}_{+}\right)  \left[  n\right]
$, and thus obtain bases $M_{\lambda}^{+}\left[  -n\right]  $ and
$M_{-\lambda}^{-}\left[  n\right]  $ due to the isomorphisms $M_{\lambda}%
^{+}\left[  -n\right]  \cong U\left(  \mathfrak{n}_{-}\right)  \left[
-n\right]  $ and $M_{-\lambda}^{-}\left[  n\right]  \cong U\left(
\mathfrak{n}_{+}\right)  \left[  n\right]  $. (See Convention
\ref{conv.invformnondeg.bases} for details.) With bases chosen this way, the
determinant $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)  $
will depend on $\lambda$ polynomially, and we will be able to conclude some
useful properties of this polynomial.

So much for our roadmap. Let us first make a convention:

\begin{Convention}
If $V$ and $W$ are two finite-dimensional vector spaces \textbf{of the same
dimension}, and if we have chosen bases for these two vector spaces $V$ and
$W$, then we can represent every bilinear form $B:V\times W\rightarrow
\mathbb{C}$ as a square matrix with respect to these two bases. The
determinant of this matrix will be denoted by $\det B$ and called the
\textit{determinant of the form }$B$. Of course, this determinant $\det B$
depends on the bases chosen. A change of either basis induces a scaling of
$\det B$ by a \textbf{nonzero} scalar. Thus, while the determinant $\det B$
itself depends on the choice of bases, the property of $\det B$ to be zero or
nonzero does \textbf{not} depend on the choice of bases.
\end{Convention}

Let us now look at how the form $\left(  \cdot,\cdot\right)  _{\lambda,n}$ and
its determinant $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
$ depend on $\lambda$. We want to show that this dependence is polynomial. In
order to make sense of this, let us define what we mean by ``polynomial'' here:

\begin{definition}
\label{def.det.US.poly}Let $V$ be a finite-dimensional vector space. A
function $\phi:V\rightarrow\mathbb{C}$ is said to be a \textit{polynomial
function} (or just to be \textit{polynomial} -- but this is not the same as
being \textit{a polynomial}) if one of the following equivalent conditions holds:

\textbf{(1)} There exist a basis $\left(  \beta_{1},\beta_{2},...,\beta
_{m}\right)  $ of the dual space $V^{\ast}$ and a polynomial $P\in
\mathbb{C}\left[  X_{1},X_{2},...,X_{m}\right]  $ such that%
\[
\text{every }v\in V\text{ satisfies }\phi\left(  v\right)  =P\left(  \beta
_{1}\left(  v\right)  ,\beta_{2}\left(  v\right)  ,...,\beta_{m}\left(
v\right)  \right)  .
\]


\textbf{(2)} For every basis $\left(  \beta_{1},\beta_{2},...,\beta
_{m}\right)  $ of the dual space $V^{\ast}$, there exists a polynomial
$P\in\mathbb{C}\left[  X_{1},X_{2},...,X_{m}\right]  $ such that%
\[
\text{every }v\in V\text{ satisfies }\phi\left(  v\right)  =P\left(  \beta
_{1}\left(  v\right)  ,\beta_{2}\left(  v\right)  ,...,\beta_{m}\left(
v\right)  \right)  .
\]


\textbf{(3)} There exist finitely many elements $\beta_{1}$, $\beta_{2}$,
$...$, $\beta_{m}$ of the dual space $V^{\ast}$ and a polynomial
$P\in\mathbb{C}\left[  X_{1},X_{2},...,X_{m}\right]  $ such that%
\[
\text{every }v\in V\text{ satisfies }\phi\left(  v\right)  =P\left(  \beta
_{1}\left(  v\right)  ,\beta_{2}\left(  v\right)  ,...,\beta_{m}\left(
v\right)  \right)  .
\]

\end{definition}

Note that this is exactly the meaning of the word ``polynomial function'' that
is used in Classical Invariant Theory. In our case (where the field is
$\mathbb{C}$), polynomial functions $V\rightarrow\mathbb{C}$ can be identified
with elements of the symmetric algebra $\operatorname*{S}\left(  V^{\ast
}\right)  $, and in some sense are an ``obsoleted version'' of the
latter.\footnote{The identification of polynomial functions $V\rightarrow
\mathbb{C}$ with elements of the symmetric algebra $\operatorname*{S}\left(
V^{\ast}\right)  $ works similarly over any \textit{infinite} field instead of
$\mathbb{C}$. It breaks down over finite fields, however (because different
elements of $\operatorname*{S}\left(  V^{\ast}\right)  $ may correspond to the
same polynomial function over a finite field).} For our goals, however,
polynomial functions are enough. Let us define the notion of
\textit{homogeneous polynomial functions}:

\begin{definition}
\label{def.det.US.poly.hom}Let $V$ be a finite-dimensional vector space.

\textbf{(a)} Let $n\in\mathbb{N}$. A polynomial function $\phi:V\rightarrow
\mathbb{C}$ is said to be \textit{homogeneous of degree }$n$ if and only if%
\[
\text{every }v\in V\text{ and every }\lambda\in\mathbb{C}\text{ satisfy }%
\phi\left(  \lambda v\right)  =\lambda^{n}\phi\left(  v\right)  .
\]


\textbf{(b)} A polynomial function $\phi:V\rightarrow\mathbb{C}$ is said to be
\textit{homogeneous} if and only if there exists some $n\in\mathbb{N}$ such
that $\phi$ is homogeneous of degree $n$.

\textbf{(c)} It is easy to see that for every polynomial function
$\phi:V\rightarrow\mathbb{C}$, there exists a unique sequence $\left(
\phi_{n}\right)  _{n\in\mathbb{N}}$ of polynomial functions $\phi
_{n}:V\rightarrow\mathbb{C}$ such that all but finitely many $n\in\mathbb{N}$
satisfy $\phi_{n}=0$, such that $\phi_{n}$ is homogeneous of degree $n$ for
every $n\in\mathbb{N}$, and such that $\phi=\sum\limits_{n\in\mathbb{N}}%
\phi_{n}$. This sequence is said to be the \textit{graded decomposition} of
$\phi$. For every $n\in\mathbb{N}$, its member $\phi_{n}$ is called the
$n$\textit{-th homogeneous component} of $\phi$. If $N$ is the highest
$n\in\mathbb{N}$ such that $\phi_{n}\neq0$, then $\phi_{N}$ is said to be the
\textit{leading term} of $\phi$.
\end{definition}

Note that Definition \ref{def.det.US.poly.hom} \textbf{(c)} defines the
``leading term'' of a polynomial as its highest-degree nonzero homogeneous
component. This ``leading term'' may (and usually will) contain more than one
monomial, so this notion of a ``leading term'' is not the same as the notion
of a ``leading term'' commonly used, e. g., in Gr\"{o}bner basis theory.

We now state the following crucial fact:

\begin{proposition}
\label{prop.det.US}Let $n\in\mathbb{N}$. Assume that $\mathfrak{g}$ is a
nondegenerate $\mathbb{Z}$-graded Lie algebra. As a consequence,
$\dim\mathfrak{h}=\dim\left(  \mathfrak{g}_{0}\right)  \neq\infty$, so that
$\dim\left(  \mathfrak{h}^{\ast}\right)  \neq\infty$, and thus the notion of a
polynomial function $\mathfrak{h}^{\ast}\rightarrow\mathbb{C}$ is well-defined.

There is an appropriate way of choosing bases of the vector spaces $S\left(
\mathfrak{n}_{-}\right)  \left[  -n\right]  $ and $S\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  $ and bases of the vector spaces $M_{\lambda
}^{+}\left[  -n\right]  $ and $M_{-\lambda}^{-}\left[  n\right]  $ for all
$\lambda\in\mathfrak{h}^{\ast}$ such that the following holds:

\textbf{(a)} The determinants $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $ and $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}\right)  $ (these determinants are defined with respect to
the chosen bases of $S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  $,
$S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  $, $M_{\lambda}%
^{+}\left[  -n\right]  $ and $M_{-\lambda}^{-}\left[  n\right]  $) depend
polynomially on $\lambda$. By this, we mean that the functions%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\]
and%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\]
are polynomial functions.

\textbf{(b)} The leading term of the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\]
is%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  .
\]

\end{proposition}

\begin{remark}
We can extend Proposition \ref{prop.det.US} to the case when $\mathfrak{g}$ is
no longer nondegenerate. However, this requires the following changes to
Proposition \ref{prop.det.US}:

Replace the requirement that $\mathfrak{g}$ be nondegenerate by the
requirement that $\mathfrak{g}$ satisfy the conditions \textbf{(1)} and
\textbf{(2)} in Definition \ref{def.gradLienondeg} as well as the condition
that $\dim\left(  \mathfrak{g}_{n}\right)  =\dim\left(  \mathfrak{g}%
_{-n}\right)  $ for every integer $n>0$ (this condition is a weakening of
condition \textbf{(3)} in Definition \ref{def.gradLienondeg}). Replace the
claim that ``The leading term of the polynomial function $\det\left(  \left(
\cdot,\cdot\right)  _{\lambda,n}\right)  $ is $\det\left(  \left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}\right)  $, up to multiplication by a
nonzero scalar'' by the claim that ``There exists some $k\in\mathbb{N}$ such
that the polynomial function $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}\right)  $ is the $k$-th homogeneous component of the
polynomial function $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda
,n}\right)  $, and such that the $\ell$-th homogeneous component of the
polynomial function $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda
,n}\right)  $ is $0$ for all $\ell>k$''. Note that this does not imply that
$\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  $ is not
identically zero, and indeed $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}\right)  $ can be identically zero.
\end{remark}

Before we prove Proposition \ref{prop.det.US}, let us show how it completes
the proof of Theorem \ref{thm.invformnondeg}:

\textit{Proof of Theorem \ref{thm.invformnondeg}.} Fix a positive
$n\in\mathbb{N}$. For generic $\lambda$, the bilinear form%
\[
\mathfrak{g}_{-k}\times\mathfrak{g}_{k}\rightarrow\mathbb{C}%
,\ \ \ \ \ \ \ \ \ \ \left(  a,b\right)  \mapsto\lambda\left(  \left[
a,b\right]  \right)
\]
is nondegenerate for every $k\in\left\{  1,2,...,n\right\}  $ (because
$\mathfrak{g}$ is nondegenerate). Thus, for generic $\lambda$, the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ must also be nondegenerate
(by Lemma \ref{lem.lambda_k.2}), so that $\det\left(  \left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}\right)  \neq0$. Since the leading term of
the polynomial function
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\]
is%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\]
(by Proposition \ref{prop.det.US}), this yields that $\det\left(  \left(
\cdot,\cdot\right)  _{\lambda,n}\right)  \neq0$ for generic $\lambda$. In
other words, the form $\left(  \cdot,\cdot\right)  _{\lambda,n}$ is
nondegenerate for generic $\lambda$. But this form $\left(  \cdot
,\cdot\right)  _{\lambda,n}$ is exactly the restriction of the form $\left(
\cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow
\mathbb{C}$ to $M_{\lambda}^{+}\left[  -n\right]  \times M_{-\lambda}%
^{-}\left[  n\right]  $. Hence, the restriction of the form $\left(
\cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow
\mathbb{C}$ to $M_{\lambda}^{+}\left[  -n\right]  \times M_{-\lambda}%
^{-}\left[  n\right]  $ is nondegenerate for generic $\lambda$. This proves
Theorem \ref{thm.invformnondeg}.

So all that remains to finish the proof of Theorem \ref{thm.invformnondeg} is
verifying Proposition \ref{prop.det.US}.

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: Polynomial maps}

We already defined the notion of a polynomial function in Definition
\ref{def.det.US.poly}. Let us give a definition of a notion of a ``polynomial
map'' which is tailored for our proof of Theorem \ref{thm.invformnondeg}. I
cannot guarantee that it is the same as what other people call ``polynomial
map'', but it should be very close.

\begin{definition}
\label{def.det.US.polymap}Let $V$ be a finite-dimensional vector space. Let
$W$ be a vector space. A map $\phi:V\rightarrow W$ is said to be a
\textit{polynomial map} if and only if there exist:

- some $n\in\mathbb{N}$;

- $n$ vectors $w_{1}$, $w_{2}$, $...$, $w_{n}$ in $W$;

- $n$ polynomial functions $P_{1}$, $P_{2}$, $...$, $P_{n}$ from $V$ to
$\mathbb{C}$

such that%
\[
\text{every }v\in V\text{ satisfies }\phi\left(  v\right)  =\sum
\limits_{i=1}^{n}P_{i}\left(  v\right)  w_{i}.
\]

\end{definition}

Note that it is clear that:

\begin{itemize}
\item If $V$ is a finite-dimensional vector space and $W$ is a vector space,
then any $\mathbb{C}$-linear combination of polynomial maps $V\rightarrow W$
is a polynomial map.

\item If $V$ is a finite-dimensional vector space and $W$ is a $\mathbb{C}%
$-algebra, then any product of polynomial maps $V\rightarrow W$ is a
polynomial map.

\item If $V$ is a finite-dimensional vector space, then polynomial maps
$V\rightarrow\mathbb{C}$ are exactly the same as polynomial functions
$V\rightarrow\mathbb{C}$ (since $\mathbb{C}$-linear combinations of polynomial
functions are polynomial functions).
\end{itemize}

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: The deformed Lie
algebra \texorpdfstring{$\mathfrak{g}^{\varepsilon}$}{g superscript epsilon}}

Before we go on, here is a rough plan of how we will attack Proposition
\ref{prop.det.US}:

In order to gain a foothold on $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $, we are going to consider not just one Lie algebra
$\mathfrak{g}$ but a whole family $\left(  \mathfrak{g}^{\varepsilon}\right)
_{\varepsilon\in\mathbb{C}}$ of its ``deformations'' at the same time. Despite
all of these deformations being isomorphic as Lie algebras with one exception,
they will give us useful information: we will show that the bilinear forms
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{\varepsilon}}$ they
induce, in some sense, depend ``polynomially'' on $\lambda$ and $\varepsilon$.
We will have to restrain from speaking directly of the bilinear form $\left(
\cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{\varepsilon}}$ as depending
polynomially on $\lambda$, since this makes no sense (the domain of the
bilinear form $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}%
^{\varepsilon}}$ changes with $\lambda$), but instead we will sample this form
on particular elements of the Verma modules coming from appropriately chosen
Poincar\'{e}-Birkhoff-Witt bases of $U\left(  \mathfrak{n}_{-}^{\varepsilon
}\right)  $ and $U\left(  \mathfrak{n}_{+}^{\varepsilon}\right)  $. These
sampled values of the form will turn out to depend polynomially on $\lambda$
and $\varepsilon$, and thus the determinant $\det\left(  \left(  \cdot
,\cdot\right)  _{\lambda,n}^{\varepsilon}\right)  $ will be a polynomial
function in $\lambda$ and $\varepsilon$. This polynomial function will turn
out to have some kind of ``homogeneity with respect to $\lambda$ and
$\varepsilon^{2}$'' (this is not a standard notion, but see Corollary
\ref{cor.invformnondeg.polynomiality} for what exactly this means in our
context), so that the leading term of $\lambda$ will be the term with smallest
power of $\varepsilon$ (and, as it will turn out, this will be the power
$\varepsilon^{0}$, so this term will be obtainable by setting $\varepsilon$ to
$0$). Once this all is formalized and proven, we will explicitly show that
(more or less) $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{0}%
}=\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ (again this does not
literally hold but must be correctly interpreted), and we know the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ to be nondegenerate (by
Lemma \ref{lem.lambda_k.2}), so that the form $\left(  \cdot,\cdot\right)
_{\lambda,n}^{\mathfrak{g}^{0}}$ will be nondegenerate, and this will quickly
yield the nondegeneracy of $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\varepsilon}\right)  $ for generic $\lambda$ and $\varepsilon$,
and thus the nondegeneracy of $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $ for generic $\lambda$.

Now, to the details. Consider the situation of Proposition \ref{prop.det.US}.
In particular, this means that (from now on until the end of Section
\ref{subsect.invform}) the Lie algebra $\mathfrak{g}$ will be assumed nondegenerate.

First, let us define $\left(  \mathfrak{g}^{\varepsilon}\right)
_{\varepsilon\in\mathbb{C}}$.

For every $\varepsilon\in\mathbb{C}$, let us define a new Lie bracket $\left[
\cdot,\cdot\right]  ^{\varepsilon}$ on the vector space $\mathfrak{g}$ by the
formula%
\begin{align}
\left[  x,y\right]  ^{\varepsilon}  &  =\varepsilon\left[  x,y\right]
+\left(  1-\varepsilon\right)  \pi\left(  \left[  x,y\right]  \right)
-\varepsilon\left(  1-\varepsilon\right)  \left[  x,\pi\left(  y\right)
\right]  -\varepsilon\left(  1-\varepsilon\right)  \left[  \pi\left(
x\right)  ,y\right] \label{pf.invformnondeg.g^epsi.1}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for all }x\in\mathfrak{g}\text{ and }%
y\in\mathfrak{g},\nonumber
\end{align}
where $\pi$ is the canonical projection $\mathfrak{g}\rightarrow
\mathfrak{g}_{0}$. In other words, let us define a new Lie bracket $\left[
\cdot,\cdot\right]  ^{\varepsilon}$ on the vector space $\mathfrak{g}$ by%
\begin{align}
\left[  x,y\right]  ^{\varepsilon}  &  =\varepsilon^{\delta_{n,0}+\delta
_{m,0}+1-\delta_{n+m,0}}\left[  x,y\right]  \label{pf.invformnondeg.g^epsi.2}%
\\
&  \ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{Z}\text{, }m\in
\mathbb{Z}\text{, }x\in\mathfrak{g}_{n}\text{ and }y\in\mathfrak{g}%
_{m}\nonumber
\end{align}
(note that the right hand side of this equation makes sense since
$1-\delta_{n+m,0}\geq0$ for all $n\in\mathbb{Z}$ and $m\in\mathbb{Z}%
$)\ \ \ \ \footnote{Proving that these two definitions of $\left[  \cdot
,\cdot\right]  ^{\varepsilon}$ are equivalent is completely straightforward:
just assume WLOG that $x$ and $y$ are homogeneous, so that $x\in
\mathfrak{g}_{n}$ and $y\in\mathfrak{g}_{m}$ for $n\in\mathbb{Z}$ and
$m\in\mathbb{Z}$, and distinguish between the following four cases:
\par
\textit{Case 1:} We have $n=0$ and $m=0$.
\par
\textit{Case 2:} We have $n\neq0$ and $m\neq0$ but $n+m=0$.
\par
\textit{Case 3:} We have $n\neq0$, $m\neq0$ and $n+m\neq0$.
\par
\textit{Case 4:} Exactly one of $n$ and $m$ is $0$.
\par
In Case 1, the assumption that $\mathfrak{g}_{0}$ is abelian must be used.}.
It is easy to prove that this Lie bracket $\left[  \cdot,\cdot\right]
^{\varepsilon}$ is antisymmetric and satisfies the Jacobi
identity\footnote{\textit{Proof.} Antisymmetry is obvious. As for the Jacobi
identity, it can be proven in a straightforward way:
\par
We must show the equality $\left[  x,\left[  y,z\right]  ^{\varepsilon
}\right]  ^{\varepsilon}+\left[  y,\left[  z,x\right]  ^{\varepsilon}\right]
^{\varepsilon}+\left[  z,\left[  x,y\right]  ^{\varepsilon}\right]
^{\varepsilon}=0$ for all $x,y,z\in\mathfrak{g}$. Since this equality is
linear in each of $x$, $y$ and $z$, it is enough to prove it for homogeneous
$x,y,z\in\mathfrak{g}$. So let $x,y,z\in\mathfrak{g}$ be homogeneous. Then,
there exist $n,m,p\in\mathbb{Z}$ such that $x\in\mathfrak{g}_{n}$,
$y\in\mathfrak{g}_{m}$ and $z\in\mathfrak{g}_{p}$. Consider these $n$, $m$ and
$p$. Then, by (\ref{pf.invformnondeg.g^epsi.2}) (applied to $y$, $z$, $m$ and
$p$ instead of $x$, $y$, $n$ and $m$), we have $\left[  y,z\right]
^{\varepsilon}=\varepsilon^{\delta_{m,0}+\delta_{p,0}+1-\delta_{m+p,0}}\left[
y,z\right]  $. Thus,%
\begin{align*}
&  \left[  x,\left[  y,z\right]  ^{\varepsilon}\right]  ^{\varepsilon}\\
&  =\left[  x,\varepsilon^{\delta_{m,0}+\delta_{p,0}+1-\delta_{m+p,0}}\left[
y,z\right]  \right]  ^{\varepsilon}=\varepsilon^{\delta_{m,0}+\delta
_{p,0}+1-\delta_{m+p,0}}\left[  x,\left[  y,z\right]  \right]  ^{\varepsilon
}\\
&  =\varepsilon^{\delta_{m,0}+\delta_{p,0}+1-\delta_{m+p,0}}\varepsilon
^{\delta_{n,0}+\delta_{m+p,0}+1-\delta_{n+m+p,0}}\left[  x,\left[  y,z\right]
\right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because (\ref{pf.invformnondeg.g^epsi.2}) (applied to }\left[
y,z\right]  \text{ and }m+p\text{ instead of }y\text{ and }m\text{) yields}\\
\left[  x,\left[  y,z\right]  \right]  ^{\varepsilon}=\varepsilon
^{\delta_{n,0}+\delta_{m+p,0}+1-\delta_{n+m+p,0}}\left[  x,\left[  y,z\right]
\right]  \text{ (since }\left[  y,z\right]  \in\mathfrak{g}_{m+p}\text{ (since
}y\in\mathfrak{g}_{m}\text{ and }z\in\mathfrak{g}_{p}\text{))}%
\end{array}
\right) \\
&  =\varepsilon^{\delta_{m,0}+\delta_{p,0}+1-\delta_{m+p,0}+\delta
_{n,0}+\delta_{m+p,0}+1-\delta_{n+m+p,0}}\left[  x,\left[  y,z\right]
\right]  =\varepsilon^{\delta_{n,0}+\delta_{m,0}+\delta_{p,0}+2-\delta
_{n+m+p,0}}\left[  x,\left[  y,z\right]  \right]  .
\end{align*}
Similarly,
\begin{align*}
\left[  y,\left[  z,x\right]  ^{\varepsilon}\right]  ^{\varepsilon}  &
=\varepsilon^{\delta_{n,0}+\delta_{m,0}+\delta_{p,0}+2-\delta_{n+m+p,0}%
}\left[  y,\left[  z,x\right]  \right]  \ \ \ \ \ \ \ \ \ \ \text{and}\\
\left[  z,\left[  x,y\right]  ^{\varepsilon}\right]  ^{\varepsilon}  &
=\varepsilon^{\delta_{n,0}+\delta_{m,0}+\delta_{p,0}+2-\delta_{n+m+p,0}%
}\left[  z,\left[  x,y\right]  \right]  .
\end{align*}
Adding up these three equations yields%
\begin{align*}
&  \left[  x,\left[  y,z\right]  ^{\varepsilon}\right]  ^{\varepsilon}+\left[
y,\left[  z,x\right]  ^{\varepsilon}\right]  ^{\varepsilon}+\left[  z,\left[
x,y\right]  ^{\varepsilon}\right]  ^{\varepsilon}\\
&  =\varepsilon^{\delta_{n,0}+\delta_{m,0}+\delta_{p,0}+2-\delta_{n+m+p,0}%
}\left[  x,\left[  y,z\right]  \right]  +\varepsilon^{\delta_{n,0}%
+\delta_{m,0}+\delta_{p,0}+2-\delta_{n+m+p,0}}\left[  y,\left[  z,x\right]
\right]  +\varepsilon^{\delta_{n,0}+\delta_{m,0}+\delta_{p,0}+2-\delta
_{n+m+p,0}}\left[  z,\left[  x,y\right]  \right] \\
&  =\varepsilon^{\delta_{n,0}+\delta_{m,0}+\delta_{p,0}+2-\delta_{n+m+p,0}%
}\underbrace{\left(  \left[  x,\left[  y,z\right]  \right]  +\left[  y,\left[
z,x\right]  \right]  +\left[  z,\left[  x,y\right]  \right]  \right)
}_{=0\text{ (since }\mathfrak{g}\text{ is a Lie algebra)}}=0.
\end{align*}
This proves the Jacobi identity for the Lie bracket $\left[  \cdot
,\cdot\right]  ^{\varepsilon}$, qed.} and is graded. Thus, this Lie bracket
$\left[  \cdot,\cdot\right]  ^{\varepsilon}$ defines a graded Lie algebra
structure on $\mathfrak{g}$. Let us denote this Lie algebra by $\mathfrak{g}%
^{\varepsilon}$. Thus, $\mathfrak{g}^{\varepsilon}$ is identical with
$\mathfrak{g}$ as a vector space, but the Lie bracket on $\mathfrak{g}%
^{\varepsilon}$ is $\left[  \cdot,\cdot\right]  ^{\varepsilon}$ rather than
$\left[  \cdot,\cdot\right]  $.

Trivially, $\mathfrak{g}^{1}=\mathfrak{g}$ (this is an actual equality, not
only an isomorphism) and $\left[  \cdot,\cdot\right]  ^{1}=\left[  \cdot
,\cdot\right]  $.

For every $\varepsilon\in\mathbb{C}$, define a $\mathbb{C}$-linear map
$J_{\varepsilon}:\mathfrak{g}^{\varepsilon}\rightarrow\mathfrak{g}$ by%
\[
J_{\varepsilon}\left(  x\right)  =\varepsilon^{1+\delta_{n,0}}%
x\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}\text{ and }%
x\in\mathfrak{g}_{n}.
\]
Then, $J_{\varepsilon}$ is a Lie algebra homomorphism\footnote{\textit{Proof.}
We must show that $J_{\varepsilon}\left(  \left[  x,y\right]  ^{\varepsilon
}\right)  =\left[  J_{\varepsilon}\left(  x\right)  ,J_{\varepsilon}\left(
y\right)  \right]  $ for all $x,y\in\mathfrak{g}$. In order to show this, it
is enough to prove that $J_{\varepsilon}\left(  \left[  x,y\right]
^{\varepsilon}\right)  =\left[  J_{\varepsilon}\left(  x\right)
,J_{\varepsilon}\left(  y\right)  \right]  $ for all homogeneous
$x,y\in\mathfrak{g}$ (because of linearity). So let $x,y\in\mathfrak{g}$ be
homogeneous. Thus, there exist $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ such that
$x\in\mathfrak{g}_{n}$ and $y\in\mathfrak{g}_{m}$. Consider these $n$ and $m$.
Then, $\left[  x,y\right]  \in\mathfrak{g}_{n+m}$. Now, $J_{\varepsilon
}\left(  x\right)  =\varepsilon^{1+\delta_{n,0}}x$ and $J_{\varepsilon}\left(
y\right)  =\varepsilon^{1+\delta_{m,0}}y$ by the definition of $J_{\varepsilon
}$. Thus,%
\[
\left[  J_{\varepsilon}\left(  x\right)  ,J_{\varepsilon}\left(  y\right)
\right]  =\left[  \varepsilon^{1+\delta_{n,0}}x,\varepsilon^{1+\delta_{m,0}%
}y\right]  =\varepsilon^{1+\delta_{n,0}}\varepsilon^{1+\delta_{m,0}}\left[
x,y\right]  =\varepsilon^{2+\delta_{n,0}+\delta_{m,0}}\left[  x,y\right]  .
\]
Compared with%
\begin{align*}
J_{\varepsilon}\left(  \left[  x,y\right]  ^{\varepsilon}\right)   &
=J_{\varepsilon}\left(  \varepsilon^{\delta_{n,0}+\delta_{m,0}+1-\delta
_{n+m,0}}\left[  x,y\right]  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.invformnondeg.g^epsi.2})}\right) \\
&  =\varepsilon^{\delta_{n,0}+\delta_{m,0}+1-\delta_{n+m,0}}%
\underbrace{J_{\varepsilon}\left(  \left[  x,y\right]  \right)  }%
_{\substack{=\varepsilon^{1+\delta_{n+m,0}}\left[  x,y\right]  \\\text{(by the
definition of }J_{\varepsilon}\text{,}\\\text{since }\left[  x,y\right]
\in\mathfrak{g}_{n+m}\text{)}}}=\varepsilon^{\delta_{n,0}+\delta
_{m,0}+1-\delta_{n+m,0}}\varepsilon^{1+\delta_{n+m,0}}\left[  x,y\right] \\
&  =\varepsilon^{2+\delta_{n,0}+\delta_{m,0}}\left[  x,y\right]  ,
\end{align*}
this yields $J_{\varepsilon}\left(  \left[  x,y\right]  ^{\varepsilon}\right)
=\left[  J_{\varepsilon}\left(  x\right)  ,J_{\varepsilon}\left(  y\right)
\right]  $, qed.}. Also, $J_{\varepsilon}$ is a vector space isomorphism when
$\varepsilon\neq0$. Hence, $J_{\varepsilon}$ is a Lie algebra isomorphism when
$\varepsilon\neq0$. Moreover, $J_{1}=\operatorname*{id}$.

For every $\varepsilon\in\mathbb{C}$, we are going to denote by $\mathfrak{n}%
_{-}^{\varepsilon}$, $\mathfrak{n}_{+}^{\varepsilon}$ and $\mathfrak{h}%
^{\varepsilon}$ the vector spaces $\mathfrak{n}_{-}$, $\mathfrak{n}_{+}$ and
$\mathfrak{h}$ \textbf{as Lie subalgebras of }$\mathfrak{g}^{\varepsilon}$.
Note that $\mathfrak{h}^{\varepsilon}=\mathfrak{h}$ as Lie algebras (because
$\mathfrak{h}$ and $\mathfrak{h}^{\varepsilon}$ are abelian Lie algebras), but
the equalities $\mathfrak{n}_{-}^{\varepsilon}=\mathfrak{n}_{-}$ and
$\mathfrak{n}_{+}^{\varepsilon}=\mathfrak{n}_{+}$ hold only as equalities of
vector spaces (unless we are in some rather special situation). Since the
grading of $\mathfrak{g}^{\varepsilon}$ is the same as the grading of
$\mathfrak{g}$, the triangular decomposition of $\mathfrak{g}^{\varepsilon}$
is $\mathfrak{n}_{-}^{\varepsilon}\oplus\mathfrak{h}^{\varepsilon}%
\oplus\mathfrak{n}_{+}^{\varepsilon}$ for every $\varepsilon\in\mathbb{C}$.

Now, we are dealing with several Lie algebras on the same vector space, and we
are going to be dealing with their Verma modules. In order not to confuse
them, let us introduce a notation:

\begin{Convention}
In the following, whenever $\mathfrak{e}$ is a $\mathbb{Z}$-graded Lie
algebra, and $\lambda\in\mathfrak{e}_{0}^{\ast}$, we are going to denote by
$M_{\lambda}^{+\mathfrak{e}}$ the Verma highest-weight module of $\left(
\mathfrak{e},\lambda\right)  $, and we are going to denote by $M_{\lambda
}^{-\mathfrak{e}}$ the Verma lowest-weight module of $\left(  \mathfrak{e}%
,\lambda\right)  $. We will furthermore denote by $v_{\lambda}^{+\mathfrak{e}%
}$ the defining vector of $M_{\lambda}^{+\mathfrak{e}}$, and we will denote by
$v_{\lambda}^{-\mathfrak{e}}$ the defining vector of $M_{\lambda
}^{-\mathfrak{e}}$.

Further, we denote by $\left(  \cdot,\cdot\right)  _{\lambda}^{\mathfrak{e}}$
and $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{e}}$ the forms
$\left(  \cdot,\cdot\right)  _{\lambda}$ and $\left(  \cdot,\cdot\right)
_{\lambda,n}$ defined for the Lie algebra $\mathfrak{e}$ instead of
$\mathfrak{g}$.
\end{Convention}

Thus, for instance, the Verma highest-weight module of $\left(  \mathfrak{g}%
,\lambda\right)  $ (which we have always denoted by $M_{\lambda}^{+}$) can now
be called $M_{\lambda}^{+\mathfrak{g}}$, and thus can be discerned from the
Verma highest-weight module $M_{\lambda}^{+\mathfrak{g}^{\varepsilon}}$ of
$\left(  \mathfrak{g}^{\varepsilon},\lambda\right)  $.

\begin{Convention}
\label{conv.invformnondeg.bases}For every $n\in\mathbb{Z}$, let $\left(
e_{n,i}\right)  _{i\in\left\{  1,2,...,m_{n}\right\}  }$ be a basis of the
vector space $\mathfrak{g}_{n}$ (such a basis exists since $\dim\left(
\mathfrak{g}_{n}\right)  <\infty$). Then, $\left(  e_{n,i}\right)  _{\left(
n,i\right)  \in E}$ is a basis of the vector space $\mathfrak{g}$, where
$E=\left\{  \left(  n,i\right)  \ \mid\ n\in\mathbb{Z};\ i\in\left\{
1,2,...,m_{n}\right\}  \right\}  $.

For every integer $n>0$, we have $\dim\left(  \mathfrak{g}_{n}\right)  =m_{n}$
(since $\left(  e_{n,i}\right)  _{i\in\left\{  1,2,...,m_{n}\right\}  }$ is a
basis of the vector space $\mathfrak{g}_{n}$) and $\dim\left(  \mathfrak{g}%
_{-n}\right)  =m_{-n}$ (similarly), so that $m_{n}=\dim\left(  \mathfrak{g}%
_{n}\right)  =\dim\left(  \mathfrak{g}_{-n}\right)  =m_{-n}$. Of course, this
yields that $m_{n}=m_{-n}$ for every integer $n$ (whether positive or not).

We totally order the set $E$ lexicographically. Let $\operatorname*{Seq}E$ be
the set of all finite sequences of elements of $E$. For every $\mathbf{i}%
\in\operatorname*{Seq}E$ and every $\varepsilon\in\mathbb{C}$, we define an
element $e_{\mathbf{i}}^{\varepsilon}$ of $U\left(  \mathfrak{g}^{\varepsilon
}\right)  $ by%
\[
e_{\mathbf{i}}^{\varepsilon}=e_{n_{1},i_{1}}e_{n_{2},i_{2}}...e_{n_{\ell
},i_{\ell}},\ \ \ \ \ \ \ \ \ \ \text{where we write }\mathbf{i}\text{ in the
form }\left(  \left(  n_{1},i_{1}\right)  ,\left(  n_{2},i_{2}\right)
,...,\left(  n_{\ell},i_{\ell}\right)  \right)  .
\]
For every $\mathbf{i}\in\operatorname*{Seq}E$, we define the \textit{length}
$\operatorname*{len}\mathbf{i}$ of $\mathbf{i}$ to be the number of members of
$\mathbf{i}$ (in other words, we set $\operatorname*{len}\mathbf{i}=\ell$,
where we write $\mathbf{i}$ in the form $\left(  \left(  n_{1},i_{1}\right)
,\left(  n_{2},i_{2}\right)  ,...,\left(  n_{\ell},i_{\ell}\right)  \right)
$), and we define the \textit{degree} $\deg\mathbf{i}$ of $\mathbf{i}$ to be
the sum $n_{1}+n_{2}+...+n_{\ell}$, where we write $\mathbf{i}$ in the form
$\left(  \left(  n_{1},i_{1}\right)  ,\left(  n_{2},i_{2}\right)  ,...,\left(
n_{\ell},i_{\ell}\right)  \right)  $. It is clear that $e_{\mathbf{i}%
}^{\varepsilon}\in U\left(  \mathfrak{g}^{\varepsilon}\right)  \left[
\deg\mathbf{i}\right]  $.

Let $\operatorname*{Seq}\nolimits_{+}E$ be the set of all
\textbf{nondecreasing} sequences $\left(  \left(  n_{1},i_{1}\right)  ,\left(
n_{2},i_{2}\right)  ,...,\left(  n_{\ell},i_{\ell}\right)  \right)
\in\operatorname*{Seq}E$ such that all of $n_{1}$, $n_{2}$, $...$, $n_{\ell}$
are \textbf{positive}. By the Poincar\'{e}-Birkhoff-Witt theorem (applied to
the Lie algebra $\mathfrak{n}_{+}^{\varepsilon}$), the family $\left(
e_{\mathbf{j}}^{\varepsilon}\right)  _{\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E}$ is a basis of the vector space $U\left(  \mathfrak{n}%
_{+}^{\varepsilon}\right)  $. Moreover, it is a graded basis, i. e., the
family $\left(  e_{\mathbf{j}}^{\varepsilon}\right)  _{\mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\ \deg\mathbf{j}=n}$ is a basis of the
vector space $U\left(  \mathfrak{n}_{+}^{\varepsilon}\right)  \left[
n\right]  $ for every $n\in\mathbb{Z}$. Hence, $\left(  e_{\mathbf{j}%
}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)
_{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\ \deg\mathbf{j}=n}$ is a
basis of the vector space $M_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\left[
n\right]  $ for every $n\in\mathbb{Z}$ and $\lambda\in\mathfrak{h}^{\ast}$.

Let $\operatorname*{Seq}\nolimits_{-}E$ be the set of all
\textbf{nonincreasing} sequences $\left(  \left(  n_{1},i_{1}\right)  ,\left(
n_{2},i_{2}\right)  ,...,\left(  n_{\ell},i_{\ell}\right)  \right)
\in\operatorname*{Seq}E$ such that all of $n_{1}$, $n_{2}$, $...$, $n_{\ell}$
are \textbf{negative}. By the Poincar\'{e}-Birkhoff-Witt theorem (applied to
the Lie algebra $\mathfrak{n}_{-}^{\varepsilon}$), the family $\left(
e_{\mathbf{i}}^{\varepsilon}\right)  _{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E}$ is a basis of the vector space $U\left(  \mathfrak{n}%
_{-}^{\varepsilon}\right)  $. Moreover, it is a graded basis, i. e., the
family $\left(  e_{\mathbf{i}}^{\varepsilon}\right)  _{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\ \deg\mathbf{i}=-n}$ is a basis of the
vector space $U\left(  \mathfrak{n}_{-}^{\varepsilon}\right)  \left[
-n\right]  $ for every $n\in\mathbb{Z}$. Hence, $\left(  e_{\mathbf{i}%
}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\right)
_{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \deg\mathbf{i}=-n}$ is a
basis of the vector space $M_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\left[
-n\right]  $ for every $n\in\mathbb{Z}$ and $\lambda\in\mathfrak{h}^{\ast}$.

We can define a bijection%
\begin{align*}
E  &  \rightarrow E,\\
\left(  n,i\right)   &  \mapsto\left(  -n,m_{n}+1-i\right)
\end{align*}
(because $m_{n}=m_{-n}$ for every $n\in\mathbb{Z}$). This bijection reverses
the order on $E$. Hence, this bijection canonically induces a bijection
$\operatorname*{Seq}E\rightarrow\operatorname*{Seq}E$, which maps
$\operatorname*{Seq}\nolimits_{+}E$ to $\operatorname*{Seq}\nolimits_{-}E$ and
vice versa, and reverses the degree of every sequence while keeping the length
of every sequence invariant. One consequence of this bijection is that for
every $n\in\mathbb{Z}$, the number of all $\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E$ satisfying$\ \deg\mathbf{j}=n$ equals the number of all
$\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$ satisfying$\ \deg
\mathbf{i}=-n$. Another consequence is that $\sum\limits_{\substack{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\\\deg\mathbf{i}=-n}}\operatorname*{len}%
\mathbf{i=}\sum\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{j}=n}}\operatorname*{len}\mathbf{j}$.

For every positive integer $n$, we represent the bilinear form $\left(
\cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{\varepsilon}}:M_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}\left[  -n\right]  \times M_{-\lambda
}^{-\mathfrak{g}^{\varepsilon}}\left[  n\right]  \rightarrow\mathbb{C}$ by its
matrix with respect to the bases $\left(  e_{\mathbf{i}}^{\varepsilon
}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\right)  _{\mathbf{i}\in
\operatorname*{Seq}\nolimits_{-}E;\ \deg\mathbf{i}=-n}$ and $\left(
e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)
_{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\ \deg\mathbf{j}=n}$ of
$M_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\left[  -n\right]  $ and
$M_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\left[  n\right]  $, respectively.
This is the matrix%
\[
\left(  \left(  e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\right)  _{\lambda,n}^{\mathfrak{g}^{\varepsilon}}\right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}.
\]
This matrix is a square matrix (since the number of all $\mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E$ satisfying$\ \deg\mathbf{j}=n$ equals
the number of all $\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$
satisfying$\ \deg\mathbf{i}=-n$), and its determinant is what we are going to
denote by $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}%
^{\varepsilon}}\right)  $.
\end{Convention}

A few words about tensor algebras:

\begin{Convention}
In the following, we let $T$ denote the tensor algebra functor. Hence, for
every vector space $V$, we denote by $T\left(  V\right)  $ the tensor algebra
of $V$.

We notice that $T\left(  V\right)  $ is canonically graded even if $V$ is not.
In fact, $T\left(  V\right)  =\bigoplus\limits_{i\in\mathbb{N}}V^{\otimes i}$,
so that we get a grading on $T\left(  V\right)  $ if we set $V^{\otimes i}$ to
be the $i$-th homogeneous component of $T\left(  V\right)  $. This grading is
called the \textit{tensor length grading} on $T\left(  V\right)  $. It makes
$T\left(  V\right)  $ concentrated in nonnegative degrees.

If $V$ itself is a graded vector space, then we can also grade $T\left(
V\right)  $ by canonically extending the grading on $V$ to $T\left(  V\right)
$ (this means that whenever $v_{1}$, $v_{2}$, $...$, $v_{n}$ are homogeneous
elements of $V$ of degrees $d_{1}$, $d_{2}$, $...$, $d_{n}$, then the pure
tensor $v_{1}\otimes v_{2}\otimes...\otimes v_{n}$ has degree $d_{1}%
+d_{2}+...+d_{n}$). This grading is called the \textit{internal grading} on
$T\left(  V\right)  $. It is different from the tensor length grading (unless
$V$ is concentrated in degree $1$).

Hence, if $V$ is a graded vector space, then $T\left(  V\right)  $ becomes a
bigraded vector space (i. e., a vector space with two gradings). Let us agree
to denote by $T\left(  V\right)  \left[  n,m\right]  $ the intersection of the
$n$-th homogeneous component in the internal grading with the $m$-th
homogeneous component in the tensor length grading (i. e., with $V^{\otimes
m}$).
\end{Convention}

Let us notice that \textbf{as vector spaces}, we have $\mathfrak{g}%
=\mathfrak{g}^{\varepsilon}$, $\mathfrak{n}_{-}=\mathfrak{n}_{-}^{\varepsilon
}$, $\mathfrak{n}_{+}=\mathfrak{n}_{+}^{\varepsilon}$ and $\mathfrak{h}%
=\mathfrak{h}^{\varepsilon}$ for every $\varepsilon\in\mathbb{C}$. Hence,
$T\left(  \mathfrak{g}\right)  =T\left(  \mathfrak{g}^{\varepsilon}\right)  $,
$T\left(  \mathfrak{n}_{-}\right)  =T\left(  \mathfrak{n}_{-}^{\varepsilon
}\right)  $, $T\left(  \mathfrak{n}_{+}\right)  =T\left(  \mathfrak{n}%
_{+}^{\varepsilon}\right)  $ and $T\left(  \mathfrak{h}\right)  =T\left(
\mathfrak{h}^{\varepsilon}\right)  $.

\begin{definition}
In the following, for every Lie algebra $\mathfrak{a}$ and every element $x\in
T\left(  \mathfrak{a}\right)  $, we denote by $\operatorname*{env}%
\nolimits_{\mathfrak{a}}x$ the projection of $x$ onto the factor algebra
$U\left(  \mathfrak{a}\right)  $ of $T\left(  \mathfrak{a}\right)  $.
\end{definition}

Let us again stress that $T\left(  \mathfrak{g}\right)  =T\left(
\mathfrak{g}^{\varepsilon}\right)  $, so that $T\left(  \mathfrak{g}%
^{\varepsilon}\right)  $ does not depend on $\varepsilon$, whereas $U\left(
\mathfrak{g}^{\varepsilon}\right)  $ does. Hence, if we want to study the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{\varepsilon}}$ as it
changes with $\varepsilon$, the easiest thing to do is to study the values of
$\left(  \left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}a\right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}},\left(
\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}b\right)
v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda,n}^{\mathfrak{g}%
^{\varepsilon}}$ for fixed $a\in T\left(  \mathfrak{g}\right)  =T\left(
\mathfrak{g}^{\varepsilon}\right)  $ and $b\in T\left(  \mathfrak{g}\right)
=T\left(  \mathfrak{g}^{\varepsilon}\right)  $. Here is the polynomiality
lemma that we want to have:

\begin{lemma}
\label{lem.invformnondeg.polynomiality}Let $\mathbf{i}\in\operatorname*{Seq}E$
and $\mathbf{j}\in\operatorname*{Seq}E$. Then, there exists a polynomial
function $Q_{\mathbf{i},\mathbf{j}}:\mathfrak{h}^{\ast}\times\mathbb{C}%
\rightarrow\mathbb{C}$ such that every $\lambda\in\mathfrak{h}^{\ast}$ and
every $\varepsilon\in\mathbb{C}$ satisfy%
\[
\left(  e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}%
},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}=Q_{\mathbf{i},\mathbf{j}%
}\left(  \lambda,\varepsilon\right)  .
\]

\end{lemma}

To prove this lemma, we show something more general:

\begin{lemma}
\label{lem.invformnondeg.polynomiality2}For every $n\in\mathbb{Z}$ and $c\in
T\left(  \mathfrak{g}\right)  \left[  n\right]  $, there exists a polynomial
map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(  \mathfrak{n}%
_{-}\right)  \left[  n\right]  $ such that every $\lambda\in\mathfrak{h}%
^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\[
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(  \lambda,\varepsilon
\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\]

\end{lemma}

To get some intuition about Lemma \ref{lem.invformnondeg.polynomiality2},
recall that the Verma highest-weight module $M_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}$ was defined as $U\left(  \mathfrak{g}^{\varepsilon}\right)
\otimes_{U\left(  \mathfrak{h}^{\varepsilon}\oplus\mathfrak{n}_{+}%
^{\varepsilon}\right)  }\mathbb{C}_{\lambda}$, but turned out to be $U\left(
\mathfrak{n}_{-}^{\varepsilon}\right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}$ (as a vector space), so that every term of the form
$xv_{\lambda}^{+\mathfrak{g}^{\varepsilon}}$ with $x\in U\left(
\mathfrak{g}^{\varepsilon}\right)  $ can be reduced to the form $yv_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}$ with $y\in U\left(  \mathfrak{n}%
_{-}^{\varepsilon}\right)  $. Lemma \ref{lem.invformnondeg.polynomiality2}
says that, if $x$ is given as the projection $\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}c$ of some tensor $c\in T\left(
\mathfrak{g}\right)  \left[  n\right]  $ onto $U\left(  \mathfrak{g}%
^{\varepsilon}\right)  $, then $y$ can be found as the projection of some
tensor $d\left(  \lambda,\varepsilon\right)  \in T\left(  \mathfrak{n}%
_{-}\right)  \left[  n\right]  $ onto $U\left(  \mathfrak{n}_{-}^{\varepsilon
}\right)  $ which depends polynomially on $\lambda$ and $\varepsilon$. This is
not particularly surprising, since $y$ is found from $x$ by picking a
tensorial representation\footnote{By a ``tensorial representation'' of $x$, I
mean a tensor $c\in T\left(  \mathfrak{g}\right)  $ such that
$\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c=x$.} of $x$ and
``gradually'' stratifying it\footnote{By ``stratifying'' a tensorial
representation of $x$, I mean writing it as a linear combination of pure
tensors, and whenever such a pure tensor has a negative tensorand (i. e., a
tensorand in $\mathfrak{n}_{-}$) standing directly before a positive tensorand
(i. e., a tensorand in $\mathfrak{n}_{+}$), applying the $xy-yx=\left[
x,y\right]  ^{\varepsilon}$ relations in $U\left(  \mathfrak{g}^{\varepsilon
}\right)  $ to move the negative tensorand past the positive one. As soon as a
positive tensorand hits the right end of the tensor, the tensor can be thrown
away since $\mathfrak{n}_{+}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=0$. For
instance, in Example \ref{exa.Vir} further below, we compute $L_{1}%
L_{-1}v_{\lambda}^{+}$ by stratifying the tensorial representation
$L_{1}\otimes L_{-1}$ of $L_{1}L_{-1}$, and we compute $L_{1}^{2}L_{-1}%
^{2}v_{\lambda}^{+}$ by stratifying the tensorial representation $L_{1}\otimes
L_{1}\otimes L_{-1}\otimes L_{-1}$ of $L_{1}^{2}L_{-1}^{2}$.}, and the
$\lambda$'s and $\varepsilon$'s which appear during this stratification
process don't appear ``randomly'', but rather appear at foreseeable places.
The following proof of Lemma \ref{lem.invformnondeg.polynomiality2} will
formalize this idea.

\textit{Proof of Lemma \ref{lem.invformnondeg.polynomiality2}.} First some notations:

If $n\in\mathbb{Z}$, then a tensor $c\in T\left(  \mathfrak{g}\right)  \left[
n\right]  $ is said to be $n$\textit{-stratifiable} if there exists a
polynomial map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(
\mathfrak{n}_{-}\right)  \left[  n\right]  $ such that every $\lambda
\in\mathfrak{h}^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\[
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(  \lambda,\varepsilon
\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\]


Lemma \ref{lem.invformnondeg.polynomiality2} states that for every
$n\in\mathbb{Z}$, every tensor $c\in T\left(  \mathfrak{g}\right)  \left[
n\right]  $ is $n$-stratifiable.

We will now prove that
\begin{equation}
\text{for every }n\in\mathbb{Z}\text{ and every }m\in\mathbb{N}\text{, every
tensor }c\in T\left(  \mathfrak{g}\right)  \left[  n,m\right]  \text{ is
}n\text{-stratifiable.} \label{lem.invformnondeg.polynomiality2.ind}%
\end{equation}


Before we start proving this, let us formulate two easy observations about
stratifiable tensors:

\textit{Observation 1:} For any fixed $n$, any $\mathbb{C}$-linear combination
of $n$-stratifiable tensors is $n$-stratifiable. (In fact, we can just take
the corresponding $\mathbb{C}$-linear combination of the corresponding
polynomial maps $d$.)

\textit{Observation 2:} If an integer $n$, a negative integer $\nu$, a vector
$x\in\mathfrak{g}_{\nu}$ and a tensor $y\in T\left(  \mathfrak{g}\right)
\left[  n-\nu\right]  $ are such that $y$ is $\left(  n-\nu\right)
$-stratifiable, then $x\otimes y\in T\left(  \mathfrak{g}\right)  \left[
n\right]  $ is $n$-stratifiable.\footnote{\textit{Proof of Observation 2.} Let
an integer $n$, a negative integer $\nu$, a vector $x\in\mathfrak{g}_{\nu}$
and a tensor $y\in T\left(  \mathfrak{g}\right)  \left[  n-\nu\right]  $ be
such that $y$ is $\left(  n-\nu\right)  $-stratifiable. Then, there exists a
polynomial map $\widetilde{d}:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow
T\left(  \mathfrak{n}_{-}\right)  \left[  n-\nu\right]  $ such that every
$\lambda\in\mathfrak{h}^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\[
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}y\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}%
\]
(by the definition of ``$\left(  n-\nu\right)  $-stratifiable''). Now, define
a map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(
\mathfrak{n}_{-}\right)  \left[  n\right]  $ by
\[
d\left(  \lambda,\varepsilon\right)  =x\otimes\widetilde{d}\left(
\lambda,\varepsilon\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }\left(
\lambda,\varepsilon\right)  \in\mathfrak{h}^{\ast}\times\mathbb{C}.
\]
(This is well-defined, since $x\in\mathfrak{g}_{\nu}\subseteq\mathfrak{n}_{-}$
(since $\nu$ is negative).) This map $d$ is clearly polynomial (since
$\widetilde{d}$ is a polynomial map), and every $\lambda\in\mathfrak{h}^{\ast
}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\begin{align*}
\underbrace{\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}\left(  x\otimes y\right)  \right)  }_{=x\cdot\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}y}v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}  &  =x\cdot\underbrace{\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}y\right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}}_{=\left(  \operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  \widetilde{d}\left(  \lambda,\varepsilon\right)
\right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}%
=\underbrace{x\cdot\left(  \operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  \widetilde{d}\left(  \lambda,\varepsilon\right)
\right)  \right)  }_{=\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon
}}\left(  x\otimes\widetilde{d}\left(  \lambda,\varepsilon\right)  \right)
}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\\
&  =\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}\underbrace{\left(  x\otimes\widetilde{d}\left(  \lambda,\varepsilon\right)
\right)  }_{=d\left(  \lambda,\varepsilon\right)  }\right)  v_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(  \lambda,\varepsilon
\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\end{align*}
Hence, $x\otimes y$ is $n$-stratifiable (by the definition of ``$n$%
-stratifiable''). This proves Observation 2.}

We are now going to prove (\ref{lem.invformnondeg.polynomiality2.ind}) by
induction on $m$:

\textit{Induction base:} We have $T\left(  \mathfrak{g}\right)  \left[
n,0\right]  =\mathbb{C}\left[  n\right]  $. Hence, every tensor $c\in T\left(
\mathfrak{g}\right)  \left[  n,0\right]  $ is $n$-stratifiable (because we can
define the polynomial map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow
T\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  $ by%
\[
d\left(  \lambda,\varepsilon\right)  =c\ \ \ \ \ \ \ \ \ \ \text{for all
}\left(  \lambda,\varepsilon\right)  \in\mathfrak{h}^{\ast}\times\mathbb{C}%
\]
). In other words, (\ref{lem.invformnondeg.polynomiality2.ind}) is proven for
$m=0$. In other words, the induction base is complete.

\textit{Induction step:} Let $m\in\mathbb{N}$ be positive. We must show that
(\ref{lem.invformnondeg.polynomiality2.ind}) holds for this $m$, using the
assumption that (\ref{lem.invformnondeg.polynomiality2.ind}) holds for $m-1$
instead of $m$.

Let $n\in\mathbb{Z}$. Let $\pi_{n}:T\left(  \mathfrak{g}\right)  \rightarrow
T\left(  \mathfrak{g}\right)  \left[  n\right]  $ denote the canonical
projection of $T\left(  \mathfrak{g}\right)  $ to the $n$-th homogeneous
component with respect to the internal grading.

Let $c\in T\left(  \mathfrak{g}\right)  \left[  n,m\right]  $. We must prove
that $c$ is $n$-stratifiable.

We have $c\in T\left(  \mathfrak{g}\right)  \left[  n,m\right]  \subseteq
\mathfrak{g}^{\otimes m}$, and since the $m$-th tensor power is generated by
pure tensors, this yields that $c$ is a $\mathbb{C}$-linear combination of
pure tensors. In other words, $c$ is a $\mathbb{C}$-linear combination of
finitely many pure tensors of the form $x_{1}\otimes x_{2}\otimes...\otimes
x_{m}$ with $x_{1},x_{2},...,x_{m}\in\mathfrak{g}$. We can WLOG assume that,
in each of these pure tensors, the elements $x_{1},x_{2},...,x_{m}$ are
homogeneous (since otherwise we can break each of $x_{1},x_{2},...,x_{m}$ into
homogeneous components, and thus the pure tensors $x_{1}\otimes x_{2}%
\otimes...\otimes x_{m}$ break into smaller pieces which are still pure
tensors). So we can write $c$ as a $\mathbb{C}$-linear combination of finitely
many pure tensors of the form $x_{1}\otimes x_{2}\otimes...\otimes x_{m}$ with
\textbf{homogeneous }$x_{1},x_{2},...,x_{m}\in\mathfrak{g}$. If we apply the
projection $\pi_{n}$ to this, then $c$ remains invariant (since $c\in T\left(
\mathfrak{g}\right)  \left[  n,m\right]  \subseteq T\left(  \mathfrak{g}%
\right)  \left[  n\right]  $), and the terms of the form $x_{1}\otimes
x_{2}\otimes...\otimes x_{m}$ with \textbf{homogeneous }$x_{1},x_{2}%
,...,x_{m}\in\mathfrak{g}$ satisfying $\deg\left(  x_{1}\right)  +\deg\left(
x_{2}\right)  +...+\deg\left(  x_{m}\right)  =n$ remain invariant as well
(since they also lie in $T\left(  \mathfrak{g}\right)  \left[  n\right]  $),
whereas the terms of the form $x_{1}\otimes x_{2}\otimes...\otimes x_{m}$ with
\textbf{homogeneous }$x_{1},x_{2},...,x_{m}\in\mathfrak{g}$ satisfying
$\deg\left(  x_{1}\right)  +\deg\left(  x_{2}\right)  +...+\deg\left(
x_{m}\right)  \neq n$ are mapped to $0$ (since they lie in homogeneous
components of $T\left(  \mathfrak{g}\right)  $ other than $T\left(
\mathfrak{g}\right)  \left[  n\right]  $). Hence, we write $c$ as a
$\mathbb{C}$-linear combination of finitely many pure tensors of the form
$x_{1}\otimes x_{2}\otimes...\otimes x_{m}$ with \textbf{homogeneous }%
$x_{1},x_{2},...,x_{m}\in\mathfrak{g}$ \textbf{satisfying} $\deg\left(
x_{1}\right)  +\deg\left(  x_{2}\right)  +...+\deg\left(  x_{m}\right)  =n$.

Therefore, in proving (\ref{lem.invformnondeg.polynomiality2.ind}), we can
WLOG assume that $c$ \textbf{is} a pure tensor of the form $x_{1}\otimes
x_{2}\otimes...\otimes x_{m}$ with homogeneous $x_{1},x_{2},...,x_{m}%
\in\mathfrak{g}$ satisfying $\deg\left(  x_{1}\right)  +\deg\left(
x_{2}\right)  +...+\deg\left(  x_{m}\right)  =n$ (because, clearly, once Lemma
\ref{lem.invformnondeg.polynomiality2} is proven for certain values of $c\in
T\left(  \mathfrak{g}\right)  \left[  n,m\right]  $, it must clearly also hold
for all their $\mathbb{C}$-linear combinations\footnote{due to Observation
1}). Let us now assume this.

So we have $c=x_{1}\otimes x_{2}\otimes...\otimes x_{m}$ with homogeneous
$x_{1},x_{2},...,x_{m}\in\mathfrak{g}$ satisfying $\deg\left(  x_{1}\right)
+\deg\left(  x_{2}\right)  +...+\deg\left(  x_{m}\right)  =n$. We must now
prove that $c$ is $n$-stratifiable.

For every $i\in\left\{  1,2,...,m\right\}  $, let $n_{i}$ be the degree of
$x_{i}$ (this is well-defined since $x_{i}$ is homogeneous). Thus, $x_{i}%
\in\mathfrak{g}_{n_{i}}$.

We have%
\[
\deg\left(  x_{2}\right)  +\deg\left(  x_{3}\right)  +...+\deg\left(
x_{m}\right)  =\underbrace{\left(  \deg\left(  x_{1}\right)  +\deg\left(
x_{2}\right)  +...+\deg\left(  x_{m}\right)  \right)  }_{=n}-\underbrace{\deg
\left(  x_{1}\right)  }_{=n_{1}}=n-n_{1},
\]
so that $x_{2}\otimes x_{3}\otimes...\otimes x_{m}\in T\left(  \mathfrak{g}%
\right)  \left[  n-n_{1}\right]  $ and thus $x_{2}\otimes x_{3}\otimes
...\otimes x_{m}\in T\left(  \mathfrak{g}\right)  \left[  n-n_{1},m-1\right]
$. Since we have assumed that (\ref{lem.invformnondeg.polynomiality2.ind})
holds for $m-1$ instead of $m$, we can thus apply
(\ref{lem.invformnondeg.polynomiality2.ind}) to $n-n_{1}$, $m-1$ and
$x_{2}\otimes x_{3}\otimes...\otimes x_{m}$ instead of $n$, $m$ and $c$. We
conclude that $x_{2}\otimes x_{3}\otimes...\otimes x_{m}$ is $\left(
n-n_{1}\right)  $-stratifiable. In other words, there exists a polynomial map
$\widetilde{d}:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(
\mathfrak{n}_{-}\right)  \left[  n-n_{1}\right]  $ such that every $\lambda
\in\mathfrak{h}^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\[
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(
x_{2}\otimes x_{3}\otimes...\otimes x_{m}\right)  \right)  v_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}.
\]


We notice that $c=x_{1}\otimes x_{2}\otimes...\otimes x_{m}$, so that%
\begin{align}
&  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\nonumber\\
&  =x_{1}x_{2}...x_{m}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\underbrace{\left(  x_{2}x_{3}...x_{i-1}x_{i}\cdot
x_{1}\cdot x_{i+1}x_{i+2}...x_{m}-x_{2}x_{3}...x_{i}x_{i+1}\cdot x_{1}\cdot
x_{i+2}x_{i+3}...x_{m}\right)  }_{=x_{2}x_{3}...x_{i-1}x_{i}\left(
x_{1}x_{i+1}-x_{i+1}x_{1}\right)  x_{i+2}x_{i+3}...x_{m}}+x_{2}x_{3}%
...x_{m}\cdot x_{1}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the sum }\sum\limits_{i=1}^{m-1}\left(  x_{2}x_{3}...x_{i-1}%
x_{i}\cdot x_{1}\cdot x_{i+1}x_{i+2}...x_{m}-x_{2}x_{3}...x_{i}x_{i+1}\cdot
x_{1}\cdot x_{i+2}x_{i+3}...x_{m}\right) \\
\text{telescopes to }x_{1}x_{2}...x_{m}-x_{2}x_{3}...x_{m}\cdot x_{1}%
\end{array}
\right) \nonumber\\
&  =\sum\limits_{i=1}^{m-1}x_{2}x_{3}...x_{i-1}x_{i}\underbrace{\left(
x_{1}x_{i+1}-x_{i+1}x_{1}\right)  }_{\substack{=\left[  x_{1},x_{i+1}\right]
^{\varepsilon}\\\text{(since we are in }U\left(  \mathfrak{g}^{\varepsilon
}\right)  \text{)}}}x_{i+2}x_{i+3}...x_{m}+x_{2}x_{3}...x_{m}\cdot
x_{1}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}x_{2}x_{3}...x_{i-1}x_{i}\underbrace{\left[
x_{1},x_{i+1}\right]  ^{\varepsilon}}_{\substack{=\varepsilon^{\delta
_{n_{1},0}+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}}\left[  x_{1}%
,x_{i+1}\right]  \\\text{(by (\ref{pf.invformnondeg.g^epsi.2}) (applied to
}x_{1}\text{ and }x_{i+1}\text{ instead of }x\text{ and }y\text{),}%
\\\text{since }x_{1}\in\mathfrak{g}_{n_{1}}\text{ and }x_{i+1}\in
\mathfrak{g}_{n_{i+1}}\text{)}}}x_{i+2}x_{i+3}...x_{m}+x_{2}x_{3}...x_{m}\cdot
x_{1}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\underbrace{x_{2}x_{3}...x_{i-1}x_{i}\left[
x_{1},x_{i+1}\right]  x_{i+2}x_{i+3}...x_{m}}_{=\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  x_{2}\otimes x_{3}%
\otimes...\otimes x_{i-1}\otimes x_{i}\otimes\left[  x_{1},x_{i+1}\right]
\otimes x_{i+2}\otimes x_{i+3}\otimes...\otimes x_{m}\right)  }\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\underbrace{x_{2}x_{3}...x_{m}}_{=\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  x_{2}\otimes x_{3}%
\otimes...\otimes x_{m}\right)  }\cdot x_{1}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  x_{2}\otimes x_{3}\otimes...\otimes x_{i-1}\otimes
x_{i}\otimes\left[  x_{1},x_{i+1}\right]  \otimes x_{i+2}\otimes
x_{i+3}\otimes...\otimes x_{m}\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  x_{2}\otimes x_{3}\otimes...\otimes x_{m}\right)  \cdot
x_{1}. \label{pf.invformnondeg.polynomiality2.big}%
\end{align}


Now, for every $i\in\left\{  1,2,...,m-1\right\}  $, denote the element
$x_{2}\otimes x_{3}\otimes...\otimes x_{i-1}\otimes x_{i}\otimes\left[
x_{1},x_{i+1}\right]  \otimes x_{i+2}\otimes x_{i+3}\otimes...\otimes x_{m}$
by $c_{i}$. It is easily seen that $c_{i}\in T\left(  \mathfrak{g}\right)
\left[  n,m-1\right]  $. Since \newline$c_{i}=x_{2}\otimes x_{3}%
\otimes...\otimes x_{i-1}\otimes x_{i}\otimes\left[  x_{1},x_{i+1}\right]
\otimes x_{i+2}\otimes x_{i+3}\otimes...\otimes x_{m}$, the equality
(\ref{pf.invformnondeg.polynomiality2.big}) rewrites as%
\begin{align}
&  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  c_{i}\right)  +\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  x_{2}\otimes x_{3}%
\otimes...\otimes x_{m}\right)  \cdot x_{1}.
\label{pf.invformnondeg.polynomiality2.small}%
\end{align}


For every $i\in\left\{  1,2,...,m-1\right\}  $, we can apply
(\ref{lem.invformnondeg.polynomiality2.ind}) to $m-1$ and $c_{i}$ instead of
$m$ and $c$ (since $c_{i}\in T\left(  \mathfrak{g}\right)  \left[
n,m-1\right]  $, and since we have assumed that
(\ref{lem.invformnondeg.polynomiality2.ind}) holds for $m-1$ instead of $m$).
We conclude that $c_{i}$ is $n$-stratifiable for every $i\in\left\{
1,2,...,m-1\right\}  $. In other words, for every $i\in\left\{
1,2,...,m-1\right\}  $, there exists a polynomial map $\widetilde{d_{i}%
}:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(  \mathfrak{n}%
_{-}\right)  \left[  n\right]  $ such that every $\lambda\in\mathfrak{h}%
^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\[
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(
c_{i}\right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(
\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(
\widetilde{d_{i}}\left(  \lambda,\varepsilon\right)  \right)  \right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\]


We now distinguish between three cases:

\textit{Case 1:} We have $n_{1}>0$.

\textit{Case 2:} We have $n_{1}=0$.

\textit{Case 3:} We have $n_{1}<0$.

First, let us consider Case 1. In this case, $n_{1}>0$. Thus, $x_{1}%
\in\mathfrak{n}_{+}$ (since $x_{1}\in\mathfrak{g}_{n_{1}}$), so that
$x_{1}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\in\mathfrak{n}_{+}%
^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=0$ and thus
$x_{1}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=0$. Now,
(\ref{pf.invformnondeg.polynomiality2.small}) yields%
\begin{align}
&  \left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\nonumber\\
&  =\left(  \sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}%
+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}}\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  c_{i}\right)
+\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  x_{2}\otimes
x_{3}\otimes...\otimes x_{m}\right)  \cdot x_{1}\right)  v_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\underbrace{\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  c_{i}\right)  \right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}_{=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}}+\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}\left(  x_{2}\otimes x_{3}\otimes...\otimes x_{m}\right)  \cdot
\underbrace{x_{1}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}_{=0}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}\nonumber\\
&  =\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(
\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\widetilde{d_{i}}\left(  \lambda,\varepsilon
\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\label{pf.invformnondeg.polynomiality2.small1}%
\end{align}
If we define a map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(
\mathfrak{n}_{-}\right)  \left[  n\right]  $ by%
\[
d\left(  \lambda,\varepsilon\right)  =\sum\limits_{i=1}^{m-1}\varepsilon
^{\delta_{n_{1},0}+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}%
}\widetilde{d_{i}}\left(  \lambda,\varepsilon\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }\left(  \lambda,\varepsilon\right)
\in\mathfrak{h}^{\ast}\times\mathbb{C},
\]
then this map $d$ is polynomial (since $\widetilde{d_{i}}$ are polynomial maps
for all $i$), and (\ref{pf.invformnondeg.polynomiality2.small1}) becomes%
\begin{align*}
&  \left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\\
&  =\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}\underbrace{\left(  \sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1}%
,0}+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}}\widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  \right)  }_{=d\left(  \lambda,\varepsilon\right)
}\right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(
\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}.
\end{align*}
Hence, $c$ is $n$-stratifiable (by the definition of ``$n$-stratifiable'').

Next, let us consider Case 2. In this case, $n_{1}=0$. Thus, $x_{1}%
\in\mathfrak{h}$ (since $x_{1}\in\mathfrak{g}_{n_{1}}$), so that
$x_{1}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\lambda\left(  x_{1}\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}$. Now,
(\ref{pf.invformnondeg.polynomiality2.small}) yields%
\begin{align}
&  \left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\nonumber\\
&  =\left(  \sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}%
+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}}\operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  c_{i}\right)
+\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  x_{2}\otimes
x_{3}\otimes...\otimes x_{m}\right)  \cdot x_{1}\right)  v_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\underbrace{\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  c_{i}\right)  \right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}_{=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}}+\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}\left(  x_{2}\otimes x_{3}\otimes...\otimes x_{m}\right)  \cdot
\underbrace{x_{1}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}_{=\lambda\left(
x_{1}\right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\lambda\left(  x_{1}\right)  \underbrace{\left(
\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  x_{2}\otimes
x_{3}\otimes...\otimes x_{m}\right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}}_{=\left(  \operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  \widetilde{d}\left(  \lambda,\varepsilon\right)
\right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}}\nonumber\\
&  =\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}+\lambda\left(  x_{1}\right)  \left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \widetilde{d}\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}\nonumber\\
&  =\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(
\sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1},0}+\delta_{n_{i+1}%
,0}+1-\delta_{n_{1}+n_{i+1},0}}\widetilde{d_{i}}\left(  \lambda,\varepsilon
\right)  +\lambda\left(  x_{1}\right)  \widetilde{d}\left(  \lambda
,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}. \label{pf.invformnondeg.polynomiality2.small2}%
\end{align}
If we define a map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(
\mathfrak{n}_{-}\right)  \left[  n\right]  $ by%
\[
d\left(  \lambda,\varepsilon\right)  =\sum\limits_{i=1}^{m-1}\varepsilon
^{\delta_{n_{1},0}+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}%
}\widetilde{d_{i}}\left(  \lambda,\varepsilon\right)  +\lambda\left(
x_{1}\right)  \widetilde{d}\left(  \lambda,\varepsilon\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }\left(  \lambda,\varepsilon\right)
\in\mathfrak{h}^{\ast}\times\mathbb{C}%
\]
(this map is well-defined, since $\widetilde{d}\left(  \lambda,\varepsilon
\right)  \in T\left(  \mathfrak{n}_{-}\right)  \left[  n-n_{1}\right]
=T\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  $ (due to $n_{1}=0$)),
then this map $d$ is polynomial (since $\widetilde{d_{i}}$ are polynomial maps
for all $i$, and since $\widetilde{d}$ is polynomial), and
(\ref{pf.invformnondeg.polynomiality2.small2}) becomes%
\begin{align*}
&  \left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\\
&  =\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}\underbrace{\left(  \sum\limits_{i=1}^{m-1}\varepsilon^{\delta_{n_{1}%
,0}+\delta_{n_{i+1},0}+1-\delta_{n_{1}+n_{i+1},0}}\widetilde{d_{i}}\left(
\lambda,\varepsilon\right)  +\lambda\left(  x_{1}\right)  \widetilde{d}\left(
\lambda,\varepsilon\right)  \right)  }_{=d\left(  \lambda,\varepsilon\right)
}\right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(
\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(
\lambda,\varepsilon\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}.
\end{align*}
Hence, $c$ is $n$-stratifiable (by the definition of ``$n$-stratifiable'').

Now, let us consider Case 3. In this case, $n_{1}<0$. Thus, we can apply
Observation 2 to $x_{1}$, $x_{2}\otimes x_{3}\otimes...\otimes x_{m}$ and
$n_{1}$ instead of $x$, $y$ and $\nu$, and conclude that $x_{1}\otimes\left(
x_{2}\otimes x_{3}\otimes...\otimes x_{m}\right)  $ is $n$-stratifiable (since
$x_{2}\otimes x_{3}\otimes...\otimes x_{m}$ is $\left(  n-n_{1}\right)
$-stratifiable). Since $x_{1}\otimes\left(  x_{2}\otimes x_{3}\otimes
...\otimes x_{m}\right)  =x_{1}\otimes x_{2}\otimes...\otimes x_{m}=c$, this
shows that $c$ is $n$-stratifiable.

Hence, in each of the cases 1, 2 and 3, we have shown that $c$ is
$n$-stratifiable. Thus, $c$ is always $n$-stratifiable.

Forget that we fixed $c$. We thus have shown that $c$ is $n$-stratifiable for
every tensor $c\in T\left(  \mathfrak{g}\right)  \left[  n,m\right]  $. In
other words, we have proven (\ref{lem.invformnondeg.polynomiality2.ind}) for
our $m$. This completes the induction step.

Thus, (\ref{lem.invformnondeg.polynomiality2.ind}) is proven by induction.

Now, let $n\in\mathbb{Z}$. Then, every $c\in T\left(  \mathfrak{g}\right)
\left[  n\right]  $ is a $\mathbb{C}$-linear combination of elements of
$T\left(  \mathfrak{g}\right)  \left[  n,m\right]  $ for varying
$m\in\mathbb{N}$ (since $T\left(  \mathfrak{g}\right)  \left[  n\right]
=\bigoplus\limits_{m\in\mathbb{N}}T\left(  \mathfrak{g}\right)  \left[
n,m\right]  $), and thus every $c\in T\left(  \mathfrak{g}\right)  \left[
n\right]  $ is $n$-stratifiable (since
(\ref{lem.invformnondeg.polynomiality2.ind}) shows that every element of
$T\left(  \mathfrak{g}\right)  \left[  n,m\right]  $ is $n$-stratifiable, and
due to Observation 1).

Now forget that we fixed $n$. We have thus proven that for every
$n\in\mathbb{Z}$, every $c\in T\left(  \mathfrak{g}\right)  \left[  n\right]
$ is $n$-stratifiable. In other words, we have proved Lemma
\ref{lem.invformnondeg.polynomiality2}.

\textit{Proof of Lemma \ref{lem.invformnondeg.polynomiality}.} We have
$e_{\mathbf{i}}^{\varepsilon}\in U\left(  \mathfrak{g}^{\varepsilon}\right)
\left[  \deg\mathbf{i}\right]  $ and thus $e_{\mathbf{i}}^{\varepsilon
}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\in M_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}\left[  \deg\mathbf{i}\right]  $. Similarly, $e_{\mathbf{j}%
}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\in M_{-\lambda
}^{-\mathfrak{g}^{\varepsilon}}\left[  \deg\mathbf{j}\right]  $. Hence, if
$\deg\mathbf{i}+\deg\mathbf{j}\neq0$, then $\left(  e_{\mathbf{i}%
}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}},e_{\mathbf{j}%
}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda
}^{\mathfrak{g}^{\varepsilon}}\in\left(  M_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}\left[  \deg\mathbf{i}\right]  ,M_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\left[  \deg\mathbf{j}\right]  \right)  _{\lambda
}^{\mathfrak{g}^{\varepsilon}}=0$ (because the form $\left(  \cdot
,\cdot\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}$ is of degree $0$,
while $\deg\mathbf{i}+\deg\mathbf{j}\neq0$) and thus $\left(  e_{\mathbf{i}%
}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}},e_{\mathbf{j}%
}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda
}^{\mathfrak{g}^{\varepsilon}}=0$. Thus, if $\deg\mathbf{i}+\deg\mathbf{j}%
\neq0$, then Lemma \ref{lem.invformnondeg.polynomiality} trivially holds
(because we can then just take $Q_{\mathbf{i},\mathbf{j}}=0$). Thus, for the
rest of the proof of Lemma \ref{lem.invformnondeg.polynomiality}, we can WLOG
assume that we \textit{don't} have $\deg\mathbf{i}+\deg\mathbf{j}\neq0$.
Hence, we have $\deg\mathbf{i}+\deg\mathbf{j}=0$.

Write the sequence $\mathbf{j}$ in the form $\left(  \left(  m_{1}%
,j_{1}\right)  ,\left(  m_{2},j_{2}\right)  ,...,\left(  m_{k},j_{k}\right)
\right)  $. Then, $e_{\mathbf{j}}^{\varepsilon}=e_{m_{1},j_{1}}e_{m_{2},j_{2}%
}...e_{m_{k},j_{k}}$ and $\deg\mathbf{j}=m_{1}+m_{2}+...+m_{k}=m_{k}%
+m_{k-1}+...+m_{1}$.

Since $e_{\mathbf{j}}^{\varepsilon}=e_{m_{1},j_{1}}e_{m_{2},j_{2}}%
...e_{m_{k},j_{k}}$, we have%
\begin{align}
&  \left(  e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}\nonumber\\
&  =\left(  e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}},e_{m_{1},j_{1}}e_{m_{2},j_{2}}...e_{m_{k},j_{k}}v_{-\lambda
}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon
}}=\left(  -1\right)  ^{k}\left(  e_{m_{k},j_{k}}e_{m_{k-1},j_{k-1}%
}...e_{m_{1},j_{1}}\cdot e_{\mathbf{i}}^{\varepsilon}v_{\lambda}%
^{+\mathfrak{g}^{\varepsilon}},v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we applied the }\mathfrak{g}%
^{\varepsilon}\text{-invariance of the form }\left(  \cdot,\cdot\right)
_{\lambda}^{\mathfrak{g}^{\varepsilon}}\text{ for a total of }k\text{
times}\right) \nonumber\\
&  =\left(  \left(  -1\right)  ^{k}e_{m_{k},j_{k}}e_{m_{k-1},j_{k-1}%
}...e_{m_{1},j_{1}}\cdot e_{\mathbf{i}}^{\varepsilon}v_{\lambda}%
^{+\mathfrak{g}^{\varepsilon}},v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}.
\label{pf.invformnondeg.polynomiality.1}%
\end{align}


Write the sequence $\mathbf{i}$ in the form $\left(  \left(  n_{1}%
,i_{1}\right)  ,\left(  n_{2},i_{2}\right)  ,...,\left(  n_{\ell},i_{\ell
}\right)  \right)  $. Then, $e_{\mathbf{i}}^{\varepsilon}=e_{n_{1},i_{1}%
}e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}$ and $\deg\mathbf{i}=n_{1}%
+n_{2}+...+n_{\ell}$. Now,%
\begin{align}
&  \left(  -1\right)  ^{k}e_{m_{k},j_{k}}e_{m_{k-1},j_{k-1}}...e_{m_{1},j_{1}%
}\cdot\underbrace{e_{\mathbf{i}}^{\varepsilon}}_{=e_{n_{1},i_{1}}%
e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}}\nonumber\\
&  =\left(  -1\right)  ^{k}e_{m_{k},j_{k}}e_{m_{k-1},j_{k-1}}...e_{m_{1}%
,j_{1}}\cdot e_{n_{1},i_{1}}e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}\nonumber\\
&  =\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  \left(
-1\right)  ^{k}e_{m_{k},j_{k}}\otimes e_{m_{k-1},j_{k-1}}\otimes...\otimes
e_{m_{1},j_{1}}\otimes e_{n_{1},i_{1}}\otimes e_{n_{2},i_{2}}\otimes...\otimes
e_{n_{\ell},i_{\ell}}\right)  . \label{pf.invformnondeg.polynomiality.2}%
\end{align}
Denote the tensor $\left(  -1\right)  ^{k}e_{m_{k},j_{k}}\otimes
e_{m_{k-1},j_{k-1}}\otimes...\otimes e_{m_{1},j_{1}}\otimes e_{n_{1},i_{1}%
}\otimes e_{n_{2},i_{2}}\otimes...\otimes e_{n_{\ell},i_{\ell}}$ by $c$. Then,
(\ref{pf.invformnondeg.polynomiality.2}) rewrites as%
\begin{equation}
\left(  -1\right)  ^{k}e_{m_{k},j_{k}}e_{m_{k-1},j_{k-1}}...e_{m_{1},j_{1}%
}\cdot e_{\mathbf{i}}^{\varepsilon}=\operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}c. \label{pf.invformnondeg.polynomiality.3}%
\end{equation}


Since
\begin{align*}
c  &  =\left(  -1\right)  ^{k}e_{m_{k},j_{k}}\otimes e_{m_{k-1},j_{k-1}%
}\otimes...\otimes e_{m_{1},j_{1}}\otimes e_{n_{1},i_{1}}\otimes
e_{n_{2},i_{2}}\otimes...\otimes e_{n_{\ell},i_{\ell}}\\
&  \in T\left(  \mathfrak{g}\right)  \left[  m_{k}+m_{k-1}+...+m_{1}%
+n_{1}+n_{2}+...+n_{\ell}\right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }e_{m_{k},j_{k}}\in\mathfrak{g}_{m_{k}}\text{, }e_{m_{k-1}%
,j_{k-1}}\in\mathfrak{g}_{m_{k-1}}\text{, }...\text{, }e_{m_{1},j_{1}}%
\in\mathfrak{g}_{m_{1}}\\
\text{and }e_{n_{1},i_{1}}\in\mathfrak{g}_{n_{1}}\text{, }e_{n_{2},i_{2}}%
\in\mathfrak{g}_{n_{2}}\text{, }...\text{, }e_{n_{\ell},i_{\ell}}%
\in\mathfrak{g}_{n_{\ell}}%
\end{array}
\right) \\
&  =T\left(  \mathfrak{g}\right)  \left[  0\right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\underbrace{m_{k}+m_{k-1}%
+...+m_{1}}_{=\deg\mathbf{j}}+\underbrace{n_{1}+n_{2}+...+n_{\ell}}%
_{=\deg\mathbf{i}}=\deg\mathbf{j}+\deg\mathbf{i}=\deg\mathbf{i}+\deg
\mathbf{j}=0\right)  ,
\end{align*}
we can apply Lemma \ref{lem.invformnondeg.polynomiality2} to $n=0$. We
conclude that there exists a polynomial map $d:\mathfrak{h}^{\ast}%
\times\mathbb{C}\rightarrow T\left(  \mathfrak{n}_{-}\right)  \left[
0\right]  $ such that every $\lambda\in\mathfrak{h}^{\ast}$ and every
$\varepsilon\in\mathbb{C}$ satisfy%
\begin{equation}
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}=\left(  \operatorname*{env}%
\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(  \lambda,\varepsilon
\right)  \right)  \right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\label{pf.invformnondeg.polynomiality.4}%
\end{equation}
Since $T\left(  \mathfrak{n}_{-}\right)  \left[  0\right]  =\mathbb{C}$
(because $\mathfrak{n}_{-}$ is concentrated in negative degrees), this
polynomial map $d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow T\left(
\mathfrak{n}_{-}\right)  \left[  0\right]  $ is a polynomial function
$d:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow\mathbb{C}$. Denote this
function $d$ by $Q_{\mathbf{i},\mathbf{j}}$. Then, every $\lambda
\in\mathfrak{h}^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy $d\left(
\lambda,\varepsilon\right)  =Q_{\mathbf{i},\mathbf{j}}\left(  \lambda
,\varepsilon\right)  $ and thus $\operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}\left(  d\left(  \lambda,\varepsilon\right)  \right)
=\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  \right)
=Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  $ (since
$Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  \in\mathbb{C}$).
Thus, every $\lambda\in\mathfrak{h}^{\ast}$ and every $\varepsilon
\in\mathbb{C}$ satisfy%
\begin{align}
\left(  \operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}c\right)
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}  &  =\underbrace{\left(
\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}}\left(  d\left(
\lambda,\varepsilon\right)  \right)  \right)  }_{=Q_{\mathbf{i},\mathbf{j}%
}\left(  \lambda,\varepsilon\right)  }v_{\lambda}^{+\mathfrak{g}^{\varepsilon
}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.invformnondeg.polynomiality.4}%
)}\right) \nonumber\\
&  =Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  \cdot
v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}.
\label{pf.invformnondeg.polynomiality.5}%
\end{align}


Now, every $\lambda\in\mathfrak{h}^{\ast}$ and every $\varepsilon\in
\mathbb{C}$ satisfy%
\begin{align*}
\left(  e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}%
},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}  &  =\left(
\underbrace{\left(  -1\right)  ^{k}e_{m_{k},j_{k}}e_{m_{k-1},j_{k-1}%
}...e_{m_{1},j_{1}}\cdot e_{\mathbf{i}}^{\varepsilon}}%
_{\substack{=\operatorname*{env}\nolimits_{\mathfrak{g}^{\varepsilon}%
}c\\\text{(by (\ref{pf.invformnondeg.polynomiality.3}))}}}v_{\lambda
}^{+\mathfrak{g}^{\varepsilon}},v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}\ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.invformnondeg.polynomiality.1})}\right) \\
&  =\left(  \underbrace{\left(  \operatorname*{env}\nolimits_{\mathfrak{g}%
^{\varepsilon}}c\right)  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}%
}_{\substack{=Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)
\cdot v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\\\text{(by
(\ref{pf.invformnondeg.polynomiality.5}))}}},v_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}=\left(
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  \cdot v_{\lambda
}^{+\mathfrak{g}^{\varepsilon}},v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}\\
&  =Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)
\cdot\underbrace{\left(  v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}%
,v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda}^{\mathfrak{g}%
^{\varepsilon}}}_{=1}=Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon
\right)  .
\end{align*}
This proves Lemma \ref{lem.invformnondeg.polynomiality}.

We shall now take a closer look at the polynomial function $Q_{\mathbf{i}%
,\mathbf{j}}$ of Lemma \ref{lem.invformnondeg.polynomiality}:

\begin{lemma}
\label{lem.invformnondeg.polynomiality3}Let $\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E$ and $\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E$. Consider
the polynomial function $Q_{\mathbf{i},\mathbf{j}}:\mathfrak{h}^{\ast}%
\times\mathbb{C}\rightarrow\mathbb{C}$ of Lemma
\ref{lem.invformnondeg.polynomiality}. Then, every $\lambda\in\mathfrak{h}%
^{\ast}$ and every nonzero $\varepsilon\in\mathbb{C}$ satisfy%
\[
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  =\varepsilon
^{\operatorname*{len}\mathbf{i}+\operatorname*{len}\mathbf{j}}Q_{\mathbf{i}%
,\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  .
\]

\end{lemma}

Note that Lemma \ref{lem.invformnondeg.polynomiality3} does not really need
the conditions $\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$ and
$\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E$. It is sufficient that
$\mathbf{i}\in\operatorname*{Seq}E$ is such that no element $\left(
n,i\right)  $ of the sequence $\mathbf{i}$ satisfies $n=0$, and that a similar
condition holds for $\mathbf{j}$. But since we will only use Lemma
\ref{lem.invformnondeg.polynomiality3} in the case when $\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E$ and $\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E$, we would not gain much from thus generalizing it.

\textit{Proof of Lemma \ref{lem.invformnondeg.polynomiality3}.} We recall that
the definition of $Q_{\mathbf{i},\mathbf{j}}$ said that%
\begin{equation}
\left(  e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}%
},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}=Q_{\mathbf{i},\mathbf{j}%
}\left(  \lambda,\varepsilon\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}\lambda\in\mathfrak{h}^{\ast}\text{ and }\varepsilon\in\mathbb{C}.
\label{pf.invformnondeg.polynomiality3.1}%
\end{equation}


Let $\lambda\in\mathfrak{h}^{\ast}$ be arbitrary, and let $\varepsilon
\in\mathbb{C}$ be nonzero. Since $\varepsilon\neq0$, the Lie algebra
isomorphism $J_{\varepsilon}:\mathfrak{g}^{\varepsilon}\rightarrow
\mathfrak{g}$ exists and satisfies $\left(  \lambda/\varepsilon^{2}\right)
\circ J_{\varepsilon}=\lambda$. Hence, we have an isomorphism $J_{\varepsilon
}:\left(  \mathfrak{g}^{\varepsilon},\lambda\right)  \rightarrow\left(
\mathfrak{g},\lambda/\varepsilon^{2}\right)  $ in the category of pairs of a
$\mathbb{Z}$-graded Lie algebra and a linear form on its $0$-th homogeneous
component (where the morphisms in this category are defined in the obvious
way). This isomorphism induces a corresponding isomorphism $M_{\lambda
}^{+\mathfrak{g}^{\varepsilon}}\rightarrow M_{\lambda/\varepsilon^{2}%
}^{+\mathfrak{g}}$ of Verma modules which sends $xv_{\lambda}^{+\mathfrak{g}%
^{\varepsilon}}$ to $\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
x\right)  v_{\lambda/\varepsilon^{2}}^{+\mathfrak{g}}$ for every $x\in
U\left(  \mathfrak{g}^{\varepsilon}\right)  $ (where $U\left(  J_{\varepsilon
}\right)  $ is the isomorphism $U\left(  \mathfrak{g}^{\varepsilon}\right)
\rightarrow U\left(  \mathfrak{g}\right)  $ canonically induced by the Lie
algebra isomorphism $J_{\varepsilon}:\mathfrak{g}^{\varepsilon}\rightarrow
\mathfrak{g}$). Similarly, we get an isomorphism $M_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\rightarrow M_{-\lambda/\varepsilon^{2}}^{-\mathfrak{g}}$ of
Verma modules which sends $yv_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}$ to
$\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(  y\right)
v_{-\lambda/\varepsilon^{2}}^{-\mathfrak{g}}$ for every $y\in U\left(
\mathfrak{g}^{\varepsilon}\right)  $. Since the bilinear form $\left(
\cdot,\cdot\right)  _{\mu}^{\mathfrak{e}}$ depends functorially on a
$\mathbb{Z}$-graded Lie algebra $\mathfrak{e}$ and a linear form
$\mu:\mathfrak{e}_{0}\rightarrow\mathbb{C}$, these isomorphisms leave the
bilinear form unchanged, i. e., we have%
\[
\left(  \left(  U\left(  J_{\varepsilon}\right)  \right)  \left(  x\right)
v_{\lambda/\varepsilon^{2}}^{+\mathfrak{g}},\left(  U\left(  J_{\varepsilon
}\right)  \right)  \left(  y\right)  v_{-\lambda/\varepsilon^{2}%
}^{-\mathfrak{g}}\right)  _{\lambda/\varepsilon^{2}}^{\mathfrak{g}}=\left(
xv_{\lambda}^{+\mathfrak{g}^{\varepsilon}},yv_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}%
\]
for every $x\in U\left(  \mathfrak{g}^{\varepsilon}\right)  $ and $y\in
U\left(  \mathfrak{g}^{\varepsilon}\right)  $. Applied to $x=e_{\mathbf{i}%
}^{\varepsilon}$ and $y=e_{\mathbf{j}}^{\varepsilon}$, this yields%
\begin{equation}
\left(  \left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
e_{\mathbf{i}}^{\varepsilon}\right)  v_{\lambda/\varepsilon^{2}}%
^{+\mathfrak{g}},\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
e_{\mathbf{j}}^{\varepsilon}\right)  v_{-\lambda/\varepsilon^{2}%
}^{-\mathfrak{g}}\right)  _{\lambda/\varepsilon^{2}}^{\mathfrak{g}}=\left(
e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}%
},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}=Q_{\mathbf{i},\mathbf{j}%
}\left(  \lambda,\varepsilon\right)  \label{pf.invformnondeg.polynomiality3.2}%
\end{equation}
(by the definition of $Q_{\mathbf{i},\mathbf{j}}$).

But we have $\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
e_{\mathbf{i}}^{\varepsilon}\right)  =\varepsilon^{\operatorname*{len}%
\mathbf{i}}e_{\mathbf{i}}^{1}$\ \ \ \ \footnote{\textit{Proof.} Write the
sequence $\mathbf{i}$ in the form $\left(  \left(  n_{1},i_{1}\right)
,\left(  n_{2},i_{2}\right)  ,...,\left(  n_{\ell},i_{\ell}\right)  \right)
$. Since $\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$, all of the numbers
$n_{1}$, $n_{2}$, $...$, $n_{\ell}$ are negative, so that none of them is $0$.
As a consequence, $\delta_{n_{u},0}=0$ for every $u\in\left\{  1,2,...,\ell
\right\}  $. By the definition of $J_{\varepsilon}$, we have%
\begin{align*}
J_{\varepsilon}\left(  e_{n_{u},i_{u}}\right)   &  =\underbrace{\varepsilon
^{1+\delta_{n_{u},0}}}_{\substack{=\varepsilon\\\text{(since }\delta_{n_{u}%
,0}=0\text{)}}}e_{n_{u},i_{u}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}e_{n_{u},i_{u}}\in\mathfrak{g}_{n_{u}}\right) \\
&  =\varepsilon e_{n_{u},i_{u}}%
\end{align*}
for every $u\in\left\{  1,2,...,\ell\right\}  $.
\par
Now, $e_{\mathbf{i}}^{\varepsilon}$ is defined as the product $e_{n_{1},i_{1}%
}e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}$ in $U\left(  \mathfrak{g}%
^{\varepsilon}\right)  $, and $e_{\mathbf{i}}^{1}$ is defined as the product
$e_{n_{1},i_{1}}e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}$ in $U\left(
\mathfrak{g}^{1}\right)  $. Hence,%
\begin{align*}
\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(  e_{\mathbf{i}%
}^{\varepsilon}\right)   &  =\left(  U\left(  J_{\varepsilon}\right)  \right)
\left(  e_{n_{1},i_{1}}e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }e_{\mathbf{i}}^{\varepsilon}%
=e_{n_{1},i_{1}}e_{n_{2},i_{2}}...e_{n_{\ell},i_{\ell}}\right) \\
&  =J_{\varepsilon}\left(  e_{n_{1},i_{1}}\right)  J_{\varepsilon}\left(
e_{n_{2},i_{2}}\right)  ...J_{\varepsilon}\left(  e_{n_{\ell},i_{\ell}}\right)
\\
&  =\varepsilon e_{n_{1},i_{1}}\cdot\varepsilon e_{n_{2},i_{2}}\cdot
...\cdot\varepsilon e_{n_{\ell},i_{\ell}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }J_{\varepsilon}\left(  e_{n_{u},i_{u}}\right)  =\varepsilon
e_{n_{u},i_{u}}\text{ for every }u\in\left\{  1,2,...,\ell\right\}  \right) \\
&  =\varepsilon^{\ell}\underbrace{e_{n_{1},i_{1}}e_{n_{2},i_{2}}...e_{n_{\ell
},i_{\ell}}}_{=e_{\mathbf{i}}^{1}}=\varepsilon^{\ell}e_{\mathbf{i}}%
^{1}=\varepsilon^{\operatorname*{len}\mathbf{i}}e_{\mathbf{i}}^{1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\ell=\operatorname*{len}%
\mathbf{i}\text{ by the definition of }\operatorname*{len}\mathbf{i}\right)  ,
\end{align*}
qed.} and similarly $\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
e_{\mathbf{j}}^{\varepsilon}\right)  =\varepsilon^{\operatorname*{len}%
\mathbf{j}}e_{\mathbf{j}}^{1}$. Hence,%
\begin{align*}
&  \left(  \left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
e_{\mathbf{i}}^{\varepsilon}\right)  v_{\lambda/\varepsilon^{2}}%
^{+\mathfrak{g}},\left(  U\left(  J_{\varepsilon}\right)  \right)  \left(
e_{\mathbf{j}}^{\varepsilon}\right)  v_{-\lambda/\varepsilon^{2}%
}^{-\mathfrak{g}}\right)  _{\lambda/\varepsilon^{2}}^{\mathfrak{g}}\\
&  =\left(  \varepsilon^{\operatorname*{len}\mathbf{i}}e_{\mathbf{i}}%
^{1}v_{\lambda/\varepsilon^{2}}^{+\mathfrak{g}},\varepsilon
^{\operatorname*{len}\mathbf{j}}e_{\mathbf{j}}^{1}v_{-\lambda/\varepsilon^{2}%
}^{-\mathfrak{g}}\right)  _{\lambda/\varepsilon^{2}}^{\mathfrak{g}%
}=\varepsilon^{\operatorname*{len}\mathbf{i}+\operatorname*{len}\mathbf{j}%
}\left(  e_{\mathbf{i}}^{1}v_{\lambda/\varepsilon^{2}}^{+\mathfrak{g}%
},e_{\mathbf{j}}^{1}v_{-\lambda/\varepsilon^{2}}^{-\mathfrak{g}}\right)
_{\lambda/\varepsilon^{2}}^{\mathfrak{g}}\\
&  =\varepsilon^{\operatorname*{len}\mathbf{i}+\operatorname*{len}\mathbf{j}%
}\underbrace{\left(  e_{\mathbf{i}}^{1}v_{\lambda/\varepsilon^{2}%
}^{+\mathfrak{g}^{1}},e_{\mathbf{j}}^{1}v_{-\lambda/\varepsilon^{2}%
}^{-\mathfrak{g}^{1}}\right)  _{\lambda/\varepsilon^{2}}^{\mathfrak{g}^{1}}%
}_{\substack{=Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon
^{2},1\right)  \\\text{(by (\ref{pf.invformnondeg.polynomiality3.1}), applied
to }\lambda/\varepsilon^{1}\text{ and }1\text{ instead of }\lambda\text{ and
}\varepsilon\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{g}%
=\mathfrak{g}^{1}\right) \\
&  =\varepsilon^{\operatorname*{len}\mathbf{i}+\operatorname*{len}\mathbf{j}%
}Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  .
\end{align*}
Compared to (\ref{pf.invformnondeg.polynomiality3.2}), this yields
$Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  =\varepsilon
^{\operatorname*{len}\mathbf{i}+\operatorname*{len}\mathbf{j}}Q_{\mathbf{i}%
,\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  $. This proves Lemma
\ref{lem.invformnondeg.polynomiality3}.

Here is the consequence of Lemmas \ref{lem.invformnondeg.polynomiality} and
\ref{lem.invformnondeg.polynomiality3} that we will actually use:

\begin{corollary}
\label{cor.invformnondeg.polynomiality}Let $n\in\mathbb{N}$. Let
$\operatorname*{LEN}n=\sum\limits_{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\\\deg\mathbf{i}=-n}}\operatorname*{len}\mathbf{i=}%
\sum\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}%
E;\\\deg\mathbf{j}=n}}\operatorname*{len}\mathbf{j}$ (we are using the fact
that $\sum\limits_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}%
E;\\\deg\mathbf{i}=-n}}\operatorname*{len}\mathbf{i=}\sum
\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}%
E;\\\deg\mathbf{j}=n}}\operatorname*{len}\mathbf{j}$, which we proved above).

Then, there exists a polynomial function $Q_{n}:\mathfrak{h}^{\ast}%
\times\mathbb{C}\rightarrow\mathbb{C}$ such that every $\lambda\in
\mathfrak{h}^{\ast}$ and every $\varepsilon\in\mathbb{C}$ satisfy%
\begin{equation}
\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}%
^{\varepsilon}}\right)  =Q_{n}\left(  \lambda,\varepsilon\right)  .
\label{cor.invformnondeg.polynomiality.1}%
\end{equation}
This function $Q_{n}$ satisfies%
\[
Q_{n}\left(  \lambda,\varepsilon\right)  =\varepsilon^{2\operatorname*{LEN}%
n}Q_{n}\left(  \lambda/\varepsilon^{2},1\right)  \ \ \ \ \ \ \ \ \ \ \text{for
every }\lambda\in\mathfrak{h}^{\ast}\text{ and every nonzero }\varepsilon
\in\mathbb{C}.
\]

\end{corollary}

\textit{Proof of Corollary \ref{cor.invformnondeg.polynomiality}.} For any
$\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$ satisfying $\deg
\mathbf{i}=-n$, and any $\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E$
satisfying $\deg\mathbf{j}=n$, consider the polynomial function $Q_{\mathbf{i}%
,\mathbf{j}}:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow\mathbb{C}$ of
Lemma \ref{lem.invformnondeg.polynomiality}. Define a polynomial function
$Q_{n}:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow\mathbb{C}$ by%
\[
Q_{n}=\det\left(  \left(  Q_{\mathbf{i},\mathbf{j}}\right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}\right)  .
\]
Then, every $\lambda\in\mathfrak{h}^{\ast}$ and every $\varepsilon
\in\mathbb{C}$ satisfy%
\begin{align*}
Q_{n}\left(  \lambda,\varepsilon\right)   &  =\det\left(  \left(
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  \right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}\right)  =\det\left(  \left(  \left(  e_{\mathbf{i}}^{\varepsilon
}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}},e_{\mathbf{j}}^{\varepsilon
}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda,n}%
^{\mathfrak{g}^{\varepsilon}}\right)  _{\substack{\mathbf{i}\in
\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since Lemma \ref{lem.invformnondeg.polynomiality} yields}\\
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda,\varepsilon\right)  =\left(
e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}%
},e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}%
}\right)  _{\lambda}^{\mathfrak{g}^{\varepsilon}}=\left(  e_{\mathbf{i}%
}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}},e_{\mathbf{j}%
}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\right)  _{\lambda
,n}^{\mathfrak{g}^{\varepsilon}}\\
\text{(since }\deg\mathbf{i}=-n\text{ yields }e_{\mathbf{i}}^{\varepsilon}\in
U\left(  \mathfrak{g}^{\varepsilon}\right)  \left[  -n\right]  \text{ and thus
}e_{\mathbf{i}}^{\varepsilon}v_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\in
M_{\lambda}^{+\mathfrak{g}^{\varepsilon}}\left[  -n\right] \\
\text{and similarly }e_{\mathbf{j}}^{\varepsilon}v_{-\lambda}^{-\mathfrak{g}%
^{\varepsilon}}\in M_{-\lambda}^{-\mathfrak{g}^{\varepsilon}}\left[  n\right]
\text{)}%
\end{array}
\right) \\
&  =\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}%
^{\varepsilon}}\right)  .
\end{align*}
We have thus proven that every $\lambda\in\mathfrak{h}^{\ast}$ and every
$\varepsilon\in\mathbb{C}$ satisfy $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\mathfrak{g}^{\varepsilon}}\right)  =Q_{n}\left(  \lambda
,\varepsilon\right)  $.

Now, it remains to show that this function $Q_{n}$ satisfies $Q_{n}\left(
\lambda,\varepsilon\right)  =\varepsilon^{2\operatorname*{LEN}n}Q_{n}\left(
\lambda/\varepsilon^{2},1\right)  $ for every $\lambda\in\mathfrak{h}^{\ast}$
and every nonzero $\varepsilon\in\mathbb{C}$. In order to do this, we let
$\lambda\in\mathfrak{h}^{\ast}$ be arbitrary and $\varepsilon\in\mathbb{C}$ be
nonzero. Then,
\begin{equation}
Q_{n}\left(  \lambda,\varepsilon\right)  =\det\left(  \left(  Q_{\mathbf{i}%
,\mathbf{j}}\left(  \lambda,\varepsilon\right)  \right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}\right)  =\det\left(  \left(  \varepsilon^{\operatorname*{len}\mathbf{i}%
}\varepsilon^{\operatorname*{len}\mathbf{j}}Q_{\mathbf{i},\mathbf{j}}\left(
\lambda/\varepsilon^{2},1\right)  \right)  _{\substack{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right)
\label{pf.invformnondeg.polynomiality5.1}%
\end{equation}
(since Lemma \ref{lem.invformnondeg.polynomiality3} yields $Q_{\mathbf{i}%
,\mathbf{j}}\left(  \lambda,\varepsilon\right)  =\varepsilon
^{\operatorname*{len}\mathbf{i}+\operatorname*{len}\mathbf{j}}Q_{\mathbf{i}%
,\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  =\varepsilon
^{\operatorname*{len}\mathbf{i}}\varepsilon^{\operatorname*{len}\mathbf{j}%
}Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  $ for all
$\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$ and$\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E$).

Now, recall that if we multiply a row of a square matrix by some scalar, then
the determinant of the matrix is also multiplied by the same scalar. A similar
fact holds for the columns. Thus,
\begin{align*}
&  \det\left(  \left(  \varepsilon^{\operatorname*{len}\mathbf{i}}%
\varepsilon^{\operatorname*{len}\mathbf{j}}Q_{\mathbf{i},\mathbf{j}}\left(
\lambda/\varepsilon^{2},1\right)  \right)  _{\substack{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right) \\
&  =\left(  \prod\limits_{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\\\deg\mathbf{i}=-n}}\varepsilon^{\operatorname*{len}%
\mathbf{i}}\right)  \cdot\left(  \prod\limits_{\substack{\mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{j}=n}}\varepsilon
^{\operatorname*{len}\mathbf{j}}\right)  \cdot\det\left(  \left(
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  \right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}\right)
\end{align*}
(because the matrix $\left(  \varepsilon^{\operatorname*{len}\mathbf{i}%
}\varepsilon^{\operatorname*{len}\mathbf{j}}Q_{\mathbf{i},\mathbf{j}}\left(
\lambda/\varepsilon^{2},1\right)  \right)  _{\substack{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}=n}}$ is obtained from the
matrix $\left(  Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon
^{2},1\right)  \right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg
\mathbf{i}=-n;\ \deg\mathbf{j}=n}}$ by multiplying every row $\mathbf{i}$ by
the scalar $\varepsilon^{\operatorname*{len}\mathbf{i}}$ and multiplying every
column $\mathbf{j}$ by the scalar $\varepsilon^{\operatorname*{len}\mathbf{j}%
}$). Hence, (\ref{pf.invformnondeg.polynomiality5.1}) becomes%
\begin{equation}
Q_{n}\left(  \lambda,\varepsilon\right)  =\left(  \prod
\limits_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}%
E;\\\deg\mathbf{i}=-n}}\varepsilon^{\operatorname*{len}\mathbf{i}}\right)
\cdot\left(  \prod\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{j}=n}}\varepsilon^{\operatorname*{len}\mathbf{j}%
}\right)  \cdot\det\left(  \left(  Q_{\mathbf{i},\mathbf{j}}\left(
\lambda/\varepsilon^{2},1\right)  \right)  _{\substack{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right)  .
\label{pf.invformnondeg.polynomiality5.3}%
\end{equation}


Now, since $\operatorname*{LEN}n=\sum\limits_{\substack{\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E;\\\deg\mathbf{i}=-n}}\operatorname*{len}%
\mathbf{i}$, we have $\varepsilon^{\operatorname*{LEN}n}=\prod
\limits_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}%
E;\\\deg\mathbf{i}=-n}}\varepsilon^{\operatorname*{len}\mathbf{i}}$. Also,
since $\operatorname*{LEN}n=\sum\limits_{\substack{\mathbf{j}\in
\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{j}=n}}\operatorname*{len}%
\mathbf{j}$, we have $\varepsilon^{\operatorname*{LEN}n}=\prod
\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}%
E;\\\deg\mathbf{j}=n}}\varepsilon^{\operatorname*{len}\mathbf{j}}$. Thus,%
\begin{equation}
\underbrace{\left(  \prod\limits_{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\\\deg\mathbf{i}=-n}}\varepsilon^{\operatorname*{len}%
\mathbf{i}}\right)  }_{=\varepsilon^{\operatorname*{LEN}n}}\cdot
\underbrace{\left(  \prod\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\\\deg\mathbf{j}=n}}\varepsilon^{\operatorname*{len}\mathbf{j}%
}\right)  }_{=\varepsilon^{\operatorname*{LEN}n}}=\varepsilon
^{\operatorname*{LEN}n}\varepsilon^{\operatorname*{LEN}n}=\varepsilon
^{2\operatorname*{LEN}n}. \label{pf.invformnondeg.polynomiality5.6}%
\end{equation}


On the other hand, since $Q_{n}=\det\left(  \left(  Q_{\mathbf{i},\mathbf{j}%
}\right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}%
E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}%
=-n;\ \deg\mathbf{j}=n}}\right)  $, we have%
\begin{equation}
Q_{n}\left(  \lambda/\varepsilon^{2},1\right)  =\det\left(  \left(
Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)  \right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}\right)  . \label{pf.invformnondeg.polynomiality5.5}%
\end{equation}
Hence, (\ref{pf.invformnondeg.polynomiality5.3}) becomes%
\begin{align*}
&  Q_{n}\left(  \lambda,\varepsilon\right) \\
&  =\underbrace{\left(  \prod\limits_{\substack{\mathbf{i}\in
\operatorname*{Seq}\nolimits_{-}E;\\\deg\mathbf{i}=-n}}\varepsilon
^{\operatorname*{len}\mathbf{i}}\right)  \cdot\left(  \prod
\limits_{\substack{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}%
E;\\\deg\mathbf{j}=n}}\varepsilon^{\operatorname*{len}\mathbf{j}}\right)
}_{\substack{=\varepsilon^{2\operatorname*{LEN}n}\\\text{(by
(\ref{pf.invformnondeg.polynomiality5.6}))}}}\cdot\underbrace{\det\left(
\left(  Q_{\mathbf{i},\mathbf{j}}\left(  \lambda/\varepsilon^{2},1\right)
\right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}%
E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}%
=-n;\ \deg\mathbf{j}=n}}\right)  }_{\substack{=Q_{n}\left(  \lambda
/\varepsilon^{2},1\right)  \\\text{(by
(\ref{pf.invformnondeg.polynomiality5.5}))}}}\\
&  =\varepsilon^{2\operatorname*{LEN}n}\cdot Q_{n}\left(  \lambda
/\varepsilon^{2},1\right)  .
\end{align*}
We have thus proven that $Q_{n}\left(  \lambda,\varepsilon\right)
=\varepsilon^{2\operatorname*{LEN}n}Q_{n}\left(  \lambda/\varepsilon
^{2},1\right)  $ for every $\lambda\in\mathfrak{h}^{\ast}$ and every nonzero
$\varepsilon\in\mathbb{C}$. This concludes the proof of Corollary
\ref{cor.invformnondeg.polynomiality}.

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: On leading terms of
pseudo-homogeneous polynomial maps}

The following lemma about polynomial maps could be an easy exercise in any
algebra text. Unfortunately I do not see a quick way to prove it, so the proof
is going to take a few pages. Reading it will probably waste more of the
reader's time than proving it on her own.

\begin{lemma}
\label{lem.invformnondeg.elemen}Let $V$ be a finite-dimensional $\mathbb{C}%
$-vector space. Let $k\in\mathbb{N}$. Let $\phi:V\times\mathbb{C}%
\rightarrow\mathbb{C}$ be a polynomial function such that every $\lambda\in V$
and every nonzero $\varepsilon\in\mathbb{C}$ satisfy%
\[
\phi\left(  \lambda,\varepsilon\right)  =\varepsilon^{2k}\phi\left(
\lambda/\varepsilon^{2},1\right)  .
\]
Then:

\textbf{(a)} The polynomial function
\[
V\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto\phi\left(
\lambda,0\right)
\]
is homogeneous of degree $k$.

\textbf{(b)} For every integer $N>k$, the $N$-th homogeneous component of the
polynomial function%
\[
V\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto\phi\left(
\lambda,1\right)
\]
is zero.

\textbf{(c)} The $k$-th homogeneous component of the polynomial function%
\[
V\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto\phi\left(
\lambda,1\right)
\]
is the polynomial function%
\[
V\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto\phi\left(
\lambda,0\right)  .
\]

\end{lemma}

\textit{Proof of Lemma \ref{lem.invformnondeg.elemen}.} \textbf{(a)} Let
$\left(  v_{1},v_{2},...,v_{n}\right)  $ be a basis of the vector space
$V^{\ast}$. Let $\pi_{V}:V\times\mathbb{C}\rightarrow V$ and $\pi_{\mathbb{C}%
}:V\times\mathbb{C}\rightarrow\mathbb{C}$ be the canonical projections. Then,
$\left(  v_{1}\circ\pi_{V},v_{2}\circ\pi_{V},...,v_{n}\circ\pi_{V}%
,\pi_{\mathbb{C}}\right)  $ is a basis of the vector space $\left(
V\times\mathbb{C}\right)  ^{\ast}$.

Therefore, since $\phi$ is a polynomial function, there exists a polynomial
$P\in\mathbb{C}\left[  X_{1},X_{2},...,X_{n},X_{n+1}\right]  $ such that every
$w\in V\times\mathbb{C}$ satisfies%
\[
\phi\left(  w\right)  =P\left(  \left(  v_{1}\circ\pi_{V}\right)  \left(
w\right)  ,\left(  v_{2}\circ\pi_{V}\right)  \left(  w\right)  ,...,\left(
v_{n}\circ\pi_{V}\right)  \left(  w\right)  ,\pi_{\mathbb{C}}\left(  w\right)
\right)  .
\]
In other words, every $\left(  \lambda,\varepsilon\right)  \in V\times
\mathbb{C}$ satisfies%
\begin{equation}
\phi\left(  \lambda,\varepsilon\right)  =P\left(  v_{1}\left(  \lambda\right)
,v_{2}\left(  \lambda\right)  ,...,v_{n}\left(  \lambda\right)  ,\varepsilon
\right)  . \label{pf.invformnondeg.elemen.1}%
\end{equation}


Now, it is easy to see that for every $\left(  x_{1},x_{2},...,x_{n}\right)
\in\mathbb{C}^{n}$ and nonzero $\varepsilon\in\mathbb{C}$, we have
\begin{equation}
P\left(  x_{1},x_{2},...,x_{n},\varepsilon\right)  =\varepsilon^{2k}P\left(
x_{1}/\varepsilon^{2},x_{2}/\varepsilon^{2},...,x_{n}/\varepsilon
^{2},1\right)  . \label{pf.invformnondeg.elemen.2}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.invformnondeg.elemen.2}).} Let $\left(
x_{1},x_{2},...,x_{n}\right)  \in\mathbb{C}^{n}$ be arbitrary, and let
$\varepsilon\in\mathbb{C}$ be nonzero.
\par
Let $\lambda\in V$ be a vector satisfying%
\[
v_{i}\left(  \lambda\right)  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}
\]
(such a vector $\lambda$ exists since $\left(  v_{1},v_{2},...,v_{n}\right)  $
is a basis of $V^{\ast}$). Then,%
\begin{align*}
P\left(  x_{1},x_{2},...,x_{n},\varepsilon\right)   &  =P\left(  v_{1}\left(
\lambda\right)  ,v_{2}\left(  \lambda\right)  ,...,v_{n}\left(  \lambda
\right)  ,\varepsilon\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }%
x_{i}=v_{i}\left(  \lambda\right)  \text{ for every }i\in\left\{
1,2,...,n\right\}  \right) \\
&  =\phi\left(  \lambda,\varepsilon\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.invformnondeg.elemen.1})}\right) \\
&  =\varepsilon^{2k}\underbrace{\phi\left(  \lambda/\varepsilon^{2},1\right)
}_{\substack{=P\left(  v_{1}\left(  \lambda/\varepsilon^{2}\right)
,v_{2}\left(  \lambda/\varepsilon^{2}\right)  ,...,v_{n}\left(  \lambda
/\varepsilon^{2}\right)  ,1\right)  \\\text{(by
(\ref{pf.invformnondeg.elemen.1}), applied to }\left(  \lambda/\varepsilon
^{2},1\right)  \text{ instead of }\left(  \lambda,\varepsilon\right)
\text{)}}}\\
&  =\varepsilon^{2k}P\left(  v_{1}\left(  \lambda/\varepsilon^{2}\right)
,v_{2}\left(  \lambda/\varepsilon^{2}\right)  ,...,v_{n}\left(  \lambda
/\varepsilon^{2}\right)  ,1\right)  =\varepsilon^{2k}P\left(  x_{1}%
/\varepsilon^{2},x_{2}/\varepsilon^{2},...,x_{n}/\varepsilon^{2},1\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }v_{i}\left(  \lambda
/\varepsilon^{2}\right)  =\underbrace{v_{i}\left(  \lambda\right)  }_{=x_{i}%
}/\varepsilon^{2}=x_{i}/\varepsilon^{2}\text{ for every }i\in\left\{
1,2,...,n\right\}  \right)  .
\end{align*}
This proves (\ref{pf.invformnondeg.elemen.2}).}

Now, since $P\in\mathbb{C}\left[  X_{1},X_{2},...,X_{n},X_{n+1}\right]
\cong\left(  \mathbb{C}\left[  X_{1},X_{2},...,X_{n}\right]  \right)  \left[
X_{n+1}\right]  $, we can write the polynomial $P$ as a polynomial in the
variable $X_{n+1}$ over the ring $\mathbb{C}\left[  X_{1},X_{2},...,X_{n}%
\right]  $. In other words, we can write the polynomial $P$ in the form
$P=\sum\limits_{i\in\mathbb{N}}P_{i}\cdot X_{n+1}^{i}$ for some polynomials
$P_{0}$, $P_{1}$, $P_{2}$, $...$ in $\mathbb{C}\left[  X_{1},X_{2}%
,...,X_{n}\right]  $ such that all but finitely many $i\in\mathbb{N}$ satisfy
$P_{i}=0$. Consider these $P_{0}$, $P_{1}$, $P_{2}$, $...$.

Since all but finitely many $i\in\mathbb{N}$ satisfy $P_{i}=0$, there exists a
$d\in\mathbb{N}$ such that every integer $i>d$ satisfies $P_{i}=0$. Consider
this $d$. Then, $P=\sum\limits_{i\in\mathbb{N}}P_{i}\cdot X_{n+1}^{i}%
=\sum\limits_{i=0}^{d}P_{i}\cdot X_{n+1}^{i}$ (here, we have removed all the
terms with $i>d$ from the sum, because every integer $i>d$ satisfies $P_{i}=0$
and thus $P_{i}\cdot X_{n+1}^{i}=0$).

For every $i\in\mathbb{N}$ and every $j\in\mathbb{N}$, let $Q_{i,j}$ be the
$j$-th homogeneous component of the polynomial $P_{i}$. Then, $P_{i}%
=\sum\limits_{j\in\mathbb{N}}Q_{i,j}$ for every $i\in\mathbb{N}$, and each
$Q_{i,j}$ is homogeneous of degree $j$.

Hence,%
\begin{equation}
P=\sum\limits_{i\in\mathbb{N}}\underbrace{P_{i}}_{=\sum\limits_{j\in
\mathbb{N}}Q_{i,j}}\cdot X_{n+1}^{i}=\sum\limits_{i\in\mathbb{N}}%
\sum\limits_{j\in\mathbb{N}}Q_{i,j}X_{n+1}^{i}.
\label{pf.invformnondeg.elemen.3a}%
\end{equation}


Now, we are going to show the following fact: We have%
\begin{equation}
Q_{u,v}=0\ \ \ \ \ \ \ \ \ \ \text{for all }\left(  u,v\right)  \in
\mathbb{N}\times\mathbb{N}\text{ which don't satisfy }u+2v=2k.
\label{pf.invformnondeg.elemen.4}%
\end{equation}


\textit{Proof of (\ref{pf.invformnondeg.elemen.4}).} Let $\left(  u,v\right)
\in\mathbb{N}\times\mathbb{N}$ be such that $u+2v\neq2k$. We must prove that
$Q_{u,v}=0$.

If $u>d$, then $Q_{u,v}=0$ is clear (because $Q_{u,v}$ is the $v$-th
homogeneous component of $P_{u}$, but we have $P_{u}=0$ since $u>d$). Hence,
for the rest of the proof of $Q_{u,v}=0$, we can WLOG assume that $u\leq d$.

We have%
\[
P=\sum\limits_{i=0}^{d}\underbrace{P_{i}}_{=\sum\limits_{j\in\mathbb{N}%
}Q_{i,j}}\cdot X_{n+1}^{i}=\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}%
}Q_{i,j}X_{n+1}^{i}.
\]


Let $\left(  x_{1},x_{2},...,x_{n}\right)  \in\mathbb{C}^{n}$ and
$\varepsilon\in\mathbb{C}\diagdown\left\{  0\right\}  $. Then, $\varepsilon$
is nonzero, and we have%
\begin{align*}
P\left(  x_{1},x_{2},...,x_{n},1/\varepsilon\right)   &  =\sum\limits_{i=0}%
^{d}\sum\limits_{j\in\mathbb{N}}Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)
\underbrace{\left(  1/\varepsilon\right)  ^{i}}_{=\varepsilon^{d-i}%
/\varepsilon^{d}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }P=\sum
\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}Q_{i,j}X_{n+1}^{i}\right) \\
&  =\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}Q_{i,j}\left(
x_{1},x_{2},...,x_{n}\right)  \varepsilon^{d-i}/\varepsilon^{d}=\dfrac
{1}{\varepsilon^{d}}\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}%
Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  \varepsilon^{d-i}%
\end{align*}
and%
\begin{align*}
P\left(  \varepsilon^{2}x_{1},\varepsilon^{2}x_{2},...,\varepsilon^{2}%
x_{n},1\right)   &  =\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}%
}\underbrace{Q_{i,j}\left(  \varepsilon^{2}x_{1},\varepsilon^{2}%
x_{2},...,\varepsilon^{2}x_{n}\right)  }_{\substack{=\left(  \varepsilon
^{2}\right)  ^{j}Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  \\\text{(since
}Q_{i,j}\text{ is homogeneous of degree }j\text{)}}}\underbrace{1^{i}}_{=1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }P=\sum\limits_{i=0}^{d}%
\sum\limits_{j\in\mathbb{N}}Q_{i,j}X_{n+1}^{i}\right) \\
&  =\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}\underbrace{\left(
\varepsilon^{2}\right)  ^{j}}_{=\varepsilon^{2j}}Q_{i,j}\left(  x_{1}%
,x_{2},...,x_{n}\right)  =\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}%
}\varepsilon^{2j}Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  .
\end{align*}
Now,%
\begin{align*}
&  \dfrac{1}{\varepsilon^{d}}\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}%
}Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  \varepsilon^{d-i}\\
&  =P\left(  x_{1},x_{2},...,x_{n},1/\varepsilon\right)  =\left(
1/\varepsilon\right)  ^{2k}\underbrace{P\left(  x_{1}/\left(  \dfrac
{1}{\varepsilon}\right)  ^{2},x_{2}/\left(  \dfrac{1}{\varepsilon}\right)
^{2},...,x_{n}/\left(  \dfrac{1}{\varepsilon}\right)  ^{2},1\right)
}_{=P\left(  \varepsilon^{2}x_{1},\varepsilon^{2}x_{2},...,\varepsilon
^{2}x_{n},1\right)  =\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}%
}\varepsilon^{2j}Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.invformnondeg.elemen.2}),
applied to }1/\varepsilon\text{ instead of }\varepsilon\right) \\
&  =\left(  1/\varepsilon\right)  ^{2k}\sum\limits_{i=0}^{d}\sum
\limits_{j\in\mathbb{N}}\varepsilon^{2j}Q_{i,j}\left(  x_{1},x_{2}%
,...,x_{n}\right)  ,
\end{align*}
so that%
\[
\varepsilon^{2k}\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}%
Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  \varepsilon^{d-i}=\varepsilon
^{d}\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}\varepsilon^{2j}%
Q_{i,j}\left(  x_{1},x_{2},...,x_{n}\right)  .
\]
For fixed $\varepsilon$, this is a polynomial identity in $\left(  x_{1}%
,x_{2},...,x_{n}\right)  \in\mathbb{C}^{n}$. Since it holds for all $\left(
x_{1},x_{2},...,x_{n}\right)  \in\mathbb{C}^{n}$ (as we just have shown), it
thus must hold as a formal identity, i. e., we must have%
\[
\varepsilon^{2k}\sum\limits_{i=0}^{d}\sum\limits_{j\in\mathbb{N}}%
Q_{i,j}\varepsilon^{d-i}=\varepsilon^{d}\sum\limits_{i=0}^{d}\sum
\limits_{j\in\mathbb{N}}\varepsilon^{2j}Q_{i,j}\ \ \ \ \ \ \ \ \ \ \text{in
}\mathbb{C}\left[  X_{1},X_{2},...,X_{n}\right]  .
\]
Let us take the $v$-th homogeneous components of both sides of this equation.
Since each $Q_{i,j}$ is homogeneous of degree $j$, this amounts to removing
all $Q_{i,j}$ with $j\neq v$, and leaving the $Q_{i,j}$ with $j=v$ unchanged.
Thus, we obtain%
\begin{equation}
\varepsilon^{2k}\sum\limits_{i=0}^{d}Q_{i,v}\varepsilon^{d-i}=\varepsilon
^{d}\sum\limits_{i=0}^{d}\varepsilon^{2v}Q_{i,v}\ \ \ \ \ \ \ \ \ \ \text{in
}\mathbb{C}\left[  X_{1},X_{2},...,X_{n}\right]  .
\label{pf.invformnondeg.elemen.6}%
\end{equation}


Now, let $\left(  x_{1},x_{2},...,x_{n}\right)  \in\mathbb{C}^{n}$ be
arbitrary again. Then, evaluating the identity
(\ref{pf.invformnondeg.elemen.6}) at $\left(  X_{1},X_{2},...,X_{n}\right)
=\left(  x_{1},x_{2},...,x_{n}\right)  $, we obtain
\[
\varepsilon^{2k}\sum\limits_{i=0}^{d}Q_{i,v}\left(  x_{1},x_{2},...,x_{n}%
\right)  \varepsilon^{d-i}=\varepsilon^{d}\sum\limits_{i=0}^{d}\varepsilon
^{2v}Q_{i,v}\left(  x_{1},x_{2},...,x_{n}\right)  .
\]
For fixed $\left(  x_{1},x_{2},...,x_{n}\right)  $, this is a polynomial
identity in $\varepsilon$ (since $d-i\geq0$ for all $i\in\left\{
0,1,...,d\right\}  $). Since it holds for all nonzero $\varepsilon
\in\mathbb{C}$ (as we just have shown), it thus must hold as a formal identity
(since any polynomial in one variable which evaluates to zero at all nonzero
complex numbers must be the zero polynomial). In other words, we must have%
\[
E^{2k}\sum\limits_{i=0}^{d}Q_{i,v}\left(  x_{1},x_{2},...,x_{n}\right)
E^{d-i}=E^{d}\sum\limits_{i=0}^{d}E^{2v}Q_{i,v}\left(  x_{1},x_{2}%
,...,x_{n}\right)  \ \ \ \ \ \ \ \ \ \ \text{in }\mathbb{C}\left[  E\right]
\]
(where $\mathbb{C}\left[  E\right]  $ denotes the polynomial ring over
$\mathbb{C}$ in one variable $E$). Let us compare the coefficients of
$E^{2k+d-u}$ on both sides of this equation: The coefficient of $E^{2k+d-u}$
on the left hand side of this equation is clearly $Q_{u,v}\left(  x_{1}%
,x_{2},...,x_{n}\right)  $, while the coefficient of $E^{2k+d-u}$ on the right
hand side is $0$ (in fact, the only coefficient on the right hand side of the
equation which is not trivially zero is the coefficient of $E^{d+2v}$, but
$d+2v\neq2k+d-u$ (since $u+2v\neq2k$ and thus $2v\neq2k-u$)). Hence,
comparison yields $Q_{u,v}\left(  x_{1},x_{2},...,x_{n}\right)  =0$. Since
this holds for all $\left(  x_{1},x_{2},...,x_{n}\right)  \in\mathbb{C}^{n}$,
we thus obtain $Q_{u,v}=0$ (because any polynomial which vanishes on the whole
$\mathbb{C}^{n}$ must be the zero polynomial). This proves
(\ref{pf.invformnondeg.elemen.4}).

Now, (\ref{pf.invformnondeg.elemen.3a}) rewrites as%
\begin{align*}
P  &  =\sum\limits_{i\in\mathbb{N}}\sum\limits_{j\in\mathbb{N}}Q_{i,j}%
X_{n+1}^{i}=\sum\limits_{u\in\mathbb{N}}\sum\limits_{v\in\mathbb{N}}%
Q_{u,v}X_{n+1}^{u}\ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed the
indices }i\text{ and }j\text{ as }u\text{ and }v\right) \\
&  =\sum\limits_{\left(  u,v\right)  \in\mathbb{N}\times\mathbb{N}}%
Q_{u,v}X_{n+1}^{u}=\sum\limits_{\substack{\left(  u,v\right)  \in
\mathbb{N}\times\mathbb{N};\\u+2v=2k}}Q_{u,v}X_{n+1}^{u}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we removed from our sum all terms for }\left(  u,v\right)
\in\mathbb{N}\times\mathbb{N}\text{ which}\\
\text{don't satisfy }u+2v=2k\text{ (because (\ref{pf.invformnondeg.elemen.4})
shows that these terms}\\
\text{don't contribute anything to the sum)}%
\end{array}
\right) \\
&  =\sum\limits_{v=0}^{k}Q_{2k-2v,v}X_{n+1}^{2k-2v}\ \ \ \ \ \ \ \ \ \ \left(
\text{here, we substituted }\left(  2k-2v,v\right)  \text{ for }\left(
u,v\right)  \text{ in the sum}\right)  .
\end{align*}


Now, for every $v\in\left\{  0,1,...,k\right\}  $, let $\psi_{v}%
:V\rightarrow\mathbb{C}$ be the polynomial map defined by%
\[
\psi_{v}\left(  \lambda\right)  =Q_{2k-2v,v}\left(  v_{1}\left(
\lambda\right)  ,v_{2}\left(  \lambda\right)  ,...,v_{n}\left(  \lambda
\right)  \right)  \ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in V.
\]
Then, $\psi_{v}$ is homogeneous of degree $v$ (since $Q_{2k-2v,v}$ is
homogeneous of degree $v$). In particular, this yields that $\psi_{k}$ is
homogeneous of degree $k$.

Every $\left(  \lambda,\varepsilon\right)  \in V\times\mathbb{C}$ satisfies%
\begin{align}
\phi\left(  \lambda,\varepsilon\right)   &  =P\left(  v_{1}\left(
\lambda\right)  ,v_{2}\left(  \lambda\right)  ,...,v_{n}\left(  \lambda
\right)  ,\varepsilon\right) \nonumber\\
&  =\sum\limits_{v=0}^{k}\underbrace{Q_{2k-2v,v}\left(  v_{1}\left(
\lambda\right)  ,v_{2}\left(  \lambda\right)  ,...,v_{n}\left(  \lambda
\right)  \right)  }_{=\psi_{v}\left(  \lambda\right)  }\varepsilon
^{2k-2v}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }P=\sum\limits_{v=0}%
^{k}Q_{2k-2v,v}X_{n+1}^{2k-2v}\right) \nonumber\\
&  =\sum\limits_{v=0}^{k}\psi_{v}\left(  \lambda\right)  \varepsilon^{2k-2v}.
\label{pf.invformnondeg.elemen.10}%
\end{align}
Applied to $\varepsilon=0$, this yields%
\[
\phi\left(  \lambda,0\right)  =\sum\limits_{v=0}^{k}\psi_{v}\left(
\lambda\right)  0^{2k-2v}=\psi_{k}\left(  \lambda\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }0^{2k-2v}=0\text{ for all
}v<k\right)
\]
for every $\lambda\in V$. Hence, the polynomial function $V\rightarrow
\mathbb{C},\ \lambda\mapsto\phi\left(  \lambda,0\right)  $ equals the
polynomial function $\psi_{k}$, and thus is homogeneous of degree $k$ (since
$\psi_{k}$ is homogeneous of degree $k$). This proves Lemma
\ref{lem.invformnondeg.elemen} \textbf{(a)}.

Applying (\ref{pf.invformnondeg.elemen.10}) to $\varepsilon=1$, we obtain%
\[
\phi\left(  \lambda,1\right)  =\sum\limits_{v=0}^{k}\psi_{v}\left(
\lambda\right)  \underbrace{1^{2k-2v}}_{=1}=\sum\limits_{v=0}^{k}\psi
_{v}\left(  \lambda\right)  .
\]
Hence, the polynomial function $V\rightarrow\mathbb{C},\ \lambda\mapsto
\phi\left(  \lambda,1\right)  $ equals the sum $\sum\limits_{v=0}^{k}\psi_{v}%
$. Since we know that the polynomial function $\psi_{v}$ is homogeneous of
degree $v$ for every $v\in\left\{  0,1,...,k\right\}  $, this yields that, for
every integer $N>k$, the $N$-th homogeneous component of the polynomial
function $V\rightarrow\mathbb{C},\ \lambda\mapsto\phi\left(  \lambda,1\right)
$ is zero. This proves Lemma \ref{lem.invformnondeg.elemen} \textbf{(b)}.

Finally, recall that the polynomial function $V\rightarrow\mathbb{C}%
,\ \lambda\mapsto\phi\left(  \lambda,1\right)  $ equals the sum $\sum
\limits_{v=0}^{k}\psi_{v}$, and the polynomial function $\psi_{v}$ is
homogeneous of degree $v$ for every $v\in\left\{  0,1,...,k\right\}  $. Hence,
for every $v\in\left\{  0,1,...,k\right\}  $, the $v$-th homogeneous component
of the polynomial function $V\rightarrow\mathbb{C},\ \lambda\mapsto\phi\left(
\lambda,1\right)  $ is $\psi_{v}$. In particular, the $k$-th homogeneous
component of the polynomial function $V\rightarrow\mathbb{C},\ \lambda
\mapsto\phi\left(  \lambda,1\right)  $ is $\psi_{k}$. Since $\psi_{k}$ equals
the function $V\rightarrow\mathbb{C},\ \lambda\mapsto\phi\left(
\lambda,0\right)  $, this rewrites as follows: The $k$-th homogeneous
component of the polynomial function $V\rightarrow\mathbb{C},\ \lambda
\mapsto\phi\left(  \lambda,1\right)  $ is the function $V\rightarrow
\mathbb{C},\ \lambda\mapsto\phi\left(  \lambda,0\right)  $. This proves Lemma
\ref{lem.invformnondeg.elemen} \textbf{(c)}.

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: The Lie algebra
\texorpdfstring{$\mathfrak{g}^{0}$}{g superscript 0}}

Consider the polynomial function $Q_{n}$ of Corollary
\ref{cor.invformnondeg.polynomiality}. Due to Corollary
\ref{cor.invformnondeg.polynomiality}, it satisfies the condition of Lemma
\ref{lem.invformnondeg.elemen} for $k=\operatorname*{LEN}n$. Hence, Lemma
\ref{lem.invformnondeg.elemen} suggests that we study the Lie algebra
$\mathfrak{g}^{0}$, since this will show us what the function $\mathfrak{h}%
^{\ast}\rightarrow\mathbb{C},$ $\lambda\mapsto Q_{n}\left(  \lambda,0\right)
$ looks like.

First, let us reformulate the definition of $\mathfrak{g}^{0}$ as follows: As
a vector space, $\mathfrak{g}^{0}=\mathfrak{g}$, but the bracket on
$\mathfrak{g}^{0}$ is given by%
\begin{equation}
\left[  \cdot,\cdot\right]  ^{0}:\mathfrak{g}_{i}\otimes\mathfrak{g}%
_{j}\rightarrow\mathfrak{g}_{i+j}\text{ }\text{is }\left\{
\begin{array}
[c]{c}%
\text{zero if }i+j\neq0\text{;}\\
\text{the Lie bracket }\left[  \cdot,\cdot\right]  \text{ of }\mathfrak{g}%
\text{ if }i+j=0
\end{array}
\right.  . \label{prop.det.US.pf.-1}%
\end{equation}


It is very easy to see (from this) that $\left[  \mathfrak{n}_{-}%
,\mathfrak{n}_{-}\right]  ^{0}=0$, $\left[  \mathfrak{n}_{+},\mathfrak{n}%
_{+}\right]  ^{0}=0$, $\left[  \mathfrak{n}_{-},\mathfrak{n}_{+}\right]
^{0}=\left[  \mathfrak{n}_{+},\mathfrak{n}_{-}\right]  ^{0}\subseteq
\mathfrak{h}$ and that $\mathfrak{h}\subseteq Z\left(  \mathfrak{g}%
^{0}\right)  $.

We notice that $\mathfrak{n}_{-}^{0}=\mathfrak{n}_{-}$, $\mathfrak{n}_{+}%
^{0}=\mathfrak{n}_{+}$ and $\mathfrak{h}^{0}=\mathfrak{h}$ as vector spaces.

Since $\left[  \mathfrak{n}_{-}^{0},\mathfrak{n}_{-}^{0}\right]  ^{0}=\left[
\mathfrak{n}_{-},\mathfrak{n}_{-}\right]  ^{0}=0$, the Lie algebra
$\mathfrak{n}_{-}^{0}$ is abelian, so that $U\left(  \mathfrak{n}_{-}%
^{0}\right)  =S\left(  \mathfrak{n}_{-}^{0}\right)  =S\left(  \mathfrak{n}%
_{-}\right)  $. Similarly, $U\left(  \mathfrak{n}_{+}^{0}\right)  =S\left(
\mathfrak{n}_{+}^{0}\right)  =S\left(  \mathfrak{n}_{+}\right)  $.

We notice that%
\begin{equation}
\lambda\left(  \left[  x,y\right]  ^{0}\right)  =\lambda\left(  \left[
x,y\right]  \right)  \ \ \ \ \ \ \ \ \ \ \text{for any }x\in\mathfrak{g}\text{
and }y\in\mathfrak{g}. \label{prop.det.US.pf.0}%
\end{equation}
\footnote{\textit{Proof of (\ref{prop.det.US.pf.0}).} Let $x\in\mathfrak{g}$
and $y\in\mathfrak{g}$. Since the equation (\ref{prop.det.US.pf.0}) is linear
in each of $x$ and $y$, we can WLOG assume that $x$ and $y$ are homogeneous
(since every element of $\mathfrak{g}$ is a sum of homogeneous elements). So
we can assume that $x\in\mathfrak{g}_{i}$ and $y\in\mathfrak{g}_{j}$ for some
$i\in\mathbb{N}$ and $j\in\mathbb{N}$. Consider these $i$ and $j$. If
$i+j\neq0$, then $\left[  x,y\right]  ^{0}=0$ (by (\ref{prop.det.US.pf.-1}))
and $\lambda\left(  \left[  x,y\right]  \right)  =0$ (since $x\in
\mathfrak{g}_{i}$ and $y\in\mathfrak{g}_{j}$ yield $\left[  x,y\right]
\in\mathfrak{g}_{i+j}$, and due to $i+j\neq0$ the form $\lambda$ annihilates
$\mathfrak{g}_{i+j}$), so that (\ref{prop.det.US.pf.0}) trivially holds in
this case. If $i+j=0$, then $\left[  x,y\right]  ^{0}=\left[  x,y\right]  $
(again by (\ref{prop.det.US.pf.-1})), and thus (\ref{prop.det.US.pf.0}) holds
in this case as well. We have thus proven (\ref{prop.det.US.pf.0}) both in the
case $i+j\neq0$ and in the case $i+j=0$. These cases cover all possibilities,
and thus (\ref{prop.det.US.pf.0}) is proven.}

In the following, we will use the form $\left(  \cdot,\cdot\right)  _{\lambda
}^{\circ}$ defined in Definition \ref{def.lambda_k}. We will only consider
this form for the Lie algebra $\mathfrak{g}$, not for the Lie algebras
$\mathfrak{g}^{\varepsilon}$ and $\mathfrak{g}^{0}$; thus we don't have any
reason to rename it as $\left(  \cdot,\cdot\right)  _{\lambda}^{\circ
\mathfrak{g}}$.

\begin{lemma}
\label{lem.invform.g^0.1}We have%
\begin{equation}
\left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda}^{-\mathfrak{g}^{0}%
}\right)  _{\lambda}^{\mathfrak{g}^{0}}=\left(  a,b\right)  _{\lambda}^{\circ
}\ \ \ \ \ \ \ \ \ \ \text{for all }a\in S\left(  \mathfrak{n}_{-}\right)
\text{ and }b\in S\left(  \mathfrak{n}_{+}\right)  . \label{prop.det.US.pf.1}%
\end{equation}
Here, $av_{\lambda}^{+\mathfrak{g}^{0}}$ and $bv_{-\lambda}^{-\mathfrak{g}%
^{0}}$ are elements of $M_{\lambda}^{+\mathfrak{g}^{0}}$ and $M_{-\lambda
}^{-\mathfrak{g}^{0}}$, respectively (because $a\in S\left(  \mathfrak{n}%
_{-}\right)  =U\left(  \mathfrak{n}_{-}^{0}\right)  $ and $b\in S\left(
\mathfrak{n}_{+}\right)  =U\left(  \mathfrak{n}_{+}^{0}\right)  $).
\end{lemma}

\textit{Proof of Lemma \ref{lem.invform.g^0.1}.} Let $a\in S\left(
\mathfrak{n}_{-}\right)  $ and $b\in S\left(  \mathfrak{n}_{+}\right)  $ be
arbitrary. Since the claim that $\left(  av_{\lambda}^{+\mathfrak{g}^{0}%
},bv_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}%
}=\left(  a,b\right)  _{\lambda}^{\circ}$ is linear in each of $a$ and $b$, we
can WLOG assume that $a=a_{1}a_{2}...a_{u}$ for some homogeneous $a_{1}%
,a_{2},...,a_{u}\in\mathfrak{n}_{-}$ and that $b=b_{1}b_{2}...b_{v}$ for some
homogeneous $b_{1},b_{2},...,b_{v}\in\mathfrak{n}_{+}$ (because every element
of $S\left(  \mathfrak{n}_{-}\right)  $ is a $\mathbb{C}$-linear combination
of products of the form $a_{1}a_{2}...a_{u}$ with homogeneous $a_{1}%
,a_{2},...,a_{u}\in\mathfrak{n}_{-}$, and because every element of $S\left(
\mathfrak{n}_{+}\right)  $ is a $\mathbb{C}$-linear combination of products of
the form $b_{1}b_{2}...b_{v}$ with homogeneous $b_{1},b_{2},...,b_{v}%
\in\mathfrak{n}_{+}$).

WLOG assume that $v\geq u$. (Else, the proof is analogous.)

Recall the equality $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)
=\left(  S\left(  b\right)  av_{\lambda}^{+},v_{-\lambda}^{-}\right)  $ shown
during the proof of Proposition \ref{prop.invform}. Applied to $\mathfrak{g}%
^{0}$ instead of $\mathfrak{g}$, this yields $\left(  av_{\lambda
}^{+\mathfrak{g}^{0}},bv_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda
}^{\mathfrak{g}^{0}}=\left(  S\left(  b\right)  av_{\lambda}^{+\mathfrak{g}%
^{0}},v_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}$.

Since $\mathfrak{h}\subseteq Z\left(  \mathfrak{g}^{0}\right)  $, we have
$\mathfrak{h}\subseteq Z\left(  U\left(  \mathfrak{g}^{0}\right)  \right)  $
(because the center of a Lie algebra always lies in the center of its
universal enveloping algebra).

Since $b=b_{1}b_{2}...b_{v}$, we have $S\left(  b\right)  =\left(  -1\right)
^{v}b_{v}b_{v-1}...b_{1}$. Combined with $a=a_{1}a_{2}...a_{u}$, this yields%
\[
S\left(  b\right)  a=\left(  -1\right)  ^{v}b_{v}b_{v-1}...b_{1}a_{1}%
a_{2}...a_{u},
\]
so that%
\begin{equation}
\left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda}^{-\mathfrak{g}^{0}%
}\right)  _{\lambda}^{\mathfrak{g}^{0}}=\left(  \underbrace{S\left(  b\right)
a}_{=\left(  -1\right)  ^{v}b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}}v_{\lambda
}^{+\mathfrak{g}^{0}},v_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda
}^{\mathfrak{g}^{0}}=\left(  -1\right)  ^{v}\left(  b_{v}b_{v-1}...b_{1}%
a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}},v_{-\lambda}^{-\mathfrak{g}%
^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}. \label{prop.det.US.pf.4}%
\end{equation}


We will now prove some identities in order to simplify the $b_{v}%
b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}$ term here.

First: In the Verma highest-weight module $M_{\lambda}^{+\mathfrak{g}^{0}}$ of
$\left(  \mathfrak{g}^{0},\lambda\right)  $, we have%
\begin{align}
\beta\alpha_{1}\alpha_{2}...\alpha_{\ell}v_{\lambda}^{+\mathfrak{g}^{0}}  &
=\sum\limits_{p=1}^{\ell}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}%
...\alpha_{\ell}v_{\lambda}^{+\mathfrak{g}^{0}}\label{prop.det.US.pf.3}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\ell\in\mathbb{N}\text{, }\alpha
_{1},\alpha_{2},...,\alpha_{\ell}\in\mathfrak{n}_{-}\text{ and }\beta
\in\mathfrak{n}_{+}\text{.}\nonumber
\end{align}
\footnote{\textit{Proof of (\ref{prop.det.US.pf.3}).} We will prove
(\ref{prop.det.US.pf.3}) by induction over $\ell$:
\par
\textit{Induction base:} For $\ell=0$, the left hand side of
(\ref{prop.det.US.pf.3}) is $\beta v_{\lambda}^{+\mathfrak{g}^{0}}=0$ (since
$\beta\in\mathfrak{n}_{+}=\mathfrak{n}_{+}^{0}$), and the right hand side of
(\ref{prop.det.US.pf.3}) is $\left(  \text{empty sum}\right)  =0$. Thus, for
$\ell=0$, the equality (\ref{prop.det.US.pf.3}) holds. This completes the
induction base.
\par
\textit{Induction step:} Let $m\in\mathbb{N}$ be positive. Assume that
(\ref{prop.det.US.pf.3}) holds for $\ell=m-1$. We now must show that
(\ref{prop.det.US.pf.3}) holds for $\ell=m$.
\par
Let $\alpha_{1},\alpha_{2},...,\alpha_{m}\in\mathfrak{n}_{-}$ and $\beta
\in\mathfrak{n}_{+}$.
\par
Since (\ref{prop.det.US.pf.3}) holds for $\ell=m-1$, we can apply
(\ref{prop.det.US.pf.3}) to $m-1$ and $\left(  \alpha_{2},\alpha
_{3},...,\alpha_{m}\right)  $ instead of $\ell$ and $\left(  \alpha_{1}%
,\alpha_{2},...,\alpha_{\ell}\right)  $, and thus obtain%
\begin{align*}
\beta\alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}  &
=\sum\limits_{p=1}^{m-1}\lambda\left(  \left[  \beta,\alpha_{p+1}\right]
\right)  \alpha_{2}\alpha_{3}...\alpha_{p-1+1}\alpha_{p+1+1}\alpha
_{p+2+1}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\sum\limits_{p=2}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}%
...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }p\text{ for
}p+1\text{ in the sum}\right)  .
\end{align*}
\par
Now, we notice that $\beta\in\mathfrak{n}_{+}$ and $\alpha_{1}\in
\mathfrak{n}_{-}$, so that $\left[  \beta,\alpha_{1}\right]  ^{0}\in\left[
\mathfrak{n}_{+},\mathfrak{n}_{-}\right]  ^{0}\subseteq\mathfrak{h}\subseteq
Z\left(  U\left(  \mathfrak{g}^{0}\right)  \right)  $. Thus, $\left[
\beta,\alpha_{1}\right]  ^{0}\alpha_{2}\alpha_{3}...\alpha_{m}=\alpha
_{2}\alpha_{3}...\alpha_{m}\left[  \beta,\alpha_{1}\right]  ^{0}$. But since
$\left[  \beta,\alpha_{1}\right]  ^{0}\in\mathfrak{h}=\mathfrak{h}^{0}$, we
also have $\left[  \beta,\alpha_{1}\right]  ^{0}v_{\lambda}^{+\mathfrak{g}%
^{0}}=\lambda\left(  \left[  \beta,\alpha_{1}\right]  ^{0}\right)  v_{\lambda
}^{+\mathfrak{g}^{0}}=\lambda\left(  \left[  \beta,\alpha_{1}\right]  \right)
v_{\lambda}^{+\mathfrak{g}^{0}}$ (since $\lambda\left(  \left[  \beta
,\alpha_{1}\right]  ^{0}\right)  =\lambda\left(  \left[  \beta,\alpha
_{1}\right]  \right)  $ by (\ref{prop.det.US.pf.0})).
\par
We now compute:
\begin{align*}
\beta\alpha_{1}\alpha_{2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}  &
=\underbrace{\beta\alpha_{1}}_{\substack{=\alpha_{1}\beta+\left[  \beta
,\alpha_{1}\right]  ^{0}\\\text{(since we are in }U\left(  \mathfrak{g}%
^{0}\right)  \text{)}}}\alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda
}^{+\mathfrak{g}^{0}}=\left(  \alpha_{1}\beta+\left[  \beta,\alpha_{1}\right]
^{0}\right)  \alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}%
}\\
&  =\alpha_{1}\underbrace{\beta\alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda
}^{+\mathfrak{g}^{0}}}_{\substack{=\sum\limits_{p=2}^{m}\lambda\left(  \left[
\beta,\alpha_{p}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{p-1}%
\alpha_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}%
}}+\underbrace{\left[  \beta,\alpha_{1}\right]  ^{0}\alpha_{2}\alpha
_{3}...\alpha_{m}}_{\substack{=\alpha_{2}\alpha_{3}...\alpha_{m}\left[
\beta,\alpha_{1}\right]  ^{0}}}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\underbrace{\alpha_{1}\sum\limits_{p=2}^{m}\lambda\left(  \left[
\beta,\alpha_{p}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{p-1}%
\alpha_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}}%
_{=\sum\limits_{p=2}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha
_{p+2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}}+\alpha_{2}\alpha
_{3}...\alpha_{m}\underbrace{\left[  \beta,\alpha_{1}\right]  ^{0}v_{\lambda
}^{+\mathfrak{g}^{0}}}_{\substack{=\lambda\left(  \left[  \beta,\alpha
_{1}\right]  \right)  v_{\lambda}^{+\mathfrak{g}^{0}}}}\\
&  =\sum\limits_{p=2}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha
_{p+2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}+\lambda\left(  \left[
\beta,\alpha_{1}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda
}^{+\mathfrak{g}^{0}}\\
&  =\sum\limits_{p=1}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha
_{p+2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\sum\limits_{p=1}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}%
...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}.
\end{align*}
Thus, (\ref{prop.det.US.pf.3}) holds for $\ell=m$. This completes the
induction step. Thus, (\ref{prop.det.US.pf.3}) is proven.}

Next we will show that in the Verma highest-weight module $M_{\lambda
}^{+\mathfrak{g}^{0}}$ of $\left(  \mathfrak{g}^{0},\lambda\right)  $, we have%
\begin{align}
\beta_{\ell}\beta_{\ell-1}...\beta_{1}\alpha_{1}\alpha_{2}...\alpha_{\ell
}v_{\lambda}^{+\mathfrak{g}^{0}}  &  =\left(  -1\right)  ^{\ell}%
\sum\limits_{\sigma\in S_{\ell}}\lambda\left(  \left[  \alpha_{1}%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{\ell},\beta_{\sigma\left(  \ell\right)  }\right]  \right)
v_{\lambda}^{+\mathfrak{g}^{0}}\label{prop.det.US.pf.2}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\ell\in\mathbb{N}\text{, }\alpha
_{1},\alpha_{2},...,\alpha_{\ell}\in\mathfrak{n}_{-}\text{ and }\beta
_{1},\beta_{2},...,\beta_{\ell}\in\mathfrak{n}_{+}\text{.}\nonumber
\end{align}


\textit{Proof of (\ref{prop.det.US.pf.2}).} We will prove
(\ref{prop.det.US.pf.2}) by induction over $\ell$:

\textit{Induction base:} For $\ell=0$, we have $\underbrace{\beta_{\ell}%
\beta_{\ell-1}...\beta_{1}}_{\text{empty product}}\underbrace{\alpha_{1}%
\alpha_{2}...\alpha_{\ell}}_{\text{empty product}}v_{\lambda}^{+\mathfrak{g}%
^{0}}=v_{\lambda}^{+\mathfrak{g}^{0}}$ and \newline$\underbrace{\left(
-1\right)  ^{\ell}}_{=1}\underbrace{\sum\limits_{\sigma\in S_{\ell}}%
}_{\text{sum over }1\text{ element}}\underbrace{\lambda\left(  \left[
\alpha_{1},\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(
\left[  \alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)
...\lambda\left(  \left[  \alpha_{\ell},\beta_{\sigma\left(  \ell\right)
}\right]  \right)  }_{\text{empty product}}v_{\lambda}^{+\mathfrak{g}^{0}%
}=v_{\lambda}^{+\mathfrak{g}^{0}}$. Thus, for $\ell=0$, the equality
(\ref{prop.det.US.pf.2}) holds. This completes the induction base.

\textit{Induction step:} Let $m\in\mathbb{N}$ be positive. Assume that
(\ref{prop.det.US.pf.2}) holds for $\ell=m-1$. We now must show that
(\ref{prop.det.US.pf.2}) holds for $\ell=m$.

Let $\alpha_{1},\alpha_{2},...,\alpha_{m}\in\mathfrak{n}_{-}$ and $\beta
_{1},\beta_{2},...,\beta_{m}\in\mathfrak{n}_{+}$.

For every $p\in\left\{  1,2,...,m\right\}  $, let $c_{p}$ denote the
permutation in $S_{m}$ which is written in row form as $\left(
1,2,...,p-1,p+1,p+2,...,m,p\right)  $. (This is the permutation with cycle
decomposition $\left(  1\right)  \left(  2\right)  ...\left(  p-1\right)
\left(  p,p+1,...,m\right)  $.) Since (\ref{prop.det.US.pf.2}) holds for
$\ell=m-1$, we can apply (\ref{prop.det.US.pf.2}) to $m-1$ and $\left(
\alpha_{c_{p}\left(  1\right)  },\alpha_{c_{p}\left(  2\right)  }%
,...,\alpha_{c_{p}\left(  m-1\right)  }\right)  $ instead of $\ell$ and
$\left(  \alpha_{1},\alpha_{2},...,\alpha_{\ell}\right)  $. This results in%
\begin{align*}
&  \beta_{m-1}\beta_{m-2}...\beta_{1}\alpha_{c_{p}\left(  1\right)  }%
\alpha_{c_{p}\left(  2\right)  }...\alpha_{c_{p}\left(  m-1\right)
}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m-1}}%
\underbrace{\lambda\left(  \left[  \alpha_{c_{p}\left(  1\right)  }%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{c_{p}\left(  2\right)  },\beta_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  \alpha_{c_{p}\left(  m-1\right)  }%
,\beta_{\sigma\left(  m-1\right)  }\right]  \right)  }_{\substack{=\prod
\limits_{i\in\left\{  1,2,...,m-1\right\}  }\lambda\left(  \left[
\alpha_{c_{p}\left(  i\right)  },\beta_{\sigma\left(  i\right)  }\right]
\right)  =\prod\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{
p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  c_{p}%
^{-1}\left(  i\right)  \right)  }\right]  \right)  \\\text{(here, we
substituted }i\text{ for }c_{p}\left(  i\right)  \text{ in the product)}%
}}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m-1}}\prod
\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }%
\lambda\left(  \left[  \alpha_{i},\underbrace{\beta_{\sigma\left(  c_{p}%
^{-1}\left(  i\right)  \right)  }}_{=\beta_{\left(  \sigma\circ c_{p}%
^{-1}\right)  \left(  i\right)  }}\right]  \right)  v_{\lambda}^{+\mathfrak{g}%
^{0}}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m-1}}\prod
\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }%
\lambda\left(  \left[  \alpha_{i},\beta_{\left(  \sigma\circ c_{p}%
^{-1}\right)  \left(  i\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}%
^{0}}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m};\ \sigma\left(
m\right)  =m}\prod\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{
p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta_{\left(  \sigma\circ
c_{p}^{-1}\right)  \left(  i\right)  }\right]  \right)  v_{\lambda
}^{+\mathfrak{g}^{0}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we identified the permutations in }S_{m-1}\text{ with the
permutations}\\
\sigma\in S_{m}\text{ satisfying }\sigma\left(  m\right)  =m
\end{array}
\right) \\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m};\ \sigma\left(
p\right)  =m}\prod\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{
p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  i\right)
}\right]  \right)  v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }\sigma\text{ for
}\sigma\circ c_{p}^{-1}\text{ in the sum}\right)  .
\end{align*}


The elements $\beta_{m}$, $\beta_{m-1}$, $...$, $\beta_{1}$ all lie in
$\mathfrak{n}_{+}$ and thus commute in $U\left(  \mathfrak{g}^{0}\right)  $
(since $\left[  \mathfrak{n}_{+},\mathfrak{n}_{+}\right]  ^{0}=0$). Thus,
$\beta_{m}\beta_{m-1}...\beta_{1}=\beta_{m-1}\beta_{m-2}...\beta_{1}\beta_{m}$
in $U\left(  \mathfrak{g}^{0}\right)  $, so that%
\begin{align*}
&  \beta_{m}\beta_{m-1}...\beta_{1}\alpha_{1}\alpha_{2}...\alpha_{m}%
v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\beta_{m-1}\beta_{m-2}...\beta_{1}\underbrace{\beta_{m}\alpha_{1}%
\alpha_{2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}^{0}}}_{\substack{=\sum
\limits_{p=1}^{m}\lambda\left(  \left[  \beta_{m},\alpha_{p}\right]  \right)
\alpha_{1}\alpha_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha
_{m}v_{\lambda}^{+\mathfrak{g}^{0}}\\\text{(by (\ref{prop.det.US.pf.3}),
applied to }\beta=\beta_{m}\text{ and }\ell=m\text{)}}}\\
&  =\beta_{m-1}\beta_{m-2}...\beta_{1}\sum\limits_{p=1}^{m}\lambda\left(
\left[  \beta_{m},\alpha_{p}\right]  \right)  \alpha_{1}\alpha_{2}%
...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda}^{+\mathfrak{g}%
^{0}}\\
&  =\sum\limits_{p=1}^{m}\underbrace{\lambda\left(  \left[  \beta_{m}%
,\alpha_{p}\right]  \right)  }_{=\lambda\left(  -\left[  \alpha_{p},\beta
_{m}\right]  \right)  =-\lambda\left(  \left[  \alpha_{p},\beta_{m}\right]
\right)  }\beta_{m-1}\beta_{m-2}...\beta_{1}\underbrace{\alpha_{1}\alpha
_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha_{m}}_{\substack{=\alpha
_{c_{p}\left(  1\right)  }\alpha_{c_{p}\left(  2\right)  }...\alpha
_{c_{p}\left(  m-1\right)  }\\\text{(by the definition of }c_{p}\text{)}%
}}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =-\sum\limits_{p=1}^{m}\lambda\left(  \left[  \alpha_{p},\beta_{m}\right]
\right)  \underbrace{\beta_{m-1}\beta_{m-2}...\beta_{1}\alpha_{c_{p}\left(
1\right)  }\alpha_{c_{p}\left(  2\right)  }...\alpha_{c_{p}\left(  m-1\right)
}v_{\lambda}^{+\mathfrak{g}^{0}}}_{=\left(  -1\right)  ^{m-1}\sum
\limits_{\sigma\in S_{m};\ \sigma\left(  p\right)  =m}\prod\limits_{i\in
\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }\lambda\left(
\left[  \alpha_{i},\beta_{\sigma\left(  i\right)  }\right]  \right)
v_{\lambda}^{+\mathfrak{g}^{0}}}\\
&  =\underbrace{-\left(  -1\right)  ^{m-1}}_{=\left(  -1\right)  ^{m}}%
\sum\limits_{p=1}^{m}\sum\limits_{\sigma\in S_{m};\ \sigma\left(  p\right)
=m}\lambda\left(  \left[  \alpha_{p},\underbrace{\beta_{m}}_{\substack{=\beta
_{\sigma\left(  p\right)  }\\\text{(since }\sigma\left(  p\right)  =m\text{)}%
}}\right]  \right)  \prod\limits_{i\in\left\{  1,2,...,m\right\}
\diagdown\left\{  p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta
_{\sigma\left(  i\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{m}\sum\limits_{p=1}^{m}\sum\limits_{\sigma\in
S_{m};\ \sigma\left(  p\right)  =m}\underbrace{\lambda\left(  \left[
\alpha_{p},\beta_{\sigma\left(  p\right)  }\right]  \right)  \prod
\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }%
\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  i\right)  }\right]
\right)  }_{\substack{=\prod\limits_{i\in\left\{  1,2,...,m\right\}  }%
\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  i\right)  }\right]
\right)  \\=\lambda\left(  \left[  \alpha_{1},\beta_{\sigma\left(  1\right)
}\right]  \right)  \lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  \alpha_{m}%
,\beta_{\sigma\left(  m\right)  }\right]  \right)  }}v_{\lambda}%
^{+\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{m}\underbrace{\sum\limits_{p=1}^{m}\sum
\limits_{\sigma\in S_{m};\ \sigma\left(  p\right)  =m}}_{=\sum\limits_{\sigma
\in S_{m}}}\lambda\left(  \left[  \alpha_{1},\beta_{\sigma\left(  1\right)
}\right]  \right)  \lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  \alpha_{m}%
,\beta_{\sigma\left(  m\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}%
^{0}}\\
&  =\left(  -1\right)  ^{m}\sum\limits_{\sigma\in S_{m}}\lambda\left(  \left[
\alpha_{1},\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(
\left[  \alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)
...\lambda\left(  \left[  \alpha_{m},\beta_{\sigma\left(  m\right)  }\right]
\right)  v_{\lambda}^{+\mathfrak{g}^{0}}.
\end{align*}
In other words, (\ref{prop.det.US.pf.2}) is proven for $\ell=m$. This
completes the induction step. Thus, the induction proof of
(\ref{prop.det.US.pf.2}) is done.

Now, back to proving $\left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda
}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}=\left(
a,b\right)  _{\lambda}^{\circ}$. Applying (\ref{prop.det.US.pf.2}) to $\ell
=u$, $\alpha_{i}=a_{i}$ and $\beta_{i}=b_{i}$, we obtain%
\[
b_{u}b_{u-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}= \left(
-1\right) ^{u} \sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[
a_{1},b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}%
^{0}}.
\]
Hence, if $v>u$, then%
\begin{align*}
&  b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =b_{v}b_{v-1}...b_{u+2}b_{u+1}\underbrace{b_{u}b_{u-1}...b_{1}a_{1}%
a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}}_{=\left(  -1\right)  ^{u}%
\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}^{0}}}\\
&  =b_{v}b_{v-1}...b_{u+2}b_{u+1}\left(  -1\right)  ^{u}\sum\limits_{\sigma\in
S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]
\right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]
\right)  v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[
a_{1},b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right)  b_{v}b_{v-1}%
...b_{u+2}\underbrace{b_{u+1}v_{\lambda}^{+\mathfrak{g}^{0}}}%
_{\substack{=0\\\text{(since }b_{u+1}\in\mathfrak{n}_{+}=\mathfrak{n}_{+}%
^{0}\text{)}}}\\
&  =0,
\end{align*}
and thus%
\begin{align*}
&  \left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda}^{-\mathfrak{g}^{0}%
}\right)  _{\lambda}^{\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{v}\left(  \underbrace{b_{v}b_{v-1}...b_{1}a_{1}%
a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}}_{=0},v_{-\lambda}^{-\mathfrak{g}%
^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}\ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{prop.det.US.pf.4})}\right) \\
&  =0=\left(  a,b\right)  _{\lambda}^{\circ}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because the form }\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}\text{
was defined as a restriction of a sum}\\
\bigoplus\limits_{k\geq0}\lambda_{k}:S\left(  \mathfrak{n}_{-}\right)  \times
S\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}\text{ of bilinear
forms }\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)  \times S^{k}\left(
\mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}\text{,}\\
\text{and thus }\left(  S^{u}\left(  \mathfrak{n}_{-}\right)  ,S^{v}\left(
\mathfrak{n}_{+}\right)  \right)  _{\lambda}^{\circ}=0\text{ for }u\neq
v\text{, so that }\left(  a,b\right)  _{\lambda}^{\circ}=0\\
\text{(since }a\in S^{u}\left(  \mathfrak{n}_{-}\right)  \text{ and }b\in
S^{v}\left(  \mathfrak{n}_{+}\right)  \text{ and }u\neq v\text{)}%
\end{array}
\right)  .
\end{align*}
We thus have proven $\left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda
}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}=\left(
a,b\right)  _{\lambda}^{\circ}$ in the case when $v>u$. It remains to prove
that $\left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda}^{-\mathfrak{g}%
^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}=\left(  a,b\right)  _{\lambda
}^{\circ}$ in the case when $v=u$. So let us assume that $v=u$. In this case,%
\begin{align*}
b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}  &
=b_{u}b_{u-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[
a_{1},b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}%
^{0}},
\end{align*}
so that%
\begin{align*}
&  \left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda}^{-\mathfrak{g}^{0}%
}\right)  _{\lambda}^{\mathfrak{g}^{0}}\\
&  =\underbrace{\left(  -1\right)  ^{v}}_{\substack{=\left(  -1\right)
^{u}\\\text{(since }v=u\text{)}}}\left(  \underbrace{b_{v}b_{v-1}...b_{1}%
a_{1}a_{2}...a_{u}v_{\lambda}^{+\mathfrak{g}^{0}}}_{=\left(  -1\right)
^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  v_{\lambda}^{+\mathfrak{g}^{0}}},v_{-\lambda
}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}\\
&  =\left(  -1\right)  ^{u}\left(  \left(  -1\right)  ^{u}\sum\limits_{\sigma
\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]
\right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]
\right)  v_{\lambda}^{+\mathfrak{g}^{0}},v_{-\lambda}^{-\mathfrak{g}^{0}%
}\right)  _{\lambda}^{\mathfrak{g}^{0}}\\
&  =\underbrace{\left(  -1\right)  ^{u}\left(  -1\right)  ^{u}}%
_{\substack{=\left(  -1\right)  ^{u+u}=\left(  -1\right)  ^{2u}%
=1\\\text{(since }2u\text{ is even)}}}\sum\limits_{\sigma\in S_{u}}%
\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]  \right)
\lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]  \right)
...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]  \right)
\underbrace{\left(  v_{\lambda}^{+\mathfrak{g}^{0}},v_{-\lambda}%
^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}}_{=1}\\
&  =\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  .
\end{align*}
Compared to%
\begin{align*}
\left(  \underbrace{a}_{=a_{1}a_{2}...a_{u}},\underbrace{b}_{\substack{=b_{1}%
b_{2}...b_{v}=b_{1}b_{2}...b_{u}\\\text{(since }v=u\text{)}}}\right)
_{\lambda}^{\circ}  &  =\left(  a_{1}a_{2}...a_{u},b_{1}b_{2}...b_{u}\right)
_{\lambda}^{\circ}=\lambda_{u}\left(  a_{1}a_{2}...a_{u},b_{1}b_{2}%
...b_{u}\right) \\
&  =\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  ,
\end{align*}
this yields $\left(  av_{\lambda}^{+\mathfrak{g}^{0}},bv_{-\lambda
}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}}=\left(
a,b\right)  _{\lambda}^{\circ}$. Now that $\left(  av_{\lambda}^{+\mathfrak{g}%
^{0}},bv_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}%
}=\left(  a,b\right)  _{\lambda}^{\circ}$ is proven in each of the cases $v>u$
and $v=u$ (and the case $v<u$ is analogous), we are done with proving
(\ref{prop.det.US.pf.1}).

This proves Proposition \ref{lem.invform.g^0.1}.

\begin{corollary}
\label{cor.invform.g^0.1}Let $n\in\mathbb{N}$. Recall that the family $\left(
e_{\mathbf{i}}^{0}\right)  _{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}%
E;\ \deg\mathbf{i}=-n}$ is a basis of the vector space $U\left(
\mathfrak{n}_{-}^{0}\right)  \left[  -n\right]  =S\left(  \mathfrak{n}%
_{-}\right)  \left[  -n\right]  $, and that the family $\left(  e_{\mathbf{j}%
}^{0}\right)  _{\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\ \deg
\mathbf{j}=n}$ is a basis of the vector space $U\left(  \mathfrak{n}_{+}%
^{0}\right)  \left[  n\right]  =S\left(  \mathfrak{n}_{+}\right)  \left[
n\right]  $. Thus, let us represent the bilinear form $\left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)  \left[
-n\right]  \times S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  $ by its
matrix with respect to the bases $\left(  e_{\mathbf{i}}^{0}\right)
_{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \deg\mathbf{i}=-n}$ and
$\left(  e_{\mathbf{j}}^{0}\right)  _{\mathbf{j}\in\operatorname*{Seq}%
\nolimits_{+}E;\ \deg\mathbf{j}=n}$ of $S\left(  \mathfrak{n}_{-}\right)
\left[  -n\right]  $ and $S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]
$, respectively. This is the matrix%
\[
\left(  \left(  e_{\mathbf{i}}^{0},e_{\mathbf{j}}^{0}\right)  _{\lambda
,n}^{\circ}\right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg
\mathbf{i}=-n;\ \deg\mathbf{j}=n}}.
\]
This matrix is a square matrix (since the number of all $\mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E$ satisfying$\ \deg\mathbf{j}=n$ equals
the number of all $\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E$
satisfying$\ \deg\mathbf{i}=-n$), and its determinant is what we are going to
denote by $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ
}\right)  $.

Then,%
\[
\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{0}%
}\right)  =\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ
}\right)  .
\]

\end{corollary}

\textit{Proof of Corollary \ref{cor.invform.g^0.1}.} For every $\mathbf{i}%
\in\operatorname*{Seq}\nolimits_{-}E$ satisfying $\deg\mathbf{i}=-n$, and
every $\mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E$ satisfying
$\deg\mathbf{j}=n$, we have%
\begin{align*}
\left(  e_{\mathbf{i}}^{0}v_{\lambda}^{+\mathfrak{g}^{0}},e_{\mathbf{j}}%
^{0}v_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda,n}^{\mathfrak{g}^{0}}
&  =\left(  e_{\mathbf{i}}^{0}v_{\lambda}^{+\mathfrak{g}^{0}},e_{\mathbf{j}%
}^{0}v_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda}^{\mathfrak{g}^{0}%
}=\left(  e_{\mathbf{i}}^{0},e_{\mathbf{j}}^{0}\right)  _{\lambda}^{\circ}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Lemma \ref{lem.invform.g^0.1}, applied
to }a=e_{\mathbf{i}}^{0}\text{ and }b=e_{\mathbf{j}}^{0}\right) \\
&  =\left(  e_{\mathbf{i}}^{0},e_{\mathbf{j}}^{0}\right)  _{\lambda,n}^{\circ
}.
\end{align*}
Thus,%
\[
\det\left(  \left(  \left(  e_{\mathbf{i}}^{0}v_{\lambda}^{+\mathfrak{g}^{0}%
},e_{\mathbf{j}}^{0}v_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda
,n}^{\mathfrak{g}^{0}}\right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg
\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right)  =\det\left(  \left(  \left(
e_{\mathbf{i}}^{0},e_{\mathbf{j}}^{0}\right)  _{\lambda,n}^{\circ}\right)
_{\substack{\mathbf{i}\in\operatorname*{Seq}\nolimits_{-}E;\ \mathbf{j}%
\in\operatorname*{Seq}\nolimits_{+}E;\\\deg\mathbf{i}=-n;\ \deg\mathbf{j}%
=n}}\right)  .
\]


Now,%
\begin{align*}
\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)   &
=\det\left(  \left(  \left(  e_{\mathbf{i}}^{0},e_{\mathbf{j}}^{0}\right)
_{\lambda,n}^{\circ}\right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg
\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right) \\
&  =\det\left(  \left(  \left(  e_{\mathbf{i}}^{0}v_{\lambda}^{+\mathfrak{g}%
^{0}},e_{\mathbf{j}}^{0}v_{-\lambda}^{-\mathfrak{g}^{0}}\right)  _{\lambda
,n}^{\mathfrak{g}^{0}}\right)  _{\substack{\mathbf{i}\in\operatorname*{Seq}%
\nolimits_{-}E;\ \mathbf{j}\in\operatorname*{Seq}\nolimits_{+}E;\\\deg
\mathbf{i}=-n;\ \deg\mathbf{j}=n}}\right)  =\det\left(  \left(  \cdot
,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{0}}\right)  .
\end{align*}
This proves Corollary \ref{cor.invform.g^0.1}.

\subsubsection{Proof of Theorem \ref{thm.invformnondeg}: Joining the threads}

\textit{Proof of Proposition \ref{prop.det.US}.} Consider the polynomial
function $Q_{n}:\mathfrak{h}^{\ast}\times\mathbb{C}\rightarrow\mathbb{C}$
introduced in Corollary \ref{cor.invformnondeg.polynomiality}. Due to
Corollary \ref{cor.invformnondeg.polynomiality}, every $\lambda\in V$ and
every nonzero $\varepsilon\in\mathbb{C}$ satisfy%
\[
Q_{n}\left(  \lambda,\varepsilon\right)  =\varepsilon^{2\operatorname*{LEN}%
n}Q_{n}\left(  \lambda/\varepsilon^{2},1\right)  .
\]
Hence, we can apply Lemma \ref{lem.invformnondeg.elemen} to $V=\mathfrak{h}%
^{\ast}$, $\phi=Q_{n}$ and $k=\operatorname*{LEN}n$. Thus, we obtain the
following three observations:

\textit{Observation 1:} The polynomial function
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto
Q_{n}\left(  \lambda,0\right)
\]
is homogeneous of degree $k$. (This follows from Lemma
\ref{lem.invformnondeg.elemen} \textbf{(a)}.)

\textit{Observation 2:} For every integer $N>k$, the $N$-th homogeneous
component of the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto
Q_{n}\left(  \lambda,1\right)
\]
is zero. (This follows from Lemma \ref{lem.invformnondeg.elemen} \textbf{(b)}.)

\textit{Observation 3:} The $k$-th homogeneous component of the polynomial
function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto
Q_{n}\left(  \lambda,1\right)
\]
is the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto
Q_{n}\left(  \lambda,0\right)  .
\]
(This follows from Lemma \ref{lem.invformnondeg.elemen} \textbf{(c)}.)

Since every $\lambda\in\mathfrak{h}^{\ast}$ satisfies%
\begin{align*}
Q_{n}\left(  \lambda,1\right)   &  =\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\mathfrak{g}^{1}}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since (\ref{cor.invformnondeg.polynomiality.1}) (applied to }%
\varepsilon=1\text{)}\\
\text{yields }\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}%
^{\mathfrak{g}^{1}}\right)  =Q_{n}\left(  \lambda,1\right)
\end{array}
\right) \\
&  =\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{g}^{1}=\mathfrak{g}\text{
and thus }\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}^{1}}=\left(
\cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}}=\left(  \cdot,\cdot\right)
_{\lambda,n}\right)  ,
\end{align*}
the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto
Q_{n}\left(  \lambda,1\right)
\]
is the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)  .
\]
This yields that%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\]
is a polynomial function.

Since every $\lambda\in\mathfrak{h}^{\ast}$ satisfies%
\begin{align*}
Q_{n}\left(  \lambda,0\right)   &  =\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}^{\mathfrak{g}^{0}}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since (\ref{cor.invformnondeg.polynomiality.1}) (applied to }%
\varepsilon=0\text{)}\\
\text{yields }\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}%
^{\mathfrak{g}^{0}}\right)  =Q_{n}\left(  \lambda,0\right)
\end{array}
\right) \\
&  =\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Corollary \ref{cor.invform.g^0.1}%
}\right)  ,
\end{align*}
the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda\mapsto
Q_{n}\left(  \lambda,0\right)
\]
is the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  .
\]
This yields that%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\]
is a polynomial function. This polynomial function is not identically
zero\footnote{\textit{Proof.} Since $\mathfrak{g}$ is nondegenerate, there
exists $\lambda\in\mathfrak{h}^{\ast}$ such that the bilinear form%
\[
\mathfrak{g}_{-k}\times\mathfrak{g}_{k}\rightarrow\mathbb{C}%
,\ \ \ \ \ \ \ \ \ \ \left(  a,b\right)  \mapsto\lambda\left(  \left[
a,b\right]  \right)
\]
is nondegenerate for every $k\in\left\{  1,2,...,n\right\}  $. For such
$\lambda$, the form $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ must be
nondegenerate (by Lemma \ref{lem.lambda_k.2}), so that $\det\left(  \left(
\cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  \neq0$. Hence, there exists
$\lambda\in\mathfrak{h}^{\ast}$ such that $\det\left(  \left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}\right)  \neq0$. In other words, the
polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\]
is not identically zero, qed.}.

Since $Q_{n}\left(  \lambda,1\right)  =\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $ for every $\lambda\in\mathfrak{h}^{\ast}$, Observation
2 rewrites as follows:

\textit{Observation 2':} For every integer $n>k$, the $n$-th homogeneous
component of the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\]
is zero.

Since $Q_{n}\left(  \lambda,1\right)  =\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  $ and $Q_{n}\left(  \lambda,0\right)  =\det\left(
\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  $ for every
$\lambda\in\mathfrak{h}^{\ast}$, Observation 3 rewrites as follows:

\textit{Observation 3':} The $k$-th homogeneous component of the polynomial
function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
\]
is the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  .
\]


Combining Observations 2' and 3' and the fact that the polynomial function
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\]
is not identically zero, we conclude that the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)
\]
is the leading term of the polynomial function%
\[
\mathfrak{h}^{\ast}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ \lambda
\mapsto\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)  .
\]


This proves Proposition \ref{prop.det.US}.

Now that Proposition \ref{prop.det.US} is proven, the proof of Theorem
\ref{thm.invformnondeg} is also complete (because we have already proven
Theorem \ref{thm.invformnondeg} using Proposition \ref{prop.det.US}).

\subsection{The irreducible quotients of the Verma modules}

We will now use the form $\left(  \cdot,\cdot\right)  _{\lambda}$ to develop
the representation theory of $\mathfrak{g}$. In the following, we assume that
$\mathfrak{g}$ is nondegenerate.

\begin{definition}
Let $\left(  \cdot,\cdot\right)  $ denote the form $\left(  \cdot
,\cdot\right)  _{\lambda}$. Let $J_{\lambda}^{\pm}$ be the kernel of $\left(
\cdot,\cdot\right)  $ on $M_{\lambda}^{\pm}$. This is a graded $\mathfrak{g}%
$-submodule of $M_{\lambda}^{\pm}$ (since the form $\left(  \cdot
,\cdot\right)  $ is $\mathfrak{g}$-invariant). Let $L_{\lambda}^{\pm}$ be the
quotient module $M_{\lambda}^{\pm}\diagup J_{\lambda}^{\pm}$. Then, $\left(
\cdot,\cdot\right)  $ descends to a nondegenerate pairing $L_{\lambda}%
^{+}\times L_{-\lambda}^{-}\rightarrow\mathbb{C}$.
\end{definition}

\begin{remark}
For Weil-generic $\lambda$ (away from a countable union of hypersurfaces), we
have $J_{\lambda}^{\pm}=0$ (by Theorem \ref{thm.invformnondeg}) and thus
$L_{\lambda}^{\pm}=M_{\lambda}^{\pm}$.
\end{remark}

\begin{theorem}
\label{thm.verma}\textbf{(i)} The $\mathfrak{g}$-module $L_{\lambda}^{\pm}$ is irreducible.

\textbf{(ii)} The $\mathfrak{g}$-module $J_{\lambda}^{\pm}$ is the maximal
proper graded submodule of $M_{\lambda}^{\pm}$. (This means that $J_{\lambda
}^{\pm}$ contains all proper graded submodules in $M_{\lambda}^{\pm}$.)

\textbf{(iii)} Assume that there exists some $L\in\mathfrak{g}_{0}$ such that
every $n\in\mathbb{Z}$ satisfies
\[
\left(  \operatorname*{ad}L\right)  \mid_{\mathfrak{g}_{n}}=n\cdot
\operatorname*{id}\mid_{\mathfrak{g}_{n}}.
\]
(In this case it is said that \textit{the grading on }$\mathfrak{g}$
\textit{is internal}, i. e., comes from bracketing with some $L\in
\mathfrak{g}_{0}$.) Then $J_{\lambda}^{\pm}$ is the maximal proper submodule
of $M_{\lambda}^{\pm}$.
\end{theorem}

\begin{remark}
Here are two examples of cases when the grading on $\mathfrak{g}$ is internal:

\textbf{(a)} If $\mathfrak{g}$ is a simple finite-dimensional Lie algebra,
then we know (from Proposition \ref{prop.grad.g}) that choosing a Cartan
subalgebra $\mathfrak{h}$ and corresponding Chevalley generators $e_{1}$,
$e_{2}$, $...$, $e_{m}$, $f_{1}$, $f_{2}$, $...$, $f_{m}$, $h_{1}$, $h_{2}$,
$...$, $h_{m}$ of $\mathfrak{g}$ endows $\mathfrak{g}$ with a grading. This
grading is internal. In fact, in this case, we can take $L=\rho^{\vee}$, where
$\rho^{\vee}$ is defined as the element of $\mathfrak{h}$ satisfying
$\alpha_{i}\left(  \rho^{\vee}\right)  =1$ for all $i$ (where $\alpha_{i}$ are
the simple roots of $\mathfrak{g}$). Since the actions of the $\alpha_{i}$ on
$\mathfrak{h}$ are a basis of $\mathfrak{h}^{\ast}$, this $\rho^{\vee}$ is
well-defined and unique. (But it depends on the choice of $\mathfrak{h}$ and
the Chevalley generators, of course.)

\textbf{(b)} If $\mathfrak{g}=\operatorname*{Vir}$, then the grading on
$\mathfrak{g}$ is internal. In fact, in this case, we can take $L=-L_{0}$.

On the other hand, if $\mathfrak{g}$ is the affine Kac-Moody algebra
$\widehat{\mathfrak{g}}_{\omega}$ of Definition \ref{def.kac}, then the
grading on $\mathfrak{g}$ is not internal.
\end{remark}

\textit{Proof of Theorem \ref{thm.verma}.} \textbf{(i)} Let us show that
$L_{\lambda}^{-}$ is irreducible (the proof for $L_{\lambda}^{+}$ will be similar).

In fact, assume the contrary. Then, there exists a nonzero $w\in L_{\lambda
}^{-}$ such that $U\left(  \mathfrak{g}\right)  \cdot w\neq L_{\lambda}^{-}$.
Since $L_{\lambda}^{-}$ is graded by \textit{nonnegative} integers, we can
choose $w$ to have the smallest possible degree $m$ (without necessarily being
homogeneous). Clearly, $m>0$. Thus we can write $w=w_{0}+w_{1}+...+w_{m}$,
where each $w_{i}$ is homogeneous of degree $\deg w_{i}=i$ and $w_{m}\neq0$.

Let $a\in\mathfrak{g}_{j}$ for some $j<0$. Then $aw=0$ (since $\deg\left(
aw\right)  <\deg w$, but still $U\left(  \mathfrak{g}\right)  \cdot aw\neq
L_{\lambda}^{-}$ (since $U\left(  \mathfrak{g}\right)  \cdot aw\subseteq
U\left(  \mathfrak{g}\right)  \cdot w$ and $U\left(  \mathfrak{g}\right)
\cdot w\neq L_{\lambda}^{-}$), and we have chosen $w$ to have the smallest
possible degree). By homogeneity, this yields $aw_{m}=0$ (since $aw_{m}$ is
the $\left(  m+j\right)  $-th homogeneous component of $aw$).

For every $u\in L_{-\lambda}^{+}\left[  -m-j\right]  $, the term $\left(
au,w_{m}\right)  $ is well-defined (since $au\in L_{-\lambda}^{+}$ and
$w_{m}\in L_{\lambda}^{-}$). Since the form $\left(  \cdot,\cdot\right)  $ is
$\mathfrak{g}$-invariant, it satisfies $\left(  au,w_{m}\right)  =-\left(
u,\underbrace{aw_{m}}_{=0}\right)  =0$. But since $m>0$, we have $L_{-\lambda
}^{+}\left[  -m\right]  =\sum\limits_{j<0}\mathfrak{g}_{j}\cdot L_{-\lambda
}^{+}\left[  -m-j\right]  $ (because Proposition \ref{prop.verma1}
\textbf{(a)} yields $M_{-\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)
v_{\lambda}^{+}$, so that $L_{-\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)
\overline{v_{\lambda}^{+}}$, thus%
\[
L_{-\lambda}^{+}\left[  -m\right]  =\underbrace{U\left(  \mathfrak{n}%
_{-}\right)  \left[  -m\right]  }_{=\sum\limits_{j<0}\left(  \mathfrak{n}%
_{-}\right)  \left[  j\right]  \cdot U\left(  \mathfrak{n}_{-}\right)  \left[
-m-j\right]  }\overline{v_{\lambda}^{+}}=\sum\limits_{j<0}\underbrace{\left(
\mathfrak{n}_{-}\right)  \left[  j\right]  }_{=\mathfrak{g}\left[  j\right]
=\mathfrak{g}_{j}}\cdot\underbrace{U\left(  \mathfrak{n}_{-}\right)  \left[
-m-j\right]  \overline{v_{\lambda}^{+}}}_{\substack{=L_{-\lambda}^{+}\left[
-m-j\right]  \\\text{(since }U\left(  \mathfrak{n}_{-}\right)  \overline
{v_{\lambda}^{+}}=L_{-\lambda}^{+}\text{)}}}=\sum\limits_{j<0}\mathfrak{g}%
_{j}\cdot L_{-\lambda}^{+}\left[  -m-j\right]
\]
). Hence, any element of $L_{-\lambda}^{+}\left[  -m\right]  $ is a linear
combination of elements of the form $au$ with $a\in\mathfrak{g}_{j}$ (for
$j<0$) and $u\in L_{-\lambda}^{+}\left[  -m-j\right]  $. Thus, since we know
that $\left(  au,w_{m}\right)  =0$ for every $a\in\mathfrak{g}_{j}$ and $u\in
L_{-\lambda}^{+}\left[  -m-j\right]  $, we conclude that $\left(  L_{-\lambda
}^{+}\left[  -m\right]  ,w_{m}\right)  =0$. As a consequence, $\left(
L_{-\lambda}^{+},w_{m}\right)  =0$ (because the form $\left(  \cdot
,\cdot\right)  :L_{-\lambda}^{+}\times L_{\lambda}^{-}\rightarrow\mathbb{C}$
is of degree $0$, and thus $\left(  L_{-\lambda}^{+}\left[  j\right]
,w_{m}\right)  =0$ for all $j\neq-m$). Since the form $\left(  \cdot
,\cdot\right)  :L_{-\lambda}^{+}\times L_{\lambda}^{-}\rightarrow\mathbb{C}$
is nondegenerate, this yields $w_{m}=0$. This is a contradiction to $w_{m}%
\neq0$. This contradiction shows that our assumption was wrong. Thus,
$L_{\lambda}^{-}$ is irreducible. Similarly, $L_{\lambda}^{+}$ is irreducible.

\textbf{(ii)} First let us prove that the $\mathfrak{g}$-module $J_{\lambda
}^{+}$ is the maximal proper graded submodule of $M_{\lambda}^{+}$.

Let $K\subseteq M_{\lambda}^{+}$ be a proper graded submodule, and let
$\overline{K}$ be its image in $L_{\lambda}^{+}$. Then, $K$ lives in strictly
negative degrees (because it is graded, so if it would have a component in
degrees $\geq0$, it would contain $v_{\lambda}^{+}$ and thus contain
everything, and thus not be proper). Hence, $\overline{K}$ also lives in
strictly negative degrees, and thus is proper. Hence, by \textbf{(i)}, we have
$\overline{K}=0$, thus $K\subseteq J_{\lambda}^{+}$. This shows that
$J_{\lambda}^{+}$ is the maximal proper graded submodule of $M_{\lambda}^{+}$.
The proof of the corresponding statement for $J_{\lambda}^{-}$ and
$M_{\lambda}^{-}$ is similar.

\textbf{(iii)} Assume that there exists some $L\in\mathfrak{g}_{0}$ such that
every $n\in\mathbb{Z}$ satisfies
\[
\left(  \operatorname*{ad}L\right)  \mid_{\mathfrak{g}_{n}}=n\cdot
\operatorname*{id}\mid_{\mathfrak{g}_{n}}.
\]
Consider this $L$. It is easy to prove (by induction) that $\left[
L,a\right]  =na$ for every $a\in U\left(  \mathfrak{g}\right)  \left[
n\right]  $.

We are now going to show that all $\mathfrak{g}$-submodules of $M_{\lambda
}^{+}$ are automatically graded.

In fact, it is easy to see that $M_{\lambda}^{+}\left[  n\right]
\subseteq\operatorname*{Ker}\left(  L\mid_{M_{\lambda}^{+}}-\left(
\lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)  $ for every
$n\in\mathbb{Z}$.\ \ \ \ \footnote{\textit{Proof.} Let $n\in\mathbb{Z}$. Let
$a\in U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  $. Then, $a\in
U\left(  \mathfrak{g}\right)  \left[  n\right]  $, so that $\left[
L,a\right]  =na$ and thus $La=aL+\underbrace{\left[  L,a\right]  }%
_{=na}=aL+na$. Thus,%
\begin{align*}
\left(  L\mid_{M_{\lambda}^{+}}\right)  \left(  av_{\lambda}^{+}\right)   &
=\underbrace{La}_{=aL+na}v_{\lambda}^{+}=\left(  aL+na\right)  v_{\lambda}%
^{+}=a\underbrace{Lv_{\lambda}^{+}}_{=\lambda\left(  L\right)  v_{\lambda}%
^{+}}+nav_{\lambda}^{+}=\lambda\left(  L\right)  av_{\lambda}^{+}%
+nav_{\lambda}^{+}\\
&  =\left(  \lambda\left(  L\right)  +n\right)  av_{\lambda}^{+},
\end{align*}
so that $av_{\lambda}^{+}\in\operatorname*{Ker}\left(  L\mid_{M_{\lambda}^{+}%
}-\left(  \lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)  $.
Forget that we fixed $a\in U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]
$. Thus we have showed that every $a\in U\left(  \mathfrak{n}_{-}\right)
\left[  n\right]  $ satisfies $av_{\lambda}^{+}\in\operatorname*{Ker}\left(
L\mid_{M_{\lambda}^{+}}-\left(  \lambda\left(  L\right)  +n\right)
\operatorname*{id}\right)  $. In other words, $\left\{  av_{\lambda}^{+}%
\ \mid\ a\in U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  \right\}
\subseteq\operatorname*{Ker}\left(  L\mid_{M_{\lambda}^{+}}-\left(
\lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)  $. Since
$\left\{  av_{\lambda}^{+}\ \mid\ a\in U\left(  \mathfrak{n}_{-}\right)
\left[  n\right]  \right\}  =U\left(  \mathfrak{n}_{-}\right)  \left[
n\right]  \cdot v_{\lambda}^{+}=M_{\lambda}^{+}\left[  n\right]  $, this
becomes $M_{\lambda}^{+}\left[  n\right]  \subseteq\operatorname*{Ker}\left(
L\mid_{M_{\lambda}^{+}}-\left(  \lambda\left(  L\right)  +n\right)
\operatorname*{id}\right)  $, qed.} In other words, for every $n\in\mathbb{Z}%
$, the $n$-th homogeneous component $M_{\lambda}^{+}\left[  n\right]  $ of
$M_{\lambda}^{+}$ is contained in the eigenspace of the operator
$L\mid_{M_{\lambda}^{+}}$ for the eigenvalue $\lambda\left(  L\right)  +n$.
Now,%
\begin{align*}
M_{\lambda}^{+}  &  =\bigoplus\limits_{n\in\mathbb{Z}}M_{\lambda}^{+}\left[
n\right]  =\sum\limits_{n\in\mathbb{Z}}\underbrace{M_{\lambda}^{+}\left[
n\right]  }_{\substack{\subseteq\operatorname*{Ker}\left(  L\mid_{M_{\lambda
}^{+}}-\left(  \lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)
\\=\left(  \text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{ for
the eigenvalue }\lambda\left(  L\right)  +n\right)  }}\\
&  \subseteq\sum\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of the
operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)  .
\end{align*}
Since all eigenspaces of $L\mid_{M_{\lambda}^{+}}$ are clearly contained in
$M_{\lambda}^{+}$, this rewrites as%
\[
M_{\lambda}^{+}=\sum\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of the
operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)  .
\]
Since eigenspaces of an operator corresponding to distinct eigenvalues are
linearly disjoint, the sum $\sum\limits_{n\in\mathbb{Z}}\left(
\text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{ for the
eigenvalue }\lambda\left(  L\right)  +n\right)  $ must be a direct sum, so
this becomes%
\begin{equation}
M_{\lambda}^{+}=\bigoplus\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of
the operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)  . \label{thm.verma.pf.5}%
\end{equation}
As a consequence of this, the map $L\mid_{M_{\lambda}^{+}}$ is diagonalizable,
and all of its eigenvalues belong to the set $\left\{  \lambda\left(
L\right)  +n\ \mid\ n\in\mathbb{Z}\right\}  $.

So for every $n\in\mathbb{Z}$, we have the inclusion%
\begin{align*}
M_{\lambda}^{+}\left[  n\right]   &  \subseteq\operatorname*{Ker}\left(
L\mid_{M_{\lambda}^{+}}-\left(  \lambda\left(  L\right)  +n\right)
\operatorname*{id}\right) \\
&  =\left(  \text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{
for the eigenvalue }\lambda\left(  L\right)  +n\right)  ,
\end{align*}
but the direct sum of these inclusions over all $n\in\mathbb{Z}$ is an
equality (since%
\[
\bigoplus\limits_{n\in\mathbb{Z}}M_{\lambda}^{+}\left[  n\right]  =M_{\lambda
}^{+}=\bigoplus\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of the
operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)
\]
by (\ref{thm.verma.pf.5})). Hence, each of these inclusions must be an
equality. In other words,
\begin{equation}
M_{\lambda}^{+}\left[  n\right]  =\left(  \text{eigenspace of the operator
}L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(  L\right)
+n\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}.
\label{thm.verma.pf.6}%
\end{equation}


Now, let $K$ be a $\mathfrak{g}$-submodule of $M_{\lambda}^{+}$. Then,
$L\mid_{K}$ is a restriction of $L\mid_{M_{\lambda}^{+}}$ to $K$. Hence, map
$L\mid_{K}$ is diagonalizable, and all of its eigenvalues belong to the set
$\left\{  \lambda\left(  L\right)  +n\ \mid\ n\in\mathbb{Z}\right\}  $
(because we know that the map $L\mid_{M_{\lambda}^{+}}$ is diagonalizable, and
all of its eigenvalues belong to the set $\left\{  \lambda\left(  L\right)
+n\ \mid\ n\in\mathbb{Z}\right\}  $). In other words,%
\begin{align*}
K  &  =\bigoplus\limits_{n\in\mathbb{Z}}\underbrace{\left(  \text{eigenspace
of the operator }L\mid_{K}\text{ for the eigenvalue }\lambda\left(  L\right)
+n\right)  }_{=K\cap\left(  \text{eigenspace of the operator }L\mid
_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(  L\right)
+n\right)  }\\
&  =\bigoplus\limits_{n\in\mathbb{Z}}\left(  K\cap\underbrace{\left(
\text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{ for the
eigenvalue }\lambda\left(  L\right)  +n\right)  }_{=M_{\lambda}^{+}\left[
n\right]  }\right) \\
&  =\bigoplus\limits_{n\in\mathbb{Z}}\left(  K\cap M_{\lambda}^{+}\left[
n\right]  \right)  .
\end{align*}
Hence, $K$ is graded. We thus have shown that every $\mathfrak{g}$-submodule
of $M_{\lambda}^{+}$ is graded. Similarly, every $\mathfrak{g}$-submodule of
$M_{\lambda}^{-}$ is graded. Thus, Theorem \ref{thm.verma} \textbf{(iii)}
follows from Theorem \ref{thm.verma} \textbf{(ii)}.

\begin{remark}
Theorem \ref{thm.verma} \textbf{(ii)} does not hold if the word ``graded'' is
removed. In fact, here is a counterexample: Let $\mathfrak{g}$ be the
3-dimensional Heisenberg algebra. (This is the Lie algebra with vector-space
basis $\left(  x,K,y\right)  $ and with Lie bracket given by $\left[
y,x\right]  =K$, $\left[  x,K\right]  =0$ and $\left[  y,K\right]  =0$. It can
be considered as a Lie subalgebra of the oscillator algebra $\mathcal{A}$
defined in Definition \ref{def.osc}.) It is easy to see that $\mathfrak{g}$
becomes a nondegenerate $\mathbb{Z}$-graded Lie algebra by setting
$\mathfrak{g}_{-1}=\left\langle x\right\rangle $, $\mathfrak{g}_{0}%
=\left\langle K\right\rangle $, $\mathfrak{g}_{1}=\left\langle y\right\rangle
$ and $\mathfrak{g}_{i}=0$ for every $i\in\mathbb{Z}\diagdown\left\{
-1,0,1\right\}  $. Then, on the Verma highest-weight module $M_{0}%
^{+}=\mathbb{C}\left[  x\right]  v_{0}^{+}$, both $K$ and $y$ act as $0$ (and
$x$ acts as multiplication with $x$), so that $Iv_{0}^{+}$ is a $\mathfrak{g}%
$-submodule of $M_{0}^{+}$ for every ideal $I\subseteq\mathbb{C}\left[
x\right]  $, but not all of these ideals are graded, and not all of them are
contained in $J_{0}^{+}$ (as can be easily checked).
\end{remark}

\begin{corollary}
\label{cor.verma.irred}For Weil-generic $\lambda$ (this means a $\lambda$
outside of countably many hypersurfaces in $\mathfrak{h}^{\ast}$), the
$\mathfrak{g}$-modules $M_{\lambda}^{+}$ and $M_{\lambda}^{-}$ are irreducible.
\end{corollary}

\begin{definition}
Let $Y$ be a $\mathfrak{g}$-module. A vector $w\in Y$ is called a
\textit{singular vector of weight }$\mu\in\mathfrak{h}^{\ast}$ (here, recall
that $\mathfrak{h}=\mathfrak{g}_{0}$) if it satisfies%
\[
hw=\mu\left(  h\right)  w\ \ \ \ \ \ \ \ \ \ \text{for every }h\in\mathfrak{h}%
\]
and%
\[
aw=0\ \ \ \ \ \ \ \ \ \ \text{for every }a\in\mathfrak{g}_{i}\text{ for every
}i>0\text{.}%
\]
We denote by $\operatorname*{Sing}\nolimits_{\mu}\left(  Y\right)  $ the space
of singular vectors of $Y$ of weight $\mu$.
\end{definition}

When people talk about ``singular vectors'', they usually mean nonzero
singular vectors in negative degrees. We are not going to adhere to this
convention, though.

\begin{lemma}
\label{lem.singvec}Let $Y$ be a $\mathfrak{g}$-module. Then there is a
canonical isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
&  \rightarrow\operatorname*{Sing}\nolimits_{\lambda}Y,\\
\phi &  \mapsto\phi\left(  v_{\lambda}^{+}\right)  .
\end{align*}

\end{lemma}

\textit{Proof of Lemma \ref{lem.singvec}.} We have $M_{\lambda}^{+}=U\left(
\mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  }\mathbb{C}_{\lambda}=\operatorname*{Ind}\nolimits_{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\mathbb{C}_{\lambda}$, so that
\[
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
=\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\mathbb{C}%
_{\lambda},Y\right)  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}\left(  \mathbb{C}_{\lambda},Y\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right)  .
\]
But $\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(
\mathbb{C}_{\lambda},Y\right)  \cong\operatorname*{Sing}\nolimits_{\lambda}Y$
(because every $\mathbb{C}$-linear map $\mathbb{C}_{\lambda}\rightarrow Y$ is
uniquely determined by the image of $v_{\lambda}^{+}$, and this map is a
$\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  $-module map if and only
if this image is a singular vector of $Y$ of weight $\lambda$). Thus,
$\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
\cong\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(
\mathbb{C}_{\lambda},Y\right)  \cong\operatorname*{Sing}\nolimits_{\lambda}Y$.
If we make this isomorphism explicit, we notice that it sends every $\phi$ to
$\phi\left(  v_{\lambda}^{+}\right)  $, so that Lemma \ref{lem.singvec} is proven.

\begin{corollary}
\label{cor.singvec}The representation $M_{\lambda}^{+}$ is irreducible if and
only if it does not have nonzero singular vectors in negative degrees. Here, a
vector in $M_{\lambda}^{+}$ is said to be ``in negative degrees'' if its
projection on the $0$-th homogeneous component $M_{\lambda}^{+}\left[
0\right]  $ is zero.
\end{corollary}

\textit{Proof of Corollary \ref{cor.singvec}.} $\Longleftarrow:$ Assume that
$M_{\lambda}^{+}$ does not have nonzero singular vectors in negative degrees.

We must then show that $M_{\lambda}^{+}$ is irreducible.

In fact, assume the contrary. Then, $M_{\lambda}^{+}$ is not irreducible.
Hence, there exists a nonzero \textit{homogeneous} $v\in M_{\lambda}^{+}$ such
that $U\left(  \mathfrak{g}\right)  \cdot v\neq M_{\lambda}^{+}$%
.\ \ \ \ \footnote{\textit{Proof.} Notice that $M_{\lambda}^{+}$ is a graded
$U\left(  \mathfrak{g}\right)  $-module (since $M_{\lambda}^{+}$ is a graded
$\mathfrak{g}$-module).
\par
Since $M_{\lambda}^{+}$ is not irreducible, there exists a nonzero $w\in
M_{\lambda}^{+}$ such that $U\left(  \mathfrak{g}\right)  \cdot w\neq
M_{\lambda}^{+}$. Since $M_{\lambda}^{+}$ is graded by \textit{nonpositive}
integers, we can write $w$ in the form $w=\sum\limits_{j=0}^{m}w_{j}$, where
each $w_{i}$ is homogeneous of degree $\deg w_{i}=-i$ and $m\in\mathbb{Z}$.
Now,
\begin{align*}
\underbrace{U\left(  \mathfrak{g}\right)  }_{=\sum\limits_{i\in\mathbb{Z}%
}U\left(  \mathfrak{g}\right)  \left[  i\right]  }\cdot\underbrace{w}%
_{=\sum\limits_{j=0}^{m}w_{j}}  &  =\left(  \sum\limits_{i\in\mathbb{Z}%
}U\left(  \mathfrak{g}\right)  \left[  i\right]  \right)  \cdot\left(
\sum\limits_{j=0}^{m}w_{j}\right) \\
&  =\sum\limits_{i\in\mathbb{Z}}\sum\limits_{j=0}^{m}U\left(  \mathfrak{g}%
\right)  \left[  i\right]  \cdot w_{j}.
\end{align*}
Hence, for every $n\in\mathbb{Z}$, we have
\begin{align*}
\left(  U\left(  \mathfrak{g}\right)  \cdot w\right)  \left[  n\right]   &
=\left(  \sum\limits_{i\in\mathbb{Z}}\sum\limits_{j=0}^{m}U\left(
\mathfrak{g}\right)  \left[  i\right]  \cdot w_{j}\right)  \left[  n\right]
=\sum\limits_{j=0}^{m}\underbrace{\left(  \sum\limits_{i\in\mathbb{Z}}U\left(
\mathfrak{g}\right)  \left[  i\right]  \cdot w_{j}\right)  }%
_{\substack{\subseteq U\left(  \mathfrak{g}\right)  \left[  i-j\right]
\\\text{(since }\deg w_{j}=-j\text{ and since}\\M_{\lambda}^{+}\text{ is a
graded }U\left(  \mathfrak{g}\right)  \text{-module)}}}\left[  n\right] \\
&  =\sum\limits_{j=0}^{m}U\left(  \mathfrak{g}\right)  \left[  n+j\right]
\cdot w_{j}.
\end{align*}
Now, since $U\left(  \mathfrak{g}\right)  \cdot w\neq M_{\lambda}^{+}$, there
exists at least one $n\in\mathbb{Z}$ such that $\left(  U\left(
\mathfrak{g}\right)  \cdot w\right)  \left[  n\right]  \neq M_{\lambda}%
^{+}\left[  n\right]  $. Consider such an $n$. Then, $M_{\lambda}^{+}\left[
n\right]  \neq\left(  U\left(  \mathfrak{g}\right)  \cdot w\right)  \left[
n\right]  =\sum\limits_{j=0}^{m}U\left(  \mathfrak{g}\right)  \left[
n+j\right]  \cdot w_{j}$. Thus, $U\left(  \mathfrak{g}\right)  \left[
n+j\right]  \cdot w_{j}\neq M_{\lambda}^{+}\left[  n\right]  $ for all
$j\in\left\{  0,1,...,m\right\}  $. But some $j\in\left\{  0,1,...,m\right\}
$ satisfies $w_{j}\neq0$ (since $\sum\limits_{j=0}^{m}w_{j}=w\neq0$). Consider
this $j$. Then, $w_{j}$ is a nonzero homogeneous element of $M_{\lambda}^{+}$
satisfying $U\left(  \mathfrak{g}\right)  \cdot w_{j}\neq M_{\lambda}^{+}$
(because $\left(  U\left(  \mathfrak{g}\right)  \cdot w_{j}\right)  \left[
n\right]  =U\left(  \mathfrak{g}\right)  \left[  n+j\right]  \cdot w_{j}\neq
M_{\lambda}^{+}\left[  n\right]  $). This proves that there exists a nonzero
\textit{homogeneous} $v\in M_{\lambda}^{+}$ such that $U\left(  \mathfrak{g}%
\right)  \cdot v\neq M_{\lambda}^{+}$. Qed.} Consider this $v$. Then,
$U\left(  \mathfrak{g}\right)  \cdot v$ is a proper graded submodule of
$M_{\lambda}^{+}$, and thus is contained in $J_{\lambda}^{+}$. Hence,
$J_{\lambda}^{+}\neq0$.

There exist some $d\in\mathbb{Z}$ such that $J_{\lambda}^{+}\left[  d\right]
\neq0$ (since $J_{\lambda}^{+}\neq0$ and since $J_{\lambda}^{+}$ is graded).
All such $d$ are nonpositive (since $J_{\lambda}^{+}$ is nonpositively
graded). Thus, there exists a highest integer $d$ such that $J_{\lambda}%
^{+}\left[  d\right]  \neq0$. Consider this $d$. Clearly, $d<0$ (since the
bilinear form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda
}^{-}$ is obviously nondegenerate on $M_{\lambda}^{+}\left[  0\right]  \times
M_{-\lambda}^{-}\left[  0\right]  $, so that $J_{\lambda}^{+}\left[  0\right]
=0$).

Every $i>0$ satisfies
\begin{align*}
\mathfrak{g}_{i}\cdot\left(  J_{\lambda}^{+}\left[  d\right]  \right)   &
\subseteq J_{\lambda}^{+}\left[  i+d\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }J_{\lambda}^{+}\text{ is a graded }\mathfrak{g}\text{-module}%
\right) \\
&  =0\ \ \ \ \ \ \ \ \ \ \left(  \text{since }i+d>d\text{, but }d\text{ was
the highest integer such that }J_{\lambda}^{+}\left[  d\right]  \neq0\right)
.
\end{align*}


By Conditions \textbf{(1)} and \textbf{(2)} of Definition
\ref{def.gradLienondeg}, the Lie algebra $\mathfrak{g}_{0}$ is abelian and
finite-dimensional. Hence, every nonzero $\mathfrak{g}_{0}$-module has a
one-dimensional submodule\footnote{\textit{Proof.} This is because of the
following fact:
\par
Every nonzero finite-dimensional module over an abelian finite-dimensional Lie
algebra has a one-dimensional submodule. (This is just a restatement of the
fact that a finite set of pairwise commuting matrices on a finite-dimensional
nonzero $\mathbb{C}$-vector space has a common nonzero eigenvector.)}. Thus,
the nonzero $\mathfrak{g}_{0}$-module $J_{\lambda}^{+}\left[  d\right]  $ has
a one-dimensional submodule. Let $w$ be the generator of this submodule. Then,
this submodule is $\left\langle w\right\rangle $.

For every $h\in\mathfrak{h}$, the vector $hw$ is a scalar multiple of $w$
(since $h\in\mathfrak{h}=\mathfrak{g}_{0}$, so that $hw$ lies in the
$\mathfrak{g}_{0}$-submodule of $J_{\lambda}^{+}\left[  d\right]  $ generated
by $w$, but this submodule is $\left\langle w\right\rangle $). Thus, we can
write $hw=\lambda_{h}w$ for some $\lambda_{h}\in\mathbb{C}$. This $\lambda
_{h}$ is uniquely determined (since $w\neq0$), so we can define a map
$\mu:\mathfrak{h}\rightarrow\mathbb{C}$ such that $\mu\left(  h\right)
=\lambda_{h}$ for every $h\in\mathfrak{h}$. This map $\mu$ is easily seen to
be $\mathbb{C}$-linear, so that we have found a $\mu\in\mathfrak{h}^{\ast}$
such that%
\[
hw=\mu\left(  h\right)  w\ \ \ \ \ \ \ \ \ \ \text{for every }h\in
\mathfrak{h}.
\]
Also,%
\[
aw=0\ \ \ \ \ \ \ \ \ \ \text{for every }a\in\mathfrak{g}_{i}\text{ for every
}i>0
\]
(since $\underbrace{a}_{\in\mathfrak{g}_{i}}\underbrace{w}_{\in J_{\lambda
}^{+}\left[  d\right]  }\in\mathfrak{g}_{i}\cdot\left(  J_{\lambda}^{+}\left[
d\right]  \right)  \subseteq0$). Thus, $w$ is a nonzero singular vector. Since
$w\in J_{\lambda}^{+}\left[  d\right]  $ and $d<0$, this vector $w$ is in
negative degrees. This contradicts to the assumption that $M_{\lambda}^{+}$
does not have nonzero singular vectors in negative degrees. This contradiction
shows that our assumption was wrong, so that $M_{\lambda}^{+}$ is irreducible.
This proves the $\Longleftarrow$ direction of Corollary \ref{cor.singvec}.

$\Longrightarrow:$ Assume that $M_{\lambda}^{+}$ is irreducible.

We must then show that $M_{\lambda}^{+}$ does not have nonzero singular
vectors in negative degrees.

Let $v$ be a singular vector of $M_{\lambda}^{+}$ in negative degrees. Let it
be a singular vector of weight $\mu$ for some $\mu\in\mathfrak{h}^{\ast}$.

By Lemma \ref{lem.singvec} (applied to $\mu$ and $M_{\lambda}^{+}$ instead of
$\lambda$ and $Y$), we have an isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\mu}^{+},M_{\lambda}%
^{+}\right)   &  \rightarrow\operatorname*{Sing}\nolimits_{\mu}\left(
M_{\lambda}^{+}\right)  ,\\
\phi &  \mapsto\phi\left(  v_{\mu}^{+}\right)  .
\end{align*}
Let $\phi$ be the preimage of $v$ under this isomorphism. Then, $v=\phi\left(
v_{\mu}^{+}\right)  $.

Since $v$ is in negative degrees, we have $v\in\sum\limits_{n<0}M_{\lambda
}^{+}\left[  n\right]  $. Now, $M_{\mu}^{+}=U\left(  \mathfrak{n}_{-}\right)
v_{\mu}^{+}=\sum\limits_{m\leq0}U\left(  \mathfrak{n}_{-}\right)  \left[
m\right]  v_{\mu}^{+}$ (since $M_{\mu}^{+}$ is nonpositively graded), so that%
\begin{align*}
\phi\left(  M_{\mu}^{+}\right)   &  =\phi\left(  \sum\limits_{m\leq0}U\left(
\mathfrak{n}_{-}\right)  \left[  m\right]  v_{\mu}^{+}\right)  =\sum
\limits_{m\leq0}U\left(  \mathfrak{n}_{-}\right)  \left[  m\right]
\underbrace{\phi\left(  v_{\mu}^{+}\right)  }_{=v\in\sum\limits_{n<0}%
M_{\lambda}^{+}\left[  n\right]  }\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\phi\in\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\mu}%
^{+},M_{\lambda}^{+}\right)  \right) \\
&  \in\sum\limits_{m\leq0}U\left(  \mathfrak{n}_{-}\right)  \left[  m\right]
\sum\limits_{n<0}M_{\lambda}^{+}\left[  n\right]  =\sum\limits_{m\leq0}%
\sum\limits_{n<0}\underbrace{U\left(  \mathfrak{n}_{-}\right)  \left[
m\right]  \cdot M_{\lambda}^{+}\left[  n\right]  }_{\substack{\subseteq
M_{\lambda}^{+}\left[  m+n\right]  \\\text{(since }M_{\lambda}^{+}\text{ is a
graded }\mathfrak{g}\text{-module)}}}\\
&  \subseteq\sum\limits_{m\leq0}\sum\limits_{n<0}M_{\lambda}^{+}\left[
m+n\right]  \subseteq\sum\limits_{r<0}M_{\lambda}^{+}\left[  r\right]  .
\end{align*}
Thus, the projection of $\phi\left(  M_{\mu}^{+}\right)  $ onto the $0$-th
degree of $M_{\lambda}^{+}$ is $0$. Hence, $\phi\left(  M_{\mu}^{+}\right)  $
is a proper $\mathfrak{g}$-submodule of $M_{\lambda}^{+}$. Therefore,
$\phi\left(  M_{\mu}^{+}\right)  =0$ (since $M_{\lambda}^{+}$ is irreducible).
Thus, $v=\phi\left(  v_{\mu}^{+}\right)  \in\phi\left(  M_{\mu}^{+}\right)
=0$, so that $v=0$.

We have thus proven: Whenever $v$ is a singular vector of $M_{\lambda}^{+}$ in
negative degrees, we have $v=0$. In other words, $M_{\lambda}^{+}$ does not
have nonzero singular vectors in negative degrees. This proves the
$\Longrightarrow$ direction of Corollary \ref{cor.singvec}.

Here is a variation on Corollary \ref{cor.singvec}:

\begin{corollary}
\label{cor.singvec.2}The representation $M_{\lambda}^{+}$ is irreducible if
and only if it does not have nonzero homogeneous singular vectors in negative degrees.
\end{corollary}

\textit{Proof of Corollary \ref{cor.singvec.2}.} $\Longrightarrow:$ This
follows from the $\Longrightarrow$ direction of Corollary \ref{cor.singvec}.

$\Longleftarrow:$ Repeat the proof of the $\Longleftarrow$ direction of
Corollary \ref{cor.singvec}, noticing that $w$ is homogeneous (since $w\in
J_{\lambda}^{+}\left[  d\right]  $).

Corollary \ref{cor.singvec.2} is thus proven.

\subsection{Highest/lowest-weight modules}

\begin{definition}
A \textit{highest-weight module} with highest weight $\lambda\in
\mathfrak{h}^{\ast}$ means a quotient $V$ of the graded $\mathfrak{g}$-module
$M_{\lambda}^{+}$ by a proper graded submodule. The projection of $v_{\lambda
}^{+}\in M_{\lambda}^{+}$ onto this quotient will be called a
\textit{highest-weight vector} of $V$. (Note that a highest-weight module may
have several highest-weight vectors: in fact, every nonzero vector in its
$0$-th homogeneous component is a highest-weight vector.) The notion
``highest-weight representation'' is also used as a synonym for
``highest-weight module''.

A \textit{lowest-weight module} with lowest weight $\lambda\in\mathfrak{h}%
^{\ast}$ means a quotient $V$ of the graded $\mathfrak{g}$-module $M_{\lambda
}^{-}$ by a proper graded submodule. The projection of $v_{\lambda}^{-}\in
M_{\lambda}^{-}$ onto this quotient will be called a \textit{lowest-weight
vector} of $V$. (Note that a lowest-weight module may have several
lowest-weight vectors: in fact, every nonzero vector in its $0$-th homogeneous
component is a lowest-weight vector.) The notion ``lowest-weight
representation'' is also used as a synonym for ``lowest-weight module''.

If $Y$ is a highest-weight module with highest weight $\lambda$, then we have
an exact sequence $%
%TCIMACRO{\TeXButton{M surj Y surj L}{\xymatrix{
%M^{+}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{+}_{\lambda}
%}}}%
%BeginExpansion
\xymatrix{
M^{+}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{+}_{\lambda}
}%
%EndExpansion
$ (by Theorem \ref{thm.verma} \textbf{(ii)}).

If $Y$ is a lowest-weight module with lowest weight $\lambda$, then we have an
exact sequence $%
%TCIMACRO{\TeXButton{M surj Y surj L}{\xymatrix{
%M^{-}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{-}_{\lambda}
%}}}%
%BeginExpansion
\xymatrix{
M^{-}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{-}_{\lambda}
}%
%EndExpansion
$ (by Theorem \ref{thm.verma} \textbf{(ii)}).
\end{definition}

\subsection{Categories \texorpdfstring{$\mathcal{O}^{+}$}{O-plus} and
\texorpdfstring{$\mathcal{O}^{-}$}{O-minus}}

The category of all $\mathfrak{g}$-modules for a graded Lie algebra is
normally not particularly well-behaved: modules can be too big. One could
restrict one's attention to finite-dimensional modules, but this is often too
much of a sacrifice (e. g., the Heisenberg algebra $\mathcal{A}$ has no
finite-dimensional modules which are not direct sums of $1$-dimensional ones).
A balance between nontriviality and tamability is achieved by considering the
so-called \textit{Category }$\mathcal{O}$. Actually, there are two of these
categories, $\mathcal{O}^{+}$ and $\mathcal{O}^{-}$, which are antiequivalent
to each other (in general) and equivalent to each other (in some more
restrictive cases). There are several definitions for each of these
categories, and some of them are not even equivalent to each other, although
they mostly differ in minor technicalities. Here are the definitions that we
are going to use:

\begin{definition}
\label{def.O+}The objects of \textit{category }$\mathcal{O}^{+}$ will be
$\mathbb{C}$-graded $\mathfrak{g}$-modules $M$ such that:

\textbf{(1)} all degrees lie in a halfplane $\operatorname{Re}z<a$ and fall
into finitely many arithmetic progressions with step $1$;

\textbf{(2)} for every $d\in\mathbb{C}$, the space $M\left[  d\right]  $ is finite-dimensional.

The \textit{morphisms of category }$\mathcal{O}^{+}$ will be graded
$\mathfrak{g}$-module homomorphisms.
\end{definition}

\begin{definition}
\label{def.O-}The objects of \textit{category }$\mathcal{O}^{-}$ will be
$\mathbb{C}$-graded $\mathfrak{g}$-modules $M$ such that:

\textbf{(1)} all degrees lie in a halfplane $\operatorname{Re}z>a$ and fall
into finitely many arithmetic progressions with step $1$;

\textbf{(2)} for every $d\in\mathbb{C}$, the space $M\left[  d\right]  $ is finite-dimensional.

The \textit{morphisms of category }$\mathcal{O}^{-}$ will be graded
$\mathfrak{g}$-module homomorphisms.
\end{definition}

It is rather clear that for a nondegenerate $\mathbb{Z}$-graded Lie algebra
(or, more generally, for a $\mathbb{Z}$-graded Lie algebra satisfying
conditions \textbf{(1)} and \textbf{(2)} of Definition \ref{def.gradLienondeg}%
), the Verma highest-weight module $M_{\lambda}^{+}$ lies in category
$\mathcal{O}^{+}$ for every $\lambda\in\mathfrak{h}^{\ast}$, and the Verma
lowest-weight module $M_{\lambda}^{-}$ lies in category $\mathcal{O}^{-}$ for
every $\lambda\in\mathfrak{h}^{\ast}$.

\begin{definition}
Let $V$ and $W$ be two $\mathbb{C}$-graded vector spaces, and $x\in\mathbb{C}%
$. A map $f:V\rightarrow W$ is said to be \textit{homogeneous of degree }$x$
if and only if every $z\in\mathbb{C}$ satisfies $f\left(  V\left[  z\right]
\right)  \subseteq W\left[  z+x\right]  $. (For example, this yields that a
map is homogeneous of degree $0$ if and only if it is graded.)
\end{definition}

\begin{proposition}
\label{prop.O.irred}The irreducible modules in category $\mathcal{O}^{\pm}$
(up to homogeneous isomorphism) are $L_{\lambda}^{\pm}$ for varying
$\lambda\in\mathbb{C}$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.O.irred}.} First of all, for every
$\lambda\in\mathfrak{h}^{\ast}$, the $\mathfrak{g}$-module $L_{\lambda}^{+}$
has a unique singular vector (up to scaling), and this vector is a singular
vector of weight $\lambda$.\ \ \ \ \footnote{\textit{Proof.} It is clear that
$\overline{v_{\lambda}^{+}}\in L_{\lambda}^{+}$ is a singular vector of weight
$\lambda$. Now we must prove that it is the only singular vector (up to
scaling).
\par
In fact, assume the opposite. Then, there exists a singular vector in
$L_{\lambda}^{+}$ which is not a scalar multiple of $\overline{v_{\lambda}%
^{+}}$. This singular vector must have a nonzero $d$-th homogeneous component
for some $d<0$ (because it is not a scalar multiple of $\overline{v_{\lambda
}^{+}}$), and this component itself must be a singular vector (since any
homogeneous component of a singular vector must itself be a singular vector).
So the module $L_{\lambda}^{+}$ has a nonzero homogeneous singular vector $w$
of degree $d$.
\par
Now, repeat the proof of the $\Longrightarrow$ part of Corollary
\ref{cor.singvec}, with $M_{\lambda}^{+}$ replaced by $L_{\lambda}^{+}$ (using
the fact that $L_{\lambda}^{+}$ is irreducible). As a consequence, it follows
that $L_{\lambda}^{+}$ does not have nonzero singular vectors in negative
degrees. This contradicts the fact that the module $L_{\lambda}^{+}$ has a
nonzero homogeneous singular vector $w$ of degree $d<0$. This contradiction
shows that our assumption was wrong, so that indeed, $\overline{v_{\lambda
}^{+}}$ is the only singular vector of $L_{\lambda}^{+}$ (up to scaling),
qed.} Thus, the $\mathfrak{g}$-modules $L_{\lambda}^{+}$ are pairwise
nonisomorphic for varying $\lambda$. Similarly, the $\mathfrak{g}$-modules
$L_{\lambda}^{-}$ are pairwise nonisomorphic for varying $\lambda$.

Let $Y$ be any irreducible module in category $\mathcal{O}^{+}$. We are now
going to prove that $Y\cong L_{\lambda}^{+}$ for some $\lambda\in
\mathfrak{h}^{\ast}$.

Let $d$ be a complex number such that $Y\left[  d\right]  \neq0$ and $Y\left[
d+j\right]  =0$ for all $j\geq1$. (Such a complex number exists due to
condition \textbf{(1)} in Definition \ref{def.O+}.) For every $v\in Y\left[
d\right]  $, we have $av=0$ for every $a\in\mathfrak{g}_{i}$ for every
$i>0$\ \ \ \ \footnote{\textit{Proof.} Let $i>0$ and $a\in\mathfrak{g}_{i}$.
Then, $i\geq1$. Now, $a\in\mathfrak{g}_{i}$ and $v\in Y\left[  d\right]  $
yield $av\in\mathfrak{g}_{i}\cdot Y\left[  d\right]  \subseteq Y\left[
d+i\right]  =0$ (since $Y\left[  d+j\right]  =0$ for all $j\geq1$), so that
$av=0$, qed.}.

By Conditions \textbf{(1)} and \textbf{(2)} of Definition
\ref{def.gradLienondeg}, the Lie algebra $\mathfrak{g}_{0}$ is abelian and
finite-dimensional. Hence, every nonzero $\mathfrak{g}_{0}$-module has a
one-dimensional submodule\footnote{\textit{Proof.} This is because of the
following fact:
\par
Every nonzero finite-dimensional module over an abelian finite-dimensional Lie
algebra has a one-dimensional submodule. (This is just a restatement of the
fact that a finite set of pairwise commuting matrices on a finite-dimensional
nonzero $\mathbb{C}$-vector space has a common nonzero eigenvector.)}. Thus,
the nonzero $\mathfrak{g}_{0}$-module $Y\left[  d\right]  $ has a
one-dimensional submodule. Let $w$ be the generator of this submodule. Then,
this submodule is $\left\langle w\right\rangle $.

For every $h\in\mathfrak{h}$, the vector $hw$ is a scalar multiple of $w$
(since $h\in\mathfrak{h}=\mathfrak{g}_{0}$, so that $hw$ lies in the
$\mathfrak{g}_{0}$-submodule of $Y\left[  d\right]  $ generated by $w$, but
this submodule is $\left\langle w\right\rangle $). Thus, we can write
$hw=\lambda_{h}w$ for some $\lambda_{h}\in\mathbb{C}$. This $\lambda_{h}$ is
uniquely determined by $h$ (since $w\neq0$), so we can define a map
$\lambda:\mathfrak{h}\rightarrow\mathbb{C}$ such that $\lambda\left(
h\right)  =\lambda_{h}$ for every $h\in\mathfrak{h}$. This map $\lambda$ is
easily seen to be $\mathbb{C}$-linear, so that we have found a $\lambda
\in\mathfrak{h}^{\ast}$ such that%
\[
hw=\lambda\left(  h\right)  w\ \ \ \ \ \ \ \ \ \ \text{for every }%
h\in\mathfrak{h}.
\]
Also,%
\[
aw=0\ \ \ \ \ \ \ \ \ \ \text{for every }a\in\mathfrak{g}_{i}\text{ for every
}i>0
\]
(since $av=0$ for every $v\in Y\left[  d\right]  $ and every $a\in
\mathfrak{g}_{i}$ for every $i>0$). Thus, $w$ is a nonzero singular vector of
weight $\lambda$.

By Lemma \ref{lem.singvec}, we have an isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
&  \rightarrow\operatorname*{Sing}\nolimits_{\lambda}Y,\\
\phi &  \mapsto\phi\left(  v_{\lambda}^{+}\right)  .
\end{align*}
Let $\phi$ be the preimage of $w$ under this isomorphism. Then, $w=\phi\left(
v_{\lambda}^{+}\right)  $. Since $w\in Y\left[  d\right]  $, it is easy to see
that $\phi$ is a homogeneous homomorphism of degree $d$ (in fact, every
$n\in\mathbb{Z}$ satisfies $M_{\lambda}^{+}\left[  n\right]  =U\left(
\mathfrak{n}_{-}\right)  \left[  n\right]  \cdot v_{\lambda}^{+}$, so that%
\begin{align*}
\phi\left(  M_{\lambda}^{+}\left[  n\right]  \right)   &  =\phi\left(
U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  \cdot v_{\lambda}%
^{+}\right)  =U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]
\cdot\underbrace{\phi\left(  v_{\lambda}^{+}\right)  }_{=w\in Y\left[
d\right]  }\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\phi\text{ is
}\mathfrak{g}\text{-linear}\right) \\
&  \subseteq U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  \cdot
Y\left[  d\right]  \subseteq Y\left[  n+d\right]
\end{align*}
). This homomorphism $\phi$ must be surjective, since $Y$ is irreducible.
Thus, we have a homogeneous isomorphism $M_{\lambda}^{+}\diagup\left(
\operatorname*{Ker}\phi\right)  \cong Y$. Also, $\operatorname*{Ker}\phi$ is a
proper graded submodule of $M_{\lambda}^{+}$, thus a submodule of $J_{\lambda
}^{+}$ (by Theorem \ref{thm.verma} \textbf{(ii)}). Hence, we have a projection
$M_{\lambda}^{+}\diagup\left(  \operatorname*{Ker}\phi\right)  \rightarrow
M_{\lambda}^{+}\diagup J_{\lambda}^{+}$. Since $M_{\lambda}^{+}\diagup\left(
\operatorname*{Ker}\phi\right)  \cong Y$ is irreducible, this projection must
either be an isomorphism or the zero map. It cannot be the zero map (since it
is a projection onto the nonzero module $M_{\lambda}^{+}\diagup J_{\lambda
}^{+}$), so it therefore is an isomorphism. Thus, $M_{\lambda}^{+}\diagup
J_{\lambda}^{+}\cong M_{\lambda}^{+}\diagup\left(  \operatorname*{Ker}%
\phi\right)  \cong Y$, so we have a homogeneous isomorphism $Y\cong
M_{\lambda}^{+}\diagup J_{\lambda}^{+}=L_{\lambda}^{+}$.

We thus have showed that any irreducible module in category $\mathcal{O}^{+}$
is isomorphic to $L_{\lambda}^{+}$ for some $\lambda\in\mathfrak{h}^{\ast}$.
Similarly, the analogous assertion holds for $\mathcal{O}^{-}$. Proposition
\ref{prop.O.irred} is thus proven.

\begin{definition}
Let $M$ be a module in category $\mathcal{O}^{+}$. We define the
\textit{character} $\operatorname*{ch}M$ of $M$ as follows:

Write $M=\bigoplus\limits_{d}M\left[  d\right]  $. Then, define
$\operatorname*{ch}M$ by%
\[
\operatorname*{ch}M=\sum\limits_{d}q^{-d}\operatorname*{tr}\nolimits_{M\left[
d\right]  }\left(  e^{x}\right)  \ \ \ \ \ \ \ \ \ \ \text{as a power series
in }q
\]
for every $x\in\mathfrak{h}$. We also write $\left(  \operatorname*{ch}%
M\right)  \left(  q,x\right)  $ for this, so it becomes a formal power series
in both $q$ and $x$. (Note that this power series can contain noninteger
powers of $q$, but due to $M\in\mathcal{O}^{+}$, the exponents in these powers
are bounded from above in their real part, and fall into infinitely many
arithmetic progressions with step $1$.)
\end{definition}

\begin{proposition}
\label{prop.chVerma}Here is an example:%
\[
\left(  \operatorname*{ch}M_{\lambda}^{+}\right)  \left(  x\right)  =\dfrac
{1}{\prod\limits_{j>0}\det\nolimits_{\mathfrak{g}\left[  -j\right]  }\left(
1-q^{j}e^{\operatorname*{ad}\left(  x\right)  }\right)  }.
\]
(To prove this, use Molien's identity which states that, for every linear map
$A:V\rightarrow V$, we have%
\[
\sum\limits_{n\in\mathbb{N}}q^{n}\operatorname*{Tr}\nolimits_{S^{n}V}\left(
S^{n}A\right)  =\dfrac{1}{\det\left(  1-qA\right)  },
\]
where $S^{n}A$ denotes the $n$-th symmetric power of the operator $A$.)
\end{proposition}

Let us consider some examples:

\begin{example}
\label{exa.sl2}Let $\mathfrak{g}=\mathfrak{sl}_{2}$. We can write this Lie
algebra in terms of Chevalley generators and their relations (this is a
particular case of what we did in Proposition \ref{prop.grad.g}). The most
traditional way to do this is by setting $e=\left(
\begin{array}
[c]{cc}%
0 & 1\\
0 & 0
\end{array}
\right)  $, $f=\left(
\begin{array}
[c]{cc}%
0 & 0\\
1 & 0
\end{array}
\right)  $ and $h=\left(
\begin{array}
[c]{cc}%
1 & 0\\
0 & -1
\end{array}
\right)  $; then, $\mathfrak{g}$ is generated by $e$, $f$ and $h$ as a Lie
algebra, and these generators satisfy $\left[  h,e\right]  =2e$, $\left[
h,f\right]  =-2f$ and $\left[  e,f\right]  =h$. Also, $\left(  e,f,h\right)  $
is a basis of the vector space $\mathfrak{g}$. In accordance with Proposition
\ref{prop.grad.g}, we grade $\mathfrak{g}$ by setting $\deg e=1$, $\deg f=-1$
and $\deg h=0$. Then, $\mathfrak{n}_{+}=\left\langle e\right\rangle $,
$\mathfrak{n}_{-}=\left\langle f\right\rangle $ and $\mathfrak{h}=\left\langle
h\right\rangle $. Hence, linear maps $\lambda:\mathfrak{h}\rightarrow
\mathbb{C}$ are in 1-to-1 correspondence with complex numbers (namely, the
images $\lambda\left(  h\right)  $ of $h$ under these maps). Thus, we can
identify any linear map $\lambda:\mathfrak{h}\rightarrow\mathbb{C}$ with the
image $\lambda\left(  h\right)  \in\mathbb{C}$.

Consider any $\lambda\in\mathfrak{h}^{\ast}$. Since $\mathfrak{n}%
_{-}=\left\langle f\right\rangle $, the universal enveloping algebra $U\left(
\mathfrak{n}_{-}\right)  $ is the polynomial algebra $\mathbb{C}\left[
f\right]  $, and Proposition \ref{prop.verma1} \textbf{(a)} yields
$M_{\lambda}^{+}=\underbrace{U\left(  \mathfrak{n}_{-}\right)  }%
_{=\mathbb{C}\left[  f\right]  }v_{\lambda}^{+}=\mathbb{C}\left[  f\right]
v_{\lambda}^{+}$. Similarly, $M_{-\lambda}^{-}=\mathbb{C}\left[  e\right]
v_{-\lambda}^{-}$. In order to compute the bilinear form $\left(  \cdot
,\cdot\right)  $ on $M_{\lambda}^{+}\times M_{-\lambda}^{-}$, it is thus
enough to compute $\left(  f^{n}v_{\lambda}^{+},e^{n}v_{-\lambda}^{-}\right)
$ for all $n\in\mathbb{N}$. (The values $\left(  f^{n}v_{\lambda}^{+}%
,e^{m}v_{-\lambda}^{-}\right)  $ for $n\neq m$ are zero since the form has
degree $0$.) In order to do this, we notice that $e^{n}f^{n}v_{\lambda}%
^{+}=n!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-n+1\right)
v_{\lambda}^{+}$\ \ \ \ \footnote{\textit{Proof.} Here is a sketch of the
proof. (If you want to see it in details, read the proof of Lemma
\ref{lem.serre-gen.sl2} \textbf{(a)} below; this lemma yields the equality
$e^{n}f^{n}v_{\lambda}^{+}=n!\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  v_{\lambda}^{+}$ by substituting $x=v_{\lambda}^{+}$.)
\par
First show that $hf^{m}v_{\lambda}^{+}=\left(  \lambda-2m\right)
f^{m}v_{\lambda}^{+}$ for every $m\in\mathbb{N}$. (This follows easily by
induction over $m$, using $hf-fh=\left[  h,f\right]  =-2f$.)
\par
Next show that $ef^{n}v_{\lambda}^{+}=n\left(  \lambda-n+1\right)
f^{n-1}v_{\lambda}^{+}$ for every positive $n\in\mathbb{N}$. (This is again an
easy induction proof using the equalities $ef-fe=\left[  e,f\right]  =h$,
$hv_{\lambda}^{+}=\underbrace{\lambda\left(  h\right)  }_{=\lambda}v_{\lambda
}^{+}=\lambda v_{\lambda}^{+}$ and $ev_{\lambda}^{+}=0$, and using the
equality $hf^{m}v_{\lambda}^{+}=\left(  \lambda-2m\right)  f^{m}v_{\lambda
}^{+}$ applied to $m=n-1$.)
\par
Now show that $e^{n}f^{n}v_{\lambda}^{+}=n!\lambda\left(  \lambda-1\right)
...\left(  \lambda-n+1\right)  v_{\lambda}^{+}$ for every $n\in\mathbb{N}$.
(For this, again use induction.)} and thus%
\begin{align}
\left(  f^{n}v_{\lambda}^{+},e^{n}v_{-\lambda}^{-}\right)   &  =\left(
\underbrace{S\left(  e^{n}\right)  }_{=\left(  -1\right)  ^{n}e^{n}}%
f^{n}v_{\lambda}^{+},v_{-\lambda}^{-}\right)  =\left(  \left(  -1\right)
^{n}\underbrace{e^{n}f^{n}v_{\lambda}^{+}}_{\substack{=n!\lambda\left(
\lambda-1\right)  ...\left(  \lambda-n+1\right)  v_{\lambda}^{+}}%
},v_{-\lambda}^{-}\right) \nonumber\\
&  =\left(  \left(  -1\right)  ^{n}n!\lambda\left(  \lambda-1\right)
...\left(  \lambda-n+1\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right)
\nonumber\\
&  =\left(  -1\right)  ^{n}n!\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  \underbrace{\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  }_{=1}\label{exa.sl2.bilinform}\\
&  =\left(  -1\right)  ^{n}n!\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  .\nonumber
\end{align}
So $M_{\lambda}^{+}$ is irreducible if $\lambda\notin\mathbb{Z}_{+}$. If
$\lambda\in\mathbb{Z}_{+}$, then $J_{\lambda}^{+}=\left\langle f^{n}%
v_{\lambda}^{+}\ \mid\ n\geq\lambda+1\right\rangle =\mathbb{C}\left[
f\right]  \cdot\left(  f^{\lambda+1}v_{\lambda}^{+}\right)  $, and the
irreducible $\mathfrak{g}$-module $L_{\lambda}^{+}=\left\langle \overline
{v_{\lambda}^{+}},f\overline{v_{\lambda}^{+}},...,f^{\lambda}\overline
{v_{\lambda}^{+}}\right\rangle $ has dimension $\dim\lambda+1$%
.\ \ \ \ \footnote{If you know the representation theory of $\mathfrak{sl}%
_{2}$, you probably recognize this module $L_{\lambda}^{+}$ as the $\left(
\dim\lambda\right)  $-th symmetric power of the vector module $\mathbb{C}^{2}$
(as there is only one irreducible $\mathfrak{sl}_{2}$-module of every
dimension).}
\end{example}

\begin{example}
\label{exa.Vir}Let $\mathfrak{g}=\operatorname*{Vir}$. With the grading that
we have defined on $\operatorname*{Vir}$, we have $\mathfrak{h}=\mathfrak{g}%
_{0}=\left\langle L_{0},C\right\rangle $. Thus, linear maps $\lambda
:\mathfrak{h}\rightarrow\mathbb{C}$ can be uniquely described by the images of
$L_{0}$ and $C$ under these maps. We thus identify every linear map
$\lambda:\mathfrak{h}\rightarrow\mathbb{C}$ with the pair $\left(
\lambda\left(  L_{0}\right)  ,\lambda\left(  C\right)  \right)  $.

For every $\lambda=\left(  \lambda\left(  L_{0}\right)  ,\lambda\left(
C\right)  \right)  $, the number $\lambda\left(  L_{0}\right)  $ is denoted by
$h$ and called the \textit{conformal weight} of $\lambda$, and the number
$\lambda\left(  C\right)  $ is denoted by $c$ and called the \textit{central
charge} of $\lambda$. Thus, $\lambda$ is identified with the pair $\left(
h,c\right)  $. As a consequence, the Verma modules $M_{\lambda}^{+}$ and
$M_{\lambda}^{-}$ are often denoted by $M_{h,c}^{+}$ and $M_{h,c}^{-}$,
respectively, and the modules $L_{\lambda}^{+}$ and $L_{\lambda}^{-}$ are
often denoted by $L_{h,c}^{+}$ and $L_{h,c}^{-}$, respectively.

(Note, of course, that the central charge of $\lambda$ is the central charge
of each of the $\operatorname*{Vir}$-modules $M_{\lambda}^{+}$, $M_{\lambda
}^{-}$, $L_{\lambda}^{+}$ and $L_{\lambda}^{-}$.)

Consider any $\lambda\in\mathfrak{h}^{\ast}$. Let us compute the bilinear form
$\left(  \cdot,\cdot\right)  $ on $M_{\lambda}^{+}\times M_{-\lambda}^{-}$.
Note first that $L_{0}v_{\lambda}^{+}=\underbrace{\lambda\left(  L_{0}\right)
}_{=h}v_{\lambda}^{+}=hv_{\lambda}^{+}$ and $Cv_{\lambda}^{+}%
=\underbrace{\lambda\left(  C\right)  }_{=c}v_{\lambda}^{+}=cv_{\lambda}^{+}$.

In order to compute $\left(  L_{-1}v_{\lambda}^{+},L_{1}v_{-\lambda}%
^{-}\right)  $, we notice that
\[
\underbrace{L_{1}L_{-1}}_{=L_{-1}L_{1}+\left[  L_{1},L_{-1}\right]
}v_{\lambda}^{+}=L_{-1}\underbrace{L_{1}v_{\lambda}^{+}}_{=0}%
+\underbrace{\left[  L_{1},L_{-1}\right]  }_{=2L_{0}}v_{\lambda}%
^{+}=2\underbrace{L_{0}v_{\lambda}^{+}}_{=hv_{\lambda}^{+}}=2hv_{\lambda}%
^{+},
\]
so that%
\[
\left(  L_{-1}v_{\lambda}^{+},L_{1}v_{-\lambda}^{-}\right)  =\left(
-\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}},v_{-\lambda}%
^{-}\right)  =\left(  -2hv_{\lambda}^{+},v_{-\lambda}^{-}\right)
=-2h\underbrace{\left(  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  }_{=1}=-2h.
\]
Since $\left(  L_{-1}v_{\lambda}^{+}\right)  $ is a basis of $M_{\lambda}%
^{+}\left[  -1\right]  $ and $\left(  L_{1}v_{-\lambda}^{-}\right)  $ is a
basis of $M_{-\lambda}^{-}\left[  1\right]  $, this yields $\det\left(
\left(  \cdot,\cdot\right)  _{1}\right)  =2h$ (where $\left(  \cdot
,\cdot\right)  _{1}$ denotes the restriction of the form $\left(  \cdot
,\cdot\right)  $ to $M_{\lambda}^{+}\left[  -1\right]  \times M_{-\lambda}%
^{-}\left[  1\right]  $). This vanishes for $h=0$.

In degree $2$, the form is somewhat more complicated: With respect to the
basis $\left(  L_{-1}^{2}v_{\lambda}^{+},L_{-2}v_{\lambda}^{+}\right)  $ of
$M_{\lambda}^{+}\left[  -2\right]  $, and the basis $\left(  L_{1}%
^{2}v_{-\lambda}^{-},L_{2}v_{-\lambda}^{-}\right)  $ of $M_{-\lambda}%
^{-}\left[  2\right]  $, the restriction $\left(  \cdot,\cdot\right)  _{2}$ of
the form $\left(  \cdot,\cdot\right)  $ to $M_{\lambda}^{+}\left[  -2\right]
\times M_{-\lambda}^{-}\left[  2\right]  $ is given by the matrix%
\[
\left(
\begin{array}
[c]{cc}%
\left(  L_{-1}^{2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda}^{-}\right)  & \left(
L_{-1}^{2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right) \\
\left(  L_{-2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda}^{-}\right)  & \left(
L_{-2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right)
\end{array}
\right)  .
\]


Let us compute, as an example, the lower right entry of this matrix, that is,
the entry $\left(  L_{-2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right)  $. We
have%
\begin{align*}
\underbrace{L_{2}L_{-2}}_{=L_{-2}L_{2}+\left[  L_{2},L_{-2}\right]
}v_{\lambda}^{+}  &  =L_{-2}\underbrace{L_{2}v_{\lambda}^{+}}_{=0}%
+\underbrace{\left[  L_{2},L_{-2}\right]  }_{=4L_{0}+\dfrac{1}{2}C}v_{\lambda
}^{+}=\left(  4L_{0}+\dfrac{1}{2}C\right)  v_{\lambda}^{+}=4\underbrace{L_{0}%
v_{\lambda}^{+}}_{=hv_{\lambda}^{+}}+\dfrac{1}{2}\underbrace{Cv_{\lambda}^{+}%
}_{=cv_{\lambda}^{+}}\\
&  =4hv_{\lambda}^{+}+\dfrac{1}{2}cv_{\lambda}^{+}=\left(  4h+\dfrac{1}%
{2}c\right)  v_{\lambda}^{+},
\end{align*}
so that%
\begin{align*}
\left(  L_{-2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right)   &  =\left(
-\underbrace{L_{2}L_{-2}v_{\lambda}^{+}}_{=\left(  4h+\dfrac{1}{2}c\right)
v_{\lambda}^{+}},v_{-\lambda}^{-}\right)  =\left(  -\left(  4h+\dfrac{1}%
{2}c\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right) \\
&  =-\left(  4h+\dfrac{1}{2}c\right)  \underbrace{\left(  v_{\lambda}%
^{+},v_{-\lambda}^{-}\right)  }_{=1}=-\left(  4h+\dfrac{1}{2}c\right)  .
\end{align*}
As a further (more complicated) example, let us compute the upper left entry
of the matrix, namely $\left(  L_{-1}^{2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda
}^{-}\right)  $. We have%
\begin{align*}
L_{1}^{2}L_{-1}^{2}v_{\lambda}^{+}  &  =L_{1}\underbrace{L_{1}L_{-1}}%
_{=L_{-1}L_{1}+\left[  L_{1},L_{-1}\right]  }L_{-1}v_{\lambda}^{+}=L_{1}%
L_{-1}\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}}%
+L_{1}\underbrace{\left[  L_{1},L_{-1}\right]  }_{=2L_{0}}L_{-1}v_{\lambda
}^{+}\\
&  =2h\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}}%
+2L_{1}\underbrace{L_{0}L_{-1}}_{\substack{=L_{-1}L_{0}+\left[  L_{0}%
,L_{-1}\right]  \\=L_{-1}L_{0}+L_{-1}\\\text{(since }\left[  L_{0}%
,L_{-1}\right]  =L_{-1}\text{)}}}v_{\lambda}^{+}=4h^{2}v_{\lambda}^{+}%
+2L_{1}L_{-1}\underbrace{L_{0}v_{\lambda}^{+}}_{=hv_{\lambda}^{+}%
}+2\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}}\\
&  =4h^{2}v_{\lambda}^{+}+2h\underbrace{L_{1}L_{-1}v_{\lambda}^{+}%
}_{=2hv_{\lambda}^{+}}+4hv_{\lambda}^{+}=4h^{2}v_{\lambda}^{+}+4h^{2}%
v_{\lambda}^{+}+4hv_{\lambda}^{+}=\left(  8h^{2}+4h\right)  v_{\lambda}^{+}%
\end{align*}
and thus%
\begin{align*}
\left(  L_{-1}^{2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda}^{-}\right)   &
=\left(  -L_{1}L_{-1}^{2}v_{\lambda}^{+},L_{1}v_{-\lambda}^{-}\right)
=\left(  \underbrace{L_{1}^{2}L_{-1}^{2}v_{\lambda}^{+}}_{=\left(
8h^{2}+4h\right)  v_{\lambda}^{+}},v_{-\lambda}^{-}\right)  =\left(  \left(
8h^{2}+4h\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right) \\
&  =\left(  8h^{2}+4h\right)  \underbrace{\left(  v_{\lambda}^{+},v_{-\lambda
}^{-}\right)  }_{=1}=8h^{2}+4h.
\end{align*}


Similarly, we compute the other two entries of the matrix. The matrix thus
becomes%
\[
\left(
\begin{array}
[c]{cc}%
8h^{2}+4h & 6h\\
-6h & -\left(  4h+\dfrac{1}{2}c\right)
\end{array}
\right)  .
\]
The determinant of this matrix is%
\[
\det\left(  \left(  \cdot,\cdot\right)  _{2}\right)  =\left(  8h^{2}%
+4h\right)  \left(  -\left(  4h+\dfrac{1}{2}c\right)  \right)  -6h\left(
-6h\right)  =-4h\left(  \left(  2h+1\right)  \left(  4h+\dfrac{1}{2}c\right)
-9h\right)  .
\]
Notice the term $\left(  2h+1\right)  \left(  4h+\dfrac{1}{2}c\right)  -9h$:
The set of zeroes of this term is a hyperbola\footnote{Here, a
\textit{hyperbola} means an affine conic over $\mathbb{C}$ which is defined
over $\mathbb{R}$ and whose restriction to $\mathbb{R}$ is a hyperbola.}. The
determinant of $\left(  \cdot,\cdot\right)  _{2}$ thus vanishes on the union
of a line and a hyperbola. For every point $\left(  h,c\right)  $ lying on
this hyperbola, the highest-weight module $M_{h,c}^{+}$ has a nonzero singular
vector in degree $-2$ (this means a nonzero singular vector of the form
$\alpha L_{-2}v_{\lambda}^{+}+\beta L_{-1}^{2}v_{\lambda}^{+}$ for some
$\alpha,\beta\in\mathbb{C}$).

We will later discuss $\det\left(  \left(  \cdot,\cdot\right)  _{n}\right)  $
for generic $n$. In fact, there is an explicit formula for this determinant,
namely the so-called Kac determinant formula.
\end{example}

\subsubsection{Restricted dual modules}

\begin{definition}
Let $V=\bigoplus\limits_{i\in I}V\left[  i\right]  $ be an $I$-graded vector
space, where $I$ is some set (for example, $I$ can be $\mathbb{Z}$,
$\mathbb{N}$ or $\mathbb{C}$). The \textit{restricted dual} $V^{\vee}$ of $V$
is defined to be the direct sum $\bigoplus\limits_{i\in I}V\left[  i\right]
^{\ast}$. This is a vector subspace of the dual $V^{\ast}$ of $V$, but (in
general) not the same as $V^{\ast}$ unless the direct sum is finite.

One can make the restricted dual $V^{\vee}$ into an $I$-graded vector space by
defining $V^{\vee}\left[  i\right]  =V\left[  i\right]  ^{\ast}$ for every
$i\in I$. But when $I$ is an abelian group, one can also make the restricted
dual $V^{\vee}$ into an $I$-graded vector space by defining $V^{\vee}\left[
i\right]  =V\left[  -i\right]  ^{\ast}$ for every $i\in I$. These two
constructions result in two (generally) \textbf{different} gradings on
$V^{\vee}$; both of these gradings are used in algebra.

Using either of these two gradings on $V^{\vee}$, we can make sense of the
restricted dual $V^{\vee\vee}$ of $V^{\vee}$. This restricted dual
$V^{\vee\vee}$ does not depend on which of the two gradings on $V^{\vee}$ has
been chosen. There is a canonical injection $V\rightarrow V^{\vee\vee}$. If
$V\left[  i\right]  $ is finite-dimensional for every $i\in I$, then this
injection $V\rightarrow V^{\vee\vee}$ is an isomorphism (so that $V^{\vee\vee
}\cong V$ canonically).

If $\mathfrak{g}$ is a $\mathbb{Z}$-graded Lie algebra, and $V$ is a
$\mathbb{C}$-graded $\mathfrak{g}$-module, then $V^{\vee}$ canonically becomes
a $\mathbb{C}$-graded $\mathfrak{g}$-module if the grading on $V^{\vee}$ is
defined by $V^{\vee}\left[  i\right]  =V\left[  -i\right]  ^{\ast}$ for every
$i\in\mathbb{C}$. (Note that the grading defined by $V^{\vee}\left[  i\right]
=V\left[  i\right]  ^{\ast}$ for every $i\in\mathbb{C}$ would \textbf{not} (in
general) make $V^{\vee}$ into a $\mathbb{C}$-graded $\mathfrak{g}$-module.)
\end{definition}

It is clear that:

\begin{proposition}
We have two mutually inverse antiequivalences of categories $\mathcal{O}%
^{+}\overset{\vee}{\rightarrow}\mathcal{O}^{-}$ and $\mathcal{O}%
^{-}\overset{\vee}{\rightarrow}\mathcal{O}^{+}$, each defined by mapping every
$\mathfrak{g}$-module in one category to its restricted dual.
\end{proposition}

We can view the form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$ as a linear map $M_{\lambda}%
^{+}\rightarrow\left(  M_{-\lambda}^{-}\right)  ^{\vee}$. The kernel of this
map is $J_{\lambda}^{+}$, and therefore, when $\mathfrak{g}$ is nondegenerate,
this map is an isomorphism for Weil-generic $\lambda$ (by Theorem
\ref{thm.invformnondeg}). In general, this map factors as $%
%TCIMACRO{\TeXButton{diag}{\xymatrix{
%M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong} &
%\left(L^{-}_{-\lambda}\right)^{\vee} \arinj[r] & \left(M^{-}_{-\lambda}%
%\right)^{\vee}
%}}}%
%BeginExpansion
\xymatrix{
M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong} &
\left(L^{-}_{-\lambda}\right)^{\vee} \arinj[r] & \left(M^{-}_{-\lambda}%
\right)^{\vee}
}%
%EndExpansion
$.

\subsubsection{\label{subsect.invol}Involutions}

In many applications, we are not just working with a graded Lie algebra
$\mathfrak{g}$. Very often we additionally have a degree-reversing involution:

\begin{definition}
\label{def.invol}Let $\mathfrak{g}$ be a graded Lie algebra. Let
$\omega:\mathfrak{g}\rightarrow\mathfrak{g}$ be an involutive automorphism of
the Lie algebra $\mathfrak{g}$ (``involutive'' means $\omega^{2}%
=\operatorname*{id}$) such that $\omega\left(  \mathfrak{g}_{i}\right)
=\mathfrak{g}_{-i}$ for all $i\in\mathbb{Z}$ and such that $\omega
\mid_{\mathfrak{g}_{0}}=-\operatorname*{id}$. Then, for every graded
$\mathfrak{g}$-module $M$, we can define a graded $\mathfrak{g}$-module
$M^{c}$ as being the $\mathfrak{g}$-module $M^{\omega}$ with opposite grading
(i. e., the grading on $M^{c}$ is defined by $M^{c}\left[  i\right]
=M^{\omega}\left[  -i\right]  $ for every $i$). Then, we have an equivalence
of categories $\mathcal{O}^{+}\overset{\omega}{\rightarrow}\mathcal{O}^{-}$
which sends every $\mathfrak{g}$-module $M\in\mathcal{O}^{+}$ to the
$\mathfrak{g}$-module $M^{c}\in\mathcal{O}^{-}$, and the quasiinverse
equivalence of categories $\mathcal{O}^{-}\overset{\omega}{\rightarrow
}\mathcal{O}^{+}$ which does the same thing.

So the functor $\mathcal{O}^{+}\overset{\vee}{\rightarrow}\mathcal{O}%
^{-}\overset{\omega}{\rightarrow}\mathcal{O}^{+}$ is an antiequivalence,
called the \textit{functor of contragredient module}. This functor allows us
to identify $\left(  M_{-\lambda}^{-}\right)  ^{\omega}$ with $M_{\lambda}%
^{+}$ (via the isomorphism $M_{\lambda}^{+}\rightarrow\left(  M_{-\lambda}%
^{-}\right)  ^{\omega}$ which sends $x\otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }v_{\lambda}^{+}$ to $\left(  U\left(
\omega\right)  \right)  \left(  x\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }v_{-\lambda}^{-}$ for every $x\in U\left(
\mathfrak{g}\right)  $), and thus to view the form $\left(  \cdot
,\cdot\right)  $ as a form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times
M_{\lambda}^{+}\rightarrow\mathbb{C}$. But this form is not $\mathfrak{g}%
$-invariant; it is contravariant; this means that any $a\in\mathfrak{g}$,
$v\in M_{\lambda}^{+}$ and $w\in M_{\lambda}^{+}$ satisfy $\left(
av,w\right)  =-\left(  v,\omega\left(  a\right)  w\right)  $ and $\left(
v,aw\right)  =-\left(  \omega\left(  a\right)  v,w\right)  $.

This form can be viewed as a linear map $M_{\lambda}^{+}\rightarrow\left(
M_{\lambda}^{+}\right)  ^{c}$, which factors into $%
%TCIMACRO{\TeXButton{diag}{\xymatrix{
%M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong}
%& \left(L^{+}_{\lambda}\right)^{c} \arinj[r] & \left(M^{+}_{\lambda}%
%\right)^{c}
%}}}%
%BeginExpansion
\xymatrix{
M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong}
& \left(L^{+}_{\lambda}\right)^{c} \arinj[r] & \left(M^{+}_{\lambda}%
\right)^{c}
}%
%EndExpansion
$.

Notice that this form $\left(  \cdot,\cdot\right)  $ is a contravariant form
$M_{\lambda}^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}$ satisfying
$\left(  v_{\lambda}^{+},v_{\lambda}^{+}\right)  =1$. Of course, this yields
that the transpose of $\left(  \cdot,\cdot\right)  $ is also such a form.
Since there exists a \textbf{unique} contravariant form $M_{\lambda}^{+}\times
M_{\lambda}^{+}\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}%
^{+},v_{\lambda}^{+}\right)  =1$ (because contravariant forms $M_{\lambda}%
^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}$ are in 1-to-1 correspondence
with $\mathfrak{g}$-invariant bilinear forms $M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$, and for the latter we have Proposition
\ref{prop.invform} \textbf{(a)}), this yields that the form $\left(
\cdot,\cdot\right)  $ and its transpose must be identical. In other words, the
form $\left(  \cdot,\cdot\right)  $ is symmetric.
\end{definition}

Involutive automorphisms of $\mathfrak{g}$ satisfying the conditions of
Definition \ref{def.invol} are not uncommon; here are four examples:

\begin{proposition}
\label{prop.invol.A}The $\mathbb{C}$-linear map $\omega:\mathcal{A}%
\rightarrow\mathcal{A}$ defined by $\omega\left(  K\right)  =-K$ and
$\omega\left(  a_{i}\right)  =-a_{-i}$ for every $i\in\mathbb{Z}$ is an
involutive automorphism of the Lie algebra $\mathcal{A}$. This automorphism
$\omega$ satisfies the conditions of Definition \ref{def.invol} (for
$\mathfrak{g}=\mathcal{A}$). We already know this from Proposition
\ref{prop.A.omega}. Moreover, if we let $\lambda=\left(  1,\mu\right)  $ for a
complex number $\mu$, then $M_{\lambda}^{+}\cong F_{\mu}$ (by Proposition
\ref{prop.fockverma.A}), and thus we can regard the contravariant form
$M_{\lambda}^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}$ from Definition
\ref{def.invol} as a contravariant form $F_{\mu}\times F_{\mu}\rightarrow
\mathbb{C}$. This contravariant form $F_{\mu}\times F_{\mu}\rightarrow
\mathbb{C}$ is exactly the form $\left(  \cdot,\cdot\right)  $ of Proposition
\ref{prop.A.contravariantform}. (This is because the form $\left(  \cdot
,\cdot\right)  $ of Proposition \ref{prop.A.contravariantform} is
contravariant (due to Proposition \ref{prop.A.contravariantform} \textbf{(c)}
and \textbf{(d)}) and satisfies $\left(  1,1\right)  =1$.)
\end{proposition}

\begin{proposition}
The $\mathbb{C}$-linear map $\omega:\operatorname*{Vir}\rightarrow
\operatorname*{Vir}$ defined by $\omega\left(  C\right)  =-C$ and
$\omega\left(  L_{i}\right)  =-L_{-i}$ for every $i\in\mathbb{Z}$ is an
involutive automorphism of the Lie algebra $\operatorname*{Vir}$. This
automorphism $\omega$ satisfies the conditions of Definition \ref{def.invol}
(for $\mathfrak{g}=\operatorname*{Vir}$).
\end{proposition}

\begin{proposition}
\label{prop.simple.omega}Let $\mathfrak{g}$ be a simple Lie algebra, graded
and presented as in Proposition \ref{prop.grad.g}. Then, there exists a unique
Lie algebra homomorphism $\omega:\mathfrak{g}\rightarrow\mathfrak{g}$
satisfying $\omega\left(  e_{i}\right)  =-f_{i}$, $\omega\left(  h_{i}\right)
=-h_{i}$ and $\omega\left(  f_{i}\right)  =-e_{i}$ for every $i\in\left\{
1,2,...,m\right\}  $. This automorphism $\omega$ satisfies the conditions of
Definition \ref{def.invol}.
\end{proposition}

\begin{proposition}
Let $\mathfrak{g}$ be a simple finite-dimensional Lie algebra, graded and
presented as in Proposition \ref{prop.grad.g}. Let $\widehat{\mathfrak{g}}$ be
the Kac-Moody Lie algebra defined in Definition \ref{def.kac}. Let $K$ denote
the element $\left(  0,1\right)  $ of $\mathfrak{g}\left[  t,t^{-1}\right]
\oplus\mathbb{C}=\widehat{\mathfrak{g}}$. Consider the $\mathbb{Z}$-grading on
$\widehat{\mathfrak{g}}$ defined in Proposition \ref{prop.grad.ghat.simple}.

Let $\omega:\mathfrak{g}\rightarrow\mathfrak{g}$ be defined as in Proposition
\ref{prop.simple.omega}. Then, the $\mathbb{C}$-linear map $\widehat{\omega
}:\widehat{\mathfrak{g}}\rightarrow\widehat{\mathfrak{g}}$ defined by
$\widehat{\omega}\left(  a\cdot t^{j}\right)  =\omega\left(  a\right)  t^{-j}$
for every $a\in\mathfrak{g}$ and $j\in\mathbb{Z}$, and $\widehat{\omega
}\left(  K\right)  =-K$, is an involutive automorphism of the Lie algebra
$\widehat{\mathfrak{g}}$. This automorphism $\widehat{\omega}$ satisfies the
conditions of Definition \ref{def.invol} (for $\widehat{\mathfrak{g}}$ and
$\widehat{\omega}$ instead of $\mathfrak{g}$ and $\omega$).
\end{proposition}

More generally:

\begin{proposition}
Let $\mathfrak{g}$ be a Lie algebra equipped with a $\mathfrak{g}$-invariant
symmetric bilinear form $\left(  \cdot,\cdot\right)  $ of degree $0$. Let
$\widehat{\mathfrak{g}}$ be the Lie algebra defined in Definition
\ref{def.loop}. Let $K$ denote the element $\left(  0,1\right)  $ of
$\mathfrak{g}\left[  t,t^{-1}\right]  \oplus\mathbb{C}=\widehat{\mathfrak{g}}$.

Let $\omega:\mathfrak{g}\rightarrow\mathfrak{g}$ be an involutive automorphism
of the Lie algebra $\mathfrak{g}$ (not to be confused with the $2$-cocycle
$\omega$ of Definition \ref{def.loop}). Then, the $\mathbb{C}$-linear map
$\widehat{\omega}:\widehat{\mathfrak{g}}\rightarrow\widehat{\mathfrak{g}}$
defined by $\widehat{\omega}\left(  a\cdot t^{j}\right)  =\omega\left(
a\right)  t^{-j}$ for every $a\in\mathfrak{g}$ and $j\in\mathbb{Z}$, and
$\widehat{\omega}\left(  K\right)  =-K$, is an involutive automorphism of the
Lie algebra $\widehat{\mathfrak{g}}$.

Assume now that the Lie algebra $\mathfrak{g}$ is graded and that the
automorphism $\omega$ satisfies the conditions of Definition \ref{def.invol}.
Assume further that we extend the grading of $\mathfrak{g}$ to a grading on
$\widehat{\mathfrak{g}}$ in such a way that $K$ is homogeneous of degree $0$,
and that the multiplications by $t$ and $t^{-1}$ are homogeneous linear maps
(that is, linear maps which shift the degree by a fixed integer). Then, the
automorphism $\widehat{\omega}$ of $\widehat{\mathfrak{g}}$ satisfies
$\widehat{\omega}\left(  \widehat{\mathfrak{g}}_{i}\right)
=\widehat{\mathfrak{g}}_{-i}$ for all $i\in\mathbb{Z}$. (But in general,
$\widehat{\omega}$ does not necessarily satisfy $\widehat{\omega}%
\mid_{\widehat{\mathfrak{g}}_{0}}=-\operatorname*{id}$.)
\end{proposition}

\subsubsection{\textbf{[unfinished]} Unitary structures}

\begin{impnot}
\textbf{The parts of these notes concerned with unitary/Hermitian/real
structures are in an unfinished state and contain mistakes which I don't know
how to fix.}

For instance, if we define $\mathfrak{g}_{\mathbb{R}}$ by $\mathfrak{g}%
_{\mathbb{R}}=\left\{  a\in\mathfrak{g}\ \mid\ a^{\dag}=-a\right\}  $, and
define $\mathfrak{g}_{0\mathbb{R}}^{\ast}$ by $\mathfrak{g}_{0\mathbb{R}%
}^{\ast}=\left\{  f\in\mathfrak{g}_{0}^{\ast}\ \mid\ f\left(  \mathfrak{g}%
_{0\mathbb{R}}\right)  \subseteq\mathbb{R}\right\}  $ (as I do below), and
define the antilinear $\mathbb{R}$-antiinvolution $\dag:\operatorname*{Vir}%
\rightarrow\operatorname*{Vir}$ on $\operatorname*{Vir}$ by $L_{i}^{\dag
}=L_{-i}$ for all $i\in\mathbb{Z}$, and $C^{\dag}=C$, then
$\operatorname*{Vir}\nolimits_{0\mathbb{R}}^{\ast}$ is \textbf{not} the set of
all weights $\left(  h,c\right)  $ satisfying $h,c\in\mathbb{R}$, but it is
the set of all weights $\left(  h,c\right)  $ satisfying $ih,ic\in\mathbb{R}$
(because the definition of $\dag$ that we gave leads to $\operatorname*{Vir}%
\nolimits_{0\mathbb{R}}=\left\langle iC,iL_{0}\right\rangle _{\mathbb{R}}$).
This is not what we want later. Probably it is possible to fix these issues by
correcting some signs, but I do not know how. If you know a consistent way to
correct these definitions and results, please drop me a mail
(AB\texttt{@gmail.com} where A=\texttt{darij} and B=\texttt{grinberg}).
\end{impnot}

Over $\mathbb{C}$, it makes sense to study not only linear but also antilinear
maps. Sometimes, the latter actually enjoy even better properties of the
former (e. g., Hermitian forms are better behaved than complex-symmetric forms).

\begin{definition}
If $\mathfrak{g}$ and $\mathfrak{h}$ are two Lie algebras over a field $k$,
then a $k$-\textit{antihomomorphism} from $\mathfrak{g}$ to $\mathfrak{h}$
means a $k$-linear map $f:\mathfrak{g}\rightarrow\mathfrak{h}$ such that
$f\left(  \left[  x,y\right]  \right)  =-\left[  f\left(  x\right)  ,f\left(
y\right)  \right]  $ for all $x,y\in\mathfrak{g}$.
\end{definition}

\begin{definition}
In the following, an \textit{$k$-antiinvolution} of a Lie algebra
$\mathfrak{g}$ over a field $k$ means a $k$-antihomomorphism from
$\mathfrak{g}$ to $\mathfrak{g}$ which is simultaneously an involution.
\end{definition}

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra. Let $\dag:\mathfrak{g}%
\rightarrow\mathfrak{g}$ be an antilinear $\mathbb{R}$-antiinvolution. This
means that $\dag$ is an $\mathbb{R}$-linear map and satisfies the relations%
\begin{align*}
\dag^{2}  &  =\operatorname*{id};\\
\left(  za\right)  ^{\dag}  &  =\overline{z}a^{\dag}%
\ \ \ \ \ \ \ \ \ \ \text{for all }z\in\mathbb{C}\text{ and }a\in
\mathfrak{g};\\
\left[  a,b\right]  ^{\dag}  &  =-\left[  a^{\dag},b^{\dag}\right]
\ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in\mathfrak{g}.
\end{align*}
(Here and in the following, we write $c^{\dag}$ for the image of an element
$c\in\mathfrak{g}$ under $\dag$.) Such a map $\dag$ is called a \textit{real
structure}, for the following reason: If $\dag$ is such a map, then we can
define an $\mathbb{R}$-vector subspace $\mathfrak{g}_{\mathbb{R}}=\left\{
a\in\mathfrak{g}\ \mid\ a^{\dag}=-a\right\}  $ of $\mathfrak{g}$, and this
$\mathfrak{g}_{\mathbb{R}}$ is a real Lie algebra such that $\mathfrak{g}%
\cong\mathfrak{g}_{\mathbb{R}}\otimes_{\mathbb{R}}\mathbb{C}$ as complex Lie
algebras. (It is said that $\mathfrak{g}_{\mathbb{R}}$ is a \textit{real form}
of $\mathfrak{g}$.)
\end{definition}

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra with a real structure $\dag$. If
$V$ is a $\mathfrak{g}$-module, we say that $V$ is \textit{Hermitian} if $V$
is equipped with a nondegenerate Hermitian form $\left(  \cdot,\cdot\right)  $
satisfying%
\[
\left(  av,w\right)  =\left(  v,a^{\dag}w\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}\text{, }v\in V\text{ and
}w\in V.
\]
The $\mathfrak{g}$-module $V$ is said to be \textit{unitary} if this form is
positive definite.
\end{definition}

The real Lie algebra $\mathfrak{g}_{\mathbb{R}}$ acts on a Hermitian module by
skew-Hermitian operators.

\begin{remark}
While we will not be studying Lie groups in this course, here are some facts
about them that explain why unitary $\mathfrak{g}$-modules are called ``unitary'':

If $\mathfrak{g}$ is a finite-dimensional Lie algebra, and $V$ is a unitary
$\mathfrak{g}$-module, then the Hilbert space completion of $V$ is a unitary
representation of the Lie group $G_{\mathbb{R}}=\exp\left(  \mathfrak{g}%
_{\mathbb{R}}\right)  $ corresponding to $\mathfrak{g}_{\mathbb{R}}$ by Lie's
Third Theorem. (Note that this Hilbert space completion of $V$ is $V$ itself
if $\dim V<\infty$.) This even holds for some infinite-dimensional
$\mathfrak{g}$ under sufficiently restrictive conditions.
\end{remark}

So let us consider this situation. Two definitions:

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra with a real structure $\dag$. Let
$V$ be a $\mathfrak{g}$-module. A Hermitian form $\left(  \cdot,\cdot\right)
$ on $V$ is said to be $\dag$\textit{-invariant} if and only if%
\[
\left(  av,w\right)  =\left(  v,a^{\dag}w\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}\text{, }v\in V\text{ and
}w\in V.
\]

\end{definition}

\begin{definition}
\label{def.gRstar}Let $\mathfrak{g}$ be a complex Lie algebra with a real
structure $\dag$. For every $f\in\mathfrak{g}^{\ast}$, we denote by $f^{\dag}$
the map $\mathfrak{g}_{0}\rightarrow\mathbb{C},$ $x\mapsto\overline{f\left(
x^{\dag}\right)  }$ (this map $f^{\dag}$ is easily seen to be $\mathbb{C}%
$-linear). Let $\mathfrak{g}_{\mathbb{R}}^{\star}$ be the subset $\left\{
f\in\mathfrak{g}^{\ast}\ \mid\ f^{\dag}=-f\right\}  $ of $\mathfrak{g}^{\star
}$. Then, it is easily seen that%
\[
\mathfrak{g}_{\mathbb{R}}^{\star}=\left\{  f\in\mathfrak{g}^{\ast}%
\ \mid\ f\left(  \mathfrak{g}_{\mathbb{R}}\right)  \subseteq\mathbb{R}%
\right\}  .
\]
Hence, we get an $\mathbb{R}$-bilinear form $\mathfrak{g}_{\mathbb{R}}^{\star
}\times\mathfrak{g}_{\mathbb{R}}\rightarrow\mathbb{R},$ $\left(  f,a\right)
\mapsto f\left(  a\right)  $. This form is nondegenerate and thus enables us
to identify $\mathfrak{g}_{\mathbb{R}}^{\star}$ with the dual space of the
$\mathbb{R}$-vector space $\mathfrak{g}_{\mathbb{R}}$. (More precisely, we
have an isomorphism from $\mathfrak{g}_{\mathbb{R}}^{\star}$ to the dual space
of the $\mathbb{R}$-vector space $\mathfrak{g}_{\mathbb{R}}$. This isomorphism
sends every $f\in\mathfrak{g}_{\mathbb{R}}^{\star}$ to the map $f\mid
_{\mathfrak{g}_{\mathbb{R}}}$ (with target restricted to $\mathbb{R}$), and
conversely, the preimage of any $\mathbb{R}$-linear map $F:\mathfrak{g}%
_{\mathbb{R}}\rightarrow\mathbb{R}$ is the $\mathbb{C}$-linear map
$f\in\mathfrak{g}_{\mathbb{R}}^{\star}$ given by%
\[
f\left(  a\right)  =F\left(  \dfrac{a-a^{\dag}}{2}\right)  +iF\left(
\dfrac{a+a^{\dag}}{2i}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }%
a\in\mathfrak{g}.
\]
) We can thus write $\mathfrak{g}_{\mathbb{R}}^{\ast}$ for $\mathfrak{g}%
_{\mathbb{R}}^{\star}$.

The elements of $\mathfrak{g}_{\mathbb{R}}^{\ast}$ are said to be the
\textit{real} elements of $\mathfrak{g}^{\ast}$.
\end{definition}

\begin{proposition}
\label{prop.M+l.unitary}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie
algebra with real structure $\dag$. Assume that the map $\dag$ reverses the
degree (i. e., every $j\in\mathbb{Z}$ satisfies $\dag\left(  \mathfrak{g}%
_{j}\right)  \subseteq\mathfrak{g}_{-j}$). In particular, $\dag\left(
\mathfrak{g}_{0}\right)  \subseteq\mathfrak{g}_{0}$. Also, assume that
$\mathfrak{g}_{0}$ is an abelian Lie algebra (but let us not require
$\mathfrak{g}$ to be nondegenerate). Note that $\mathfrak{g}_{0}$ itself is a
Lie algebra, and thus Definition \ref{def.gRstar} can be applied to
$\mathfrak{g}_{0}$ in lieu of $\mathfrak{g}$.

If $\lambda\in\mathfrak{g}_{0\mathbb{R}}^{\ast}$, then the $\mathfrak{g}%
$-module $M_{\lambda}^{+}$ carries a $\dag$-invariant Hermitian form $\left(
\cdot,\cdot\right)  $ satisfying $\left(  v_{\lambda}^{+},v_{\lambda}%
^{+}\right)  =1$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.M+l.unitary}.} In the following,
whenever $U$ is a $\mathbb{C}$-vector space, we will denote by $\overline{U}$
the $\mathbb{C}$-vector space which is identical to $U$ as a set, but with the
$\mathbb{C}$-vector space structure twisted by complex conjugation.

The antilinear $\mathbb{R}$-Lie algebra homomorphism $-\dag:\mathfrak{g}%
\rightarrow\mathfrak{g}$ can be viewed as a $\mathbb{C}$-Lie algebra
homomorphism $-\dag:\mathfrak{g}\rightarrow\overline{\mathfrak{g}}$, and thus
induces a $\mathbb{C}$-algebra homomorphism $U\left(  -\dag\right)  :U\left(
\mathfrak{g}\right)  \rightarrow U\left(  \overline{\mathfrak{g}}\right)  $.
Since $U\left(  \overline{\mathfrak{g}}\right)  \cong\overline{U\left(
\mathfrak{g}\right)  }$ canonically as $\mathbb{C}$-algebras (because taking
the universal enveloping algebra commutes with base change)\footnote{Warning:
This isomorphism $U\left(  \overline{\mathfrak{g}}\right)  \rightarrow
\overline{U\left(  \mathfrak{g}\right)  }$ sends $i\cdot1_{U\left(
\overline{\mathfrak{g}}\right)  }$ to $-i\cdot1_{U\left(  \mathfrak{g}\right)
}$.}, we can thus consider this $U\left(  -\dag\right)  $ as a $\mathbb{C}%
$-algebra homomorphism $U\left(  \mathfrak{g}\right)  \rightarrow
\overline{U\left(  \mathfrak{g}\right)  }$. This, in turn, can be viewed as an
antilinear $\mathbb{R}$-algebra homomorphism $U\left(  -\dag\right)  :U\left(
\mathfrak{g}\right)  \rightarrow U\left(  \mathfrak{g}\right)  $.

Let $\lambda\in\mathfrak{g}_{0\mathbb{R}}^{\ast}$. Let $\left(  M_{-\lambda
}^{-}\right)  ^{-\dag}$ be the $\mathfrak{g}$-module $M_{-\lambda}^{-}$
twisted by the isomorphism $-\dag:\mathfrak{g}\rightarrow\mathfrak{g}$ of
$\mathbb{R}$-Lie algebras. Then, $\left(  M_{-\lambda}^{-}\right)  ^{-\dag}$
is a module over the $\mathbb{R}$-Lie algebra $\mathfrak{g}$, but not a module
over the $\mathbb{C}$-Lie algebra $\mathfrak{g}$, since it satisfies $\left(
za\right)  \rightharpoonup v=\overline{z}\left(  a\rightharpoonup v\right)  $
(rather than $\left(  za\right)  \rightharpoonup v=z\left(  a\rightharpoonup
v\right)  $) for all $z\in\mathbb{C}$, $a\in\mathfrak{g}$ and $v\in
M_{-\lambda}^{-}$ (where $\rightharpoonup$ denotes the action of
$\mathfrak{g}$). However, this can be easily transformed into a $\mathbb{C}%
$-Lie algebra action: Namely, $\overline{\left(  M_{-\lambda}^{-}\right)
^{-\dag}}$ is a module over the $\mathbb{C}$-Lie algebra $\mathfrak{g}$.

We have an isomorphism%
\begin{align*}
\overline{\left(  M_{-\lambda}^{-}\right)  ^{-\dag}}  &  \rightarrow
M_{\lambda}^{+},\\
x\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }zv_{-\lambda
}^{-}  &  \mapsto U\left(  -\dag\right)  \left(  x\right)  \otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{-}\right)  }\overline{z}v_{\lambda}^{+}%
\end{align*}
of modules over the $\mathbb{C}$-Lie algebra $\mathfrak{g}$%
.\ \ \ \ \footnote{Here are some details on the definition of this
isomorphism:
\par
As $\mathbb{R}$-vector spaces, $\overline{\left(  M_{-\lambda}^{-}\right)
^{-\dag}}=M_{-\lambda}^{-}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{-\lambda}$ and
$M_{\lambda}^{+}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}_{\lambda}$. Hence, we
can define an $\mathbb{R}$-linear map $\overline{\left(  M_{-\lambda}%
^{-}\right)  ^{-\dag}}\rightarrow M_{\lambda}^{+}$ that sends $x\otimes
_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }zv_{-\lambda}^{-}$ to
$U\left(  -\dag\right)  \left(  x\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\overline{z}v_{\lambda}^{+}$ for every $x\in
U\left(  \mathfrak{g}\right)  $ and $z\in\mathbb{C}$ if we are able to show
that
\[
U\left(  -\dag\right)  \left(  xw\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\overline{z}v_{\lambda}^{+}=U\left(
-\dag\right)  \left(  x\right)  \otimes_{U\left(  \mathfrak{h}\oplus
\mathfrak{n}_{-}\right)  }\overline{wz}v_{\lambda}^{+}%
\ \ \ \ \ \ \ \ \ \ \text{for all }x\in U\left(  \mathfrak{g}\right)  \text{,
}w\in U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  \text{ and }%
z\in\mathbb{C}.
\]
But showing this is rather easy (left to the reader), and thus we get an
$\mathbb{R}$-linear map $\overline{\left(  M_{-\lambda}^{-}\right)  ^{-\dag}%
}\rightarrow M_{\lambda}^{+}$ that sends $x\otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }zv_{-\lambda}^{-}$ to $U\left(  -\dag\right)
\left(  x\right)  \otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)
}\overline{z}v_{\lambda}^{+}$ for every $x\in U\left(  \mathfrak{g}\right)  $
and $z\in\mathbb{C}$. This map is easily seen to be $\mathfrak{g}$-linear and
$\mathbb{C}$-linear, so it is a homomorphism of modules over $\mathbb{C}$-Lie
algebra $\mathfrak{g}$. Showing that it is an isomorphism is easy as well (one
just has to construct its inverse).} Hence, $M_{-\lambda}^{-}\cong%
\overline{\left(  M_{\lambda}^{+}\right)  ^{-\dag}}$.

Hence, our bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ can be viewed as a bilinear form $M_{\lambda}^{+}%
\times\overline{M_{\lambda}^{+}}\rightarrow\mathbb{C}$, id est, as a
sesquilinear form $M_{\lambda}^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}%
$. This sesquilinear form is the unique sesquilinear Hermitian form
$M_{\lambda}^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}$ satisfying
$\left(  v_{\lambda}^{+},v_{\lambda}^{+}\right)  =1$\ \ \ \ \footnote{This can
be easily derived from Proposition \ref{prop.invform} \textbf{(a)}, which
claims that our form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$ is the unique $\mathfrak{g}$-invariant
bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$
satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  =1$.}. As a
consequence, this sesquilinear form can be easily seen to be Hermitian
symmetric, i. e., to satisfy%
\[
\left(  v,w\right)  =\overline{\left(  w,v\right)  }%
\ \ \ \ \ \ \ \ \ \ \text{for all }v\in M_{\lambda}^{+}\text{ and }w\in
M_{\lambda}^{+}.
\]
\footnote{In fact, the form which sends $v\times w$ to $\overline{\left(
w,v\right)  }$ is also a sesquilinear Hermitian form $M_{\lambda}^{+}\times
M_{\lambda}^{+}\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}%
^{+},v_{\lambda}^{+}\right)  =1$, so that by uniqueness, it must be identical
with the form which sends $v\times w$ to $\left(  v,w\right)  $.}

However, this form can be degenerate. Its kernel is $J_{\lambda}^{+}$, so it
descends to a nondegenerate Hermitian form on $L_{\lambda}^{+}$. Thus, we get:

\begin{proposition}
\label{prop.hermitian.lambdareal}If $\lambda$ is real (this means that
$\lambda\in\mathfrak{g}_{0\mathbb{R}}^{\ast}$), then $L_{\lambda}^{+}$ carries
a $\dag$-invariant nondegenerate Hermitian form. Different degrees in
$L_{\lambda}^{+}$ are orthogonal with respect to this form.
\end{proposition}

A reasonable (and, in most cases, difficult and interesting) question to ask
is the following: For which $\lambda$ is $L_{\lambda}^{+}$ unitary?

We are going to address this question in some cases and give hints in some
others, leaving many more unanswered.

First, let us give several examples of complex Lie algebras $\mathfrak{g}$
with antilinear $\mathbb{R}$-antiinvolutions $\dag:\mathfrak{g}\rightarrow
\mathfrak{g}$:

\begin{proposition}
We can define an antilinear map $\dag:\mathcal{A}\rightarrow\mathcal{A}$ by
$K^{\dag}=K$ and\ $a_{i}^{\dag}=a_{-i}$ for all $i\in\mathbb{Z}$. This map is
an antilinear $\mathbb{R}$-antiinvolution of the Heisenberg algebra
$\mathcal{A}$.
\end{proposition}

\begin{proposition}
One can define an antilinear map $\dag:\mathfrak{sl}_{2}\rightarrow
\mathfrak{sl}_{2}$ by$\ e^{\dag}=f,\ f^{\dag}=e,\ h^{\dag}=h$. This map is an
antilinear $\mathbb{R}$-antiinvolution of the Lie algebra $\mathfrak{sl}_{2}$.
\end{proposition}

More generally:

\begin{proposition}
Let $\mathfrak{g}$ be a simple finite-dimensional Lie algebra. Using the
Chevalley generators $e_{1}$, $e_{2}$, $...$, $e_{m}$, $f_{1}$, $f_{2}$,
$...$, $f_{m}$, $h_{1}$, $h_{2}$, $...$, $h_{m}$ of Proposition
\ref{prop.grad.g}, we can define an antilinear map $\dag:\mathfrak{g}%
\rightarrow\mathfrak{g}$ by $e_{i}^{\dag}=f_{i},$ $f_{i}^{\dag}=e_{i}%
,\ h_{i}^{\dag}=h_{i}$ for all $i\in\left\{  1,2,...,m\right\}  $. This map is
an antilinear $\mathbb{R}$-antiinvolution of the Lie algebra $\mathfrak{g}$.
\end{proposition}

\begin{proposition}
We can define an antilinear map $\dag:\operatorname*{Vir}\rightarrow
\operatorname*{Vir}$ by $L_{i}^{\dag}=L_{-i}$ for all $i\in\mathbb{Z}$, and
$C^{\dag}=C$. This map is an antilinear $\mathbb{R}$-antiinvolution of the
Virasoro algebra $\operatorname*{Vir}$.
\end{proposition}

\begin{proposition}
If $\mathfrak{g}$ is a Lie algebra with an antilinear $\mathbb{R}%
$-antiinvolution $\dag:\mathfrak{g}\rightarrow\mathfrak{g}$ and with a
symmetric $\mathfrak{g}$-invariant bilinear form $\left(  \cdot,\cdot\right)
$ of degree $0$, then we can define an antilinear map $\dag
:\widehat{\mathfrak{g}}\rightarrow\widehat{\mathfrak{g}}$ (where
$\widehat{\mathfrak{g}}$ is the Lie algebra defined in Definition
\ref{def.loop}) by $\left(  at^{n}\right)  ^{\dag}=a^{\dag}\cdot t^{-n}$ for
every $a\in\mathfrak{g}$ and $n\in\mathbb{Z}$, and by $K^{\dag}=K$ (where $K$
denotes the element $\left(  0,1\right)  $ of $\mathfrak{g}\left[
t,t^{-1}\right]  \oplus\mathbb{C}=\widehat{\mathfrak{g}}$). This map $\dag$ is
an antilinear involution of the Lie algebra $\widehat{\mathfrak{g}}$.
\end{proposition}

As for examples of Hermitian modules: The $\operatorname*{Vir}$-module
$L_{h,c}^{+}$ (see Example \ref{exa.Vir} for the definition of this module)
for $h,c\in\mathbb{R}$ has a $\dag$-invariant nondegenerate Hermitian form.
(This is because the requirement $h,c\in\mathbb{R}$ forces the form
$\lambda\in\mathfrak{g}_{0}^{\ast}$ which corresponds to the pair $\left(
h,c\right)  $ to lie in $\mathfrak{g}_{0\mathbb{R}}^{\ast}$, and thus we can
apply Proposition \ref{prop.hermitian.lambdareal}.)

But now, back to the general case:

\begin{proposition}
\label{prop.unitrick}Let $V$ be a unitary representation in Category
$\mathcal{O}^{+}$. Then, $V$ is completely reducible (i. e., the
representation $V$ is a direct sum of irreducible representations).
\end{proposition}

To prove this, we will use a lemma:

\begin{lemma}
\label{lem.unitrick}If $V$ is a highest-weight representation, and $V$ has a
nondegenerate $\dag$-invariant Hermitian form, then $V$ is irreducible. (We
recall that a ``highest-weight representation'' means a quotient of
$M_{\lambda}^{+}$ by a proper graded submodule for some $\lambda$.)
\end{lemma}

\textit{Proof of Lemma \ref{lem.unitrick}.} Let $V$ be a highest-weight
representation having a nondegenerate $\dag$-invariant Hermitian form. Since
$V$ is a highest-weight representation, $V$ is a quotient of $M_{\lambda}^{+}$
by a proper graded submodule $P$ for some $\lambda$. The nondegenerate $\dag
$-invariant Hermitian form on $V$ thus induces a $\dag$-invariant Hermitian
form on $M_{\lambda}^{+}$ whose kernel is $P$. It is easy to see that
$\lambda$ is real. Thus, this $\dag$-invariant Hermitian form on $M_{\lambda
}^{+}$ can be rewritten as a $\mathfrak{g}$-invariant bilinear form
$M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$, which still has
kernel $P$. Such a form is unique up to scaling (by Proposition
\ref{prop.invform} \textbf{(c)}), and thus must be the form defined in
Proposition \ref{prop.invform} \textbf{(a)}. But the kernel of this form is
$J_{\lambda}^{+}$. Thus, the kernel of this form is, at the same time, $P$ and
$J_{\lambda}^{+}$. Hence, $P=J_{\lambda}^{+}$, so that $V=L_{\lambda}^{+}$
(since $V$ is the quotient of $M_{\lambda}^{+}$ by $P$), and thus $V$ is
irreducible. Lemma \ref{lem.unitrick} is proven.

\textit{Proof of Proposition \ref{prop.unitrick}.} Take a nonzero homogeneous
vector $v\in V$ of maximal degree. (``Maximal'' means ``maximal in real
part''. Such a maximal degree exists by the definition of Category
$\mathcal{O}^{+}$.) Let $v$ be an eigenvector of $\mathfrak{g}_{0}$ with
eigenvalue $\lambda$. Consider the submodule of $V$ generated by $v$. This
submodule is highest-weight (since $\mathfrak{g}_{j}v=0$ for $j>0$). Hence, by
Lemma \ref{lem.unitrick}, this submodule is irreducible and therefore $\cong
L_{\lambda_{1}}^{+}$ for some $\lambda_{1}\in\mathfrak{h}^{\ast}$. Let $V_{1}$
be the orthogonal complement of $L_{\lambda_{1}}^{+}$. Then, $V=L_{\lambda
_{1}}^{+}\oplus V_{1}$. Now take a vector in $V_{1}$, and so on. Since the
degrees of $V$ lie in finitely many arithmetic progressions, and homogeneous
subspaces have finite dimension, this process is exhaustive, so we obtain
$V=L_{\lambda_{1}}^{+}\oplus L_{\lambda_{2}}^{+}\oplus...$.

\begin{remark}
In this decomposition, every irreducible object of Category $\mathcal{O}^{+}$
occurs finitely many times.
\end{remark}
\end{document}
