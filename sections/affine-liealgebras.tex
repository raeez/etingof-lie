\documentclass[etingof-lie.tex]{subfiles}
\begin{document}
\section{Affine Lie algebras}

\subsection{Introducing
\texorpdfstring{$\protect\widehat{\mathfrak{gl}_{n}}$}{gl-n-hat}}

\begin{definition}
\label{def.glnhat}Let $V$ denote the vector representation of $\mathfrak{gl}%
_{\infty}$ defined in Definition~\ref{def.glinf.V}.

Let $n$ be a positive integer. Consider $L\mathfrak{gl}_{n}=\mathfrak{gl}%
_{n}\left[  t,t^{-1}\right]  $; this is the loop algebra of the Lie algebra
$\mathfrak{gl}_{n}$. This loop algebra clearly acts on $\mathbb{C}^{n}\left[
t,t^{-1}\right]  $ (by $\left(  At^{i}\right)  \rightharpoonup\left(
wt^{j}\right)  =Awt^{i+j}$ for all $A\in\mathfrak{gl}_{n}$, $w\in
\mathbb{C}^{n}$, $i\in\mathbb{Z}$ and $j\in\mathbb{Z}$). But we can identify
the vector space $\mathbb{C}^{n}\left[  t,t^{-1}\right]  $ with $V$ as
follows: Let $\left(  e_{1},e_{2},...,e_{n}\right)  $ be the standard basis of
$\mathbb{C}^{n}$. Then we identify $e_{i}t^{k}\in\mathbb{C}^{n}\left[
t,t^{-1}\right]  $ with $v_{i-kn}\in V$ for every $i\in\left\{
1,2,...,n\right\}  $ and $k\in\mathbb{Z}$. The action of $L\mathfrak{gl}_{n}$
on $\mathbb{C}^{n}\left[  t,t^{-1}\right]  $ now becomes an action of
$L\mathfrak{gl}_{n}$ on $V$. Hence, $L\mathfrak{gl}_{n}$ maps into
$\operatorname*{End}V$. More precisely, $L\mathfrak{gl}_{n}$ maps into
$\overline{\mathfrak{a}_{\infty}}\subseteq\operatorname*{End}V$. Here is a
direct way to construct this mapping:

Let $a\left(  t\right)  \in L\mathfrak{gl}_{n}$ be a Laurent polynomial with
coefficients in $\mathfrak{gl}_{n}$. Write $a\left(  t\right)  $ in the form
$a\left(  t\right)  =\sum\limits_{k\in\mathbb{Z}}a_{k}t^{k}$ with all $a_{k}$
lying in $\mathfrak{gl}_{n}$. Then, let $\operatorname*{Toep}\nolimits_{n}%
\left(  a\left(  t\right)  \right)  $ be the matrix%
\[
\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2} & ...\\
... & a_{-1} & a_{0} & a_{1} & ...\\
... & a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  \in\overline{\mathfrak{a}_{\infty}}.
\]
Formally speaking, this matrix is defined as the matrix whose $\left(
ni+\alpha,nj+\beta\right)  $-th entry equals the $\left(  \alpha,\beta\right)
$-th entry of the $n\times n$ matrix $a_{j-i}$ for all $i\in\mathbb{Z}$,
$j\in\mathbb{Z}$, $\alpha\in\left\{  1,2,...,n\right\}  $ and $\beta
\in\left\{  1,2,...,n\right\}  $. In other words, this is the block matrix
consisting of infinitely many $n\times n$-blocks such that the ``$i$-th block
diagonal'' is filled with $a_{i}$'s for every $i\in\mathbb{Z}$.

We thus have defined a map $\operatorname*{Toep}\nolimits_{n}:L\mathfrak{gl}%
_{n}\rightarrow\overline{\mathfrak{a}_{\infty}}$. This map
$\operatorname*{Toep}\nolimits_{n}$ is injective, and is exactly the map
$L\mathfrak{gl}_{n}\rightarrow\overline{\mathfrak{a}_{\infty}}$ we obtain from
the above action of $L\mathfrak{gl}_{n}$ on $V$. In particular, this map
$\operatorname*{Toep}\nolimits_{n}$ is a Lie algebra homomorphism.

In the following, we will often regard the injective map $\operatorname*{Toep}%
\nolimits_{n}$ as an inclusion, i. e., we will identify any $a\left(
t\right)  \in L\mathfrak{gl}_{n}$ with its image $\operatorname*{Toep}%
\nolimits_{n}\left(  a\left(  t\right)  \right)  \in\overline{\mathfrak{a}%
_{\infty}}$.
\end{definition}

Note that I chose the notation $\operatorname*{Toep}\nolimits_{n}$ because of
the notion of Toeplitz matrices. For any $a\left(  t\right)  \in
L\mathfrak{gl}_{n}$, the matrix $\operatorname*{Toep}\nolimits_{n}\left(
a\left(  t\right)  \right)  $ can be called an infinite ``block-Toeplitz''
matrix. If $n=1$, then $\operatorname*{Toep}\nolimits_{1}\left(  a\left(
t\right)  \right)  $ is an actual infinite Toeplitz matrix.

\begin{example}
Since $\mathfrak{gl}_{1}$ is a $1$-dimensional abelian Lie algebra, we can
identify $L\mathfrak{gl}_{1}$ with the Lie algebra $\overline{\mathcal{A}}$.
The image $\operatorname*{Toep}\nolimits_{1}\left(  L\mathfrak{gl}_{1}\right)
$ is the abelian Lie subalgebra $\left\langle T^{j}\ \mid\ j\in\mathbb{Z}%
\right\rangle $ of $\overline{\mathfrak{a}_{\infty}}$ (where $T$ is the shift
operator) and is isomorphic to $\overline{\mathcal{A}}$.
\end{example}

It is easy to see that:

\begin{proposition}
\label{prop.Toep.alg}Let $n$ be a positive integer. Define an associative
algebra structure on $L\mathfrak{gl}_{n}=\mathfrak{gl}_{n}\left[
t,t^{-1}\right]  $ by%
\[
\left(  at^{i}\right)  \cdot\left(  bt^{j}\right)  =abt^{i+j}%
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{gl}_{n}\text{, }%
b\in\mathfrak{gl}_{n}\text{, }i\in\mathbb{Z}\text{ and }j\in\mathbb{Z}.
\]
Then, $\operatorname*{Toep}\nolimits_{n}$ is not only a Lie algebra
homomorphism, but also a homomorphism of associative algebras.
\end{proposition}

\textit{Proof of Proposition \ref{prop.Toep.alg}.} Let $a\left(  t\right)  \in
L\mathfrak{gl}_{n}$ and $b\left(  t\right)  \in L\mathfrak{gl}_{n}$. Write
$a\left(  t\right)  $ in the form $a\left(  t\right)  =\sum\limits_{k\in
\mathbb{Z}}a_{k}t^{k}$ with all $a_{k}$ lying in $\mathfrak{gl}_{n}$. Write
$b\left(  t\right)  $ in the form $b\left(  t\right)  =\sum\limits_{k\in
\mathbb{Z}}b_{k}t^{k}$ with all $b_{k}$ lying in $\mathfrak{gl}_{n}$. By the
definition of $\operatorname*{Toep}\nolimits_{n}$, we have%
\begin{align*}
\operatorname*{Toep}\nolimits_{n}\left(  a\left(  t\right)  \right)   &
=\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2} & ...\\
... & a_{-1} & a_{0} & a_{1} & ...\\
... & a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right) \\
\text{and}\ \ \ \ \ \ \ \ \ \ \operatorname*{Toep}\nolimits_{n}\left(
b\left(  t\right)  \right)   &  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & b_{0} & b_{1} & b_{2} & ...\\
... & b_{-1} & b_{0} & b_{1} & ...\\
... & b_{-2} & b_{-1} & b_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  .
\end{align*}
Hence,%
\begin{align}
&  \operatorname*{Toep}\nolimits_{n}\left(  a\left(  t\right)  \right)
\cdot\operatorname*{Toep}\nolimits_{n}\left(  b\left(  t\right)  \right)
\nonumber\\
&  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2} & ...\\
... & a_{-1} & a_{0} & a_{1} & ...\\
... & a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  \cdot\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & b_{0} & b_{1} & b_{2} & ...\\
... & b_{-1} & b_{0} & b_{1} & ...\\
... & b_{-2} & b_{-1} & b_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right) \nonumber\\
&  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k-\left(  -1\right)  }b_{-1-k} &
\sum\limits_{k\in\mathbb{Z}}a_{k-\left(  -1\right)  }b_{0-k} & \sum
\limits_{k\in\mathbb{Z}}a_{k-\left(  -1\right)  }b_{1-k} & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k-0}b_{-1-k} & \sum\limits_{k\in
\mathbb{Z}}a_{k-0}b_{0-k} & \sum\limits_{k\in\mathbb{Z}}a_{k-0}b_{1-k} & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k-1}b_{-1-k} & \sum\limits_{k\in
\mathbb{Z}}a_{k-1}b_{0-k} & \sum\limits_{k\in\mathbb{Z}}a_{k-1}b_{1-k} & ...\\
... & ... & ... & ... & ...
\end{array}
\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the rule for multiplying block
matrices}\right) \nonumber\\
&  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{\left(  -1\right)  +\left(
-1\right)  -k} & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{\left(  -1\right)  +0-k}
& \sum\limits_{k\in\mathbb{Z}}a_{k}b_{\left(  -1\right)  +1-k} & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{0+\left(  -1\right)  -k} &
\sum\limits_{k\in\mathbb{Z}}a_{k}b_{0+0-k} & \sum\limits_{k\in\mathbb{Z}}%
a_{k}b_{0+1-k} & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{1+\left(  -1\right)  -k} &
\sum\limits_{k\in\mathbb{Z}}a_{k}b_{1+0-k} & \sum\limits_{k\in\mathbb{Z}}%
a_{k}b_{1+1-k} & ...\\
... & ... & ... & ... & ...
\end{array}
\right) \label{pf.Toep.alg.1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since any }\left(  i,j\right)
\in\mathbb{Z}^{2}\text{ satisfies }\sum\limits_{k\in\mathbb{Z}}a_{k-i}%
b_{j-k}=\sum\limits_{k\in\mathbb{Z}}a_{k}b_{i+j-k}\right)  .\nonumber
\end{align}
On the other hand, multiplying $a\left(  t\right)  =\sum\limits_{k\in
\mathbb{Z}}a_{k}t^{k}$ and $b\left(  t\right)  =\sum\limits_{k\in\mathbb{Z}%
}b_{k}t^{k}$, we obtain%
\[
a\left(  t\right)  \cdot b\left(  t\right)  =\left(  \sum\limits_{k\in
\mathbb{Z}}a_{k}t^{k}\right)  \cdot\left(  \sum\limits_{k\in\mathbb{Z}}%
b_{k}t^{k}\right)  =\sum\limits_{i\in\mathbb{Z}}\left(  \sum\limits_{k\in
\mathbb{Z}}a_{k}b_{i-k}\right)  t^{i}%
\]
(by the definition of the product of two Laurent polynomials), so that%
\[
\operatorname*{Toep}\nolimits_{n}\left(  a\left(  t\right)  \cdot b\left(
t\right)  \right)  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{\left(  -1\right)  +\left(
-1\right)  -k} & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{\left(  -1\right)  +0-k}
& \sum\limits_{k\in\mathbb{Z}}a_{k}b_{\left(  -1\right)  +1-k} & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{0+\left(  -1\right)  -k} &
\sum\limits_{k\in\mathbb{Z}}a_{k}b_{0+0-k} & \sum\limits_{k\in\mathbb{Z}}%
a_{k}b_{0+1-k} & ...\\
... & \sum\limits_{k\in\mathbb{Z}}a_{k}b_{1+\left(  -1\right)  -k} &
\sum\limits_{k\in\mathbb{Z}}a_{k}b_{1+0-k} & \sum\limits_{k\in\mathbb{Z}}%
a_{k}b_{1+1-k} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)
\]
(by the definition of $\operatorname*{Toep}\nolimits_{n}$). Compared with
(\ref{pf.Toep.alg.1}), this yields $\operatorname*{Toep}\nolimits_{n}\left(
a\left(  t\right)  \right)  \cdot\operatorname*{Toep}\nolimits_{n}\left(
b\left(  t\right)  \right)  =\operatorname*{Toep}\nolimits_{n}\left(  a\left(
t\right)  \cdot b\left(  t\right)  \right)  $.

Now forget that we fixed $a\left(  t\right)  $ and $b\left(  t\right)  $. We
thus have proven that every $a\left(  t\right)  \in L\mathfrak{gl}_{n}$ and
$b\left(  t\right)  \in L\mathfrak{gl}_{n}$ satisfy $\operatorname*{Toep}%
\nolimits_{n}\left(  a\left(  t\right)  \right)  \cdot\operatorname*{Toep}%
\nolimits_{n}\left(  b\left(  t\right)  \right)  =\operatorname*{Toep}%
\nolimits_{n}\left(  a\left(  t\right)  \cdot b\left(  t\right)  \right)  $.
Combined with the fact that $\operatorname*{Toep}\nolimits_{n}\left(
1\right)  =\operatorname*{id}$ (this is very easy to prove), this yields that
$\operatorname*{Toep}\nolimits_{n}$ is a homomorphism of associative algebras.
Hence, $\operatorname*{Toep}\nolimits_{n}$ is also a homomorphism of Lie
algebras. Proposition \ref{prop.Toep.alg} is proven.

Recall that the Lie algebra $\overline{\mathfrak{a}_{\infty}}$ has a central
extension $\mathfrak{a}_{\infty}$, which equals $\overline{\mathfrak{a}%
_{\infty}}\oplus\mathbb{C}K$ as a vector space but has its Lie bracket defined
using the cocycle $\alpha$.

\begin{proposition}
\label{prop.ainf.alphaomega}Let $\alpha:\overline{\mathfrak{a}_{\infty}}%
\times\overline{\mathfrak{a}_{\infty}}\rightarrow\mathbb{C}$ be the Japanese cocycle.

Let $n\in\mathbb{N}$. Let $\omega:L\mathfrak{gl}_{n}\times L\mathfrak{gl}%
_{n}\rightarrow\mathbb{C}$ be the $2$-cocycle on $L\mathfrak{gl}_{n}$ which is
defined by%
\begin{equation}
\omega\left(  a\left(  t\right)  ,b\left(  t\right)  \right)  =\sum
\limits_{k\in\mathbb{Z}}k\operatorname*{Tr}\left(  a_{k}b_{-k}\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\left(  t\right)  \in L\mathfrak{gl}%
_{n}\text{ and }b\left(  t\right)  \in L\mathfrak{gl}_{n}
\label{prop.ainf.alphaomega.form}%
\end{equation}
(where we write $a\left(  t\right)  $ in the form $a\left(  t\right)
=\sum\limits_{i\in\mathbb{Z}}a_{i}t^{i}$ with $a_{i}\in\mathfrak{gl}_{n}$, and
where we write $b\left(  t\right)  $ in the form $b\left(  t\right)
=\sum\limits_{i\in\mathbb{Z}}b_{i}t^{i}$ with $b_{i}\in\mathfrak{gl}_{n}$).

Then, the restriction of the Japanese cocycle $\alpha:\overline{\mathfrak{a}%
_{\infty}}\times\overline{\mathfrak{a}_{\infty}}\rightarrow\mathbb{C}$ to
$L\mathfrak{gl}_{n}\times L\mathfrak{gl}_{n}$ is the $2$-cocycle $\omega$.
\end{proposition}

\begin{remark}
The $2$-cocycle $\omega$ in Proposition \ref{prop.ainf.alphaomega} coincides
with the cocycle $\omega$ defined in Definition \ref{def.loop} in the case
when $\mathfrak{g}=\mathfrak{gl}_{n}$ and $\left(  \cdot,\cdot\right)  $ is
the form $\mathfrak{gl}_{n}\times\mathfrak{gl}_{n}\rightarrow\mathbb{C}%
,\ \left(  a,b\right)  \mapsto\operatorname*{Tr}\left(  ab\right)  $. The
$1$-dimensional central extension $\widehat{\mathfrak{gl}_{n}}_{\omega}$
induced by this $2$-cocycle $\omega$ (by the procedure shown in Definition
\ref{def.loop}) will be denoted by $\widehat{\mathfrak{gl}_{n}}$ in the
following. Note that $\widehat{\mathfrak{gl}_{n}}=L\mathfrak{gl}_{n}%
\oplus\mathbb{C}K$ as a vector space.

Note that the equality (\ref{prop.ainf.alphaomega.form}) can be rewritten in
the suggestive form%
\[
\omega\left(  a\left(  t\right)  ,b\left(  t\right)  \right)
=\operatorname*{Res}\nolimits_{t=0}\operatorname*{Tr}\left(  da\left(
t\right)  b\left(  t\right)  \right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}a\left(  t\right)  \in L\mathfrak{gl}_{n}\text{ and }b\left(  t\right)  \in
L\mathfrak{gl}_{n}%
\]
(as long as the ``matrix-valued differential form'' $da\left(  t\right)
b\left(  t\right)  $ is understood correctly).
\end{remark}

\textit{Proof of Proposition \ref{prop.ainf.alphaomega}.} We need to prove
that $\alpha\left(  a\left(  t\right)  ,b\left(  t\right)  \right)
=\omega\left(  a\left(  t\right)  ,b\left(  t\right)  \right)  $ for any
$a\left(  t\right)  \in L\mathfrak{gl}_{n}$ and $b\left(  t\right)  \in
L\mathfrak{gl}_{n}$ (where, of course, we consider $a\left(  t\right)  $ and
$b\left(  t\right)  $ as elements of $\overline{\mathfrak{a}_{\infty}}$ in the
term $\alpha\left(  a\left(  t\right)  ,b\left(  t\right)  \right)  $).

Write $a\left(  t\right)  $ in the form $a\left(  t\right)  =\sum
\limits_{k\in\mathbb{Z}}a_{k}t^{k}$ with all $a_{k}$ lying in $\mathfrak{gl}%
_{n}$. Write $b\left(  t\right)  $ in the form $b\left(  t\right)
=\sum\limits_{k\in\mathbb{Z}}b_{k}t^{k}$ with all $b_{k}$ lying in
$\mathfrak{gl}_{n}$.

In the following, for any integers $u$ and $v$, the $\left(  u,v\right)  $-th
\textit{block} of a matrix will mean the submatrix obtained by leaving only
the rows numbered $un+1$, $un+2$, $...$, $\left(  u+1\right)  n$ and the
columns numbered $vn+1$, $vn+2$, $...$, $\left(  v+1\right)  n$. (This, of
course, makes sense only when the matrix has such rows and such columns.)

By the definition of our embedding $\operatorname*{Toep}\nolimits_{n}\left(
a\left(  t\right)  \right)  :L\mathfrak{gl}_{n}\rightarrow\overline
{\mathfrak{a}_{\infty}}$, we have%
\begin{align*}
a\left(  t\right)   &  =\operatorname*{Toep}\nolimits_{n}\left(  a\left(
t\right)  \right)  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2} & ...\\
... & a_{-1} & a_{0} & a_{1} & ...\\
... & a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \text{and}\\
b\left(  t\right)   &  =\operatorname*{Toep}\nolimits_{n}\left(  b\left(
t\right)  \right)  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & b_{0} & b_{1} & b_{2} & ...\\
... & b_{-1} & b_{0} & b_{1} & ...\\
... & b_{-2} & b_{-1} & b_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  ,
\end{align*}
where the matrices $\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2} & ...\\
... & a_{-1} & a_{0} & a_{1} & ...\\
... & a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  $ and $\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & b_{0} & b_{1} & b_{2} & ...\\
... & b_{-1} & b_{0} & b_{1} & ...\\
... & b_{-2} & b_{-1} & b_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  $ are understood as block matrices made of $n\times n$ blocks.

In order to compute $\alpha\left(  a\left(  t\right)  ,b\left(  t\right)
\right)  $, let us write these two infinite matrices $a\left(  t\right)  $ and
$b\left(  t\right)  $ as $2\times2$ block matrices \textbf{made of infinite
blocks each}, where the blocks are separated as follows:

- The left blocks contain the $j$-th columns for all $j\leq0$; the right
blocks contain the $j$-th columns for all $j>0$.

- The upper blocks contain the $i$-th rows for all $i\leq0$; the lower blocks
contain the $i$-th rows for all $i>0$.

Written like this, the matrix $a\left(  t\right)  $ takes the form $\left(
\begin{array}
[c]{cc}%
A_{11} & A_{12}\\
A_{21} & A_{22}%
\end{array}
\right)  $ with%
\begin{align*}
A_{11}  &  =\left(
\begin{array}
[c]{cccc}%
... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2}\\
... & a_{-1} & a_{0} & a_{1}\\
... & a_{-2} & a_{-1} & a_{0}%
\end{array}
\right)  ,\ \ \ \ \ \ \ \ \ \ A_{12}=\left(
\begin{array}
[c]{cccc}%
... & ... & ... & ...\\
a_{3} & a_{4} & a_{5} & ...\\
a_{2} & a_{3} & a_{4} & ...\\
a_{1} & a_{2} & a_{3} & ...
\end{array}
\right)  ,\\
A_{21}  &  =\left(
\begin{array}
[c]{cccc}%
... & a_{-3} & a_{-2} & a_{-1}\\
... & a_{-4} & a_{-3} & a_{-2}\\
... & a_{-5} & a_{-4} & a_{-3}\\
... & ... & ... & ...
\end{array}
\right)  ,\ \ \ \ \ \ \ \ \ \ A_{22}=\left(
\begin{array}
[c]{cccc}%
a_{0} & a_{1} & a_{2} & ...\\
a_{-1} & a_{0} & a_{1} & ...\\
a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ...
\end{array}
\right)  ,
\end{align*}
and the matrix $b\left(  t\right)  $ takes the form $\left(
\begin{array}
[c]{cc}%
B_{11} & B_{12}\\
B_{21} & B_{22}%
\end{array}
\right)  $ with similarly-defined blocks $B_{11}$, $B_{12}$, $B_{21}$ and
$B_{22}$.

By the definition of $\alpha$ given in Theorem \ref{thm.japan}, we now have
$\alpha\left(  a\left(  t\right)  ,b\left(  t\right)  \right)
=\operatorname*{Tr}\left(  -B_{12}A_{21}+A_{12}B_{21}\right)  $. We now need
to compute $B_{12}A_{21}$ and $A_{12}B_{21}$ in order to simplify this.

Now, since $B_{12}=\left(
\begin{array}
[c]{cccc}%
... & ... & ... & ...\\
b_{3} & b_{4} & b_{5} & ...\\
b_{2} & b_{3} & b_{4} & ...\\
b_{1} & b_{2} & b_{3} & ...
\end{array}
\right)  $ and $A_{21}=\left(
\begin{array}
[c]{cccc}%
... & a_{-3} & a_{-2} & a_{-1}\\
... & a_{-4} & a_{-3} & a_{-2}\\
... & a_{-5} & a_{-4} & a_{-3}\\
... & ... & ... & ...
\end{array}
\right)  $, the matrix $B_{12}A_{21}$ is a matrix whose rows and columns are
indexed by nonpositive integers, and whose $\left(  i,j\right)  $-th block
equals $\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k-\left(  i+1\right)
}a_{-k+\left(  j+1\right)  }$ for any pair of negative integers $i$ and $j$.
Similarly, the matrix $A_{12}B_{21}$ is a matrix whose rows and columns are
indexed by nonpositive integers, and whose $\left(  i,j\right)  $-th block
equals $\sum\limits_{k\in\mathbb{Z};\ k>0}a_{k-\left(  i+1\right)
}b_{-k+\left(  j+1\right)  }$ for any pair of negative integers $i$ and $j$.
Thus, the matrix $-B_{12}A_{21}+A_{12}B_{21}$ is a matrix whose rows and
columns are indexed by nonpositive integers, and whose $\left(  i,j\right)
$-th block equals $-\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k-\left(  i+1\right)
}a_{-k+\left(  j+1\right)  }+\sum\limits_{k\in\mathbb{Z};\ k>0}a_{k-\left(
i+1\right)  }b_{-k+\left(  j+1\right)  }$ for any pair of negative integers
$i$ and $j$. But since $\operatorname*{Tr}\left(  -B_{12}A_{21}+A_{12}%
B_{21}\right)  $ is clearly the sum of the traces of the $\left(  i,i\right)
$-th blocks of the matrix $-B_{12}A_{21}+A_{12}B_{21}$ over all negative
integers $i$, we thus have%
\begin{align*}
\operatorname*{Tr}\left(  -B_{12}A_{21}+A_{12}B_{21}\right)   &
=\sum\limits_{i\in\mathbb{Z};\ i<0}\operatorname*{Tr}\left(  -\sum
\limits_{k\in\mathbb{Z};\ k>0}b_{k-\left(  i+1\right)  }a_{-k+\left(
i+1\right)  }+\sum\limits_{k\in\mathbb{Z};\ k>0}a_{k-\left(  i+1\right)
}b_{-k+\left(  i+1\right)  }\right) \\
&  =\sum\limits_{i\in\mathbb{Z};\ i\leq0}\operatorname*{Tr}\left(
-\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k-i}a_{-k+i}+\sum\limits_{k\in
\mathbb{Z};\ k>0}a_{k-i}b_{-k+i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }i\text{ for
}i+1\right) \\
&  =\sum\limits_{i\in\mathbb{Z};\ i\geq0}\operatorname*{Tr}\left(
-\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k+i}a_{-k-i}+\sum\limits_{k\in
\mathbb{Z};\ k>0}a_{k+i}b_{-k-i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }i\text{ for
}-i\text{ in the first sum}\right)  .
\end{align*}


We are now going to split the first sum on the right hand side and get the
$\operatorname*{Tr}$ out of it. To see that this is allowed, we notice that
each of the infinite sums $\sum\limits_{\substack{\left(  i,k\right)
\in\mathbb{Z}^{2};\\i\geq0;\ k>0}}b_{k+i}a_{-k-i}$ and $\sum
\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0}}a_{k+i}b_{-k-i}$ converges with respect to the discrete
topology\footnote{\textit{Proof.} Since $\sum\limits_{k\in\mathbb{Z}}%
a_{k}t^{k}=a\left(  t\right)  \in L\mathfrak{gl}_{n}$, only finitely many
$k\in\mathbb{Z}$ satisfy $a_{k}\neq0$. Hence, there exists some $N\in
\mathbb{Z}$ such that every $\nu\in\mathbb{Z}$ satisfying $\nu<N$ satisfies
$a_{\nu}=0$. Consider this $N$. Any pair $\left(  i,k\right)  \in
\mathbb{Z}^{2}$ such that $k+i>-N$ satisfies $-k-i=-\underbrace{\left(
k+i\right)  }_{>-N}<N$ and thus $a_{-k-i}=0$ (because we know that every
$\nu\in\mathbb{Z}$ satisfying $\nu<N$ satisfies $a_{\nu}=0$) and thus
$b_{k+i}a_{-k-i}=0$. Thus, all but finitely many pairs $\left(  i,k\right)
\in\mathbb{Z}^{2}$ such that $i\geq0$ and $k>0$ satisfy $b_{k+i}a_{-k-i}=0$
(because it is clear that all but finitely many pairs $\left(  i,k\right)
\in\mathbb{Z}^{2}$ such that $i\geq0$ and $k>0$ satisfy $k+i>-N$). In other
words, the sum $\sum\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}%
^{2};\\i\geq0;\ k>0}}b_{k+i}a_{-k-i}$ converges with respect to the discrete
topology. A similar argument shows that the sum $\sum
\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0}}a_{k+i}b_{-k-i}$ converges with respect to the discrete topology.}.
Hence, we can transform these sums as we please: For example,%
\begin{align}
&  \sum\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0}}b_{k+i}a_{-k-i}\nonumber\\
&  =\sum\limits_{\substack{\ell\in\mathbb{Z};\\\ell>0}}\sum
\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0;\\k+i=\ell}}\underbrace{b_{k+i}}_{\substack{=b_{\ell}\\\text{(since
}k+i=\ell\text{)}}}\underbrace{a_{-k-i}}_{\substack{=a_{-\left(  k+i\right)
}=a_{-\ell}\\\text{(since }k+i=\ell\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }k+i>0\text{ for all }i\geq0\text{ and }k>0\right) \nonumber\\
&  =\sum\limits_{\substack{\ell\in\mathbb{Z};\\\ell>0}}\underbrace{\sum
\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0;\\k+i=\ell}}b_{\ell}a_{-\ell}}_{\substack{=\ell b_{\ell}a_{-\ell
}\\\text{(since there exist exactly }\ell\text{ pairs }\left(  i,k\right)
\in\mathbb{Z}^{2}\\\text{satisfying }i\geq0\text{, }k>0\text{ and }%
k+i=\ell\text{)}}}=\sum\limits_{\substack{\ell\in\mathbb{Z};\\\ell>0}}\ell
b_{\ell}a_{-\ell}=\sum\limits_{\substack{k\in\mathbb{Z};\\k>0}}kb_{k}a_{-k}
\label{pf.ainf.alphaomega.sum1}%
\end{align}
(here, we renamed the summation index $\ell$ as $k$) and similarly
\begin{equation}
\sum\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0}}a_{k+i}b_{-k-i}=\sum\limits_{\substack{k\in\mathbb{Z};\\k>0}%
}ka_{k}b_{-k}. \label{pf.ainf.alphaomega.sum2}%
\end{equation}
The equality (\ref{pf.ainf.alphaomega.sum1}) becomes%
\begin{align*}
\sum\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0}}b_{k+i}a_{-k-i}  &  =\sum\limits_{\substack{k\in\mathbb{Z}%
;\\k>0}}kb_{k}a_{-k}=\sum\limits_{\substack{k\in\mathbb{Z};\\k<0}}\left(
-k\right)  b_{-k}a_{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }k\text{ for
}-k\text{ in the first sum}\right) \\
&  =-\sum\limits_{\substack{k\in\mathbb{Z};\\k<0}}kb_{-k}a_{k},
\end{align*}
so that
\begin{equation}
\sum\limits_{\substack{k\in\mathbb{Z};\\k<0}}kb_{-k}a_{k}=-\sum
\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2};\\i\geq
0;\ k>0}}b_{k+i}a_{-k-i}. \label{pf.ainf.alphaomega.sum3}%
\end{equation}


But
\begin{align*}
&  \omega\left(  a\left(  t\right)  ,b\left(  t\right)  \right) \\
&  =\sum\limits_{k\in\mathbb{Z}}k\operatorname*{Tr}\left(  a_{k}b_{-k}\right)
=\sum\limits_{\substack{k\in\mathbb{Z};\\k<0}}k\underbrace{\operatorname*{Tr}%
\left(  a_{k}b_{-k}\right)  }_{=\operatorname*{Tr}\left(  b_{-k}a_{k}\right)
}+\underbrace{0\operatorname*{Tr}\left(  a_{0}b_{-0}\right)  }_{=0}%
+\sum\limits_{\substack{k\in\mathbb{Z};\\k>0}}k\operatorname*{Tr}\left(
a_{k}b_{-k}\right) \\
&  =\underbrace{\sum\limits_{\substack{k\in\mathbb{Z};\\k<0}%
}k\operatorname*{Tr}\left(  b_{-k}a_{k}\right)  }_{=\operatorname*{Tr}\left(
\sum\limits_{\substack{k\in\mathbb{Z};\\k<0}}kb_{-k}a_{k}\right)
}+\underbrace{\sum\limits_{\substack{k\in\mathbb{Z};\\k>0}}k\operatorname*{Tr}%
\left(  a_{k}b_{-k}\right)  }_{=\operatorname*{Tr}\left(  \sum
\limits_{\substack{k\in\mathbb{Z};\\k>0}}ka_{k}b_{-k}\right)  }\\
&  =\operatorname*{Tr}\left(  \underbrace{\sum\limits_{\substack{k\in
\mathbb{Z};\\k<0}}kb_{-k}a_{k}}_{\substack{=-\sum\limits_{\substack{\left(
i,k\right)  \in\mathbb{Z}^{2};\\i\geq0;\ k>0}}b_{k+i}a_{-k-i}\\\text{(by
(\ref{pf.ainf.alphaomega.sum3}))}}}\right)  +\operatorname*{Tr}\left(
\underbrace{\sum\limits_{\substack{k\in\mathbb{Z};\\k>0}}ka_{k}b_{-k}%
}_{\substack{=\sum\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}%
^{2};\\i\geq0;\ k>0}}a_{k+i}b_{-k-i}\\\text{(by (\ref{pf.ainf.alphaomega.sum2}%
))}}}\right) \\
&  =\operatorname*{Tr}\left(  -\sum\limits_{\substack{\left(  i,k\right)
\in\mathbb{Z}^{2};\\i\geq0;\ k>0}}b_{k+i}a_{-k-i}\right)  +\operatorname*{Tr}%
\left(  \sum\limits_{\substack{\left(  i,k\right)  \in\mathbb{Z}^{2}%
;\\i\geq0;\ k>0}}a_{k+i}b_{-k-i}\right) \\
&  =\operatorname*{Tr}\left(  -\sum\limits_{i\in\mathbb{Z};\ i\geq0}%
\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k+i}a_{-k-i}\right)  +\operatorname*{Tr}%
\left(  \sum\limits_{i\in\mathbb{Z};\ i\geq0}\sum\limits_{k\in\mathbb{Z}%
;\ k>0}a_{k+i}b_{-k-i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we have unfolded our single sums
into double sums}\right) \\
&  =\sum\limits_{i\in\mathbb{Z};\ i\geq0}\operatorname*{Tr}\left(
-\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k+i}a_{-k-i}\right)  +\sum
\limits_{i\in\mathbb{Z};\ i\geq0}\operatorname*{Tr}\left(  \sum\limits_{k\in
\mathbb{Z};\ k>0}a_{k+i}b_{-k-i}\right) \\
&  =\sum\limits_{i\in\mathbb{Z};\ i\geq0}\operatorname*{Tr}\left(
-\sum\limits_{k\in\mathbb{Z};\ k>0}b_{k+i}a_{-k-i}+\sum\limits_{k\in
\mathbb{Z};\ k>0}a_{k+i}b_{-k-i}\right)  =\operatorname*{Tr}\left(
-B_{12}A_{21}+A_{12}B_{21}\right) \\
&  =\alpha\left(  a\left(  t\right)  ,b\left(  t\right)  \right)  .
\end{align*}
Thus, $\alpha\left(  a\left(  t\right)  ,b\left(  t\right)  \right)
=\omega\left(  a\left(  t\right)  ,b\left(  t\right)  \right)  $ is proven, so
we have verified Proposition \ref{prop.ainf.alphaomega}.

Note that Proposition \ref{prop.ainf.alphaomega} gives a new proof of
Proposition \ref{prop.japan.nontr}. This proof (whose details are left to the
reader) uses two easy facts:

\begin{itemize}
\item If $\sigma:\mathfrak{g}\times\mathfrak{g}\rightarrow\mathbb{C}$ is a
$2$-coboundary on a Lie algebra $\mathfrak{g}$, and $\mathfrak{h}$ is a Lie
subalgebra of $\mathfrak{g}$, then $\sigma\mid_{\mathfrak{h}\times
\mathfrak{h}}$ must be a $2$-coboundary on $\mathfrak{h}$.

\item For any positive integer $n$, the $2$-cocycle $\omega$ of Proposition
\ref{prop.ainf.alphaomega} is not a $2$-coboundary.
\end{itemize}

But if we look closely at this argument, we see that it is not a completely
new proof; it is a direct generalization of the proof of Proposition
\ref{prop.japan.nontr} that we gave above. In fact, in the particular case
when $n=1$, our embedding of $L\mathfrak{gl}_{n}$ into $\overline
{\mathfrak{a}_{\infty}}$ becomes the canonical injection of the abelian Lie
subalgebra $\left\langle T^{j}\ \mid\ j\in\mathbb{Z}\right\rangle $ into
$\overline{\mathfrak{a}_{\infty}}$ (where $T$ is as in the proof of
Proposition \ref{prop.japan.nontr}), and we see that what we just did was
generalizing that abelian Lie subalgebra.

\begin{definition}
Due to Proposition \ref{prop.ainf.alphaomega}, the restriction of the
$2$-cocycle $\alpha$ to $L\mathfrak{gl}_{n}\times L\mathfrak{gl}_{n}$ is the
$2$-cocycle $\omega$. Thus, the $1$-dimensional central extension of
$L\mathfrak{gl}_{n}$ determined by the $2$-cocycle $\omega$ canonically
injects into the $1$-dimensional central extension of $\overline
{\mathfrak{a}_{\infty}}$ determined by the $2$-cocycle $\alpha$. If we recall
that the $1$-dimensional central extension of $L\mathfrak{gl}_{n}$ by the
$2$-cocycle $\omega$ is $\widehat{\mathfrak{gl}_{n}}$ whereas the
$1$-dimensional central extension of $\overline{\mathfrak{a}_{\infty}}$
determined by the $2$-cocycle $\alpha$ is $\mathfrak{a}_{\infty}$, we can
rewrite this as follows: We have an injection $\widehat{\mathfrak{gl}_{n}%
}\rightarrow\mathfrak{a}_{\infty}$ which lifts the inclusion $L\mathfrak{gl}%
_{n}\subseteq\overline{\mathfrak{a}_{\infty}}$ and sends $K$ to $K$. We denote
this inclusion map $\widehat{\mathfrak{gl}_{n}}\rightarrow\mathfrak{a}%
_{\infty}$ by $\widehat{\operatorname*{Toep}\nolimits_{n}}$, but we will often
consider it as an inclusion.

Similarly, we can get an inclusion $\widehat{\mathfrak{sl}_{n}}\subseteq
\mathfrak{a}_{\infty}$ which lifts the inclusion $L\mathfrak{sl}_{n}%
\subseteq\overline{\mathfrak{a}_{\infty}}$.

So $\mathcal{B}^{\left(  m\right)  }\cong\mathcal{F}^{\left(  m\right)  }$ is
a module over $\widehat{\mathfrak{gl}_{n}}$ and $\widehat{\mathfrak{sl}_{n}}$
at level $1$ (this means that $K$ acts as $1$).
\end{definition}

\begin{corollary}
\label{cor.glnhat.div}There is a Lie algebra isomorphism $\widehat{\phi
}:\mathcal{A}\rightarrow\widehat{\mathfrak{gl}_{1}}$ which sends $K$ to $K$
and sends $a_{m}$ to $T^{m}\in\widehat{\mathfrak{gl}_{1}}$ for every
$m\in\mathbb{Z}$. (Here, we are considering the injection
$\widehat{\mathfrak{gl}_{1}}\rightarrow\mathfrak{a}_{\infty}$ as an inclusion,
so that $\widehat{\mathfrak{gl}_{1}}$ is identified with the image of this inclusion.)
\end{corollary}

\textit{Proof of Corollary \ref{cor.glnhat.div}.} There is an obvious Lie
algebra isomorphism $\phi:\overline{\mathcal{A}}\rightarrow L\mathfrak{gl}%
_{1}$ which sends $a_{m}$ to $t^{m}\in L\mathfrak{gl}_{1}$ for every
$m\in\mathbb{Z}$. This isomorphism $\phi$ is easily seen to satisfy%
\begin{equation}
\omega\left(  \phi\left(  x\right)  ,\phi\left(  y\right)  \right)
=\omega^{\prime}\left(  x,y\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }%
x\in\overline{\mathcal{A}}\text{ and }y\in\overline{\mathcal{A}}\text{,}
\label{pf.glinhat.div.1}%
\end{equation}
where $\omega:L\mathfrak{gl}_{1}\times L\mathfrak{gl}_{1}\rightarrow
\mathbb{C}$ is the $2$-cocycle on $L\mathfrak{gl}_{1}$ defined in Proposition
\ref{prop.ainf.alphaomega}, and $\omega^{\prime}:\overline{\mathcal{A}}%
\times\overline{\mathcal{A}}\rightarrow\mathbb{C}$ is the $2$-cocycle on
$\overline{\mathcal{A}}$ defined by%
\[
\omega^{\prime}\left(  a_{k},a_{\ell}\right)  =k\delta_{k,-\ell}%
\ \ \ \ \ \ \ \ \ \ \text{for all }k\in\mathbb{Z}\text{ and }\ell\in
\mathbb{Z}.
\]
Thus, the Lie algebra isomorphism $\phi:\overline{\mathcal{A}}\rightarrow
L\mathfrak{gl}_{1}$ gives rise to an isomorphism $\widehat{\phi}$ from the
extension of $\overline{\mathcal{A}}$ defined by the $2$-cocycle
$\omega^{\prime}$ to the extension of $L\mathfrak{gl}_{1}$ defined by the
$2$-cocycle $\omega$. Since the extension of $\overline{\mathcal{A}}$ defined
by the $2$-cocycle $\omega^{\prime}$ is $\mathcal{A}$, while the extension of
$L\mathfrak{gl}_{1}$ defined by the $2$-cocycle $\omega$ is
$\widehat{\mathfrak{gl}_{1}}$, this rewrites as follows: The Lie algebra
isomorphism $\phi:\overline{\mathcal{A}}\rightarrow L\mathfrak{gl}_{1}$ gives
rise to an isomorphism $\widehat{\phi}:\mathcal{A}\rightarrow
\widehat{\mathfrak{gl}_{1}}$. This isomorphism $\widehat{\phi}$ sends $K$ to
$K$, and sends $a_{m}$ to $t^{m}\in\widehat{\mathfrak{gl}_{1}}$ for every
$m\in\mathbb{Z}$. Since $t^{m}$ corresponds to $T^{m}$ under our inclusion
$\widehat{\mathfrak{gl}_{1}}\rightarrow\mathfrak{a}_{\infty}$ (in fact,
$\operatorname*{Toep}\nolimits_{1}\left(  t^{m}\right)  =T^{m}$), this shows
that $\widehat{\phi}$ sends $a_{m}$ to $T^{m}\in\widehat{\mathfrak{gl}_{1}}$
for every $m\in\mathbb{Z}$. Corollary \ref{cor.glnhat.div} is thus proven.

\begin{proposition}
\label{prop.glnhat.T}Let $n$ be a positive integer. Consider the shift
operator $T$. Let us regard the injections $\overline{\mathfrak{a}_{\infty}%
}\rightarrow\mathfrak{a}_{\infty}$, $L\mathfrak{gl}_{n}\rightarrow
\overline{\mathfrak{a}_{\infty}}$ and $\widehat{\mathfrak{gl}_{n}}%
\rightarrow\mathfrak{a}_{\infty}$ as inclusions, so that $L\mathfrak{gl}_{n}$,
$\widehat{\mathfrak{gl}_{n}}$ and $\mathfrak{a}_{\infty}$ all become subspaces
of $\mathfrak{a}_{\infty}$.

\textbf{(a)} For every $m\in\mathbb{Z}$, we have $T^{m}\in L\mathfrak{gl}%
_{n}\subseteq\widehat{\mathfrak{gl}_{n}}$.

\textbf{(b)} We have $\widehat{\mathfrak{gl}_{1}}\subseteq
\widehat{\mathfrak{gl}_{n}}$. Hence, the Lie algebra isomorphism
$\widehat{\phi}:\mathcal{A}\rightarrow\widehat{\mathfrak{gl}_{1}}$ constructed
in Corollary \ref{cor.glnhat.div} induces a Lie algebra injection
$\mathcal{A}\rightarrow\widehat{\mathfrak{gl}_{n}}$ (which sends every
$a\in\mathcal{A}$ to $\widehat{\phi}\left(  a\right)  \in
\widehat{\mathfrak{gl}_{n}}$). The restriction of the $\widehat{\mathfrak{gl}%
_{n}}$-module $\mathcal{F}^{\left(  m\right)  }$ by means of this injection is
the $\mathcal{A}$-module $\mathcal{F}^{\left(  m\right)  }$ that we know.
\end{proposition}

\textit{First proof of Proposition \ref{prop.glnhat.T}.} \textbf{(a)} We
recall that $T=\left(
\begin{array}
[c]{cccccc}%
... & ... & ... & ... & ... & ...\\
... & 0 & 1 & 0 & 0 & ...\\
... & 0 & 0 & 1 & 0 & ...\\
... & 0 & 0 & 0 & 1 & ...\\
... & 0 & 0 & 0 & 0 & ...\\
... & ... & ... & ... & ... & ...
\end{array}
\right)  $ (this is the matrix which has $1$'s on the $1$-st diagonal and
$0$'s everywhere else). Clearly, $T\in\overline{\mathfrak{a}_{\infty}}$. We
want to prove that $T$ lies in $L\mathfrak{gl}_{n}\subseteq\overline
{\mathfrak{a}_{\infty}}$.

Let $a_{0}=\left(
\begin{array}
[c]{ccccc}%
0 & 1 & 0 & ... & 0\\
0 & 0 & 1 & ... & 0\\
0 & 0 & 0 & ... & 0\\
... & ... & ... & ... & ...\\
0 & 0 & 0 & ... & 0
\end{array}
\right)  $ (this is the $n\times n$ matrix which has $1$'s on the $1$-st
diagonal and $0$'s everywhere else).

Let $a_{1}=\left(
\begin{array}
[c]{ccccc}%
0 & 0 & 0 & ... & 0\\
0 & 0 & 0 & ... & 0\\
0 & 0 & 0 & ... & 0\\
... & ... & ... & ... & ...\\
0 & 0 & 0 & ... & 0\\
1 & 0 & 0 & ... & 0
\end{array}
\right)  $ (this is the $n\times n$ matrix which has a $1$ in its lowermost
leftmost corner, and $0$'s everywhere else).

Then, $T=\operatorname*{Toep}\nolimits_{n}\left(  a_{0}+ta_{1}\right)  $.
Thus, for every $m\in\mathbb{N}$, we have%
\begin{align*}
T^{m}  &  =\left(  \operatorname*{Toep}\nolimits_{n}\left(  a_{0}%
+ta_{1}\right)  \right)  ^{m}=\operatorname*{Toep}\nolimits_{n}\left(  \left(
a_{0}+ta_{1}\right)  ^{m}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{because of
Proposition \ref{prop.Toep.alg}}\right) \\
&  \in\operatorname*{Toep}\nolimits_{n}\left(  L\mathfrak{gl}_{n}\right)
=L\mathfrak{gl}_{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{since we regard
}\operatorname*{Toep}\nolimits_{n}\text{ as an inclusion}\right)  .
\end{align*}
Since it is easy to see that $T^{-1}\in L\mathfrak{gl}_{n}$ as
well\footnote{This is analogous to $T\in L\mathfrak{gl}_{n}$ (because $T^{-1}$
is the matrix which has $1$'s on the $\left(  -1\right)  $-st diagonal and
$0$'s everywhere else).}, a similar argument yields that $\left(
T^{-1}\right)  ^{m}\in L\mathfrak{gl}_{n}$ for all $m\in\mathbb{N}$. In other
words, $T^{-m}\in L\mathfrak{gl}_{n}$ for all $m\in\mathbb{N}$. In other
words, $T^{m}\in\mathfrak{gl}_{n}$ for all nonpositive integers $m$. Combined
with the fact that $T^{m}\in L\mathfrak{gl}_{n}$ for all $m\in\mathbb{N}$,
this yields that $T^{m}\in L\mathfrak{gl}_{n}$ for all $m\in\mathbb{Z}$. Since
$L\mathfrak{gl}_{n}\subseteq\widehat{\mathfrak{gl}_{n}}$, we thus have
$T^{m}\in L\mathfrak{gl}_{n}\subseteq\widehat{\mathfrak{gl}_{n}}$ for all
$m\in\mathbb{Z}$. This proves Proposition \ref{prop.glnhat.T} \textbf{(a)}.

\textbf{(b)} For every $a\left(  t\right)  \in L\mathfrak{gl}_{1}$, we have
$\operatorname*{Toep}\nolimits_{1}\left(  a\left(  t\right)  \right)
\in\left\langle T^{j}\ \mid\ j\in\mathbb{Z}\right\rangle $%
\ \ \ \ \footnote{\textit{Proof.} Let $a\left(  t\right)  \in L\mathfrak{gl}%
_{1}$. Write $a\left(  t\right)  $ in the form $\sum\limits_{i\in\mathbb{Z}%
}a_{i}t^{i}$ with $a_{i}\in\mathfrak{gl}_{1}$. Then, of course, the $a_{i}$
are scalars (since $\mathfrak{gl}_{1}=\mathbb{C}$). By the definition of
$\operatorname*{Toep}\nolimits_{1}$, we have%
\[
\operatorname*{Toep}\nolimits_{1}\left(  a\left(  t\right)  \right)  =\left(
\begin{array}
[c]{ccccc}%
... & ... & ... & ... & ...\\
... & a_{0} & a_{1} & a_{2} & ...\\
... & a_{-1} & a_{0} & a_{1} & ...\\
... & a_{-2} & a_{-1} & a_{0} & ...\\
... & ... & ... & ... & ...
\end{array}
\right)  =\sum\limits_{i\in\mathbb{Z}}a_{i}T^{i}\in\left\langle T^{j}%
\ \mid\ j\in\mathbb{Z}\right\rangle ,
\]
qed.}. Thus, $\operatorname*{Toep}\nolimits_{1}\left(  L\mathfrak{gl}%
_{1}\right)  \subseteq\left\langle T^{j}\ \mid\ j\in\mathbb{Z}\right\rangle $.
Since we are considering $\operatorname*{Toep}\nolimits_{1}$ as an inclusion,
this becomes $L\mathfrak{gl}_{1}\subseteq\left\langle T^{j}\ \mid
\ j\in\mathbb{Z}\right\rangle $. Combined with $\left\langle T^{j}\ \mid
\ j\in\mathbb{Z}\right\rangle \subseteq L\mathfrak{gl}_{n}$ (because every
$m\in\mathbb{Z}$ satisfies $T^{m}\in L\mathfrak{gl}_{n}$ (according to
Proposition \ref{prop.glnhat.T} \textbf{(a)})), this yields $L\mathfrak{gl}%
_{1}\subseteq L\mathfrak{gl}_{n}$. Thus, $\widehat{\mathfrak{gl}_{1}}%
\subseteq\widehat{\mathfrak{gl}_{n}}$.

Hence, the Lie algebra isomorphism $\widehat{\phi}:\mathcal{A}\rightarrow
\widehat{\mathfrak{gl}_{1}}$ constructed in Corollary \ref{cor.glnhat.div}
induces a Lie algebra injection $\mathcal{A}\rightarrow\widehat{\mathfrak{gl}%
_{n}}$ (which sends every $a\in\mathcal{A}$ to $\widehat{\phi}\left(
a\right)  \in\widehat{\mathfrak{gl}_{n}}$). This injection is exactly the
embedding $\mathcal{A}\rightarrow\mathfrak{a}_{\infty}$ constructed in
Definition \ref{def.ainf.A} (apart from the fact that its target is
$\widehat{\mathfrak{gl}_{n}}$ rather than $\mathfrak{a}_{\infty}$). Hence, the
restriction of the $\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{F}^{\left(
m\right)  }$ by means of this injection is the $\mathcal{A}$-module
$\mathcal{F}^{\left(  m\right)  }$ that we know\footnote{because both the
$\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{F}^{\left(  m\right)  }$ and
the $\mathcal{A}$-module $\mathcal{F}^{\left(  m\right)  }$ were defined as
restrictions of the $\mathfrak{a}_{\infty}$-module $\mathcal{F}^{\left(
m\right)  }$}. This proves Proposition \ref{prop.glnhat.T} \textbf{(b)}.

Our inclusions $L\mathfrak{gl}_{n}\subseteq\overline{\mathfrak{a}_{\infty}}$
and $\widehat{\mathfrak{gl}_{n}}\subseteq\mathfrak{a}_{\infty}$ can be
somewhat refined: For any positive integers $n$ and $N$ satisfying $n\mid N$,
we have $L\mathfrak{gl}_{n}\subseteq L\mathfrak{gl}_{N}$ and
$\widehat{\mathfrak{gl}_{n}}\subseteq\widehat{\mathfrak{gl}_{N}}$. Let us
formulate this more carefully without abuse of notation:

\begin{proposition}
\label{prop.glnhat.div}Let $n$ and $N$ be positive integers such that $n\mid
N$. Then, the inclusion $\operatorname*{Toep}\nolimits_{n}:L\mathfrak{gl}%
_{n}\rightarrow\overline{\mathfrak{a}_{\infty}}$ factors through the inclusion
$\operatorname*{Toep}\nolimits_{N}:L\mathfrak{gl}_{N}\rightarrow
\overline{\mathfrak{a}_{\infty}}$. More precisely:

Let $d=\dfrac{N}{n}$. Let $\operatorname*{Toep}\nolimits_{n,N}:L\mathfrak{gl}%
_{n}\rightarrow L\mathfrak{gl}_{N}$ be the map which sends every $a\left(
t\right)  \in L\mathfrak{gl}_{n}$ to%
\[
\sum\limits_{\ell\in\mathbb{Z}}\underbrace{\left(
\begin{array}
[c]{ccccc}%
a_{\left(  j-i\right)  d} & a_{\left(  j-i\right)  d+1} & a_{\left(
j-i\right)  d+2} & ... & a_{\left(  j-i\right)  d+\left(  d-1\right)  }\\
a_{\left(  j-i\right)  d-1} & a_{\left(  j-i\right)  d} & a_{\left(
j-i\right)  d+1} & ... & a_{\left(  j-i\right)  d+\left(  d-2\right)  }\\
a_{\left(  j-i\right)  d-2} & a_{\left(  j-i\right)  d-1} & a_{\left(
j-i\right)  d} & ... & a_{\left(  j-i\right)  d+\left(  d-3\right)  }\\
... & ... & ... & ... & ...\\
a_{\left(  j-i\right)  d-\left(  d-1\right)  } & a_{\left(  j-i\right)
d-\left(  d-2\right)  } & a_{\left(  j-i\right)  d-\left(  d-3\right)  } &
... & a_{\left(  j-i\right)  d}%
\end{array}
\right)  }_{\substack{\text{this is an }N\times N\text{-matrix constructed as
a }d\times d\text{-block matrix}\\\text{consisting of }n\times n\text{-blocks;
one can formally define this matrix}\\\text{as the }N\times N\text{-matrix
whose }\left(  nI+\alpha,nJ+\beta\right)  \text{-th entry equals}\\\text{the
}\left(  \alpha,\beta\right)  \text{-th entry of }a_{\left(  j-i\right)
d+J-I}\text{ for all }I\in\left\{  0,1,...,d-1\right\}  \text{,}\\J\in\left\{
0,1,...,d-1\right\}  \text{, }\alpha\in\left\{  1,2,...,n\right\}  \text{ and
}\beta\in\left\{  1,2,...,n\right\}  }}t^{\ell}\in L\mathfrak{gl}_{N}%
\]
(where we write $a\left(  t\right)  $ in the form $a\left(  t\right)
=\sum\limits_{i\in\mathbb{Z}}a_{i}t^{i}$ with $a_{i}\in\mathfrak{gl}_{n}$).

\textbf{(a)} We have $\operatorname*{Toep}\nolimits_{N}\circ
\operatorname*{Toep}\nolimits_{n,N}=\operatorname*{Toep}\nolimits_{n}$. In
other words, we can regard $\operatorname*{Toep}\nolimits_{n,N}$ as an
inclusion map $L\mathfrak{gl}_{n}\rightarrow L\mathfrak{gl}_{N}$ which forms a
commutative triangle with the inclusion maps $\operatorname*{Toep}%
\nolimits_{n}:L\mathfrak{gl}_{n}\rightarrow\overline{\mathfrak{a}_{\infty}}$
and $\operatorname*{Toep}\nolimits_{N}:L\mathfrak{gl}_{N}\rightarrow
\overline{\mathfrak{a}_{\infty}}$. In other words, if we consider
$L\mathfrak{gl}_{n}$ and $L\mathfrak{gl}_{N}$ as Lie subalgebras of
$\overline{\mathfrak{a}_{\infty}}$ (by means of the injections
$\operatorname*{Toep}\nolimits_{n}:L\mathfrak{gl}_{n}\rightarrow
\overline{\mathfrak{a}_{\infty}}$ and $\operatorname*{Toep}\nolimits_{N}%
:L\mathfrak{gl}_{N}\rightarrow\overline{\mathfrak{a}_{\infty}}$), then
$L\mathfrak{gl}_{n}\subseteq L\mathfrak{gl}_{N}$.

\textbf{(b)} If we consider $\operatorname*{Toep}\nolimits_{n,N}$ as an
inclusion map $L\mathfrak{gl}_{n}\rightarrow L\mathfrak{gl}_{N}$, then the
$2$-cocycle $\omega:L\mathfrak{gl}_{n}\times L\mathfrak{gl}_{n}\rightarrow
\mathbb{C}$ defined in Proposition \ref{prop.ainf.alphaomega} is the
restriction of the similarly-defined $2$-cocycle $\omega:L\mathfrak{gl}%
_{N}\times L\mathfrak{gl}_{N}\rightarrow\mathbb{C}$ (we also call it $\omega$
because it is constructed similarly) to $L\mathfrak{gl}_{n}\times
L\mathfrak{gl}_{n}$. As a consequence, the inclusion map $\operatorname*{Toep}%
\nolimits_{n,N}:L\mathfrak{gl}_{n}\rightarrow L\mathfrak{gl}_{N}$ induces a
Lie algebra injection $\widehat{\operatorname*{Toep}\nolimits_{n,N}%
}:\widehat{\mathfrak{gl}_{n}}\rightarrow\widehat{\mathfrak{gl}_{N}}$ which
satisfies $\widehat{\operatorname*{Toep}\nolimits_{N}}\circ
\widehat{\operatorname*{Toep}\nolimits_{n,N}}=\widehat{\operatorname*{Toep}%
\nolimits_{n}}$. Thus, this injection $\widehat{\operatorname*{Toep}%
\nolimits_{n,N}}$ forms a commutative triangle with the inclusion maps
$\widehat{\operatorname*{Toep}\nolimits_{n}}:\widehat{\mathfrak{gl}_{n}%
}\rightarrow\mathfrak{a}_{\infty}$ and $\widehat{\operatorname*{Toep}%
\nolimits_{N}}:\widehat{\mathfrak{gl}_{N}}\rightarrow\mathfrak{a}_{\infty}$.
In other words, if we consider $\widehat{\mathfrak{gl}_{n}}$ and
$\widehat{\mathfrak{gl}_{N}}$ as Lie subalgebras of $\mathfrak{a}_{\infty}$
(by means of the injections $\widehat{\operatorname*{Toep}\nolimits_{n}%
}:\widehat{\mathfrak{gl}_{n}}\rightarrow\mathfrak{a}_{\infty}$ and
$\widehat{\operatorname*{Toep}\nolimits_{N}}:\widehat{\mathfrak{gl}_{N}%
}\rightarrow\mathfrak{a}_{\infty}$), then $\widehat{\mathfrak{gl}_{n}%
}\subseteq\widehat{\mathfrak{gl}_{N}}$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.glnhat.div}.} \textbf{(a)} The proof of
Proposition \ref{prop.glnhat.div} \textbf{(a)} is completely straightforward.
(One has to show that the $\left(  Ni+nI+\alpha,Nj+nJ+\beta\right)  $-th entry
of $\left(  \operatorname*{Toep}\nolimits_{N}\circ\operatorname*{Toep}%
\nolimits_{n,N}\right)  \left(  a\left(  t\right)  \right)  $ equals the
$\left(  Ni+nI+\alpha,Nj+nJ+\beta\right)  $-th entry of $\operatorname*{Toep}%
\nolimits_{n}\left(  a\left(  t\right)  \right)  $ for every $a\left(
t\right)  \in L\mathfrak{gl}_{n}$, every $i\in\mathbb{Z}$, every
$j\in\mathbb{Z}$, every $I\in\left\{  0,1,...,d-1\right\}  $, $J\in\left\{
0,1,...,d-1\right\}  $, $\alpha\in\left\{  1,2,...,n\right\}  $ and $\beta
\in\left\{  1,2,...,n\right\}  $.)

\textbf{(b)} The $2$-cocycle $\omega:L\mathfrak{gl}_{n}\times L\mathfrak{gl}%
_{n}\rightarrow\mathbb{C}$ defined in Proposition \ref{prop.ainf.alphaomega}
is the restriction of the similarly-defined $2$-cocycle $\omega:L\mathfrak{gl}%
_{N}\times L\mathfrak{gl}_{N}\rightarrow\mathbb{C}$ to $L\mathfrak{gl}%
_{n}\times L\mathfrak{gl}_{n}$. (This is because both of these $2$-cocycles
are restrictions of the Japanese cocycle $\alpha:\overline{\mathfrak{a}%
_{\infty}}\times\overline{\mathfrak{a}_{\infty}}\rightarrow\mathbb{C}$, as
shown in Proposition \ref{prop.ainf.alphaomega}.) This proves Proposition
\ref{prop.glnhat.div}.

Note that Proposition \ref{prop.glnhat.div} can be used to derive Proposition
\ref{prop.glnhat.T}:

\textit{Second proof of Proposition \ref{prop.glnhat.T}.} \textbf{(a)} For
every $m\in\mathbb{Z}$, we have $T^{m}\in\widehat{\mathfrak{gl}_{1}}$ (because
the Lie algebra isomorphism $\widehat{\phi}$ constructed in Corollary
\ref{cor.glnhat.div} satisfies $\phi\left(  a_{m}\right)  =T^{m}$, so that
$T^{m}\in\phi\left(  a_{m}\right)  \in\widehat{\mathfrak{gl}_{1}}$). Thus, for
every $m\in\mathbb{Z}$, we have $T^{m}\in\widehat{\mathfrak{gl}_{1}}%
\cap\overline{\mathfrak{a}_{\infty}}=L\mathfrak{gl}_{1}$.

Due to Proposition \ref{prop.glnhat.div} \textbf{(a)}, we have $L\mathfrak{gl}%
_{1}\subseteq L\mathfrak{gl}_{n}$ (since $1\mid n$). Thus, for every
$m\in\mathbb{Z}$, we have $T^{m}\in L\mathfrak{gl}_{1}\subseteq L\mathfrak{gl}%
_{n}\subseteq\widehat{\mathfrak{gl}_{n}}$. This proves Proposition
\ref{prop.glnhat.T} \textbf{(a)}.

\textbf{(b)} Due to Proposition \ref{prop.glnhat.div} \textbf{(b)}, we have
$\widehat{\mathfrak{gl}_{1}}\subseteq\widehat{\mathfrak{gl}_{n}}$ (since
$1\mid n$). Hence, the Lie algebra isomorphism $\widehat{\phi}:\mathcal{A}%
\rightarrow\widehat{\mathfrak{gl}_{1}}$ constructed in Corollary
\ref{cor.glnhat.div} induces a Lie algebra injection $\mathcal{A}%
\rightarrow\widehat{\mathfrak{gl}_{n}}$ (which sends every $a\in\mathcal{A}$
to $\widehat{\phi}\left(  a\right)  \in\widehat{\mathfrak{gl}_{n}}$). Formally
speaking, this injection is the map $\widehat{\operatorname*{Toep}%
\nolimits_{1,n}}\circ\widehat{\phi}:\mathcal{A}\rightarrow
\widehat{\mathfrak{gl}_{n}}$ (because the injection $\widehat{\mathfrak{gl}%
_{1}}\rightarrow\widehat{\mathfrak{gl}_{n}}$ is $\widehat{\operatorname*{Toep}%
\nolimits_{1,n}}$). Therefore, the restriction of the $\widehat{\mathfrak{gl}%
_{n}}$-module $\mathcal{F}^{\left(  m\right)  }$ by means of this injection is%
\begin{align*}
&  \left(  \text{the restriction of the }\widehat{\mathfrak{gl}_{n}%
}\text{-module }\mathcal{F}^{\left(  m\right)  }\text{ by means of the
injection }\widehat{\operatorname*{Toep}\nolimits_{1,n}}\circ\widehat{\phi
}:\mathcal{A}\rightarrow\widehat{\mathfrak{gl}_{n}}\right) \\
&  =\left(  \text{the restriction of the }\mathfrak{a}_{\infty}\text{-module
}\mathcal{F}^{\left(  m\right)  }\text{ by means of the injection
}\widehat{\operatorname*{Toep}\nolimits_{n}}\circ\widehat{\operatorname*{Toep}%
\nolimits_{1,n}}\circ\widehat{\phi}:\mathcal{A}\rightarrow\mathfrak{a}%
_{\infty}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because the }\widehat{\mathfrak{gl}_{n}}\text{-module }\mathcal{F}%
^{\left(  m\right)  }\text{ itself was the restriction of the }\mathfrak{a}%
_{\infty}\text{-module }\mathcal{F}^{\left(  m\right)  }\\
\text{by means of the injection }\widehat{\operatorname*{Toep}\nolimits_{n}%
}:\widehat{\mathfrak{gl}_{n}}\rightarrow\mathfrak{a}_{\infty}%
\end{array}
\right) \\
&  =\left(  \text{the restriction of the }\mathfrak{a}_{\infty}\text{-module
}\mathcal{F}^{\left(  m\right)  }\text{ by means of the injection
}\widehat{\operatorname*{Toep}\nolimits_{1}}\circ\widehat{\phi}:\mathcal{A}%
\rightarrow\mathfrak{a}_{\infty}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\widehat{\operatorname*{Toep}\nolimits_{n}}\circ
\widehat{\operatorname*{Toep}\nolimits_{1,n}}=\widehat{\operatorname*{Toep}%
\nolimits_{1}}\\
\text{(by Proposition \ref{prop.glnhat.div} \textbf{(b)}, applied to }n\text{
and }1\text{ instead of }N\text{ and }n\text{)}%
\end{array}
\right) \\
&  =\left(
\begin{array}
[c]{c}%
\text{the restriction of the }\mathfrak{a}_{\infty}\text{-module }%
\mathcal{F}^{\left(  m\right)  }\text{ by means of the}\\
\text{embedding }\mathcal{A}\rightarrow\mathfrak{a}_{\infty}\text{ constructed
in Definition \ref{def.ainf.A}}%
\end{array}
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because }\widehat{\operatorname*{Toep}\nolimits_{1}}\circ\widehat{\phi
}:\mathcal{A}\rightarrow\mathfrak{a}_{\infty}\text{ is exactly the}\\
\text{embedding }\mathcal{A}\rightarrow\mathfrak{a}_{\infty}\text{ constructed
in Definition \ref{def.ainf.A}}%
\end{array}
\right) \\
&  =\left(  \text{the }\mathcal{A}\text{-module }\mathcal{F}^{\left(
m\right)  }\text{ that we know}\right)  .
\end{align*}
This proves Proposition \ref{prop.glnhat.T} \textbf{(b)}.

\subsection{The semidirect product
\texorpdfstring{$\protect\widetilde{\mathfrak{gl}_{n}}$}{gl-n-tilde} and its
representation theory}

\subsubsection{Extending affine Lie algebras by derivations}

Now we give a definition pertaining to general affine Lie algebras:

\begin{definition}
\label{def.gwave}If $\widehat{\mathfrak{g}}=L\mathfrak{g}\oplus\mathbb{C}K$ is
an affine Lie algebra (the $\oplus$ sign here only means a direct sum of
vector spaces, not a direct sum of Lie algebras), then there exists a unique
linear map $d:\widehat{\mathfrak{g}}\rightarrow\widehat{\mathfrak{g}}$ such
that $d\left(  a\left(  t\right)  \right)  =ta^{\prime}\left(  t\right)  $ for
every $a\left(  t\right)  \in L\mathfrak{g}$ (so that $d\left(  at^{\ell
}\right)  =\ell at^{\ell}$ for every $a\in\mathfrak{g}$ and $\ell\in
\mathbb{N}$) and $d\left(  K\right)  =0$. This linear map $d$ is a derivation
(as can be easily checked). Thus, the abelian Lie algebra $\mathbb{C}d$ (a
one-dimensional Lie algebra) acts on the Lie algebra $\widehat{\mathfrak{g}}$
by derivations (in the obvious way, with $d$ acting as $d$). Thus, a
semidirect product $\mathbb{C}d\ltimes\widehat{\mathfrak{g}}$ is well-defined
(according to Definition \ref{def.semidir.lielie}).

Set $\widetilde{\mathfrak{g}}=\mathbb{C}d\ltimes\widehat{\mathfrak{g}}$.
Clearly, $\widetilde{\mathfrak{g}}=\mathbb{C}d\oplus\widehat{\mathfrak{g}}$ as
vector space. The Lie algebra $\widetilde{\mathfrak{g}}$ is graded by taking
the grading of $\widehat{\mathfrak{g}}$ and additionally giving $d$ the degree
$0$.
\end{definition}

One can wonder which $\widehat{\mathfrak{g}}$-modules can be extended to
$\widetilde{\mathfrak{g}}$-modules. This can't be generally answered, but here
is a partial uniqueness result:

\begin{lemma}
\label{lem.gwave.uniqueder}Let $\mathfrak{g}$ be a Lie algebra, and $d$ be the
unique derivation $\widehat{\mathfrak{g}}\rightarrow\widehat{\mathfrak{g}}$
constructed in Definition \ref{def.gwave}. Let $M$ be a $\widehat{\mathfrak{g}%
}$-module, and $v$ an element of $M$ such that $M$ is generated by $v$ as a
$\widehat{\mathfrak{g}}$-module. Then, there exists \textbf{at most one}
extension of the $\widehat{\mathfrak{g}}$-representation on $M$ to
$\widetilde{\mathfrak{g}}$ such that $dv=0$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.gwave.uniqueder}.} Let $\rho_{1}%
:\widetilde{\mathfrak{g}}\rightarrow\operatorname*{End}M$ and $\rho
_{2}:\widetilde{\mathfrak{g}}\rightarrow\operatorname*{End}M$ be two
extensions of the $\widehat{\mathfrak{g}}$-representation on $M$ to
$\widetilde{\mathfrak{g}}$ such that $\rho_{1}\left(  d\right)  v=0$ and
$\rho_{2}\left(  d\right)  v=0$. If we succeed in showing that $\rho_{1}%
=\rho_{2}$, then Lemma \ref{lem.gwave.uniqueder} will be proven.

Let $U$ be the subset $\left\{  u\in M\ \mid\ \rho_{1}\left(  d\right)
u=\rho_{2}\left(  d\right)  u\right\}  $ of $M$. Clearly, $U$ is a vector
subspace of $M$. Also, $v\in U$ (since $\rho_{1}\left(  d\right)  v=0=\rho
_{2}\left(  d\right)  v$). We will now show that $U$ is a
$\widehat{\mathfrak{g}}$-submodule of $M$.

In fact, since $\rho_{1}$ is an action of $\widetilde{\mathfrak{g}}$ on $M$,
every $m\in M$ and every $\alpha\in\widehat{\mathfrak{g}}$ satisfy%
\[
\left(  \rho_{1}\left(  d\right)  \right)  \left(  \rho_{1}\left(
\alpha\right)  m\right)  -\left(  \rho_{1}\left(  \alpha\right)  \right)
\left(  \rho_{1}\left(  d\right)  m\right)  =\rho_{1}\left(  \left[
d,\alpha\right]  \right)  m.
\]
Since $\rho_{1}\left(  \alpha\right)  m=\alpha\rightharpoonup m$ (because the
action $\rho_{1}$ extends the $\widehat{\mathfrak{g}}$-representation on $M$)
and $\left[  d,\alpha\right]  =d\left(  \alpha\right)  $ (by the definition of
the Lie bracket on the semidirect product $\widetilde{\mathfrak{g}}%
=\mathbb{C}d\ltimes\widehat{\mathfrak{g}}$), this rewrites as follows: Every
$m\in M$ and every $\alpha\in\widehat{\mathfrak{g}}$ satisfy%
\[
\left(  \rho_{1}\left(  d\right)  \right)  \left(  \alpha\rightharpoonup
m\right)  -\left(  \rho_{1}\left(  \alpha\right)  \right)  \left(  \rho
_{1}\left(  d\right)  m\right)  =\rho_{1}\left(  d\left(  \alpha\right)
\right)  m.
\]
Since $\left(  \rho_{1}\left(  \alpha\right)  \right)  \left(  \rho_{1}\left(
d\right)  m\right)  =\alpha\rightharpoonup\left(  \rho_{1}\left(  d\right)
m\right)  $ (again because the action $\rho_{1}$ extends the
$\widehat{\mathfrak{g}}$-representation on $M$) and $\rho_{1}\left(  d\left(
\alpha\right)  \right)  m=\left(  d\left(  \alpha\right)  \right)
\rightharpoonup m$ (for the same reason), this further rewrites as follows:
Every $m\in M$ and every $\alpha\in\widehat{\mathfrak{g}}$ satisfy%
\begin{equation}
\left(  \rho_{1}\left(  d\right)  \right)  \left(  \alpha\rightharpoonup
m\right)  -\alpha\rightharpoonup\left(  \rho_{1}\left(  d\right)  m\right)
=\left(  d\left(  \alpha\right)  \right)  \rightharpoonup m.
\label{pf.gwave.uniqueder.1}%
\end{equation}


Now, let $m\in U$ and $\alpha\in\widehat{\mathfrak{g}}$ be arbitrary. Then,
$\rho_{1}\left(  d\right)  m=\rho_{2}\left(  d\right)  m$ (by the definition
of $U$, since $m\in U$), but we have%
\[
\left(  \rho_{1}\left(  d\right)  \right)  \left(  \alpha\rightharpoonup
m\right)  =\alpha\rightharpoonup\left(  \rho_{1}\left(  d\right)  m\right)
+\left(  d\left(  \alpha\right)  \right)  \rightharpoonup m
\]
(by (\ref{pf.gwave.uniqueder.1})) and%
\[
\left(  \rho_{2}\left(  d\right)  \right)  \left(  \alpha\rightharpoonup
m\right)  =\alpha\rightharpoonup\left(  \rho_{2}\left(  d\right)  m\right)
+\left(  d\left(  \alpha\right)  \right)  \rightharpoonup m
\]
(similarly). Hence,%
\begin{align*}
\left(  \rho_{1}\left(  d\right)  \right)  \left(  \alpha\rightharpoonup
m\right)   &  =\alpha\rightharpoonup\underbrace{\left(  \rho_{1}\left(
d\right)  m\right)  }_{=\rho_{2}\left(  d\right)  m}+\left(  d\left(
\alpha\right)  \right)  \rightharpoonup m\\
&  =\alpha\rightharpoonup\left(  \rho_{2}\left(  d\right)  m\right)  +\left(
d\left(  \alpha\right)  \right)  \rightharpoonup m=\left(  \rho_{2}\left(
d\right)  \right)  \left(  \alpha\rightharpoonup m\right)  ,
\end{align*}
so that $\alpha\rightharpoonup m\in U$ (by the definition of $U$).

Now forget that we fixed $m\in U$ and $\alpha\in\widehat{\mathfrak{g}}$. We
thus have showed that $\alpha\rightharpoonup m\in U$ for every $m\in U$ and
$\alpha\in\widehat{\mathfrak{g}}$. In other words, $U$ is a
$\widehat{\mathfrak{g}}$-submodule of $M$. Since $v\in U$, this yields that
$U$ is a $\widehat{\mathfrak{g}}$-submodule of $M$ containing $v$, and thus
must be the whole $M$ (since $M$ is generated by $v$ as a
$\widehat{\mathfrak{g}}$-module). Thus, $M=U=\left\{  u\in M\ \mid\ \rho
_{1}\left(  d\right)  u=\rho_{2}\left(  d\right)  u\right\}  $. Hence, every
$u\in M$ satisfies $\rho_{1}\left(  d\right)  u=\rho_{2}\left(  d\right)  u$.
Thus, $\rho_{1}\left(  d\right)  =\rho_{2}\left(  d\right)  $.

Combining $\rho_{1}\mid_{\widehat{\mathfrak{g}}}=\rho_{2}\mid
_{\widehat{\mathfrak{g}}}$ (because both $\rho_{1}$ and $\rho_{2}$ are
extensions of the $\widehat{\mathfrak{g}}$-representation on $M$, and thus
coincide on $\widehat{\mathfrak{g}}$) and $\rho_{1}\mid_{\mathbb{C}d}=\rho
_{2}\mid_{\mathbb{C}d}$ (because $\rho_{1}\left(  d\right)  =\rho_{2}\left(
d\right)  $), we obtain $\rho_{1}=\rho_{2}$ (because the vector space
$\widetilde{\mathfrak{g}}=\mathbb{C}d\ltimes\widehat{\mathfrak{g}}$ is
generated by $\mathbb{C}d$ and $\widehat{\mathfrak{g}}$, and thus two linear
maps which coincide on $\mathbb{C}d$ and on $\widehat{\mathfrak{g}}$ must be
identical). Thus, as we said above, Lemma \ref{lem.gwave.uniqueder} is proven.

\subsubsection{\texorpdfstring{$\protect\widetilde{\mathfrak{gl}_{n}}$}
{gl-n-tilde}}

Applying Definition \ref{def.gwave} to $\mathfrak{g}=\mathfrak{gl}_{n}$, we
obtain a Lie algebra $\widetilde{\mathfrak{gl}_{n}}$. We want to study its
highest weight theory.

\begin{Convention}
For the sake of disambiguation, let us, in the following, use $E_{i,j}%
^{\mathfrak{gl}_{n}}$ to denote the elementary matrices of $\mathfrak{gl}_{n}$
(these are defined for $\left(  i,j\right)  \in\left\{  1,2,...,n\right\}
^{2}$), and use $E_{i,j}^{\mathfrak{gl}_{\infty}}$ to denote the elementary
matrices of $\mathfrak{gl}_{\infty}$ (these are defined for $\left(
i,j\right)  \in\mathbb{Z}^{2}$).
\end{Convention}

\begin{definition}
We can make $L\mathfrak{gl}_{n}$ into a graded Lie algebra by setting $\deg
E_{i,j}^{\mathfrak{gl}_{n}}=j-i$ (this, so far, is the standard grading on
$\mathfrak{gl}_{n}$) and $\deg t=n$. Consequently, $\widehat{\mathfrak{gl}%
_{n}}=\mathbb{C}K\oplus\mathfrak{gl}_{n}$ (this is just a direct sum of vector
spaces) becomes a graded Lie algebra with $\deg K=0$, and
$\widetilde{\mathfrak{gl}_{n}}=\mathbb{C}d\oplus\widehat{\mathfrak{gl}_{n}}$
(again, this is only a direct sum of vector spaces) becomes a graded Lie
algebra with $\deg d=0$.
\end{definition}

The triangular decomposition of $\widetilde{\mathfrak{gl}_{n}}$ is
$\widetilde{\mathfrak{gl}_{n}}=\widetilde{\mathfrak{n}_{-}}\oplus
\widetilde{\mathfrak{h}}\oplus\widetilde{\mathfrak{n}_{+}}$. Here,
$\widetilde{\mathfrak{h}}=\mathbb{C}K\oplus\mathbb{C}d\oplus\mathfrak{h}$
where $\mathfrak{h}$ is the Lie algebra of diagonal $n\times n$ matrices (in
other words, $\mathfrak{h}=\left\langle E_{1,1}^{\mathfrak{gl}_{n}}%
,E_{2,2}^{\mathfrak{gl}_{n}},...,E_{n,n}^{\mathfrak{gl}_{n}}\right\rangle $).
Further, $\widetilde{\mathfrak{n}_{+}}=\mathfrak{n}_{+}\oplus t\mathfrak{gl}%
_{n}\left[  t\right]  $ (where $\mathfrak{n}_{+}$ is the Lie algebra of
strictly upper-triangular matrices) and $\widetilde{\mathfrak{n}_{-}%
}=\mathfrak{n}_{-}\oplus t^{-1}\mathfrak{gl}_{n}\left[  t^{-1}\right]  $
(where $\mathfrak{n}_{-}$ is the Lie algebra of strictly lower-triangular matrices).

\begin{definition}
For every $m\in\mathbb{Z}$, define the weight $\widetilde{\omega}_{m}%
\in\widetilde{\mathfrak{h}}^{\ast}$ by%
\begin{align*}
\widetilde{\omega}_{m}\left(  E_{i,i}^{\mathfrak{gl}_{n}}\right)   &
=\left\{
\begin{array}
[c]{c}%
1,\text{ if }i\leq\overline{m};\\
0,\text{ if }i>\overline{m}%
\end{array}
\right.  +\dfrac{m-\overline{m}}{n}\ \ \ \ \ \ \ \ \ \ \text{for all }%
i\in\left\{  1,2,...,n\right\}  ;\\
\widetilde{\omega}_{m}\left(  K\right)   &  =1;\\
\widetilde{\omega}_{m}\left(  d\right)   &  =0,
\end{align*}
where $\overline{m}$ is the remainder of $m$ modulo $n$ (that is, the element
of $\left\{  0,1,...,n-1\right\}  $ satisfying $m\equiv\overline
{m}\operatorname{mod}n$).
\end{definition}

Note that we can rewrite the definition of $\widetilde{\omega}_{m}\left(
E_{i,i}^{\mathfrak{gl}_{n}}\right)  $ as%
\begin{align*}
&  \widetilde{\omega}_{m}\left(  E_{i,i}^{\mathfrak{gl}_{n}}\right) \\
&  =\left\{
\begin{array}
[c]{c}%
\left(  \text{the number of all }j\in\mathbb{Z}\text{ such that }j\equiv
i\operatorname{mod}n\text{ and }1\leq j\leq m\right)
,\ \ \ \ \ \ \ \ \ \ \text{if }m\geq0;\\
-\left(  \text{the number of all }j\in\mathbb{Z}\text{ such that }j\equiv
i\operatorname{mod}n\text{ and }m<j\leq0\right)  ,\ \ \ \ \ \ \ \ \ \ \text{if
}m\leq0
\end{array}
\right.  .
\end{align*}


\subsubsection{The \texorpdfstring{$\protect\widetilde{\mathfrak{gl}_{n}}$}
{gl-n-tilde}-module
\texorpdfstring{$\mathcal{F}^{\left(  m\right)  }$}{structure on the
semi-infinite wedge space}}

A natural question to ask about representations of $\widehat{\mathfrak{g}}$ is
when and how they can be extended to representations of
$\widetilde{\mathfrak{g}}$. Here is an answer for $\mathfrak{g}%
=\widehat{\mathfrak{gl}_{n}}$ and the representation $\mathcal{F}^{\left(
m\right)  }$:

\begin{proposition}
\label{prop.glwave.F}Let $m\in\mathbb{Z}$. Let $\psi_{m}$ be the element
$v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\in\mathcal{F}^{\left(  m\right)
}$.

There exists a unique extension of the $\widehat{\mathfrak{gl}_{n}}%
$-representation on $\mathcal{F}^{\left(  m\right)  }$ to
$\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}=0$. The action of $d$ in
this extension is given by%
\[
d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  =\left(
\sum\limits_{k\geq0}\left(  \left\lceil \dfrac{m-k}{n}\right\rceil
-\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)  \right)  \cdot v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...
\]
for every $m$-degression $\left(  i_{0},i_{1},i_{2},...\right)  $.
\end{proposition}

Note that the infinite sum $\sum\limits_{k\geq0}\left(  \left\lceil
\dfrac{m-k}{n}\right\rceil -\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)
$ in Proposition \ref{prop.glwave.F} is well-defined\footnote{In fact,
$\left(  i_{0},i_{1},i_{2},...\right)  $ is an $m$-degression. Hence, every
sufficiently high $k\geq0$ satisfies $i_{k}+k=m$ and thus $m-k=i_{k}$ and thus
$\left\lceil \dfrac{m-k}{n}\right\rceil -\left\lceil \dfrac{i_{k}}%
{n}\right\rceil =0$. Thus, all but finitely many addends of the infinite sum
$\sum\limits_{k\geq0}\left(  \left\lceil \dfrac{m-k}{n}\right\rceil
-\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)  $ are zero, so that this
sum is well-defined, qed.}.

\textit{Proof of Proposition \ref{prop.glwave.F}.} \textit{Uniqueness:} Let us
prove that there exists \textbf{at most one} extension of the
$\widehat{\mathfrak{gl}_{n}}$-representation on $\mathcal{F}^{\left(
m\right)  }$ to $\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}=0$.

By Proposition \ref{prop.glnhat.T} \textbf{(b)}, the $\mathcal{A}$-module
$\mathcal{F}^{\left(  m\right)  }$ is a restriction of the
$\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{F}^{\left(  m\right)  }$. As a
consequence, $\mathcal{F}^{\left(  m\right)  }$ is generated by $\psi_{m}$ as
a $\widehat{\mathfrak{gl}_{n}}$-module (since $\mathcal{F}^{\left(  m\right)
}$ is generated by $\psi_{m}$ as an $\mathcal{A}$-module). Hence, by Lemma
\ref{lem.gwave.uniqueder} (applied to $\mathfrak{g}=\mathfrak{gl}_{n}$,
$M=\mathcal{F}^{\left(  m\right)  }$ and $v=\psi_{m}$), there exists
\textbf{at most one} extension of the $\widehat{\mathfrak{gl}_{n}}%
$-representation on $\mathcal{F}^{\left(  m\right)  }$ to
$\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}=0$.

\textit{Existence:} Let us now show that there exists an extension of the
$\widehat{\mathfrak{gl}_{n}}$-representation on $\mathcal{F}^{\left(
m\right)  }$ to $\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}=0$.

In fact, let us construct this extension. In order to do so, it is clearly
enough to define the action of $d$ on $\mathcal{F}^{\left(  m\right)  }$
(because an action of $\widehat{\mathfrak{gl}_{n}}$ on $\mathcal{F}^{\left(
m\right)  }$ is already defined), and then show that every $A\in
\widehat{\mathfrak{gl}_{n}}$ satisfies%
\begin{equation}
\left[  d\mid_{\mathcal{F}^{\left(  m\right)  }},A\mid_{\mathcal{F}^{\left(
m\right)  }}\right]  =\left[  d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}%
\mid_{\mathcal{F}^{\left(  m\right)  }}. \label{pf.glwave.F.1}%
\end{equation}
\footnote{Here, for every $\xi\in\widetilde{\mathfrak{gl}_{n}}$, we denote by
$\xi\mid_{\mathcal{F}^{\left(  m\right)  }}$ the action of $\xi$ on
$\mathcal{F}^{\left(  m\right)  }$. Besides, $\left[  d,A\right]
_{\widetilde{\mathfrak{gl}_{n}}}$ means the Lie bracket of $d$ and $A$ in the
Lie algebra $\widetilde{\mathfrak{gl}_{n}}$.}

Let us define the action of $d$ on $\mathcal{F}^{\left(  m\right)  }$ by
stipulating that
\begin{equation}
d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  =\left(
\sum\limits_{k\geq0}\left(  \left\lceil \dfrac{m-k}{n}\right\rceil
-\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)  \right)  \cdot v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge... \label{pf.glwave.F.2}%
\end{equation}
for every $m$-degression $\left(  i_{0},i_{1},i_{2},...\right)  $. (This is
extended by linearity to the whole of $\mathcal{F}^{\left(  m\right)  }$,
since $\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)
_{\left(  i_{0},i_{1},i_{2},...\right)  \text{ is an }m\text{-degression}}$ is
a basis of $\mathcal{F}^{\left(  m\right)  }$.)

It is rather clear that (\ref{pf.glwave.F.2}) holds not only for every
$m$-degression $\left(  i_{0},i_{1},i_{2},...\right)  $, but also for every
straying $m$-degression $\left(  i_{0},i_{1},i_{2},...\right)  $%
.\ \ \ \ \footnote{In fact, if $\left(  i_{0},i_{1},i_{2},...\right)  $ is a
straying $m$-degression with no two equal elements, and $\pi$ is its
straightening permutation, then $\sum\limits_{k\geq0}\left(  \left\lceil
\dfrac{m-k}{n}\right\rceil -\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)
=\sum\limits_{k\geq0}\left(  \left\lceil \dfrac{m-k}{n}\right\rceil
-\left\lceil \dfrac{i_{\pi^{-1}\left(  k\right)  }}{n}\right\rceil \right)  $,
and this readily yields (\ref{pf.glwave.F.2}). If $\left(  i_{0},i_{1}%
,i_{2},...\right)  $ is a straying $m$-degression with two equal elements,
then (\ref{pf.glwave.F.2}) is even more obvious (since both sides of
(\ref{pf.glwave.F.2}) are zero in this case).} Renaming $\left(  i_{0}%
,i_{1},i_{2},...\right)  $ as $\left(  j_{0},j_{1},j_{2},...\right)  $ and
renaming the summation index $k$ as $p$, we can rewrite this as follows: We
have%
\begin{equation}
d\left(  v_{j_{0}}\wedge v_{j_{1}}\wedge v_{j_{2}}\wedge...\right)  =\left(
\sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{j_{p}}{n}\right\rceil \right)  \right)  \cdot v_{j_{0}%
}\wedge v_{j_{1}}\wedge v_{j_{2}}\wedge... \label{pf.glwave.F.2stray}%
\end{equation}
for every straying $m$-degression $\left(  j_{0},j_{1},j_{2},...\right)  $.

We now need to prove that every $A\in\widehat{\mathfrak{gl}_{n}}$ satisfies
(\ref{pf.glwave.F.1}). Since this equation (\ref{pf.glwave.F.1}) is linear in
$A$, we need to check it only in the case when $A=K$ and in the case when
$A=at^{\ell}$ for some $a\in\mathfrak{gl}_{n}$ and some $\ell\in\mathbb{Z}$
(because the vector space $\widehat{\mathfrak{gl}_{n}}$ is generated by $K$
and all elements of the form $at^{\ell}$ for some $a\in\mathfrak{gl}_{n}$ and
some $\ell\in\mathbb{Z}$). But checking the equation (\ref{pf.glwave.F.1}) in
the case when $A=K$ is trivial\footnote{In fact, $K\mid_{\mathcal{F}^{\left(
m\right)  }}=\operatorname*{id}$, so that $\left[  d\mid_{\mathcal{F}^{\left(
m\right)  }},K\mid_{\mathcal{F}^{\left(  m\right)  }}\right]  =\left[
d\mid_{\mathcal{F}^{\left(  m\right)  }},\operatorname*{id}\right]  =0$, and
by the definition of a semidirect product of Lie algebras we have $\left[
d,K\right]  _{\widetilde{\mathfrak{gl}_{n}}}=d\left(  K\right)  =0$, so that
both sides of (\ref{pf.glwave.F.1}) are zero in the case $A=K$, so that
(\ref{pf.glwave.F.1}) trivially holds in the case when $A=K$.}. Hence, it only
remains to check the equation (\ref{pf.glwave.F.1}) in the case when
$A=at^{\ell}$ for some $a\in\mathfrak{gl}_{n}$ and some $\ell\in\mathbb{Z}$.

So let $a\in\mathfrak{gl}_{n}$ and $\ell\in\mathbb{Z}$ be arbitrary. We can
WLOG assume that if $\ell=0$, then the diagonal entries of the matrix $a$ are
zero\footnote{Here is why this assumption is allowed:
\par
We must prove that every $a\in\mathfrak{gl}_{n}$ and $\ell\in\mathbb{Z}$
satisfy the equation (\ref{pf.glwave.F.1}) for $A=at^{\ell}$. In other words,
we must prove that every $a\in\mathfrak{gl}_{n}$ and $\ell\in\mathbb{Z}$
satisfy $\left[  d\mid_{\mathcal{F}^{\left(  m\right)  }},\left(  at^{\ell
}\right)  \mid_{\mathcal{F}^{\left(  m\right)  }}\right]  =\left[  d,\left(
at^{\ell}\right)  \right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}%
^{\left(  m\right)  }}$. If $\ell\neq0$, then our assumption (that if $\ell
=0$, then the diagonal entries of the matrix $a$ are zero) is clearly allowed
(because it only makes a statement about the case $\ell=0$). So we only need
to consider the case $\ell=0$. In this case, the equation which we must prove
(this is the equation $\left[  d\mid_{\mathcal{F}^{\left(  m\right)  }%
},\left(  at^{\ell}\right)  \mid_{\mathcal{F}^{\left(  m\right)  }}\right]
=\left[  d,\left(  at^{\ell}\right)  \right]  _{\widetilde{\mathfrak{gl}_{n}}%
}\mid_{\mathcal{F}^{\left(  m\right)  }}$) simplifies to $\left[
d\mid_{\mathcal{F}^{\left(  m\right)  }},a\mid_{\mathcal{F}^{\left(  m\right)
}}\right]  =\left[  d,a\right]  _{\widetilde{\mathfrak{gl}_{n}}}%
\mid_{\mathcal{F}^{\left(  m\right)  }}$. This equation is clearly linear in
$a$. Hence, we can WLOG\ assume that either the matrix $a$ is diagonal, or all
diagonal entries of the matrix $a$ are zero (because every $n\times n$ matrix
can be decomposed as a sum of a diagonal matrix with a matrix all of whose
diagonal entries are zero). But in the case when the matrix $a$ is diagonal,
the equation $\left[  d\mid_{\mathcal{F}^{\left(  m\right)  }},a\mid
_{\mathcal{F}^{\left(  m\right)  }}\right]  =\left[  d,a\right]
_{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}^{\left(  m\right)  }}$ is
very easy to check (the details of this are left to the reader). Hence, it is
enough to only consider the case when the diagonal entries of the matrix $a$
are $0$. Of course, our assumption is justified in this case.
\par
Thus, we are allowed to make the assumption that if $\ell=0$, then the
diagonal entries of the matrix $a$ are zero.}. Let us assume this. (The
purpose of this assumption is to ensure that we can apply Proposition
\ref{prop.glinf.ainfact} to $at^{\ell}$ in lieu of $a$.)

Let $\left(  i_{0},i_{1},i_{2},...\right)  $ be an $m$-degression.

We recall that, when we embedded $L\mathfrak{gl}_{n}$ into $\overline
{\mathfrak{a}_{\infty}}$, we identified the element $at^{\ell}\in
L\mathfrak{gl}_{n}$ with the matrix $\operatorname*{Toep}\nolimits_{n}\left(
at^{\ell}\right)  $ whose $\left(  ni+\alpha,nj+\beta\right)  $-th entry
equals%
\[
\left\{
\begin{array}
[c]{l}%
\text{the }\left(  \alpha,\beta\right)  \text{-th entry of }%
a,\ \ \ \ \ \ \ \ \ \ \text{if }j-i=\ell;\\
0,\ \ \ \ \ \ \ \ \ \ \text{if }j-i\neq\ell
\end{array}
\right.
\]
for all $i\in\mathbb{Z}$, $j\in\mathbb{Z}$, $\alpha\in\left\{
1,2,...,n\right\}  $ and $\beta\in\left\{  1,2,...,n\right\}  $. Hence, for
every $j\in\mathbb{Z}$ and $\beta\in\left\{  1,2,...,n\right\}  $, we have%
\begin{align}
&  \left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  \right)
\rightharpoonup v_{nj+\beta}\nonumber\\
&  =\sum\limits_{i\in\mathbb{Z}}\sum\limits_{\alpha\in\left\{
1,2,...,n\right\}  }\left\{
\begin{array}
[c]{l}%
\text{the }\left(  \alpha,\beta\right)  \text{-th entry of }%
a,\ \ \ \ \ \ \ \ \ \ \text{if }j-i=\ell;\\
0,\ \ \ \ \ \ \ \ \ \ \text{if }j-i\neq\ell
\end{array}
\right.  v_{ni+\alpha}\nonumber\\
&  =\sum\limits_{\alpha\in\left\{  1,2,...,n\right\}  }\underbrace{\sum
\limits_{i\in\mathbb{Z}}\left\{
\begin{array}
[c]{l}%
\text{the }\left(  \alpha,\beta\right)  \text{-th entry of }%
a,\ \ \ \ \ \ \ \ \ \ \text{if }j-i=\ell;\\
0,\ \ \ \ \ \ \ \ \ \ \text{if }j-i\neq\ell
\end{array}
\right.  v_{ni+\alpha}}_{\substack{=\left(  \text{the }\left(  \alpha
,\beta\right)  \text{-th entry of }a\right)  v_{n\left(  j-\ell\right)
+\alpha}\\\text{(since there is precisely one }i\in\mathbb{Z}\text{ satisfying
}j-i=\ell\text{, namely }i=j-\ell\text{)}}}\nonumber\\
&  =\sum\limits_{\alpha\in\left\{  1,2,...,n\right\}  }\left(  \text{the
}\left(  \alpha,\beta\right)  \text{-th entry of }a\right)  v_{n\left(
j-\ell\right)  +\alpha}. \label{pf.glwave.F.3}%
\end{align}


Note that the matrix $\operatorname*{Toep}\nolimits_{n}\left(  at^{\ell
}\right)  $ has the property that, for every integer $i\leq0$, the $\left(
i,i\right)  $-th entry of $\operatorname*{Toep}\nolimits_{n}\left(  at^{\ell
}\right)  $ is $0$. (This is due to our assumption that if $\ell=0$, then the
diagonal entries of the matrix $a$ are zero.) As a consequence, we can apply
Proposition \ref{prop.glinf.ainfact} to $\operatorname*{Toep}\nolimits_{n}%
\left(  at^{\ell}\right)  $ and $v_{i_{k}}$ instead of $a$ and $b_{k}$, and
obtain%
\begin{align}
&  \left(  \widehat{\rho}\left(  \operatorname*{Toep}\nolimits_{n}\left(
at^{\ell}\right)  \right)  \right)  \left(  v_{i_{0}}\wedge v_{i_{1}}\wedge
v_{i_{2}}\wedge...\right) \nonumber\\
&  =\sum\limits_{k\geq0}v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}%
}\wedge\left(  \left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell
}\right)  \right)  \rightharpoonup v_{i_{k}}\right)  \wedge v_{i_{k+1}}\wedge
v_{i_{k+2}}\wedge.... \label{pf.glwave.F.4}%
\end{align}


Now, we can check that, for every $k\geq0$, we have%
\begin{align}
&  d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge\left(
\left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  \right)
\rightharpoonup v_{i_{k}}\right)  \wedge v_{i_{k+1}}\wedge v_{i_{k+2}}%
\wedge...\right) \nonumber\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \cdot v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge
v_{i_{k-1}}\wedge\left(  \left(  \operatorname*{Toep}\nolimits_{n}\left(
at^{\ell}\right)  \right)  \rightharpoonup v_{i_{k}}\right)  \wedge
v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge.... \label{pf.glwave.F.4a}%
\end{align}
\footnote{\textit{Proof of (\ref{pf.glwave.F.4a}):} Let $k\geq0$. Write the
integer $i_{k}$ in the form $nj+\beta$ for some $j\in\mathbb{Z}$ and $\beta
\in\left\{  1,2,...,n\right\}  $. Then,
\[
\left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  \right)
\rightharpoonup v_{i_{k}}=\left(  \operatorname*{Toep}\nolimits_{n}\left(
at^{\ell}\right)  \right)  \rightharpoonup v_{nj+\beta}=\sum\limits_{\alpha
\in\left\{  1,2,...,n\right\}  }\left(  \text{the }\left(  \alpha
,\beta\right)  \text{-th entry of }a\right)  v_{n\left(  j-\ell\right)
+\alpha}%
\]
due to (\ref{pf.glwave.F.3}). Hence,%
\begin{align}
&  v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge
\underbrace{\left(  \left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell
}\right)  \right)  \rightharpoonup v_{i_{k}}\right)  }_{=\sum\limits_{\alpha
\in\left\{  1,2,...,n\right\}  }\left(  \text{the }\left(  \alpha
,\beta\right)  \text{-th entry of }a\right)  v_{n\left(  j-\ell\right)
+\alpha}}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge...\nonumber\\
&  =\sum\limits_{\alpha\in\left\{  1,2,...,n\right\}  }\left(  \text{the
}\left(  \alpha,\beta\right)  \text{-th entry of }a\right)  \cdot v_{i_{0}%
}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge v_{n\left(  j-\ell\right)
+\alpha}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge.... \label{pf.glwave.F.5}%
\end{align}
\par
Now, fix $\alpha\in\left\{  1,2,...,n\right\}  $. Let $\left(  j_{0}%
,j_{1},j_{2},...\right)  $ be the straying $m$-degression $\left(  i_{0}%
,i_{1},i_{2},...,i_{k-1},n\left(  j-\ell\right)  +\alpha,i_{k+1}%
,i_{k+2},...\right)  $. Then, $j_{p}=i_{p}$ for every $p\geq0$ satisfying
$p\neq k$.
\par
Comparing $\left\lceil \dfrac{i_{k}}{n}\right\rceil =j+1$ (since
$i_{k}=nj+\beta$ with $\beta\in\left\{  1,2,...,n\right\}  $) with
$\left\lceil \dfrac{j_{k}}{n}\right\rceil =j-\ell+1$ (since $j_{k}=n\left(
j-\ell\right)  +\alpha$ with $\alpha\in\left\{  1,2,...,n\right\}  $), we get
$\left\lceil \dfrac{j_{k}}{n}\right\rceil =\left\lceil \dfrac{i_{k}}%
{n}\right\rceil -\ell$.
\par
Since $\left\lceil \dfrac{j_{p}}{n}\right\rceil =\left\lceil \dfrac{i_{p}}%
{n}\right\rceil $ for every $p\geq0$ satisfying $p\neq k$ (because every
$p\geq0$ satisfying $p\neq k$ satisfies $j_{p}=i_{p}$), the two sums
$\sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{j_{p}}{n}\right\rceil \right)  $ and $\sum\limits_{p\geq
0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil -\left\lceil \dfrac{i_{p}}%
{n}\right\rceil \right)  $ differ only in their $k$-th addends. Since the
$k$-th addends differ in $\ell$ (because $\left\lceil \dfrac{j_{k}}%
{n}\right\rceil =\left\lceil \dfrac{i_{k}}{n}\right\rceil -\ell$), this yields
$\sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{j_{p}}{n}\right\rceil \right)  =\sum\limits_{p\geq
0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil -\left\lceil \dfrac{i_{p}}%
{n}\right\rceil \right)  +\ell$.
\par
But since $\left(  i_{0},i_{1},i_{2},...,i_{k-1},n\left(  j-\ell\right)
+\alpha,i_{k+1},i_{k+2},...\right)  =\left(  j_{0},j_{1},j_{2},...\right)  $,
we have
\par%
\begin{align}
&  d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge
v_{n\left(  j-\ell\right)  +\alpha}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}%
\wedge...\right) \nonumber\\
&  =d\left(  v_{j_{0}}\wedge v_{j_{1}}\wedge v_{j_{2}}\wedge...\right)
=\underbrace{\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}%
{n}\right\rceil -\left\lceil \dfrac{j_{p}}{n}\right\rceil \right)  \right)
}_{=\sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell}\cdot
\underbrace{v_{j_{0}}\wedge v_{j_{1}}\wedge v_{j_{2}}\wedge...}%
_{\substack{=v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge
v_{n\left(  j-\ell\right)  +\alpha}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}%
\wedge...\\\text{(since }\left(  j_{0},j_{1},j_{2},...\right)  =\left(
i_{0},i_{1},i_{2},...,i_{k-1},n\left(  j-\ell\right)  +\alpha,i_{k+1}%
,i_{k+2},...\right)  \text{)}}}\nonumber\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right)  \cdot
v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge v_{n\left(
j-\ell\right)  +\alpha}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge....
\label{pf.glwave.F.6}%
\end{align}
Now forget that we fixed $\alpha$. Now, applying $d$ to the equality
(\ref{pf.glwave.F.5}), we get%
\begin{align*}
&  d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge\left(
\left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  \right)
\rightharpoonup v_{i_{k}}\right)  \wedge v_{i_{k+1}}\wedge v_{i_{k+2}}%
\wedge...\right) \\
&  =\sum\limits_{\alpha\in\left\{  1,2,...,n\right\}  }\left(  \text{the
}\left(  \alpha,\beta\right)  \text{-th entry of }a\right) \\
&  \ \ \ \ \ \ \ \ \ \ \cdot\underbrace{d\left(  v_{i_{0}}\wedge v_{i_{1}%
}\wedge...\wedge v_{i_{k-1}}\wedge v_{n\left(  j-\ell\right)  +\alpha}\wedge
v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge...\right)  }_{\substack{=\left(
\sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right)  \cdot
v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge v_{n\left(
j-\ell\right)  +\alpha}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge
...\\\text{(by (\ref{pf.glwave.F.6}))}}}\\
&  =\sum\limits_{\alpha\in\left\{  1,2,...,n\right\}  }\left(  \text{the
}\left(  \alpha,\beta\right)  \text{-th entry of }a\right) \\
&  \ \ \ \ \ \ \ \ \ \ \cdot\left(  \sum\limits_{p\geq0}\left(  \left\lceil
\dfrac{m-p}{n}\right\rceil -\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)
+\ell\right)  \cdot v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge
v_{n\left(  j-\ell\right)  +\alpha}\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}%
\wedge...\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right) \\
&  \ \ \ \ \ \ \ \ \ \ \cdot\underbrace{\sum\limits_{\alpha\in\left\{
1,2,...,n\right\}  }\left(  \text{the }\left(  \alpha,\beta\right)  \text{-th
entry of }a\right)  \cdot v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}%
}\wedge v_{n\left(  j-\ell\right)  +\alpha}\wedge v_{i_{k+1}}\wedge
v_{i_{k+2}}\wedge...}_{\substack{=v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge
v_{i_{k-1}}\wedge\left(  \left(  \operatorname*{Toep}\nolimits_{n}\left(
at^{\ell}\right)  \right)  \rightharpoonup v_{i_{k}}\right)  \wedge
v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge...\\\text{(by (\ref{pf.glwave.F.5}))}}}\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right)  \cdot
v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge\left(  \left(
\operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  \right)
\rightharpoonup v_{i_{k}}\right)  \wedge v_{i_{k+1}}\wedge v_{i_{k+2}}%
\wedge...,
\end{align*}
so that (\ref{pf.glwave.F.4a}) is proven.}

Since $A=at^{\ell}$, we have $A\mid_{\mathcal{F}^{\left(  m\right)  }}=\left(
at^{\ell}\right)  \mid_{\mathcal{F}^{\left(  m\right)  }}=\widehat{\rho
}\left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  \right)  $
(because the element $at^{\ell}\in L\mathfrak{gl}_{n}$ was identified with the
matrix $\operatorname*{Toep}\nolimits_{n}\left(  at^{\ell}\right)  $ and this
matrix acts on $\mathcal{F}^{\left(  m\right)  }$ via $\widehat{\rho}$). Thus,
we can rewrite (\ref{pf.glwave.F.4}) as%
\begin{align}
&  \left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right) \nonumber\\
&  =\sum\limits_{k\geq0}v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}%
}\wedge\left(  \left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell
}\right)  \right)  \rightharpoonup v_{i_{k}}\right)  \wedge v_{i_{k+1}}\wedge
v_{i_{k+2}}\wedge.... \label{pf.glwave.F.4b}%
\end{align}
Applying $d$ to this equality, we get%
\begin{align}
&  d\left(  \left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  \right) \nonumber\\
&  =\sum\limits_{k\geq0}\underbrace{d\left(  v_{i_{0}}\wedge v_{i_{1}}%
\wedge...\wedge v_{i_{k-1}}\wedge\left(  \left(  \operatorname*{Toep}%
\nolimits_{n}\left(  at^{\ell}\right)  \right)  \rightharpoonup v_{i_{k}%
}\right)  \wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge...\right)  }%
_{\substack{=\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}%
{n}\right\rceil -\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)
+\ell\right)  \cdot v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i_{k-1}}%
\wedge\left(  \left(  \operatorname*{Toep}\nolimits_{n}\left(  at^{\ell
}\right)  \right)  \rightharpoonup v_{i_{k}}\right)  \wedge v_{i_{k+1}}\wedge
v_{i_{k+2}}\wedge...\\\text{(by (\ref{pf.glwave.F.4a}))}}}\nonumber\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \cdot\underbrace{\sum\limits_{k\geq0}v_{i_{0}}\wedge
v_{i_{1}}\wedge...\wedge v_{i_{k-1}}\wedge\left(  \left(  \operatorname*{Toep}%
\nolimits_{n}\left(  at^{\ell}\right)  \right)  \rightharpoonup v_{i_{k}%
}\right)  \wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge...}_{\substack{=\left(
A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  \\\text{(by (\ref{pf.glwave.F.4b}%
))}}}\nonumber\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  +\ell\right)  \left(
A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\right) \nonumber\\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  \right)  \left(
A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\ell\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }%
}\right)  \left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  .
\label{pf.glwave.F.10}%
\end{align}
Since%
\begin{align*}
&  \left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)
\underbrace{\left(  d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  \right)  }_{\substack{=\left(  \sum\limits_{p\geq0}\left(
\left\lceil \dfrac{m-p}{n}\right\rceil -\left\lceil \dfrac{j_{p}}%
{n}\right\rceil \right)  \right)  \cdot v_{i_{0}}\wedge v_{i_{1}}\wedge
v_{i_{2}}\wedge...\\\text{(by (\ref{pf.glwave.F.2stray}), applied to }\left(
j_{0},j_{1},j_{2},...\right)  =\left(  i_{0},i_{1},i_{2},...\right)  \text{)}%
}}\\
&  =\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  \left(
\sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{j_{p}}{n}\right\rceil \right)  \right)  \cdot v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right) \\
&  =\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}{n}\right\rceil
-\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  \right)  \left(
A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)
\end{align*}
and%
\begin{align*}
&  \left(  \left[  d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid
_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}}\wedge v_{i_{1}%
}\wedge v_{i_{2}}\wedge...\right) \\
&  =\left(  \ell A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since, by the definition of the Lie bracket on the semidirect product}\\
\widetilde{\mathfrak{gl}_{n}}=\mathbb{C}d\ltimes\widehat{\mathfrak{gl}_{n}%
}\text{, we have }\left[  d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}%
}=d\underbrace{\left(  A\right)  }_{=at^{\ell}}=d\left(  at^{\ell}\right)
=\ell\underbrace{at^{\ell}}_{=A}=\ell A
\end{array}
\right) \\
&  =\ell\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  ,
\end{align*}
we can rewrite (\ref{pf.glwave.F.10}) as%
\begin{align*}
&  d\left(  \left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  \right) \\
&  =\underbrace{\left(  \sum\limits_{p\geq0}\left(  \left\lceil \dfrac{m-p}%
{n}\right\rceil -\left\lceil \dfrac{i_{p}}{n}\right\rceil \right)  \right)
\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  }_{=\left(  A\mid
_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  d\left(  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  \right)  }\\
&  \ \ \ \ \ \ \ \ \ \ +\underbrace{\ell\left(  A\mid_{\mathcal{F}^{\left(
m\right)  }}\right)  \left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  }_{=\left(  \left[  d,A\right]  _{\widetilde{\mathfrak{gl}%
_{n}}}\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  }\\
&  =\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \left(  d\left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  \right)  +\left(
\left[  d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}^{\left(
m\right)  }}\right)  \left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  .
\end{align*}
In other words,%
\begin{align*}
&  \left(  \left(  d\mid_{\mathcal{F}^{\left(  m\right)  }}\right)
\circ\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \right)  \left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right) \\
&  =\left(  \left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)
\circ\left(  d\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \right)  \left(
v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  +\left(  \left[
d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}^{\left(
m\right)  }}\right)  \left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right) \\
&  =\left(  \left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)
\circ\left(  d\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  +\left[
d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}^{\left(
m\right)  }}\right)  \left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  .
\end{align*}
Since this holds for every $m$-degression $\left(  i_{0},i_{1},i_{2}%
,...\right)  $, this yields that $\left(  d\mid_{\mathcal{F}^{\left(
m\right)  }}\right)  \circ\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }%
}\right)  =\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)
\circ\left(  d\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  +\left[
d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}^{\left(
m\right)  }}$ (because $\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}%
}\wedge...\right)  _{\left(  i_{0},i_{1},i_{2},...\right)  \text{ is an
}m\text{-degression}}$ is a basis of $\mathcal{F}^{\left(  m\right)  }$). In
other words,%
\[
\left[  d,A\right]  _{\widetilde{\mathfrak{gl}_{n}}}\mid_{\mathcal{F}^{\left(
m\right)  }}=\left(  d\mid_{\mathcal{F}^{\left(  m\right)  }}\right)
\circ\left(  A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  -\left(
A\mid_{\mathcal{F}^{\left(  m\right)  }}\right)  \circ\left(  d\mid
_{\mathcal{F}^{\left(  m\right)  }}\right)  =\left[  d\mid_{\mathcal{F}%
^{\left(  m\right)  }},A\mid_{\mathcal{F}^{\left(  m\right)  }}\right]  .
\]
In other words, (\ref{pf.glwave.F.1}) holds.

We have thus checked the equation (\ref{pf.glwave.F.1}) in the case when
$A=at^{\ell}$ for some $a\in\mathfrak{gl}_{n}$ and some $\ell\in\mathbb{Z}$.
As explained above, this completes the proof of the equation
(\ref{pf.glwave.F.1}) for every $A\in\widehat{\mathfrak{gl}_{n}}$. Hence, we
have constructed an action of $d$ on $\mathcal{F}^{\left(  m\right)  }$. This
action clearly satisfies $d\psi_{m}=0$ (because $\psi_{m}=v_{m}\wedge
v_{m-1}\wedge v_{m-2}\wedge...$, so that%
\begin{align*}
d\psi_{m}  &  =d\left(  v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\right) \\
&  =\left(  \sum\limits_{k\geq0}\underbrace{\left(  \left\lceil \dfrac{m-k}%
{n}\right\rceil -\left\lceil \dfrac{m-k}{n}\right\rceil \right)  }%
_{=0}\right)  \cdot v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.glwave.F.2}), applied to
}i_{k}=m-k\right) \\
&  =0
\end{align*}
). Hence, we have proven the existence of an extension of the
$\widehat{\mathfrak{gl}_{n}}$-representation on $\mathcal{F}^{\left(
m\right)  }$ to $\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}=0$.

Altogether, we have now proven both the uniqueness and the existence of an
extension of the $\widehat{\mathfrak{gl}_{n}}$-representation on
$\mathcal{F}^{\left(  m\right)  }$ to $\widetilde{\mathfrak{gl}_{n}}$ such
that $d\psi_{m}=0$. Moreover, in the proof of the existence, we have showed
that the action of $d$ in this extension is given by%
\[
d\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)  =\left(
\sum\limits_{k\geq0}\left(  \left\lceil \dfrac{m-k}{n}\right\rceil
-\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)  \right)  \cdot v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...
\]
for every $m$-degression $\left(  i_{0},i_{1},i_{2},...\right)  $ (because we
defined this extension using (\ref{pf.glwave.F.2})). This completes the proof
of Proposition \ref{prop.glwave.F}.

Next, an irreducibility result:

\begin{proposition}
\label{prop.glwave.F.irr}Let $m\in\mathbb{Z}$. Let $\psi_{m}$ be the element
$v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\in\mathcal{F}^{\left(  m\right)
}$.

\textbf{(a)} The $\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{F}^{\left(
m\right)  }$ is irreducible.

\textbf{(b)} Let $\widehat{\rho}\mid_{\widetilde{\mathfrak{gl}_{n}}%
}:\widetilde{\mathfrak{gl}_{n}}\rightarrow\operatorname*{End}\left(
\mathcal{F}^{\left(  m\right)  }\right)  $ denote the unique extension of the
$\widehat{\mathfrak{gl}_{n}}$-representation on $\mathcal{F}^{\left(
m\right)  }$ to $\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}=0$. (This
is well-defined due to Proposition \ref{prop.glwave.F}.)

The $\widetilde{\mathfrak{gl}_{n}}$-module $\left(  \mathcal{F}^{\left(
m\right)  },\widehat{\rho}\mid_{\widetilde{\mathfrak{gl}_{n}}}\right)  $ is
irreducible with highest weight $\widetilde{\omega}_{m}$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.glwave.F.irr}.} \textbf{(a)} By
Proposition \ref{prop.F.irrep}, we know that $F$ is an irreducible
$\mathcal{A}_{0}$-module. In other words, $\mathcal{B}^{\left(  m\right)  }$
is an irreducible $\mathcal{A}_{0}$-module (since $\mathcal{B}^{\left(
m\right)  }=F_{m}=F$ as $\mathcal{A}_{0}$-modules). Hence, $\mathcal{B}%
^{\left(  m\right)  }$ is also an irreducible $\mathcal{A}$-module (since the
$\mathcal{A}_{0}$-module $\mathcal{B}^{\left(  m\right)  }$ is a restriction
of the $\mathcal{A}$-module $\mathcal{B}^{\left(  m\right)  }$).

Since the Boson-Fermion correspondence $\sigma_{m}:\mathcal{B}^{\left(
m\right)  }\rightarrow\mathcal{F}^{\left(  m\right)  }$ is an $\mathcal{A}%
$-module isomorphism, we have $\mathcal{B}^{\left(  m\right)  }\cong%
\mathcal{F}^{\left(  m\right)  }$ as $\mathcal{A}$-modules. Since
$\mathcal{B}^{\left(  m\right)  }$ is an irreducible $\mathcal{A}$-module,
this yields that $\mathcal{F}^{\left(  m\right)  }$ is an irreducible
$\mathcal{A}$-module.

By Proposition \ref{prop.glnhat.T} \textbf{(b)}, the $\mathcal{A}$-module
$\mathcal{F}^{\left(  m\right)  }$ is a restriction of the
$\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{F}^{\left(  m\right)  }$. Since
the $\mathcal{A}$-module $\mathcal{F}^{\left(  m\right)  }$ is irreducible,
this yields that the $\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{F}%
^{\left(  m\right)  }$ is irreducible. Proposition \ref{prop.glwave.F.irr}
\textbf{(a)} is proven.

\textbf{(b)} It is easy to check that $\widetilde{\mathfrak{n}_{+}}\psi_{m}=0$
and $x\psi_{m}=\widetilde{\omega}_{m}\left(  x\right)  \psi_{m}$ for every
$x\in\widetilde{\mathfrak{h}}$.

\textit{Proof.} Proving that $\widetilde{\mathfrak{n}_{+}}\psi_{m}=0$ is easy,
since $\widetilde{\mathfrak{n}_{+}}$ embeds into $\mathfrak{a}_{\infty}$ as
strictly upper-triangular matrices (and $\mathcal{F}^{\left(  m\right)  }$ is
a graded $\mathfrak{a}_{\infty}$-module).

In order to prove that $x\psi_{m}=\widetilde{\omega}_{m}\left(  x\right)
\psi_{m}$ for every $x\in\widetilde{\mathfrak{h}}$, we must show that
$E_{i,i}^{\mathfrak{gl}_{n}}\psi_{m}=\widetilde{\omega}_{m}\left(
E_{i,i}^{\mathfrak{gl}_{n}}\right)  \psi_{m}$ for every $i\in\left\{
1,2,...,n\right\}  $. (In fact, this is enough, because the relations
$K\psi_{m}=\widetilde{\omega}_{m}\left(  K\right)  \psi_{m}$ and $d\psi
_{m}=\widetilde{\omega}_{m}\left(  d\right)  \psi_{m}$ follow directly from
$\widehat{\rho}\left(  K\right)  =\operatorname*{id}$ and $d\psi_{m}=0$.)

Let $i\in\left\{  1,2,...,n\right\}  $. Use $\operatorname*{Toep}%
\nolimits_{n}\left(  E_{i,i}^{\mathfrak{gl}_{n}}\right)  =\sum\limits_{j\equiv
i\operatorname{mod}n}E_{j,j}^{\mathfrak{gl}_{\infty}}$ to conclude that
\[
\widehat{\rho}\left(  E_{i,i}^{\mathfrak{gl}_{n}}\right)  \psi_{m}%
=\underbrace{\left(  \left\{
\begin{array}
[c]{c}%
1,\text{ if }i\leq\overline{m};\\
0,\text{ if }i>\overline{m}%
\end{array}
\right.  +\dfrac{m-\overline{m}}{n}\right)  }_{=\widetilde{\omega}_{m}\left(
E_{i,i}^{\mathfrak{gl}_{n}}\right)  }\psi_{m}=\widetilde{\omega}_{m}\left(
E_{i,i}^{\mathfrak{gl}_{n}}\right)  \psi_{m},
\]
where $\overline{m}$ is the element of $\left\{  0,1,...,n-1\right\}  $
satisfying $m\equiv\overline{m}\operatorname{mod}n$.

Thus, we have checked that $\widetilde{\mathfrak{n}_{+}}\psi_{m}=0$ and
$x\psi_{m}=\widetilde{\omega}_{m}\left(  x\right)  \psi_{m}$ for every
$x\in\widetilde{\mathfrak{h}}$. Thus, $\psi_{m}$ is a singular vector of
weight $\widetilde{\omega}_{m}$. In other words, $\psi_{m}\in
\operatorname*{Sing}\nolimits_{\widetilde{\omega}_{m}}\left(  \mathcal{F}%
^{\left(  m\right)  }\right)  $. By Lemma \ref{lem.singvec}, we thus have a
canonical isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\widetilde{\mathfrak{gl}_{n}}}\left(
M_{\widetilde{\omega}_{m}}^{+},\mathcal{F}^{\left(  m\right)  }\right)   &
\rightarrow\operatorname*{Sing}\nolimits_{\widetilde{\omega}_{m}}\left(
\mathcal{F}^{\left(  m\right)  }\right)  ,\\
\phi &  \mapsto\phi\left(  v_{\widetilde{\omega}_{m}}^{+}\right)  .
\end{align*}
Thus, since $\psi_{m}\in\operatorname*{Sing}\nolimits_{\widetilde{\omega}_{m}%
}\left(  \mathcal{F}^{\left(  m\right)  }\right)  $, there exists a
$\widetilde{\mathfrak{gl}_{n}}$-module homomorphism $\phi:M_{\widetilde{\omega
}_{m}}^{+}\rightarrow\mathcal{F}^{\left(  m\right)  }$ such that $\phi\left(
v_{\widetilde{\omega}_{m}}^{+}\right)  =\psi_{m}$. Consider this $\phi$.

Since $\mathcal{F}^{\left(  m\right)  }$ is generated by $\psi_{m}$ as a
$\widehat{\mathfrak{gl}_{n}}$-module (this was proven in the proof of
Proposition \ref{prop.glwave.F}), it is clear that $\mathcal{F}^{\left(
m\right)  }$ is generated by $\psi_{m}$ as a $\widetilde{\mathfrak{gl}_{n}}%
$-module as well. Thus, $\phi$ must be surjective (because $\psi_{m}%
=\phi\left(  v_{\widetilde{\omega}_{m}}^{+}\right)  \in\phi\left(
M_{\widetilde{\omega}_{m}}^{+}\right)  $). Hence, $\mathcal{F}^{\left(
m\right)  }$ is (isomorphic to) a quotient of the $\widetilde{\mathfrak{gl}%
_{n}}$-module $M_{\widetilde{\omega}_{m}}^{+}$. In other words, $\mathcal{F}%
^{\left(  m\right)  }$ is a highest-weight module with highest weight
$\widetilde{\omega}_{m}$. Combined with the irreducibility of $\mathcal{F}%
^{\left(  m\right)  }$, this proves Proposition \ref{prop.glwave.F.irr}.

\subsubsection{The
\texorpdfstring{$\protect\widetilde{\mathfrak{gl}_{n}}$}{gl-n-tilde}-module
\texorpdfstring{$\mathcal{B}^{\left(  m\right)  }$}{structure on the bosonic
Fock space}}

By applying the Boson-Fermion correspondence $\sigma$ to Proposition
\ref{prop.glwave.F}, we obtain:

\begin{proposition}
\label{prop.glwave.B}Let $m\in\mathbb{Z}$. Let $\psi_{m}^{\prime}$ be the
element $\sigma^{-1}\left(  v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\right)
\in\mathcal{B}^{\left(  m\right)  }$ (the highest-weight vector of
$\mathcal{B}^{\left(  m\right)  }$).

There exists a unique extension of the $\widehat{\mathfrak{gl}_{n}}%
$-representation on $\mathcal{B}^{\left(  m\right)  }$ to
$\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}^{\prime}=0$. The action
of $d$ in this extension is given by%
\[
d\left(  \sigma^{-1}\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  \right)  =\left(  \sum\limits_{k\geq0}\left(  \left\lceil
\dfrac{m-k}{n}\right\rceil -\left\lceil \dfrac{i_{k}}{n}\right\rceil \right)
\right)  \cdot\sigma^{-1}\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}%
}\wedge...\right)
\]
for every $m$-degression $\left(  i_{0},i_{1},i_{2},...\right)  $.
\end{proposition}

By applying the Boson-Fermion correspondence $\sigma$ to Proposition
\ref{prop.glwave.F.irr}, we obtain:

\begin{proposition}
Let $m\in\mathbb{Z}$. Let $\psi_{m}^{\prime}$ be the element $\sigma
^{-1}\left(  v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\right)  \in
\mathcal{B}^{\left(  m\right)  }$ (the highest-weight vector of $\mathcal{B}%
^{\left(  m\right)  }$).

\textbf{(a)} The $\widehat{\mathfrak{gl}_{n}}$-module $\mathcal{B}^{\left(
m\right)  }$ is irreducible.

\textbf{(b)} Let $\widehat{\rho}\mid_{\widetilde{\mathfrak{gl}_{n}}%
}:\widetilde{\mathfrak{gl}_{n}}\rightarrow\operatorname*{End}\left(
\mathcal{B}^{\left(  m\right)  }\right)  $ denote the unique extension of the
$\widehat{\mathfrak{gl}_{n}}$-representation on $\mathcal{B}^{\left(
m\right)  }$ to $\widetilde{\mathfrak{gl}_{n}}$ such that $d\psi_{m}^{\prime
}=0$. (This is well-defined due to Proposition \ref{prop.glwave.B}.)

The $\widetilde{\mathfrak{gl}_{n}}$-module $\left(  \mathcal{B}^{\left(
m\right)  },\widehat{\rho}\mid_{\widetilde{\mathfrak{gl}_{n}}}\right)  $ is
irreducible with highest weight $\widetilde{\omega}_{m}$.
\end{proposition}

\subsubsection{\texorpdfstring{$\protect\widetilde{\mathfrak{sl}_{n}}$}
{sl-n-tilde} and its action on
\texorpdfstring{$\mathcal{B}^{\left(  m\right)  }$}{the bosonic
Fock space}}

We have $\left[  I_{n}t,\widehat{\mathfrak{sl}_{n}}\right]  =0$ in the Lie
algebra $\widehat{\mathfrak{gl}_{n}}$ (this is because $\left[  I_{n}%
t,L\mathfrak{sl}_{n}\right]  =0$ in the Lie algebra $L\mathfrak{gl}_{n}$, and
because $\omega\left(  I_{n}t,L\mathfrak{sl}_{n}\right)  =0$ where the
$2$-cocycle $\omega$ is the one defined in Proposition
\ref{prop.ainf.alphaomega}). Since $I_{n}t\in\widehat{\mathfrak{gl}_{n}}$ acts
on $\mathcal{F}$ by the operator $\widehat{\operatorname*{Toep}\nolimits_{n}%
}\left(  I_{n}t\right)  =T^{n}$ (more precisely, by the action of $T^{n}$ on
$\mathcal{F}$, but let us abbreviate this by $T^{n}$ here), this yields that
the action of $T^{n}$ on $\mathcal{F}$ is an $\widehat{\mathfrak{sl}_{n}}%
$-module homomorphism. Thus, the action of $T^{n}$ on $\mathcal{B}$ also is an
$\widehat{\mathfrak{sl}_{n}}$-module homomorphism. As a consequence, the
restriction to $\widehat{\mathfrak{sl}_{n}}$ of the representation
$\mathcal{B}^{\left(  m\right)  }$ is not irreducible.

But $\psi_{m}^{\prime}$ is still a highest-weight vector with highest weight
$\widetilde{\omega}_{m}$. Let us look at how this representation
$\mathcal{B}^{\left(  m\right)  }$ decomposes.

\begin{definition}
Let $h_{i}=E_{i,i}^{\mathfrak{gl}_{n}}-E_{i+1,i+1}^{\mathfrak{gl}_{n}}$ for
$i\in\left\{  1,2,...,n-1\right\}  $, and let $h_{0}=K-h_{1}-h_{2}%
-...-h_{n-1}$. Then, $\left(  h_{0},h_{1},...,h_{n-1},d\right)  $ is a basis
of $\widetilde{\mathfrak{h}}\cap\widetilde{\mathfrak{sl}_{n}}$ (which is the
$0$-th homogeneous component of $\widetilde{\mathfrak{sl}_{n}}$).
\end{definition}

\begin{definition}
For every $m\in\mathbb{Z}$, define the weight $\omega_{m}\in\left(
\widetilde{\mathfrak{h}}\cap\widetilde{\mathfrak{sl}_{n}}\right)  ^{\ast}$ to
be the restriction $\widetilde{\omega}_{m}\mid_{\widetilde{\mathfrak{h}}%
\cap\widetilde{\mathfrak{sl}_{n}}}$ of $\widetilde{\omega}_{m}$ to the $0$-th
homogeneous component of $\widetilde{\mathfrak{sl}_{n}}$.
\end{definition}

This weight $\omega_{m}$ does not depend on $m$ but only depends on the
residue class of $m$ modulo $n$. In fact, it satisfies%
\begin{align*}
\omega_{m}\left(  h_{i}\right)   &  =\widetilde{\omega}_{m}\left(
h_{i}\right)  =\left\{
\begin{array}
[c]{c}%
1,\text{ if }i\equiv m\operatorname{mod}n;\\
0,\text{ if }i\not \equiv m\operatorname{mod}n
\end{array}
\right.  \ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{  0,1,...,n-1\right\}
;\\
\omega_{m}\left(  d\right)   &  =\widetilde{\omega}_{m}\left(  d\right)  =0.
\end{align*}


\begin{definition}
Let $\mathcal{A}^{\left(  n\right)  }$ be the Lie subalgebra $\left\langle
K\right\rangle +\left\langle a_{ni}\ \mid\ i\in\mathbb{Z}\right\rangle $ of
$\mathcal{A}$.
\end{definition}

Note that the map%
\begin{align*}
\mathcal{A}  &  \rightarrow\mathcal{A}^{\left(  n\right)  },\\
a_{i}  &  \mapsto a_{ni}\ \ \ \ \ \ \ \ \ \ \text{for every }i\in\mathbb{Z},\\
K  &  \mapsto nK
\end{align*}
is a Lie algebra isomorphism. But we still consider $\mathcal{A}^{\left(
n\right)  }$ as a Lie subalgebra of $\mathcal{A}$, and we won't identify it
with $\mathcal{A}$ via this isomorphism.

Since $\mathcal{A}^{\left(  n\right)  }$ is a Lie subalgebra of $\mathcal{A}$,
both $\mathcal{A}$-modules $\mathcal{F}$ and $\mathcal{B}$ become
$\mathcal{A}^{\left(  n\right)  }$-modules.

Let us consider the direct sum $\widehat{\mathfrak{sl}_{n}}\oplus
\mathcal{A}^{\left(  n\right)  }$ of Lie algebras. Let us denote by $K_{1}$
the element $\left(  K,0\right)  $ of $\widehat{\mathfrak{sl}_{n}}%
\oplus\mathcal{A}^{\left(  n\right)  }$ (where the $K$ means the element $K$
of $\widehat{\mathfrak{sl}_{n}}$), and let us denote by $K_{2}$ the element
$\left(  0,K\right)  $ of $\widehat{\mathfrak{sl}_{n}}\oplus\mathcal{A}%
^{\left(  n\right)  }$ (where the $K$ means the element $K$ of $\mathcal{A}%
^{\left(  n\right)  }$). Note that both elements $K_{1}=\left(  K,0\right)  $
and $K_{2}=\left(  0,K\right)  $ lie in the center of $\widehat{\mathfrak{sl}%
_{n}}\oplus\mathcal{A}^{\left(  n\right)  }$; hence, so does their difference
$K_{1}-K_{2}=\left(  K,-K\right)  $. Thus, $\left\langle K_{1}-K_{2}%
\right\rangle $ (the $\mathbb{C}$-linear span of the set $\left\{  K_{1}%
-K_{2}\right\}  $) is an ideal of $\widehat{\mathfrak{sl}_{n}}\oplus
\mathcal{A}^{\left(  n\right)  }$. Thus, $\left(  \widehat{\mathfrak{sl}_{n}%
}\oplus\mathcal{A}^{\left(  n\right)  }\right)  \diagup\left(  K_{1}%
-K_{2}\right)  $ is a Lie algebra.

\begin{proposition}
The Lie algebras $\widehat{\mathfrak{gl}_{n}}$ and $\left(
\widehat{\mathfrak{sl}_{n}}\oplus\mathcal{A}^{\left(  n\right)  }\right)
\diagup\left(  K_{1}-K_{2}\right)  $ are isomorphic. More precisely, the maps%
\begin{align*}
\left(  \widehat{\mathfrak{sl}_{n}}\oplus\mathcal{A}^{\left(  n\right)
}\right)  \diagup\left(  K_{1}-K_{2}\right)   &  \rightarrow
\widehat{\mathfrak{gl}_{n}},\\
\overline{\left(  At^{\ell},0\right)  }  &  \mapsto At^{\ell}%
\ \ \ \ \ \ \ \ \ \ \text{for every }A\in\mathfrak{sl}_{n}\text{ and }\ell
\in\mathbb{Z},\\
\overline{\left(  0,a_{n\ell}\right)  }  &  \mapsto\operatorname*{id}%
\nolimits_{n}t^{\ell}\ \ \ \ \ \ \ \ \ \ \text{for every }\ell\in\mathbb{Z},\\
\overline{K_{1}}=\overline{K_{2}}  &  \mapsto K
\end{align*}
and%
\begin{align*}
\widehat{\mathfrak{gl}_{n}}  &  \rightarrow\left(  \widehat{\mathfrak{sl}_{n}%
}\oplus\mathcal{A}^{\left(  n\right)  }\right)  \diagup\left(  K_{1}%
-K_{2}\right)  ,\\
At^{\ell}  &  \mapsto\overline{\left(  \left(  A-\dfrac{1}{n}\left(
\operatorname*{Tr}A\right)  \cdot\operatorname*{id}\nolimits_{n}\right)
t^{\ell},\left(  \dfrac{1}{n}\operatorname*{Tr}A\right)  a_{n\ell}\right)
}\ \ \ \ \ \ \ \ \ \ \text{for every }A\in\mathfrak{gl}_{n}\text{ and }\ell
\in\mathbb{Z},\\
K  &  \mapsto\overline{K_{1}}=\overline{K_{2}}.
\end{align*}
are mutually inverse isomorphisms of Lie algebras.
\end{proposition}

The proof of this proposition is left to the reader (it is completely
straightforward). This isomorphism $\widehat{\mathfrak{gl}_{n}}\cong\left(
\widehat{\mathfrak{sl}_{n}}\oplus\mathcal{A}^{\left(  n\right)  }\right)
\diagup\left(  K_{1}-K_{2}\right)  $ allows us to consider any
$\widehat{\mathfrak{gl}_{n}}$-module as an $\left(  \widehat{\mathfrak{sl}%
_{n}}\oplus\mathcal{A}^{\left(  n\right)  }\right)  \diagup\left(  K_{1}%
-K_{2}\right)  $-module, i. e., as an $\widehat{\mathfrak{sl}_{n}}%
\oplus\mathcal{A}^{\left(  n\right)  }$-module on which $K_{1}$ and $K_{2}$
act the same way. In particular, $\mathcal{F}$ and $\mathcal{B}$ become
$\widehat{\mathfrak{sl}_{n}}\oplus\mathcal{A}^{\left(  n\right)  }$-modules.
Of course, the actions of the two addends $\widehat{\mathfrak{sl}_{n}}$ and
$\mathcal{A}^{\left(  n\right)  }$ on $\mathcal{F}$ and $\mathcal{B}$ are
exactly the actions of $\widehat{\mathfrak{sl}_{n}}$ and $\mathcal{A}^{\left(
n\right)  }$ on $\mathcal{F}$ and $\mathcal{B}$ that result from the canonical
inclusions $\widehat{\mathfrak{sl}_{n}}\subseteq\widehat{\mathfrak{gl}_{n}%
}\subseteq\mathfrak{a}_{\infty}$ and $\mathcal{A}^{\left(  n\right)
}\subseteq\mathcal{A}\cong\widehat{\mathfrak{gl}_{1}}\subseteq\mathfrak{a}%
_{\infty}$. (This is clear for the action of $\widehat{\mathfrak{sl}_{n}}$,
and is very easy to see for the action of $\mathcal{A}^{\left(  n\right)  }$.)

We checked above that the action of $T^{n}$ on $\mathcal{B}$ is an
$\widehat{\mathfrak{sl}_{n}}$-module homomorphism. This easily generalizes:
For every integer $i$, the action of $T^{ni}$ on $\mathcal{B}$ is an
$\widehat{\mathfrak{sl}_{n}}$-module homomorphism.\footnote{\textit{Proof.}
Let $i$ be an integer. We have $\left[  I_{n}t^{i},\widehat{\mathfrak{sl}_{n}%
}\right]  =0$ in the Lie algebra $\widehat{\mathfrak{gl}_{n}}$ (this is
because $\left[  I_{n}t^{i},L\mathfrak{sl}_{n}\right]  =0$ in the Lie algebra
$L\mathfrak{gl}_{n}$, and because $\omega\left(  I_{n}t^{i},L\mathfrak{sl}%
_{n}\right)  =0$ where the $2$-cocycle $\omega$ is the one defined in
Proposition \ref{prop.ainf.alphaomega}). Since $I_{n}t^{i}\in
\widehat{\mathfrak{gl}_{n}}$ acts on $\mathcal{F}$ by the operator
$\widehat{\operatorname*{Toep}\nolimits_{n}}\left(  I_{n}t^{i}\right)
=T^{ni}$ (more precisely, by the action of $T^{ni}$ on $\mathcal{F}$, but let
us abbreviate this by $T^{ni}$ here), this yields that the action of $T^{ni}$
on $\mathcal{F}$ is an $\widehat{\mathfrak{sl}_{n}}$-module homomorphism.
Thus, the action of $T^{ni}$ on $\mathcal{B}$ also is an
$\widehat{\mathfrak{sl}_{n}}$-module homomorphism.} Thus, the subspace
$\mathcal{B}_{0}^{\left(  m\right)  }=\left\{  v\in\mathcal{B}^{\left(
m\right)  }\ \mid\ T^{ni}v=0\text{ for all }i>0\right\}  $ of $\mathcal{B}%
^{\left(  m\right)  }$ is an $\widehat{\mathfrak{sl}_{n}}$-submodule.
Recalling that $\mathcal{B}^{\left(  m\right)  }=\mathbb{C}\left[  x_{1}%
,x_{2},x_{3},...\right]  $, with $T^{ni}$ acting as $ni\dfrac{\partial
}{\partial x_{ni}}$, we have $\mathcal{B}_{0}^{\left(  m\right)  }%
\cong\mathbb{C}\left[  x_{j}\ \mid\ n\nmid j\right]  $.

\begin{theorem}
\label{thm.B0m}This $\mathcal{B}_{0}^{\left(  m\right)  }$ is an irreducible
$\widehat{\mathfrak{sl}_{n}}$-module (or $\widetilde{\mathfrak{sl}_{n}}%
$-module; this doesn't matter) with highest weight $\omega_{\overline{m}}$
(this means that $\mathcal{B}_{0}^{\left(  m\right)  }\cong L_{\omega
_{\overline{m}}}$) and depends only on $\overline{m}$ (the remainder of $m$
modulo $n$) rather than on $m$. Moreover, $\mathcal{B}^{\left(  m\right)
}\cong\mathcal{B}_{0}^{\left(  m\right)  }\otimes\widetilde{F}_{m}$, where
$\widetilde{F}_{m}$ is the appropriate Fock module over $\mathcal{A}^{\left(
n\right)  }$.
\end{theorem}

\textit{Proof of Theorem \ref{thm.B0m}.} We clearly have such a decomposition
as vector spaces, $\widetilde{F}_{m}=\mathbb{C}\left[  x_{n},x_{2n}%
,x_{3n},...\right]  $. Each of the two Lie algebras acts in its own factor:
$\mathcal{A}^{\left(  n\right)  }$ acts in $\widetilde{F}_{m}$, and
$\widehat{\mathfrak{gl}_{n}}$ commutes with $\mathcal{A}^{\left(  n\right)  }%
$. Since the tensor product is irreducible, each factor is irreducible, so
that $\mathcal{B}_{0}^{\left(  m\right)  }$ is irreducible.

\subsubsection{\textbf{[unfinished]} Classification of unitary highest-weight
\texorpdfstring{$\protect\widehat{\mathfrak{sl}_{n}}$}{sl-n-hat}-modules}

We can now classify unitary highest-weight representations of
$\widehat{\mathfrak{sl}_{n}}$:

\begin{proposition}
The highest-weight representation $L_{\omega_{m}}$ is unitary for each
$m\in\left\{  0,1,...,n-1\right\}  $.
\end{proposition}

\textit{Proof.} The contravariant Hermitian form on $L_{\omega_{m}}$ is the
restriction of the form on $\mathcal{B}^{\left(  m\right)  }$.

\begin{corollary}
If $k_{0},k_{1},...,k_{n-1}$ are nonnegative integers, then $L_{k_{0}%
\omega_{0}+k_{1}\omega_{1}+...+k_{n-1}\omega_{n-1}}$ is unitary (of level
$k_{0}+k_{1}+...+k_{n-1}$).
\end{corollary}

\textit{Proof.} The tensor product $L_{\omega_{0}}^{\otimes k_{0}}\otimes
L_{\omega_{1}}^{\otimes k_{1}}\otimes...\otimes L_{\omega_{n-1}}^{\otimes
k_{n-1}}$ is unitary (being a tensor product of unitary representations), and
thus is a direct sum of irreducible representations. Clearly, $L_{k_{0}%
\omega_{0}+k_{1}\omega_{1}+...+k_{n-1}\omega_{n-1}}$ is a summand of this
module, and thus also unitary, qed.

\begin{theorem}
\label{thm.sln.unitaries}These $L_{k_{0}\omega_{0}+k_{1}\omega_{1}%
+...+k_{n-1}\omega_{n-1}}$ (with $k_{0},k_{1},...,k_{n-1}$ being nonnegative
integers) are the only unitary highest-weight representations of
$\widehat{\mathfrak{sl}_{n}}$.
\end{theorem}

To prove this, first a lemma:

\begin{lemma}
\label{lem.sl2.unitaries}Consider the antilinear $\mathbb{R}$-antiinvolution
$\dag:\mathfrak{sl}_{2}\rightarrow\mathfrak{sl}_{2}$ defined by $e^{\dag}=f$,
$f^{\dag}=e$ and $h^{\dag}=h$. Let $\lambda\in\mathfrak{h}^{\ast}$. We
identify the function $\lambda\in\mathfrak{h}^{\ast}$ with the value
$\lambda\left(  h\right)  \in\mathbb{C}$. Then, $L_{\lambda}$ is a unitary
representation of $\mathfrak{sl}_{2}$ if and only if $\lambda\in\mathbb{Z}%
_{+}$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.sl2.unitaries}.} Assume that $L_{\lambda}$ is
a unitary representation of $\mathfrak{sl}_{2}$. Let $v_{\lambda}=v_{\lambda
}^{+}$. Since $L_{\lambda}$ is unitary, the form $\left(  \cdot,\cdot\right)
$ is positive definite, so that $\left(  v_{\lambda},v_{\lambda}\right)  >0$.

Every $n\in\mathbb{N}$ satisfies
\[
\left(  f^{n}v_{\lambda},f^{n}v_{\lambda}\right)  =n!\overline{\lambda}\left(
\overline{\lambda}-1\right)  ...\left(  \overline{\lambda}-n+1\right)  \left(
v_{\lambda},v_{\lambda}\right)
\]
(the proof of this is analogous to the proof of (\ref{exa.sl2.bilinform}), but
uses $e^{\dag}=f$). Since $\left(  \cdot,\cdot\right)  $ is positive definite,
we must have $\left(  f^{n}v_{\lambda},f^{n}v_{\lambda}\right)  \geq0$ for
every $n\in\mathbb{N}$. Thus, every $n\in\mathbb{N}$ satisfies $n!\overline
{\lambda}\left(  \overline{\lambda}-1\right)  ...\left(  \overline{\lambda
}-n+1\right)  \left(  v_{\lambda},v_{\lambda}\right)  =\left(  f^{n}%
v_{\lambda},f^{n}v_{\lambda}\right)  \geq0$, so that $\overline{\lambda
}\left(  \overline{\lambda}-1\right)  ...\left(  \overline{\lambda
}-n+1\right)  \geq0$ (since $\left(  v_{\lambda},v_{\lambda}\right)  >0$).
Applied to $n=1$, this yields $\overline{\lambda}\geq0$, so that
$\overline{\lambda}\in\mathbb{R}$ and thus $\lambda\in\mathbb{R}$. Hence,
$\overline{\lambda}\geq0$ becomes $\lambda\geq0$.

Every $n\in\mathbb{N}$ satisfies $\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  =\overline{\lambda}\left(  \overline{\lambda}-1\right)
...\left(  \overline{\lambda}-n+1\right)  \geq0$. Thus, $\lambda\in
\mathbb{Z}_{+}$ (otherwise, $\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  $ would alternate in sign for each sufficiently large $n$).

This proves one direction of Lemma \ref{lem.sl2.unitaries}. The converse
direction is classical and easy. Lemma \ref{lem.sl2.unitaries} is proven.

\begin{corollary}
Let $\lambda\in\mathbb{C}$. If $\mathfrak{g}$ is a Lie algebra with antilinear
$\mathbb{R}$-antiinvolution $\dag$ and $\mathfrak{sl}_{2}$ is a Lie subalgebra
of $\mathfrak{g}$, and if $\dag\mid_{\mathfrak{sl}_{2}}$ sends $e,f,h$ to
$f,e,h$, and if $V$ is a unitary representation of $\mathfrak{g}$, and if some
$v\in V$ satisfies $ev=0$ and $hv=\lambda v$, then $\lambda\in\mathbb{Z}_{+}$.
\end{corollary}

\textit{Proof of Theorem \ref{thm.sln.unitaries}.} For every $i\in\left\{
0,1,...,n-1\right\}  $, we have an $\mathfrak{sl}_{2}$-subalgebra:%
\begin{align*}
h_{i}  &  =\left\{
\begin{array}
[c]{c}%
E_{i,i}-E_{i+1,i+1},\ \ \ \ \ \ \ \ \ \ \text{if }i\neq0;\\
K+E_{n,n}-E_{1,1},\ \ \ \ \ \ \ \ \ \ \text{if }i=0
\end{array}
\right.  ,\\
e_{i}  &  =\left\{
\begin{array}
[c]{c}%
E_{i,i+1},\ \ \ \ \ \ \ \ \ \ \text{if }i\neq0;\\
E_{n,1}t,\ \ \ \ \ \ \ \ \ \ \text{if }i=0
\end{array}
\right.  ;\\
f_{i}  &  =\left\{
\begin{array}
[c]{c}%
E_{i+1,i},\ \ \ \ \ \ \ \ \ \ \text{if }i\neq0;\\
E_{1,n}t^{-1},\ \ \ \ \ \ \ \ \ \ \text{if }i=0
\end{array}
\right.
\end{align*}
\footnote{Here, $E_{i,j}$ means $E_{i,j}^{\mathfrak{gl}_{n}}$.} (these form an
$\mathfrak{sl}_{2}$-triple, as can be easily checked). These satisfy
$e_{i}^{\dag}=f_{i}$, $f_{i}^{\dag}=e_{i}$ and $h_{i}^{\dag}=h_{i}$. Thus, if
$L_{\lambda}$ is a unitary representation of $\widehat{\mathfrak{sl}_{n}}$,
then $\lambda\left(  h_{i}\right)  \in\mathbb{Z}_{+}$. But $\omega_{i}$ are a
basis for the weights, and namely the dual basis to the basis of the $h_{i}$.
Thus, $\lambda=\sum\limits_{i=0}^{n-1}\lambda\left(  h_{i}\right)  \omega_{i}%
$. Hence, $\lambda=\sum\limits_{i=0}^{n-1}k_{i}\omega_{i}$ with $k_{i}%
\in\mathbb{Z}_{+}$. Qed.

\begin{remark}
Relation between $\widehat{\mathfrak{sl}_{n}}$-modules and $\mathfrak{sl}_{n}$-modules:

Let $L_{\lambda}$ be a unitary $\widehat{\mathfrak{sl}_{n}}$-module, with
$\lambda=k_{0}\omega_{0}+k_{1}\omega_{1}+...+k_{n-1}\omega_{n-1}$.

Then, $U\left(  \mathfrak{sl}_{n}\right)  v_{\lambda}=L_{\overline{\lambda}}$
where $\overline{\lambda}=k_{1}\omega_{1}+k_{2}\omega_{2}+...+k_{n-1}%
\omega_{n-1}$ is a weight for $\mathfrak{sl}_{n}$. And if the level of
$L_{\lambda}$ was $k$, then we must have $k_{1}+k_{2}+...+k_{n-1}\leq k$.
\end{remark}

\subsection{The Sugawara construction}

We will now study the Sugawara construction. It constructs a
$\operatorname*{Vir}$ action on a $\widehat{\mathfrak{g}}$-module (under some
conditions), and it generalizes the action of $\operatorname*{Vir}$ on the
$\mu$-Fock representation $F_{\mu}$ (that was constructed in Proposition
\ref{prop.fockvir.answer2}).

\begin{definition}
\label{def.sugawara}Let $\mathfrak{g}$ be a finite-dimensional $\mathbb{C}%
$-Lie algebra equipped with a $\mathfrak{g}$-invariant symmetric bilinear form
$\left(  \cdot,\cdot\right)  $. (This form needs not be nondegenerate; it is
even allowed to be $0$.)

Consider the $2$-cocycle $\omega:\mathfrak{g}\left[  t,t^{-1}\right]
\times\mathfrak{g}\left[  t,t^{-1}\right]  \rightarrow\mathbb{C}$ defined by%
\[
\omega\left(  a,b\right)  =\operatorname*{Res}\nolimits_{t=0}\left(
a^{\prime},b\right)  dt\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}%
\left[  t,t^{-1}\right]  \text{ and }b\in\mathfrak{g}\left[  t,t^{-1}\right]
.
\]
(This is the $2$-cocycle $\omega$ in Definition \ref{def.loop}. We just
slightly rewrote the definition.) Also consider the affine Lie algebra
$\widehat{\mathfrak{g}}=\mathfrak{g}\left[  t,t^{-1}\right]  \oplus
\mathbb{C}K$ defined through this cocycle $\omega$.

Let $\operatorname*{Kil}$ denote the Killing form on $\mathfrak{g}$, defined
by
\[
\operatorname*{Kil}\left(  a,b\right)  =\operatorname*{Tr}\left(
\operatorname*{ad}\left(  a\right)  \cdot\operatorname*{ad}\left(  b\right)
\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in\mathfrak{g}.
\]


An element $k\in\mathbb{C}$ is said to be \textit{non-critical for }$\left(
\mathfrak{g},\left(  \cdot,\cdot\right)  \right)  $ if and only if the form
$k\cdot\left(  \cdot,\cdot\right)  +\dfrac{1}{2}\operatorname*{Kil}$ is nondegenerate.
\end{definition}

\begin{definition}
\label{def.sugawara.M}Let $M$ be a $\widehat{\mathfrak{g}}$-module.

We say that $M$ is \textit{admissible} if for every $v\in M$, there exists
some $N\in\mathbb{N}$ such that every integer $n\geq N$ and every
$a\in\mathfrak{g}$ satisfy $at^{n}\cdot v=0$.

If $k\in\mathbb{C}$, then we say that $M$ is \textit{of level }$k$ if
$K\mid_{M}=k\cdot\operatorname*{id}$.
\end{definition}

\begin{proposition}
\label{prop.WtoDerg}Let $\mathfrak{g}$ be a finite-dimensional $\mathbb{C}%
$-Lie algebra equipped with a $\mathfrak{g}$-invariant symmetric bilinear form
$\left(  \cdot,\cdot\right)  $. Consider the affine Lie algebra
$\widehat{\mathfrak{g}}$ defined as in Definition \ref{def.sugawara}.

\textbf{(a)} Then, there is a natural homomorphism $\eta
_{\widehat{\mathfrak{g}}}:W\rightarrow\operatorname*{Der}\widehat{\mathfrak{g}%
}$ of Lie algebras given by
\[
\left(  \eta_{\widehat{\mathfrak{g}}}\left(  f\partial\right)  \right)
\left(  g,\alpha\right)  =\left(  fg^{\prime},0\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }f\in\mathbb{C}\left[  t,t^{-1}\right]
\text{, }g\in\mathfrak{g}\left[  t,t^{-1}\right]  \text{ and }\alpha
\in\mathbb{C}.
\]


\textbf{(b)} There also is a natural homomorphism $\widetilde{\eta
}_{\widehat{\mathfrak{g}}}:\operatorname*{Vir}\rightarrow\operatorname*{Der}%
\widehat{\mathfrak{g}}$ of Lie algebras given by
\[
\left(  \widetilde{\eta}_{\widehat{\mathfrak{g}}}\left(  f\partial+\lambda
K\right)  \right)  \left(  g,\alpha\right)  =\left(  fg^{\prime},0\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }f\in\mathbb{C}\left[  t,t^{-1}\right]
\text{, }g\in\mathfrak{g}\left[  t,t^{-1}\right]  \text{, }\lambda
\in\mathbb{C}\text{ and }\alpha\in\mathbb{C}.
\]
This homomorphism $\widetilde{\eta}_{\widehat{\mathfrak{g}}}$ is simply the
extension of the homomorphism $\eta_{\widehat{\mathfrak{g}}}:W\rightarrow
\operatorname*{Der}\widehat{\mathfrak{g}}$ to $\operatorname*{Vir}$ by means
of requiring that $\widetilde{\eta}_{\widehat{\mathfrak{g}}}\left(  K\right)
=0$.

This homomorphism $\widetilde{\eta}_{\widehat{\mathfrak{g}}}$ makes
$\widehat{\mathfrak{g}}$ a $\operatorname*{Vir}$-module on which
$\operatorname*{Vir}$ acts by derivations. Therefore, a Lie algebra
$\operatorname*{Vir}\ltimes\widehat{\mathfrak{g}}$ is defined (according to
Definition \ref{def.semidir.lielie}).
\end{proposition}

The proof of Proposition \ref{prop.WtoDerg} is left to the reader. (A proof of
Proposition \ref{prop.WtoDerg} \textbf{(a)} can be obtained by carefully
generalizing the proof of Lemma \ref{lem.WtoDerA}. Actually, Proposition
\ref{prop.WtoDerg} \textbf{(a)} generalizes Lemma \ref{lem.WtoDerA}, since (as
we will see in Remark \ref{rmk.sugawara.fockvir}) the Lie algebra
$\widehat{\mathfrak{g}}$ generalizes $\mathcal{A}$.)

The following theorem is one of the most important facts about affine Lie algebras:

\begin{theorem}
[Sugawara construction]\label{thm.sugawara}Let us work in the situation of
Definition \ref{def.sugawara}.

Let $k\in\mathbb{C}$ be non-critical for $\left(  \mathfrak{g},\left(
\cdot,\cdot\right)  \right)  $. Let $M$ be an admissible
$\widehat{\mathfrak{g}}$-module of level $k$. Let $B\subseteq\mathfrak{g}$ be
a basis orthonormal with respect to the form $k\left(  \cdot,\cdot\right)
+\dfrac{1}{2}\operatorname*{Kil}$.

For every $x\in\mathfrak{g}$ and $n\in\mathbb{Z}$, let us denote by $x_{n}$
the element $xt^{n}\in\widehat{\mathfrak{g}}$.

For every $x\in\mathfrak{g}$, every $m\in\mathbb{Z}$ and $\ell\in\mathbb{Z}$,
define the ``normal ordered product'' $\left.  :x_{m}x_{\ell}:\right.  $ in
$U\left(  \widehat{\mathfrak{g}}\right)  $ by%
\[
\left.  :x_{m}x_{\ell}:\right.  =\left\{
\begin{array}
[c]{c}%
x_{m}x_{\ell},\ \ \ \ \ \ \ \ \ \ \text{if }m\leq\ell;\\
x_{\ell}x_{m},\ \ \ \ \ \ \ \ \ \ \text{if }m>\ell
\end{array}
\right.  .
\]


For every $n\in\mathbb{Z}$, define an endomorphism $L_{n}$ of $M$ by%
\[
L_{n}=\dfrac{1}{2}\sum\limits_{a\in B}\sum\limits_{m\in\mathbb{Z}}\left.
:a_{m}a_{n-m}:\right.  .
\]


\textbf{(a)} This endomorphism $L_{n}$ is indeed well-defined. In other words,
for every $n\in\mathbb{Z}$, every $a\in B$ and every $v\in M$, the sum
$\sum\limits_{m\in\mathbb{Z}}\left.  :a_{m}a_{n-m}:\right.  v$ converges in
the discrete topology (i. e., has only finitely many nonzero addends).

\textbf{(b)} For every $n\in\mathbb{Z}$, the endomorphism $L_{n}$ does not
depend on the choice of the orthonormal basis $B$.

\textbf{(c)} The endomorphisms $L_{n}$ for $n\in\mathbb{Z}$ give rise to a
$\operatorname*{Vir}$-representation on $M$ with central charge%
\[
c=k\cdot\sum\limits_{a\in B}\left(  a,a\right)  .
\]


\textbf{(d)} These formulas (for $L_{n}$ and $c$) extend the action of
$\widehat{\mathfrak{g}}$ on $M$ to an action of $\operatorname*{Vir}%
\ltimes\widehat{\mathfrak{g}}$, so they satisfy $\left[  L_{n},a_{m}\right]
=-ma_{n+m}$ and $\left[  L_{n},K\right]  =0$.

\textbf{(e)} We have $\left[  L_{n},a_{m}\right]  =-ma_{n+m}$ for any
$a\in\mathfrak{g}$ and any integers $n$ and $m$.
\end{theorem}

\begin{remark}
\label{rmk.sugawara.fockvir}We have already encountered an example of this
construction: namely, the example where $\mathfrak{g}$ is the trivial Lie
algebra $\mathbb{C}$, where $\left(  \cdot,\cdot\right)  :\mathfrak{g}%
\times\mathfrak{g}\rightarrow\mathbb{C}$ is the bilinear form $\left(
x,y\right)  \mapsto xy$, where $k=1$, and where $M$ is the
$\widehat{\mathfrak{g}}$-module $F_{\mu}$. (To make sense of this, notice that
when $\mathfrak{g}$ is the trivial Lie algebra $\mathbb{C}$, the affine Lie
algebra $\widehat{\mathfrak{g}}$ is canonically isomorphic to the Heisenberg
algebra $\mathcal{A}$, through an isomorphism $\widehat{\mathfrak{g}%
}\rightarrow\mathcal{A}$ which takes $t^{n}$ to $a_{n}$ and $K$ to $K$.) In
this example, the operators $L_{n}$ defined in Theorem \ref{thm.sugawara} are
exactly the operators $L_{n}$ defined in Definition \ref{def.fockvir}.
\end{remark}

Before we prove Theorem \ref{thm.sugawara}, we formulate a number of lemmas.
First, an elementary lemma on Killing forms of finite-dimensional Lie algebras:

\begin{lemma}
\label{lem.sugawara.Kil}Let $\mathfrak{g}$ be a finite-dimensional Lie
algebra. Denote by $\operatorname*{Kil}$ the Killing form of $\mathfrak{g}$.
Let $n\in\mathbb{N}$ and $p_{1},p_{2},...,p_{n}\in\mathfrak{g}$ and
$q_{1},q_{2},...,q_{n}\in\mathfrak{g}$ be such that the tensor $\sum
\limits_{i=1}^{n}p_{i}\otimes q_{i}\in\mathfrak{g}\otimes\mathfrak{g}$ is
$\mathfrak{g}$-invariant. Then, $\sum\limits_{i=1}^{n}\left[  \left[
b,p_{i}\right]  ,q_{i}\right]  =\sum\limits_{i=1}^{n}\operatorname*{Kil}%
\left(  b,p_{i}\right)  q_{i}$ for every $b\in\mathfrak{g}$.
\end{lemma}

Here, we are using the following notation:

\begin{remark}
Let $\mathfrak{g}$ be a Lie algebra. An element $m$ of a $\mathfrak{g}$-module
$M$ is said to be $\mathfrak{g}$\textit{-invariant} if and only if it
satisfies $\left(  x\rightharpoonup m=0\text{ for every }x\in\mathfrak{g}%
\right)  $. We regard $\mathfrak{g}$ as a $\mathfrak{g}$-module by means of
the adjoint action of $\mathfrak{g}$ (that is, we set $x\rightharpoonup
m=\left[  x,m\right]  $ for every $x\in\mathfrak{g}$ and $m\in\mathfrak{g}$);
thus, $\mathfrak{g}\otimes\mathfrak{g}$ becomes a $\mathfrak{g}$-module as
well. Explicitly, the action of $\mathfrak{g}$ on $\mathfrak{g}\otimes
\mathfrak{g}$ is given by%
\[
x\rightharpoonup\left(  \sum\limits_{i=1}^{n}p_{i}\otimes q_{i}\right)
=\sum\limits_{i=1}^{n}\left[  x,p_{i}\right]  \otimes q_{i}+\sum
\limits_{i=1}^{n}p_{i}\otimes\left[  x,q_{i}\right]
\]
for every tensor $\sum\limits_{i=1}^{n}p_{i}\otimes q_{i}\in\mathfrak{g}%
\otimes\mathfrak{g}$. Hence, a tensor $\sum\limits_{i=1}^{n}p_{i}\otimes
q_{i}\in\mathfrak{g}\otimes\mathfrak{g}$ is $\mathfrak{g}$-invariant if and
only if every $x\in\mathfrak{g}$ satisfies $\sum\limits_{i=1}^{n}\left[
x,p_{i}\right]  \otimes q_{i}+\sum\limits_{i=1}^{n}p_{i}\otimes\left[
x,q_{i}\right]  =0$. In other words, a tensor $\sum\limits_{i=1}^{n}%
p_{i}\otimes q_{i}\in\mathfrak{g}\otimes\mathfrak{g}$ is $\mathfrak{g}%
$-invariant if and only if every $x\in\mathfrak{g}$ satisfies $\sum
\limits_{i=1}^{n}\left[  p_{i},x\right]  \otimes q_{i}=-\sum\limits_{i=1}%
^{n}p_{i}\otimes\left[  q_{i},x\right]  $.
\end{remark}

\textit{Proof of Lemma \ref{lem.sugawara.Kil}.} Let $\left(  c_{1}%
,c_{2},...,c_{m}\right)  $ be a basis of the vector space $\mathfrak{g}$, and
let $\left(  c_{1}^{\ast},c_{2}^{\ast},...,c_{m}^{\ast}\right)  $ be the dual
basis of $\mathfrak{g}^{\ast}$. Then, every $i\in\left\{  1,2,...,n\right\}  $
satisfies
\[
\operatorname*{Kil}\left(  b,p_{i}\right)  =\operatorname*{Tr}\left(  \left(
\operatorname*{ad}b\right)  \circ\left(  \operatorname*{ad}p_{i}\right)
\right)  =\sum\limits_{j=1}^{m}c_{j}^{\ast}\left(  \left(  \left(
\operatorname*{ad}b\right)  \circ\left(  \operatorname*{ad}p_{i}\right)
\right)  \left(  c_{j}\right)  \right)  =\sum\limits_{j=1}^{m}c_{j}^{\ast
}\left(  \left[  b,\left[  p_{i},c_{j}\right]  \right]  \right)  .
\]
Hence,%
\begin{align*}
\sum\limits_{i=1}^{n}\operatorname*{Kil}\left(  b,p_{i}\right)  q_{i}  &
=\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{m}c_{j}^{\ast}\left(  \left[
b,\left[  p_{i},c_{j}\right]  \right]  \right)  q_{i}=\sum\limits_{j=1}%
^{m}\sum\limits_{i=1}^{n}c_{j}^{\ast}\left(  \left[  b,\left[  p_{i}%
,c_{j}\right]  \right]  \right)  q_{i}\\
&  =-\sum\limits_{j=1}^{m}\sum\limits_{i=1}^{n}c_{j}^{\ast}\left(  \left[
b,p_{i}\right]  \right)  \left[  q_{i},c_{j}\right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\sum\limits_{i=1}^{n}p_{i}\otimes q_{i}\text{ is } \mathfrak{g}%
\text{-invariant, so that}\\
\sum\limits_{i=1}^{n}\left[  p_{i},c_{j}\right]  \otimes q_{i}=-\sum
\limits_{i=1}^{n}p_{i}\otimes\left[  q_{i},c_{j}\right]  \text{ for every
}j\in\left\{  1,2,...,m\right\}  \text{, and thus}\\
\sum\limits_{i=1}^{n}c_{j}^{\ast}\left(  \left[  b,\left[  p_{i},c_{j}\right]
\right]  \right)  q_{i}=-\sum\limits_{i=1}^{n}c_{j}^{\ast}\left(  \left[
b,p_{i}\right]  \right)  \left[  q_{i},c_{j}\right]  \text{ for every }%
j\in\left\{  1,2,...,m\right\}
\end{array}
\right) \\
&  =-\sum\limits_{j=1}^{m}\sum\limits_{i=1}^{n}\left[  q_{i},c_{j}^{\ast
}\left(  \left[  b,p_{i}\right]  \right)  c_{j}\right]  =-\sum\limits_{i=1}%
^{n}\left[  q_{i},\underbrace{\sum\limits_{j=1}^{m}c_{j}^{\ast}\left(  \left[
b,p_{i}\right]  \right)  c_{j}}_{\substack{=\left[  b,p_{i}\right]
\\\text{(since }\left(  c_{1}^{\ast},c_{2}^{\ast},...,c_{m}^{\ast}\right)
\text{ is the dual basis}\\\text{to the basis }\left(  c_{1},c_{2}%
,...,c_{m}\right)  \text{)}}}\right] \\
&  =-\sum\limits_{i=1}^{n}\left[  q_{i},\left[  b,p_{i}\right]  \right]
=\sum\limits_{i=1}^{n}\left[  \left[  b,p_{i}\right]  ,q_{i}\right]  ,
\end{align*}
which proves Lemma \ref{lem.sugawara.Kil}.

Here comes another lemma on $\mathfrak{g}$-invariant bilinear forms:

\begin{lemma}
\label{lem.sugawara.Kil2}Let $\mathfrak{g}$ be a finite-dimensional
$\mathbb{C}$-Lie algebra equipped with a $\mathfrak{g}$-invariant symmetric
bilinear form $\left\langle \cdot,\cdot\right\rangle $. Let $B\subseteq
\mathfrak{g}$ be a basis orthonormal with respect to the form $\left\langle
\cdot,\cdot\right\rangle $.

\textbf{(a)} Then, the tensor $\sum\limits_{a\in B}a\otimes a$ is
$\mathfrak{g}$-invariant in $\mathfrak{g}\otimes\mathfrak{g}$.

\textbf{(b)} Let $B^{\prime}$ also be a basis of $\mathfrak{g}$ orthonormal
with respect to the form $\left\langle \cdot,\cdot\right\rangle $. Then,
$\sum\limits_{a\in B}a\otimes a=\sum\limits_{a\in B^{\prime}}a\otimes a$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.sugawara.Kil2}.} The bilinear form
$\left\langle \cdot,\cdot\right\rangle $ is nondegenerate (since it has an
orthonormal basis).

\textbf{(a)} For every $v\in\mathfrak{g}$, let $v^{\ast}:\mathfrak{g}%
\rightarrow\mathbb{C}$ be the $\mathbb{C}$-linear map which sends every
$w\in\mathfrak{g}$ to $\left\langle v,w\right\rangle $. Then, $\mathfrak{g}%
^{\ast}=\left\{  v^{\ast}\ \mid\ v\in\mathfrak{g}\right\}  $ (since the form
$\left\langle \cdot,\cdot\right\rangle $ is nondegenerate).

Let $b\in\mathfrak{g}$. We will now prove that $h\left(  \sum\limits_{a\in
B}\left(  \left[  b,a\right]  \otimes a+a\otimes\left[  b,a\right]  \right)
\right)  =0$ for every $h\in\left(  \mathfrak{g}\otimes\mathfrak{g}\right)
^{\ast}$.

In fact, let $h\in\left(  \mathfrak{g}\otimes\mathfrak{g}\right)  ^{\ast}$.
Since $\mathfrak{g}$ is finite-dimensional, we have $\left(  \mathfrak{g}%
\otimes\mathfrak{g}\right)  ^{\ast}=\mathfrak{g}^{\ast}\otimes\mathfrak{g}%
^{\ast}$, so that $h\in\mathfrak{g}^{\ast}\otimes\mathfrak{g}^{\ast}$. We can
WLOG assume that $h=f_{1}\otimes f_{2}$ for some $f_{1}\in\mathfrak{g}^{\ast}$
and $f_{2}\in\mathfrak{g}^{\ast}$ (because every tensor in $\mathfrak{g}%
^{\ast}\otimes\mathfrak{g}^{\ast}$ is a $\mathbb{C}$-linear combination of
pure tensors, and the assertion which we want to prove (namely, the equality
$h\left(  \sum\limits_{a\in B}\left(  \left[  b,a\right]  \otimes
a+a\otimes\left[  b,a\right]  \right)  \right)  =0$) is $\mathbb{C}$-linear in
$h$). Assume this.

Since $f_{1}\in\mathfrak{g}^{\ast}=\left\{  v^{\ast}\ \mid\ v\in
\mathfrak{g}\right\}  $, there exists some $v_{1}\in\mathfrak{g}$ such that
$f_{1}=v_{1}^{\ast}$. Consider this $v_{1}$.

Since $f_{2}\in\mathfrak{g}^{\ast}=\left\{  v^{\ast}\ \mid\ v\in
\mathfrak{g}\right\}  $, there exists some $v_{2}\in\mathfrak{g}$ such that
$f_{2}=v_{2}^{\ast}$. Consider this $v_{2}$.

Since $B$ is an orthonormal basis with respect to $\left\langle \cdot
,\cdot\right\rangle $, we have $\sum\limits_{a\in B}a\left\langle \left[
b,v_{2}\right]  ,a\right\rangle =\left[  b,v_{2}\right]  $ and $\sum
\limits_{a\in B}\left\langle \left[  b,v_{1}\right]  ,a\right\rangle a=\left[
b,v_{1}\right]  $.

Now, $h=\underbrace{f_{1}}_{=v_{1}^{\ast}}\otimes\underbrace{f_{2}}%
_{=v_{2}^{\ast}}=v_{1}^{\ast}\otimes v_{2}^{\ast}$, so that%
\begin{align*}
&  h\left(  \sum\limits_{a\in B}\left(  \left[  b,a\right]  \otimes
a+a\otimes\left[  b,a\right]  \right)  \right) \\
&  =\left(  v_{1}^{\ast}\otimes v_{2}^{\ast}\right)  \left(  \sum\limits_{a\in
B}\left(  \left[  b,a\right]  \otimes a+a\otimes\left[  b,a\right]  \right)
\right) \\
&  =\sum\limits_{a\in B}\left(  \underbrace{v_{1}^{\ast}\left(  \left[
b,a\right]  \right)  }_{\substack{=\left\langle v_{1},\left[  b,a\right]
\right\rangle \\\text{(by the definition of }v_{1}^{\ast}\text{)}}%
}\cdot\underbrace{v_{2}^{\ast}\left(  a\right)  }_{\substack{=\left\langle
v_{2},a\right\rangle \\\text{(by the definition of }v_{2}^{\ast}\text{)}%
}}+\underbrace{v_{1}^{\ast}\left(  a\right)  }_{\substack{=\left\langle
v_{1},a\right\rangle \\\text{(by the definition of }v_{1}^{\ast}\text{)}%
}}\cdot\underbrace{v_{2}^{\ast}\left(  \left[  b,a\right]  \right)
}_{\substack{=\left\langle v_{2},\left[  b,a\right]  \right\rangle \\\text{(by
the definition of }v_{2}^{\ast}\text{)}}}\right) \\
&  =\sum\limits_{a\in B}\left(  \underbrace{\left\langle v_{1},\left[
b,a\right]  \right\rangle }_{\substack{=-\left\langle \left[  b,v_{1}\right]
,a\right\rangle \\\text{(since }\left\langle \cdot,\cdot\right\rangle \text{
is invariant)}}}\cdot\left\langle v_{2},a\right\rangle +\left\langle
v_{1},a\right\rangle \cdot\underbrace{\left\langle v_{2},\left[  b,a\right]
\right\rangle }_{\substack{=-\left\langle \left[  b,v_{2}\right]
,a\right\rangle \\\text{(since }\left\langle \cdot,\cdot\right\rangle \text{
is invariant)}}}\right) \\
&  =\sum\limits_{a\in B}\left(  -\left\langle \left[  b,v_{1}\right]
,a\right\rangle \cdot\left\langle v_{2},a\right\rangle -\left\langle
v_{1},a\right\rangle \cdot\left\langle \left[  b,v_{2}\right]  ,a\right\rangle
\right) \\
&  =-\underbrace{\sum\limits_{a\in B}\left\langle \left[  b,v_{1}\right]
,a\right\rangle \cdot\left\langle v_{2},a\right\rangle }_{=\left\langle
v_{2},\sum\limits_{a\in B}\left\langle \left[  b,v_{1}\right]  ,a\right\rangle
a\right\rangle }-\underbrace{\sum\limits_{a\in B}\left\langle v_{1}%
,a\right\rangle \cdot\left\langle \left[  b,v_{2}\right]  ,a\right\rangle
}_{=\left\langle v_{1},\sum\limits_{a\in B}a\left\langle \left[
b,v_{2}\right]  ,a\right\rangle \right\rangle }\\
&  =-\left\langle v_{2},\underbrace{\sum\limits_{a\in B}\left\langle \left[
b,v_{1}\right]  ,a\right\rangle a}_{=\left[  b,v_{1}\right]  }\right\rangle
-\left\langle v_{1},\underbrace{\sum\limits_{a\in B}a\left\langle \left[
b,v_{2}\right]  ,a\right\rangle }_{=\left[  b,v_{2}\right]  }\right\rangle \\
&  =-\underbrace{\left\langle v_{2},\left[  b,v_{1}\right]  \right\rangle
}_{\substack{=\left\langle \left[  b,v_{1}\right]  ,v_{2}\right\rangle
\\\text{(since }\left\langle \cdot,\cdot\right\rangle \text{ is symmetric)}%
}}-\underbrace{\left\langle v_{1},\left[  b,v_{2}\right]  \right\rangle
}_{\substack{=-\left\langle \left[  b,v_{1}\right]  ,v_{2}\right\rangle
\\\text{(since }\left\langle \cdot,\cdot\right\rangle \text{ is invariant)}%
}}=-\left\langle \left[  b,v_{1}\right]  ,v_{2}\right\rangle -\left(
-\left\langle \left[  b,v_{1}\right]  ,v_{2}\right\rangle \right)  =0.
\end{align*}


We thus have proven that $h\left(  \sum\limits_{a\in B}\left(  \left[
b,a\right]  \otimes a+a\otimes\left[  b,a\right]  \right)  \right)  =0$ for
every $h\in\left(  \mathfrak{g}\otimes\mathfrak{g}\right)  ^{\ast}$.
Consequently, $\sum\limits_{a\in B}\left(  \left[  b,a\right]  \otimes
a+a\otimes\left[  b,a\right]  \right)  =0$.

Hence, we have shown that $\sum\limits_{a\in B}\left(  \left[  b,a\right]
\otimes a+a\otimes\left[  b,a\right]  \right)  =0$ for every $b\in
\mathfrak{g}$. In other words, the tensor $\sum\limits_{a\in B}a\otimes a$ is
$\mathfrak{g}$-invariant. Lemma \ref{lem.sugawara.Kil2} \textbf{(a)} is proven.

\textbf{(b)} For every $a\in B$ and $b\in B^{\prime}$, let $\xi_{a,b}$ be the
$b$-coordinate of $a$ with respect to the basis $B^{\prime}$. Then, every
$a\in B$ satisfies $a=\sum\limits_{b\in B^{\prime}}\xi_{a,b}b$. Thus, $\left(
\xi_{a,b}\right)  _{\left(  a,b\right)  \in B\times B^{\prime}}$ (this is a
matrix whose rows and columns are indexed by elements of $B$ and $B^{\prime}$,
respectively) is the matrix which represents the change of bases from
$B^{\prime}$ to $B$ (or from $B$ to $B^{\prime}$, depending on how you define
the matrix representing a change of basis). Since both $B$ and $B^{\prime}$
are two orthonormal bases with respect to the same bilinear form $\left\langle
\cdot,\cdot\right\rangle $, this matrix must thus be orthogonal. Hence, every
$b\in B^{\prime}$ and $b^{\prime}\in B^{\prime}$ satisfy $\sum\limits_{a\in
B}\xi_{a,b}\xi_{a,b^{\prime}}=\delta_{b,b^{\prime}}$ (where $\delta
_{b,b^{\prime}}$ is the Kronecker delta of $b$ and $b^{\prime}$). Now, since
every $a\in B$ satisfies $a=\sum\limits_{b\in B^{\prime}}\xi_{a,b}b$ and
$a=\sum\limits_{b\in B^{\prime}}\xi_{a,b}b=\sum\limits_{b^{\prime}\in
B^{\prime}}\xi_{a,b^{\prime}}b^{\prime}$ (here, we renamed $b$ as $b^{\prime}$
in the sum), we have%
\begin{align*}
&  \sum\limits_{a\in B}\underbrace{a}_{=\sum\limits_{b\in B^{\prime}}\xi
_{a,b}b}\otimes\underbrace{a}_{=\sum\limits_{b^{\prime}\in B^{\prime}}%
\xi_{a,b^{\prime}}b^{\prime}}\\
&  =\sum\limits_{a\in B}\left(  \sum\limits_{b\in B^{\prime}}\xi
_{a,b}b\right)  \otimes\left(  \sum\limits_{b^{\prime}\in B^{\prime}}%
\xi_{a,b^{\prime}}b^{\prime}\right)  =\sum\limits_{a\in B}\sum\limits_{b\in
B^{\prime}}\sum\limits_{b^{\prime}\in B^{\prime}}\xi_{a,b}\xi_{a,b^{\prime}%
}b\otimes b^{\prime}\\
&  =\sum\limits_{b\in B^{\prime}}\sum\limits_{b^{\prime}\in B^{\prime}%
}\underbrace{\sum\limits_{a\in B}\xi_{a,b}\xi_{a,b^{\prime}}}_{=\delta
_{b,b^{\prime}}}b\otimes b^{\prime}=\sum\limits_{b\in B^{\prime}%
}\underbrace{\sum\limits_{b^{\prime}\in B^{\prime}}\delta_{b,b^{\prime}%
}b\otimes b^{\prime}}_{=b\otimes b}=\sum\limits_{b\in B^{\prime}}b\otimes b\\
&  =\sum\limits_{a\in B^{\prime}}a\otimes a\ \ \ \ \ \ \ \ \ \ \left(
\text{here, we renamed }b\text{ as }a\text{ in the sum}\right)  .
\end{align*}
This proves Lemma \ref{lem.sugawara.Kil2} \textbf{(b)}.

As a consequence of this lemma, we get:

\begin{lemma}
\label{lem.sugawara.Kil3}Let $\mathfrak{g}$ be a finite-dimensional
$\mathbb{C}$-Lie algebra equipped with a $\mathfrak{g}$-invariant symmetric
bilinear form $\left(  \cdot,\cdot\right)  $. Denote by $\operatorname*{Kil}$
the Killing form of $\mathfrak{g}$. Let $B\subseteq\mathfrak{g}$ be a basis
orthonormal with respect to the form $k\left(  \cdot,\cdot\right)  +\dfrac
{1}{2}\operatorname*{Kil}$. Let $b\in\mathfrak{g}$.

\textbf{(a)} We have $\sum\limits_{a\in B}\left(  \left[  b,a\right]  \otimes
a+a\otimes\left[  b,a\right]  \right)  =0$.

\textbf{(b)} We have $\dfrac{1}{2}\sum\limits_{a\in B}\left[  \left[
b,a\right]  ,a\right]  +k\sum\limits_{a\in B}\left(  b,a\right)  a=b$.

\textbf{(c)} We have $\left(  \left[  b,a\right]  ,a\right)  =0$ for every
$a\in\mathfrak{g}$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.sugawara.Kil3}.} The basis $B$ is orthonormal
with respect to a symmetric $\mathfrak{g}$-invariant bilinear form (namely,
the form $k\left(  \cdot,\cdot\right)  +\dfrac{1}{2}\operatorname*{Kil}$). As
a consequence, the tensor $\sum\limits_{a\in B}a\otimes a$ is $\mathfrak{g}%
$-invariant in $\mathfrak{g}\otimes\mathfrak{g}$ (by Lemma
\ref{lem.sugawara.Kil2} \textbf{(a)}, applied to $\left\langle \cdot
,\cdot\right\rangle =k\left(  \cdot,\cdot\right)  +\dfrac{1}{2}%
\operatorname*{Kil}$). In other words, $\sum\limits_{a\in B}\left(  \left[
b,a\right]  \otimes a+a\otimes\left[  b,a\right]  \right)  =0$. This proves
Lemma \ref{lem.sugawara.Kil3} \textbf{(a)}.

\textbf{(b)} If $\left\langle \cdot,\cdot\right\rangle $ is any nondegenerate
inner product\footnote{By ``inner product'', we mean a symmetric bilinear
form.} on a finite-dimensional vector space $V$ and $B$ is an orthonormal
basis with respect to that product, then any vector $b\in V$ is equal to
$\sum\limits_{a\in B}\left\langle b,a\right\rangle a$. Applying this fact to
the inner product $\left\langle \cdot,\cdot\right\rangle =k\left(  \cdot
,\cdot\right)  +\dfrac{1}{2}\operatorname*{Kil}$ on the vector space
$V=\mathfrak{g}$, we conclude that $b=k\sum\limits_{a\in B}\left(  b,a\right)
a+\dfrac{1}{2}\sum\limits_{a\in B}\operatorname*{Kil}\left(  b,a\right)  a$.

Now, applying Lemma \ref{lem.sugawara.Kil} to the $\mathfrak{g}$-invariant
tensor $\sum\limits_{a\in B}a\otimes a$ in lieu of $\sum\limits_{i=1}^{n}%
p_{i}\otimes q_{i}$, we see that $\sum\limits_{a\in B}\left[  \left[
b,a\right]  ,a\right]  =\sum\limits_{a\in B}\operatorname*{Kil}\left(
b,a\right)  a$. Hence,%
\[
b=k\sum\limits_{a\in B}\left(  b,a\right)  a+\dfrac{1}{2}\underbrace{\sum
\limits_{a\in B}\operatorname*{Kil}\left(  b,a\right)  a}_{=\sum\limits_{a\in
B}\left[  \left[  b,a\right]  ,a\right]  }=\dfrac{1}{2}\sum\limits_{a\in
B}\left[  \left[  b,a\right]  ,a\right]  +k\sum\limits_{a\in B}\left(
b,a\right)  a.
\]
This proves Lemma \ref{lem.sugawara.Kil3} \textbf{(b)}.

\begin{vershort}
\textbf{(c)} Every $c\in\mathfrak{g}$ satisfies $\left(  \left[  a,b\right]
,c\right)  +\left(  b,\left[  a,c\right]  \right)  =0$ (due to the
$\mathfrak{g}$-invariance of $\left(  \cdot,\cdot\right)  $). Applying this to
$c=a$, we obtain $\left(  \left[  a,b\right]  ,a\right)  +\left(  b,\left[
a,a\right]  \right)  =0$. Since $\left[  a,a\right]  =0$ and $\left[
a,b\right]  =-\left[  b,a\right]  $, this rewrites as $\left(  -\left[
b,a\right]  ,a\right)  +\left(  b,0\right)  =0$. This simplifies to $-\left(
\left[  b,a\right]  ,a\right)  =0$. Thus, $\left(  \left[  b,a\right]
,a\right)  =0$. This proves Lemma \ref{lem.sugawara.Kil3} \textbf{(c)}.
\end{vershort}

\begin{verlong}
\textbf{(c)} Every $c\in\mathfrak{g}$ satisfies $\left(  \left[  a,b\right]
,c\right)  +\left(  b,\left[  a,c\right]  \right)  =0$ (due to the
$\mathfrak{g}$-invariance of $\left(  \cdot,\cdot\right)  $). Applying this to
$c=a$, we obtain $\left(  \left[  a,b\right]  ,a\right)  +\left(  b,\left[
a,a\right]  \right)  =0$. Thus,%
\begin{align*}
0  &  =\left(  \underbrace{\left[  a,b\right]  }_{\substack{=-\left[
b,a\right]  \\\text{(since the Lie bracket}\\\text{is antisymmetric)}%
}},a\right)  +\left(  b,\underbrace{\left[  a,a\right]  }%
_{\substack{=0\\\text{(since the Lie bracket}\\\text{is antisymmetric)}%
}}\right)  =\underbrace{\left(  -\left[  b,a\right]  ,a\right)  }%
_{\substack{=-\left(  \left[  b,a\right]  ,a\right)  \\\text{(since the form
}\left(  \cdot,\cdot\right)  \\\text{is bilinear)}}}+\underbrace{\left(
b,0\right)  }_{\substack{=0\\\text{(since the form }\left(  \cdot
,\cdot\right)  \\\text{is bilinear)}}}\\
&  =-\left(  \left[  b,a\right]  ,a\right)  +0=-\left(  \left[  b,a\right]
,a\right)  .
\end{align*}
Adding $\left(  \left[  b,a\right]  ,a\right)  $ to this equality, we obtain
$\left(  \left[  b,a\right]  ,a\right)  =0$. This proves Lemma
\ref{lem.sugawara.Kil3} \textbf{(c)}.
\end{verlong}

\begin{noncompile}
Here is a \textit{different proof of Lemma \ref{lem.sugawara.Kil3}
\textbf{(c)} (which I had written before I found the trivial proof above):}
Every $c\in\mathfrak{g}$ satisfies $\left(  \left[  b,a\right]  ,c\right)
+\left(  a,\left[  b,c\right]  \right)  =0$ (due to the $\mathfrak{g}%
$-invariance of $\left(  \cdot,\cdot\right)  $). Applying this to $c=a$, we
obtain $\left(  \left[  b,a\right]  ,a\right)  +\left(  a,\left[  b,a\right]
\right)  =0$. Since the form $\left(  \cdot,\cdot\right)  $ is symmetric, this
rewrites as $2\left(  \left[  b,a\right]  ,a\right)  =0$. Thus, $\left(
\left[  b,a\right]  ,a\right)  =0$. This proves Lemma \ref{lem.sugawara.Kil3}
\textbf{(c)}.
\end{noncompile}

Next, we formulate the analogue of Remark \ref{rmk.fockvir.normal.mn}:

\begin{remark}
\label{rmk.sugawara.normal.mn}Let $x\in\mathfrak{g}$. If $m$ and $n$ are
integers such that $m\neq-n$, then $\left.  :x_{m}x_{n}:\right.  =x_{m}x_{n}$.
(This is because $\left[  x_{m},x_{n}\right]  =0$ in $\widehat{\mathfrak{g}}$
when $m\neq-n$.)
\end{remark}

In analogy to Remark \ref{rmk.fockvir.normal.comm} \textbf{(a)}, we have
commutativity of normal ordered products:

\begin{remark}
\label{rmk.sugawara.normal.comm}Let $x\in\mathfrak{g}$. Any $m\in\mathbb{Z}$
and $n\in\mathbb{Z}$ satisfy $\left.  :x_{m}x_{n}:\right.  =\left.
:x_{n}x_{m}:\right.  $.
\end{remark}

Also, here is a simple way to rewrite the definition of $\left.  :x_{m}%
x_{n}:\right.  $:

\begin{remark}
\label{rmk.sugawara.normal.max}Let $x\in\mathfrak{g}$. Any $m\in\mathbb{Z}$
and $n\in\mathbb{Z}$ satisfy $\left.  :x_{m}x_{n}:\right.  =x_{\min\left\{
m,n\right\}  }x_{\max\left\{  m,n\right\}  }$.
\end{remark}

Generalizing Remark \ref{rmk.fockvir.normal.K}, we have:

\begin{remark}
\label{rmk.sugawara.normal.K}Let $x\in\mathfrak{g}$. Let $m$ and $n$ be integers.

\textbf{(a)} Then, $\left.  :x_{m}x_{n}:\right.  =x_{m}x_{n}+n\left[
m>0\right]  \delta_{m,-n}\left(  x,x\right)  K$. Here, when $\mathfrak{A}$ is
an assertion, we denote by $\left[  \mathfrak{A}\right]  $ the truth value of
$\mathfrak{A}$ (that is, the number $\left\{
\begin{array}
[c]{c}%
1\text{, if }\mathfrak{A}\text{ is true;}\\
0\text{, if }\mathfrak{A}\text{ is false }%
\end{array}
\right.  $).

\textbf{(b)} For any $y\in U\left(  \widehat{\mathfrak{g}}\right)  $, we have
$\left[  y,\left.  :x_{m}x_{n}:\right.  \right]  =\left[  y,x_{m}x_{n}\right]
$ in $U\left(  \widehat{\mathfrak{g}}\right)  $ (where $\left[  \cdot
,\cdot\right]  $ denotes the commutator in $U\left(  \widehat{\mathfrak{g}%
}\right)  $).
\end{remark}

The proof of this is left to the reader (it follows very quickly from the definitions).

Next, here is a completely elementary lemma:

\begin{lemma}
\label{lem.telescope}Let $G$ be an abelian group (written additively).
Whenever $\left(  u_{m}\right)  _{m\in\mathbb{Z}}\in G^{\mathbb{Z}}$ is a
family of elements of $G$, and $\mathcal{A}\left(  m\right)  $ is an assertion
for every $m\in\mathbb{Z}$, let us abbreviate the sum $\sum
\limits_{\substack{m\in\mathbb{Z};\\\mathcal{A}\left(  m\right)  }}u_{m}$ (if
this sum is well-defined) by $\sum\limits_{\mathcal{A}\left(  m\right)  }%
u_{m}$. (For instance, we will abbreviate the sum $\sum\limits_{\substack{m\in
\mathbb{Z};\\3\leq m\leq7}}u_{m}$ by $\sum\limits_{3\leq m\leq7}u_{m}$.)

For any integers $\alpha$ and $\beta$ such that $\alpha\leq\beta$, for any
nonnegative integer $N$, and for any family $\left(  u_{m}\right)
_{m\in\mathbb{Z}}\in G^{\mathbb{Z}}$ of elements of $G$, we have%
\[
\sum\limits_{\left\vert m-\beta\right\vert \leq N}u_{m}-\sum
\limits_{\left\vert m-\alpha\right\vert \leq N}u_{m}=-\sum\limits_{\alpha
-N\leq m<\beta-N}u_{m}+\sum\limits_{\alpha+N<m\leq\beta+N}u_{m}.
\]

\end{lemma}

The proof of Lemma \ref{lem.telescope} (which is merely an easy generalization
of the telescope principle) is left to the reader.

\textit{Proof of Theorem \ref{thm.sugawara}.} Let us use the notation
$\sum\limits_{\mathcal{A}\left(  m\right)  }u_{m}$ defined in Lemma
\ref{lem.telescope}.

In the following, we will consider the topology on $\operatorname*{End}M$
defined as follows: Endow $M$ with the discrete topology, endow $M^{M}$ with
the product topology, and endow $\operatorname*{End}M$ with a topology by
viewing $\operatorname*{End}M$ as a subset of the set $M^{M}$. Clearly, in
this topology, a net $\left(  a_{s}\right)  _{s\in S}$ of elements of
$\operatorname*{End}M$ converges if and only if for every $v\in M$, the net
$\left(  a_{s}v\right)  _{s\in S}$ of elements of $M$ converges (in the
discrete topology). As a consequence, whenever $\left(  u_{m}\right)
_{m\in\mathbb{Z}}$ is a family of elements of $\operatorname*{End}M$ indexed
by integers, the sum $\sum\limits_{m\in\mathbb{Z}}u_{m}$ converges with
respect to the topology which we defined on $\operatorname*{End}M$ if and only
if for every $v\in M$, the sum $\sum\limits_{m\in\mathbb{Z}}u_{m}v$ converges
in the discrete topology (i. e., has only finitely many nonzero addends).
Consequently, the convergence of an infinite sum with respect to the topology
which we defined on $\operatorname*{End}M$ is equivalent to the convergence of
this sum in the meaning in which we used the word ``convergence'' in Theorem
\ref{thm.sugawara}.

Note that addition, composition, and scalar multiplication (in the sense of:
multiplication by scalars) of maps in $\operatorname*{End}M$ are continuous
maps with respect to this topology.

We will use the notation $\lim\limits_{N\rightarrow\infty}$ for limits with
respect to the topology on $\operatorname*{End}M$. Note that, if $\left(
u_{m}\right)  _{m\in\mathbb{Z}}$ is a family of elements of
$\operatorname*{End}M$ indexed by integers, and if the sum $\sum
\limits_{m\in\mathbb{Z}}u_{m}$ converges with respect to the topology which we
defined on $\operatorname*{End}M$, then $\sum\limits_{m\in\mathbb{Z}}%
u_{m}=\lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert m-\alpha
\right\vert \leq N}u_{m}$ for every $\alpha\in\mathbb{R}$.

In the following, $\left[  \cdot,\cdot\right]  _{L\mathfrak{g}}$ will mean the
Lie bracket of $L\mathfrak{g}$, whereas the notation $\left[  \cdot
,\cdot\right]  $ without a subscript will mean either the Lie bracket of
$\widehat{\mathfrak{g}}$ or the Lie bracket of $\mathfrak{g}$. Note that the
use of the same notation for the Lie bracket of $\widehat{\mathfrak{g}}$ and
for the Lie bracket of $\mathfrak{g}$ will not lead to conflicts, since the
Lie bracket of $\mathfrak{g}$ is the restriction of the Lie bracket of
$\widehat{\mathfrak{g}}$ to $\mathfrak{g}\times\mathfrak{g}$ (this follows
quickly from $\omega\left(  \mathfrak{g},\mathfrak{g}\right)  =0$).

Note that any $x\in\mathfrak{g}$, $y\in\mathfrak{g}$, $n\in\mathbb{Z}$ and
$m\in\mathbb{Z}$ satisfy%
\begin{equation}
\left[  x_{n},y_{m}\right]  =\left[  x,y\right]  _{n+m}+K\omega\left(
x_{n},y_{m}\right)  \label{pf.sugawara.lie}%
\end{equation}
\footnote{This is because%
\begin{align*}
\left[  \underbrace{x_{n}}_{=xt^{n}},\underbrace{y_{m}}_{=yt^{m}}\right]   &
=\left[  xt^{n},yt^{m}\right]  =\left(  \underbrace{\left[  xt^{n}%
,yt^{m}\right]  _{L\mathfrak{g}}}_{\substack{=\left[  x,y\right]
t^{n+m}\\\text{(by the definition of the Lie}\\\text{algebra structure on
}L\mathfrak{g}\text{)}}},\omega\left(  \underbrace{xt^{n}}_{=x_{n}%
},\underbrace{yt^{m}}_{=y_{m}}\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the Lie bracket on
}\widehat{\mathfrak{g}}\right) \\
&  =\left(  \underbrace{\left[  x,y\right]  t^{n+m}}_{=\left[  x,y\right]
_{n+m}},\omega\left(  x_{n},y_{m}\right)  \right)  =\left(  \left[
x,y\right]  _{n+m},\omega\left(  x_{n},y_{m}\right)  \right)  =\left[
x,y\right]  _{n+m}+K\omega\left(  x_{n},y_{m}\right)  .
\end{align*}
}.

\textbf{(a)} Let $n\in\mathbb{Z}$ and $v\in M$. We must prove that for every
$a\in B$, the sum $\sum\limits_{m\in\mathbb{Z}}\left.  :a_{m}a_{n-m}:\right.
v$ converges in the discrete topology. We will prove a slightly more general
statement: We will prove that for every $x\in\mathfrak{g}$, the sum
$\sum\limits_{m\in\mathbb{Z}}\left.  :x_{m}x_{n-m}:\right.  v$ converges in
the discrete topology.

In fact, let $x\in\mathfrak{g}$. We must prove that the sum $\sum
\limits_{m\in\mathbb{Z}}\left.  :x_{m}x_{n-m}:\right.  v$ converges in the
discrete topology.

Recall the definition of an admissible module. With slightly modified
notations, it looks as follows: A $\widehat{\mathfrak{g}}$-module $P$ is said
to be \textit{admissible} if for every $w\in P$, there exists some
$\mathbf{M}\in\mathbb{N}$ such that every integer $\mathbf{m}\geq\mathbf{M}$
and every $a\in\mathfrak{g}$ satisfy $at^{\mathbf{m}}\cdot w=0$. Hence, for
every $w\in M$, there exists some $\mathbf{M}\in\mathbb{N}$ such that every
integer $\mathbf{m}\geq\mathbf{M}$ and every $a\in\mathfrak{g}$ satisfy
$at^{\mathbf{m}}\cdot w=0$ (because $M$ is admissible). Applying this to
$w=v$, we see that there exists some $\mathbf{M}\in\mathbb{N}$ such that every
integer $\mathbf{m}\geq\mathbf{M}$ and every $a\in\mathfrak{g}$ satisfy
$at^{\mathbf{m}}\cdot v=0$. Fix this $\mathbf{M}$. Every integer
$m\geq\mathbf{M}$ satisfies%
\begin{equation}
\underbrace{x_{m}}_{=xt^{m}}v=xt^{m}\cdot v=0 \label{pf.sugawara.a.1}%
\end{equation}
(by the equality $at^{\mathbf{m}}\cdot v=0$, applied to $a=x$ and
$\mathbf{m}=m$). Now, every integer $m$ such that $\max\left\{  m,n-m\right\}
\geq\mathbf{M}$ satisfies%
\[
\underbrace{\left.  :x_{m}x_{n-m}:\right.  }_{\substack{=x_{\min\left\{
m,n-m\right\}  }x_{\max\left\{  m,n-m\right\}  }\\\text{(by Remark
\ref{rmk.sugawara.normal.max}, applied}\\\text{to }\ell=n-m\text{)}}%
}v=x_{\min\left\{  m,n-m\right\}  }\underbrace{x_{\max\left\{  m,n-m\right\}
}v}_{\substack{=0\\\text{(by (\ref{pf.sugawara.a.1}), applied to }\max\left\{
m,n-m\right\}  \\\text{instead of }m\text{ (since }\max\left\{  m,n-m\right\}
\geq\mathbf{M}\text{))}}}=x_{\min\left\{  m,n-m\right\}  }0=0.
\]
Since all but finitely many integers $m$ satisfy $\max\left\{  m,n-m\right\}
\geq\mathbf{M}$ (this is obvious), this shows that all but finitely many
integers $m$ satisfy $\left.  :x_{m}x_{n-m}:\right.  v=0$. In other words, all
but finitely many addends of the sum $\sum\limits_{m\in\mathbb{Z}}\left.
:x_{m}x_{n-m}:\right.  v$ are zero. Hence, the sum $\sum\limits_{m\in
\mathbb{Z}}\left.  :x_{m}x_{n-m}:\right.  v$ converges in the discrete
topology. This proves Theorem \ref{thm.sugawara} \textbf{(a)}.

Note that, during the proof of Theorem \ref{thm.sugawara} \textbf{(a)}, we
have shown that for every $n\in\mathbb{Z}$, $x\in\mathfrak{g}$ and $v\in M$,
the sum $\sum\limits_{m\in\mathbb{Z}}\left.  :x_{m}x_{n-m}:\right.  v$
converges in the discrete topology. In other words, for every $n\in\mathbb{Z}$
and $x\in\mathfrak{g}$, the sum $\sum\limits_{m\in\mathbb{Z}}\left.
:x_{m}x_{n-m}:\right.  $ converges in the topology which we defined on
$\operatorname*{End}M$.

\textbf{(b)} Let $n\in\mathbb{Z}$. Let $B^{\prime}$ be an orthonormal basis of
$\mathfrak{g}$ with respect to the form $k\left(  \cdot,\cdot\right)
+\dfrac{1}{2}\operatorname*{Kil}$. We are going to prove that%
\begin{equation}
L_{n}=\dfrac{1}{2}\sum\limits_{a\in B^{\prime}}\sum\limits_{m\in\mathbb{Z}%
}\left.  :a_{m}a_{n-m}:\right.  \label{pf.sugawara.basisind.1}%
\end{equation}
(where $L_{n}$ still denotes the operator $\dfrac{1}{2}\sum\limits_{a\in
B}\sum\limits_{m\in\mathbb{Z}}\left.  :a_{m}a_{n-m}:\right.  $ defined in
Theorem \ref{thm.sugawara} using the orthonormal basis $B$, not the
orthonormal basis $B^{\prime}$). Once (\ref{pf.sugawara.basisind.1}) is
proven, it will follow that $L_{n}$ does not depend on $B$, and thus Theorem
\ref{thm.sugawara} \textbf{(b)} will be proven.

Applying Lemma \ref{lem.sugawara.Kil2} \textbf{(b)} to $\left\langle
\cdot,\cdot\right\rangle =k\left(  \cdot,\cdot\right)  +\dfrac{1}%
{2}\operatorname*{Kil}$, we obtain $\sum\limits_{a\in B}a\otimes
a=\sum\limits_{a\in B^{\prime}}a\otimes a$. Thus,%
\begin{equation}
\sum\limits_{a\in B}a_{u}a_{v}=\sum\limits_{a\in B^{\prime}}a_{u}%
a_{v}\ \ \ \ \ \ \ \ \ \ \text{for any }u\in\mathbb{Z}\text{ and }%
v\in\mathbb{Z} \label{pf.sugawara.basisind.pf.1}%
\end{equation}
\footnote{This follows from applying the linear map
\begin{align*}
\mathfrak{g}\otimes\mathfrak{g}  &  \rightarrow\operatorname*{End}M,\\
x\otimes y  &  \mapsto x_{u}y_{v}%
\end{align*}
to the equality $\sum\limits_{a\in B}a\otimes a=\sum\limits_{a\in B^{\prime}%
}a\otimes a$.}.

Thus, every $m\in\mathbb{Z}$ satisfies $\sum\limits_{a\in B}\left.
:a_{m}a_{n-m}:\right.  =\sum\limits_{a\in B^{\prime}}\left.  :a_{m}%
a_{n-m}:\right.  $\ \ \ \ \footnote{\textit{Proof.} We distinguish between two
cases:
\par
\textit{Case 1:} We have $m\leq n-m$.
\par
\textit{Case 2:} We have $m>n-m$.
\par
Let us first consider Case 1. In this case, $m\leq n-m$. Hence, every
$a\in\mathfrak{g}$ satisfies $\left.  :a_{m}a_{n-m}:\right.  =a_{m}a_{n-m}$.
Thus,
\begin{align*}
\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.   &  =\sum\limits_{a\in
B}a_{m}a_{n-m}=\sum\limits_{a\in B^{\prime}}\underbrace{a_{m}a_{n-m}%
}_{=\left.  :a_{m}a_{n-m}:\right.  }\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.sugawara.basisind.pf.1}), applied to }u=m\text{ and }v=n-m\right) \\
&  =\sum\limits_{a\in B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  .
\end{align*}
This proves $\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.  =\sum
\limits_{a\in B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  $ in Case 1.
\par
Let us now consider Case 2. In this case, $m>n-m$. Hence, every $a\in
\mathfrak{g}$ satisfies $\left.  :a_{m}a_{n-m}:\right.  =a_{n-m}a_{m}$. Thus,
\begin{align*}
\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.   &  =\sum\limits_{a\in
B}a_{n-m}a_{m}=\sum\limits_{a\in B^{\prime}}\underbrace{a_{n-m}a_{m}%
}_{=\left.  :a_{m}a_{n-m}:\right.  }\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.sugawara.basisind.pf.1}), applied to }u=n-m\text{ and }v=m\right) \\
&  =\sum\limits_{a\in B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  .
\end{align*}
This proves $\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.  =\sum
\limits_{a\in B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  $ in Case 2.
\par
Hence, $\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.  =\sum\limits_{a\in
B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  $ is proven in each of the cases 1
and 2. Thus, $\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.
=\sum\limits_{a\in B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  $ always holds
(since cases 1 and 2 cover all possibilities), qed.}. Hence,%
\begin{align*}
L_{n}  &  =\dfrac{1}{2}\sum\limits_{a\in B}\sum\limits_{m\in\mathbb{Z}}\left.
:a_{m}a_{n-m}:\right.  =\dfrac{1}{2}\sum\limits_{m\in\mathbb{Z}}%
\underbrace{\sum\limits_{a\in B}\left.  :a_{m}a_{n-m}:\right.  }%
_{=\sum\limits_{a\in B^{\prime}}\left.  :a_{m}a_{n-m}:\right.  }=\dfrac{1}%
{2}\sum\limits_{m\in\mathbb{Z}}\sum\limits_{a\in B^{\prime}}\left.
:a_{m}a_{n-m}:\right. \\
&  =\dfrac{1}{2}\sum\limits_{a\in B^{\prime}}\sum\limits_{m\in\mathbb{Z}%
}\left.  :a_{m}a_{n-m}:\right.  .
\end{align*}
Thus, (\ref{pf.sugawara.basisind.1}) is proven. As we said, this completes the
proof of Theorem \ref{thm.sugawara} \textbf{(b)}.

\textbf{(c)} \textit{1st step:} Let us first show that%
\begin{equation}
\left[  b_{r},L_{n}\right]  =rb_{n+r}\ \ \ \ \ \ \ \ \ \ \text{for every }%
b\in\mathfrak{g}\text{ and any integers }r\text{ and }n.
\label{pf.sugawara.step1}%
\end{equation}


\textit{Proof of (\ref{pf.sugawara.step1}):} Let $b\in\mathfrak{g}$,
$r\in\mathbb{Z}$ and $n\in\mathbb{Z}$.

We must be careful here with infinite sums, since not even formal algebra
allows us to manipulate infinite sums like $\sum\limits_{m\in\mathbb{Z}%
}\left[  b,a\right]  _{r+m}a_{n-m}$ (for good reasons: these are divergent in
every meaning of this word). While we were working in the Heisenberg algebra
$\mathcal{A}$ (which can be written as $\widehat{\mathfrak{g}}$ for
$\mathfrak{g}$ being the trivial Lie algebra $\mathbb{C}$), these infinite
sums made sense due to all of their addends being $0$ (since $\left[
b,a\right]  =0$ for all $a$ and $b$ lying in the trivial Lie algebra
$\mathbb{C}$). But this was an exception rather than the rule, and now we need
to take care.

Let us first assume that $r\geq0$.

Since%
\begin{align*}
L_{n}  &  =\dfrac{1}{2}\sum\limits_{a\in B}\underbrace{\sum\limits_{m\in
\mathbb{Z}}\left.  :a_{m}a_{n-m}:\right.  }_{=\lim\limits_{N\rightarrow\infty
}\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left.
:a_{m}a_{n-m}:\right.  }=\dfrac{1}{2}\sum\limits_{a\in B}\lim
\limits_{N\rightarrow\infty}\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert
\leq N}\left.  :a_{m}a_{n-m}:\right. \\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left.  :a_{m}%
a_{n-m}:\right.  ,
\end{align*}
we have%
\begin{align}
&  \left[  b_{r},L_{n}\right] \nonumber\\
&  =\left[  b_{r},\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum
\limits_{a\in B}\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq
N}\left.  :a_{m}a_{n-m}:\right.  \right] \nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\underbrace{\left[
b_{r},\left.  :a_{m}a_{n-m}:\right.  \right]  }%
_{\substack{_{\substack{=\left[  b_{r},a_{m}a_{n-m}\right]  }}\\\text{(by
Remark \ref{rmk.sugawara.normal.K} \textbf{(b)}, applied to}\\a\text{, }%
b_{r}\text{ and }n-m\text{ instead of }x\text{, }y\text{ and }n\text{)}%
}}\nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\underbrace{\left[
b_{r},a_{m}a_{n-m}\right]  }_{=\left[  b_{r},a_{m}\right]  a_{n-m}%
+a_{m}\left[  b_{r},a_{n-m}\right]  }\nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(
\underbrace{\left[  b_{r},a_{m}\right]  }_{\substack{=\left[  b,a\right]
_{r+m}+K\omega\left(  b_{r},a_{m}\right)  \\\text{(by (\ref{pf.sugawara.lie}%
))}}}a_{n-m}+a_{m}\underbrace{\left[  b_{r},a_{n-m}\right]  }%
_{\substack{=\left[  b,a\right]  _{n+r-m}+K\omega\left(  b_{r},a_{n-m}\right)
\\\text{(by (\ref{pf.sugawara.lie}))}}}\right) \nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+K\omega\left(  b_{r},a_{m}\right)  a_{n-m}%
+a_{m}\left[  b,a\right]  _{n+r-m}+a_{m}K\omega\left(  b_{r},a_{n-m}\right)
\right) \nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}+K\omega\left(
b_{r},a_{m}\right)  a_{n-m}+a_{m}K\omega\left(  b_{r},a_{n-m}\right)  \right)
. \label{pf.sugawara.b.1}%
\end{align}


Now fix $a\in B$. We now notice that for any $N\in\mathbb{N}$, the sum
$\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}K\omega\left(
b_{r},a_{m}\right)  a_{n-m}$ (in $\operatorname*{End}M$) has at most one
nonzero addend (because $\omega\left(  b_{r},a_{m}\right)  $ can be nonzero
for at most one integer $m$ (namely, for $m=-r$)). Hence, this sum
$\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}K\omega\left(
b_{r},a_{m}\right)  a_{n-m}$ converges for any $N\in\mathbb{N}$. For
sufficiently high $N$, this sum does have an addend for $m=-r$, and all other
addends of this sum are $0$ (since $\omega\left(  b_{r},a_{m}\right)  =0$
whenever $m\neq-r$), so that the value of this sum is $\underbrace{K}%
_{\substack{=k\\\text{(since }K\text{ acts as}\\k\cdot\operatorname*{id}\text{
on }M\text{)}}}\underbrace{\omega\left(  b_{r},a_{-r}\right)  }%
_{\substack{=r\left(  b,a\right)  \\\text{(by the definition of }%
\omega\text{)}}}\underbrace{a_{n-\left(  -r\right)  }}_{=a_{n+r}}=kr\left(
b,a\right)  a_{n+r}$. We thus have shown that the sum $\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}K\omega\left(  b_{r},a_{m}\right)  a_{n-m}$
converges for all $N\in\mathbb{N}$, and satisfies%
\begin{equation}
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}K\omega\left(
b_{r},a_{m}\right)  a_{n-m}=kr\left(  b,a\right)  a_{n+r}%
\ \ \ \ \ \ \ \ \ \ \text{for sufficiently high }N\text{.}
\label{pf.sugawara.b.2a}%
\end{equation}
Similarly, we see that the sum $\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}a_{m}K\omega\left(  b_{r},a_{n-m}\right)  $ converges
for all $N\in\mathbb{N}$, and satisfies%
\begin{equation}
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}a_{m}K\omega\left(
b_{r},a_{n-m}\right)  =a_{n+r}kr\left(  b,a\right)
\ \ \ \ \ \ \ \ \ \ \text{for sufficiently high }N\text{.}
\label{pf.sugawara.b.2b}%
\end{equation}
Finally, for all $N\in\mathbb{N}$, the sum $\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[  b,a\right]  _{r+m}%
a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)  $
converges\footnote{\textit{Proof.} Let $N\in\mathbb{N}$. The sum
$\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}+K\omega\left(
b_{r},a_{m}\right)  a_{n-m}+a_{m}K\omega\left(  b_{r},a_{n-m}\right)  \right)
$ converges (because it appears on the right hand side of
(\ref{pf.sugawara.b.1})), and the sums $\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}K\omega\left(  b_{r},a_{m}\right)  a_{n-m}$ and
$\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}a_{m}K\omega\left(
b_{r},a_{n-m}\right)  $ converge (as we have just seen). Hence, the sum%
\begin{align*}
&  \sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left(
\left[  b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}%
+K\omega\left(  b_{r},a_{m}\right)  a_{n-m}+a_{m}K\omega\left(  b_{r}%
,a_{n-m}\right)  \right)  \right. \\
&  \ \ \ \ \ \ \ \ \ \ \left.  -K\omega\left(  b_{r},a_{m}\right)
a_{n-m}-a_{m}K\omega\left(  b_{r},a_{n-m}\right)  \right)
\end{align*}
converges as well (since it is obtained by subtracting the latter two sums
from the former sum componentwise). But this sum clearly simplifies to
$\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)  $. Hence,
the sum $\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(
\left[  b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)  $
converges, qed.}.

Since the sums $\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq
N}K\omega\left(  b_{r},a_{m}\right)  a_{n-m}$, $\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}a_{m}K\omega\left(  b_{r},a_{n-m}\right)  $
and \newline$\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(
\left[  b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)  $
converge for every $N\in\mathbb{N}$, we have%
\begin{align*}
&  \sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}+K\omega\left(
b_{r},a_{m}\right)  a_{n-m}+a_{m}K\omega\left(  b_{r},a_{n-m}\right)  \right)
\\
&  =\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)
+\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}K\omega\left(
b_{r},a_{m}\right)  a_{n-m}\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq
N}a_{m}K\omega\left(  b_{r},a_{n-m}\right)
\end{align*}
for every $N\in\mathbb{N}$. Hence, for every sufficiently high $N\in
\mathbb{N}$, we have%
\begin{align}
&  \sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}+K\omega\left(
b_{r},a_{m}\right)  a_{n-m}+a_{m}K\omega\left(  b_{r},a_{n-m}\right)  \right)
\nonumber\\
&  =\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)
+\underbrace{\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}%
K\omega\left(  b_{r},a_{m}\right)  a_{n-m}}_{\substack{=kr\left(  b,a\right)
a_{n+r}\text{ for sufficiently high }N\\\text{(by (\ref{pf.sugawara.b.2a}))}%
}}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\underbrace{\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}a_{m}K\omega\left(  b_{r},a_{n-m}\right)  }%
_{\substack{=a_{n+r}kr\left(  b,a\right)  \text{ for sufficiently high
}N\\\text{(by (\ref{pf.sugawara.b.2a}))}}}\nonumber\\
&  =\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)
+\underbrace{kr\left(  b,a\right)  a_{n+r}+a_{n+r}kr\left(  b,a\right)
}_{=2rk\cdot\left(  b,a\right)  a_{n+r}}\nonumber\\
&  =\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)
+2rk\cdot\left(  b,a\right)  a_{n+r}. \label{pf.sugawara.b.3.sufficiently}%
\end{align}


Now, forget that we fixed $a$. The equality (\ref{pf.sugawara.b.1}) becomes%
\begin{align}
&  \left[  b_{r},L_{n}\right] \nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in
B}\underbrace{\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(
\left[  b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}%
+K\omega\left(  b_{r},a_{m}\right)  a_{n-m}+a_{m}K\omega\left(  b_{r}%
,a_{n-m}\right)  \right)  }_{\substack{=\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}\left(  \left[  b,a\right]  _{r+m}a_{n-m}+a_{m}\left[
b,a\right]  _{n+r-m}\right)  +2rk\cdot\left(  b,a\right)  a_{n+r}\\\text{for
sufficiently high }N\text{ (by (\ref{pf.sugawara.b.3.sufficiently}))}%
}}\nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left[
b,a\right]  _{r+m}a_{n-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)
+2rk\cdot\left(  b,a\right)  a_{n+r}\right) \nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[
b,a\right]  _{r+m}a_{n-m}+\sum\limits_{a\in B}a_{m}\left[  b,a\right]
_{n+r-m}\right)  +rk\sum\limits_{a\in B}\left(  b,a\right)  a_{n+r}.
\label{pf.sugawara.b.6}%
\end{align}
But since $\sum\limits_{a\in B}\left(  \left[  b,a\right]  \otimes
a+a\otimes\left[  b,a\right]  \right)  =0$ (by Lemma \ref{lem.sugawara.Kil3}
\textbf{(a)}), we have \newline$\sum\limits_{a\in B}\left(  \left[
b,a\right]  _{\ell}\otimes a_{s}+a_{\ell}\otimes\left[  b,a\right]
_{s}\right)  =0$ for any two integers $\ell$ and $s$. In particular, every
$m\in\mathbb{Z}$ satisfies $\sum\limits_{a\in B}\left(  \left[  b,a\right]
_{m}\otimes a_{n+r-m}+a_{m}\otimes\left[  b,a\right]  _{n+r-m}\right)  =0$.
Hence, every $m\in\mathbb{Z}$ satisfies $\sum\limits_{a\in B}\left(  \left[
b,a\right]  _{m}a_{n+r-m}+a_{m}\left[  b,a\right]  _{n+r-m}\right)  =0$, so
that $\sum\limits_{a\in B}\left[  b,a\right]  _{m}a_{n+r-m}+\sum\limits_{a\in
B}a_{m}\left[  b,a\right]  _{n+r-m}=0$ and thus $\sum\limits_{a\in B}%
a_{m}\left[  b,a\right]  _{n+r-m}=-\sum\limits_{a\in B}\left[  b,a\right]
_{m}a_{n+r-m}$. Hence, (\ref{pf.sugawara.b.6}) becomes%
\begin{align}
&  \left[  b_{r},L_{n}\right] \nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[
b,a\right]  _{r+m}a_{n-m}+\underbrace{\sum\limits_{a\in B}a_{m}\left[
b,a\right]  _{n+r-m}}_{=-\sum\limits_{a\in B}\left[  b,a\right]  _{m}%
a_{n+r-m}}\right)  +rk\sum\limits_{a\in B}\left(  b,a\right)  a_{n+r}%
\nonumber\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[
b,a\right]  _{r+m}a_{n-m}-\sum\limits_{a\in B}\left[  b,a\right]
_{m}a_{n+r-m}\right)  +rk\sum\limits_{a\in B}\left(  b,a\right)  a_{n+r}.
\label{pf.sugawara.b.9}%
\end{align}
We will now transform the limit in this equation: In fact,%
\begin{align*}
&  \lim\limits_{N\rightarrow\infty}\underbrace{\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[
b,a\right]  _{r+m}a_{n-m}-\sum\limits_{a\in B}\left[  b,a\right]
_{m}a_{n+r-m}\right)  }_{=\sum\limits_{a\in B}\left(  \sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left[  b,a\right]  _{r+m}a_{n-m}%
-\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left[  b,a\right]
_{m}a_{n+r-m}\right)  }\\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(
\underbrace{\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left[
b,a\right]  _{r+m}a_{n-m}}_{\substack{=\sum\limits_{\left\vert m-r-\dfrac
{n}{2}\right\vert \leq N}\left[  b,a\right]  _{m}a_{n+r-m}\\\text{(here, we
substituted }m-r\text{ for }m\text{ in the sum)}}}-\sum\limits_{\left\vert
m-\dfrac{n}{2}\right\vert \leq N}\left[  b,a\right]  _{m}a_{n+r-m}\right) \\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\underbrace{\left(
\sum\limits_{\left\vert m-r-\dfrac{n}{2}\right\vert \leq N}\left[  b,a\right]
_{m}a_{n+r-m}-\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left[
b,a\right]  _{m}a_{n+r-m}\right)  }_{\substack{=-\sum\limits_{\dfrac{n}%
{2}-N\leq m<\dfrac{n}{2}+r-N}\left[  b,a\right]  _{m}a_{n+r-m}+\sum
\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left[  b,a\right]
_{m}a_{n+r-m}\\\text{(by Lemma \ref{lem.telescope}, applied to }u_{m}=\left[
b,a\right]  _{m}a_{n+r-m}\text{,}\\\alpha=\dfrac{n}{2}\text{ and }\beta
=\dfrac{n}{2}+r\text{)}}}\\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(  -\sum
\limits_{\dfrac{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\left[  b,a\right]
_{m}a_{n+r-m}+\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left[
b,a\right]  _{m}a_{n+r-m}\right)  .
\end{align*}
Since every $a\in B$ satisfies $\sum\limits_{\dfrac{n}{2}-N\leq m<\dfrac{n}%
{2}+r-N}\left[  b,a\right]  _{m}a_{n+r-m}\rightarrow0$ for $N\rightarrow
\infty$\ \ \ \ \footnote{\textit{Proof.} Let $a\in B$.
\par
Let $w\in M$. From the proof of Theorem \ref{thm.sugawara} \textbf{(a)},
recall the fact that for every $w\in M$, there exists some $\mathbf{M}%
\in\mathbb{N}$ such that every integer $\mathbf{m}\geq\mathbf{M}$ and every
$a\in\mathfrak{g}$ satisfy $at^{\mathbf{m}}\cdot w=0$. Applied to $w=a$, this
yields that there exists some $\mathbf{M}\in\mathbb{N}$ such that%
\begin{equation}
\text{every integer }\mathbf{m}\geq\mathbf{M}\text{ satisfies }at^{\mathbf{m}%
}\cdot w=0. \label{pf.sugawara.foot.1}%
\end{equation}
Consider this $\mathbf{M}$.
\par
Let $N$ be an integer such that $N\geq\mathbf{M}-\dfrac{n}{2}-r$. Then,
$\dfrac{n}{2}+r+N\geq\mathbf{M}$. Now, every integer $m$ such that $\dfrac
{n}{2}-N\leq m<\dfrac{n}{2}+r-N$ must satisfy $n+r-\underbrace{m}_{\geq
\dfrac{n}{2}-N}\leq n+r-\left(  \dfrac{n}{2}-N\right)  =\dfrac{n}{2}%
+r+N\geq\mathbf{M}$ and thus $at^{n+r-m}\cdot w=0$ (by
(\ref{pf.sugawara.foot.1}), applied to $\mathbf{m}=n+r-m$), thus $\left[
b,a\right]  _{m}\underbrace{a_{n+r-m}}_{=at^{n+r-m}}w=\left[  b,a\right]
_{m}\cdot\underbrace{at^{n+r-m}\cdot w}_{=0}=0$. Hence, $\sum\limits_{\dfrac
{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\underbrace{\left[  b,a\right]  _{m}%
a_{n+r-m}w}_{=0}=\sum\limits_{\dfrac{n}{2}-N\leq m<\dfrac{n}{2}+r-N}0=0$.
\par
Now forget that we fixed $N$. We thus have showed that $\sum\limits_{\dfrac
{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\left[  b,a\right]  _{m}a_{n+r-m}w=0$ for
every integer $N$ such that $N\geq\mathbf{M}-\dfrac{n}{2}-r$. Hence,
$\sum\limits_{\dfrac{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\left[  b,a\right]
_{m}a_{n+r-m}w=0$ for every sufficiently large $N$. Thus, $\sum\limits_{\dfrac
{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\left[  b,a\right]  _{m}a_{n+r-m}%
w\rightarrow0$ for $N\rightarrow\infty$. Since this holds for every $w\in M$,
we thus obtain $\sum\limits_{\dfrac{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\left[
b,a\right]  _{m}a_{n+r-m}\rightarrow0$ for $N\rightarrow\infty$, qed.}, this
becomes%
\begin{align*}
&  \lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[  b,a\right]
_{r+m}a_{n-m}-\sum\limits_{a\in B}\left[  b,a\right]  _{m}a_{n+r-m}\right) \\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(
-\underbrace{\sum\limits_{\dfrac{n}{2}-N\leq m<\dfrac{n}{2}+r-N}\left[
b,a\right]  _{m}a_{n+r-m}}_{\rightarrow0\text{ for }N\rightarrow\infty}%
+\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left[  b,a\right]
_{m}a_{n+r-m}\right) \\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\sum\limits_{\dfrac
{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\underbrace{\left[  b,a\right]  _{m}a_{n+r-m}%
}_{=a_{n+r-m}\left[  b,a\right]  _{m}+\left[  \left[  b,a\right]
_{m},a_{n+r-m}\right]  }\\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\sum\limits_{\dfrac
{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left(  a_{n+r-m}\left[  b,a\right]
_{m}+\left[  \left[  b,a\right]  _{m},a_{n+r-m}\right]  \right) \\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(  \sum
\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}a_{n+r-m}\left[  b,a\right]
_{m}+\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left[  \left[
b,a\right]  _{m},a_{n+r-m}\right]  \right)  .
\end{align*}
Since every $a\in B$ satisfies $\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}%
{2}+r+N}a_{n+r-m}\left[  b,a\right]  _{m}\rightarrow0$ for $N\rightarrow
\infty$\ \ \ \ \footnote{\textit{Proof.} Let $w\in M$. From the proof of
Theorem \ref{thm.sugawara} \textbf{(a)}, recall the fact that for every $w\in
M$, there exists some $\mathbf{M}\in\mathbb{N}$ such that every integer
$\mathbf{m}\geq\mathbf{M}$ and every $a\in\mathfrak{g}$ satisfy
$at^{\mathbf{m}}\cdot w=0$. Consider this $\mathbf{M}$. Thus,%
\begin{equation}
\text{every integer }\mathbf{m}\geq\mathbf{M}\text{ and every }a\in
\mathfrak{g}\text{ satisfy }at^{\mathbf{m}}\cdot w=0.
\label{pf.sugawara.foot.2a}%
\end{equation}
\par
Let $a\in B$.
\par
Let $N$ be an integer such that $N\geq\mathbf{M}-\dfrac{n}{2}$. Then,
$\dfrac{n}{2}+N\geq\mathbf{M}$. Now, every integer $m$ such that $\dfrac{n}%
{2}+N<m\leq\dfrac{n}{2}+r+N$ must satisfy $m>\dfrac{n}{2}+N\geq\mathbf{M}$ and
thus $\left[  b,a\right]  t^{m}\cdot w=0$ (by (\ref{pf.sugawara.foot.2a}),
applied to $m$ and $\left[  b,a\right]  $ instead of $\mathbf{m}$ and $a$),
thus $a_{n+r-m}\underbrace{\left[  b,a\right]  _{m}}_{=\left[  b,a\right]
t^{m}}w=a_{n+r-m}\underbrace{\left[  b,a\right]  t^{m}\cdot w}_{=0}=0$. Hence,
$\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\underbrace{a_{n+r-m}%
\left[  b,a\right]  _{m}w}_{=0}=\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}%
{2}+r+N}0=0$.
\par
Now forget that we fixed $N$. We thus have showed that $\sum\limits_{\dfrac
{n}{2}+N<m\leq\dfrac{n}{2}+r+N}a_{n+r-m}\left[  b,a\right]  _{m}w=0$ for every
integer $N$ such that $N\geq\mathbf{M}-\dfrac{n}{2}$. Hence, $\sum
\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}a_{n+r-m}\left[  b,a\right]
_{m}w=0$ for every sufficiently large $N$. Thus, $\sum\limits_{\dfrac{n}%
{2}+N<m\leq\dfrac{n}{2}+r+N}a_{n+r-m}\left[  b,a\right]  _{m}w\rightarrow0$
for $N\rightarrow\infty$. Since this holds for every $w\in M$, we thus obtain
$\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}a_{n+r-m}\left[
b,a\right]  _{m}\rightarrow0$ for $N\rightarrow\infty$, qed.}, this becomes%
\begin{align*}
&  \lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[  b,a\right]
_{r+m}a_{n-m}-\sum\limits_{a\in B}\left[  b,a\right]  _{m}a_{n+r-m}\right) \\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(
\underbrace{\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}a_{n+r-m}\left[
b,a\right]  _{m}}_{\rightarrow0\text{ for }N\rightarrow\infty}+\sum
\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left[  \left[  b,a\right]
_{m},a_{n+r-m}\right]  \right) \\
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\sum\limits_{\dfrac
{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\underbrace{\left[  \left[  b,a\right]
_{m},a_{n+r-m}\right]  }_{\substack{=\left[  \left[  b,a\right]  ,a\right]
_{n+r}+K\omega\left(  \left[  b,a\right]  _{m},a_{n+r-m}\right)  \\\text{(by
(\ref{pf.sugawara.lie}), applied to }\left[  b,a\right]  \text{, }a\text{,
}m\text{ and }n+r-m\\\text{instead of }x\text{, }y\text{, }n\text{, }%
m\text{)}}}
\end{align*}%
\begin{align*}
&  =\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\sum\limits_{\dfrac
{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left(  \left[  \left[  b,a\right]  ,a\right]
_{n+r}+\underbrace{K}_{\substack{=k\\\text{(since }K\text{ acts on }M\text{ as
}k\cdot\operatorname*{id}\text{)}}}\omega\left(  \left[  b,a\right]
_{m},a_{n+r-m}\right)  \right) \\
&  =\lim\limits_{N\rightarrow\infty}\underbrace{\sum\limits_{a\in B}%
\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\left(  \left[  \left[
b,a\right]  ,a\right]  _{n+r}+k\omega\left(  \left[  b,a\right]
_{m},a_{n+r-m}\right)  \right)  }_{=\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac
{n}{2}+r+N}\sum\limits_{a\in B}\left[  \left[  b,a\right]  ,a\right]
_{n+r}+k\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\sum\limits_{a\in
B}\omega\left(  \left[  b,a\right]  _{m},a_{n+r-m}\right)  }\\
&  =\lim\limits_{N\rightarrow\infty}\left(  \underbrace{\sum\limits_{\dfrac
{n}{2}+N<m\leq\dfrac{n}{2}+r+N}\sum\limits_{a\in B}\left[  \left[  b,a\right]
,a\right]  _{n+r}}_{=r\sum\limits_{a\in B}\left[  \left[  b,a\right]
,a\right]  _{n+r}}+k\sum\limits_{\dfrac{n}{2}+N<m\leq\dfrac{n}{2}+r+N}%
\sum\limits_{a\in B}\omega\left(  \left[  b,a\right]  _{m},a_{n+r-m}\right)
\right) \\
&  =\lim\limits_{N\rightarrow\infty}\left(  r\sum\limits_{a\in B}\left[
\left[  b,a\right]  ,a\right]  _{n+r}+k\sum\limits_{\dfrac{n}{2}+N<m\leq
\dfrac{n}{2}+r+N}\sum\limits_{a\in B}\omega\left(  \left[  b,a\right]
_{m},a_{n+r-m}\right)  \right)  .
\end{align*}
Since every integer $m$ and every $a\in B$ satisfy $\omega\left(  \left[
b,a\right]  _{m},a_{n+r-m}\right)  =0$\ \ \ \ \footnote{\textit{Proof.} Let
$m$ be an integer, and let $a\in B$. From Lemma \ref{lem.sugawara.Kil3}
\textbf{(c)}, we have $\left(  \left[  b,a\right]  ,a\right)  =0$, so that
$m\left(  \left[  b,a\right]  ,a\right)  =0$. But by the definition of
$\omega$, we have
\begin{align*}
\omega\left(  \left[  b,a\right]  _{m},a_{n+r-m}\right)   &  =\left\{
\begin{array}
[c]{c}%
m\left(  \left[  b,a\right]  ,a\right)  ,\text{ if }m=-\left(  n+r-m\right)
;\\
0,\text{ if }m\neq-\left(  n+r-m\right)
\end{array}
\right.  =\left\{
\begin{array}
[c]{c}%
0,\text{ if }m=-\left(  n+r-m\right)  ;\\
0,\text{ if }m\neq-\left(  n+r-m\right)
\end{array}
\right. \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }m\left(  \left[  b,a\right]
,a\right)  =0\right) \\
&  =0,
\end{align*}
qed.}, this simplifies to%
\begin{align*}
&  \lim\limits_{N\rightarrow\infty}\sum\limits_{\left\vert m-\dfrac{n}%
{2}\right\vert \leq N}\left(  \sum\limits_{a\in B}\left[  b,a\right]
_{r+m}a_{n-m}-\sum\limits_{a\in B}\left[  b,a\right]  _{m}a_{n+r-m}\right) \\
&  =\lim\limits_{N\rightarrow\infty}\left(  r\sum\limits_{a\in B}\left[
\left[  b,a\right]  ,a\right]  _{n+r}+k\sum\limits_{\dfrac{n}{2}+N<m\leq
\dfrac{n}{2}+r+N}\sum\limits_{a\in B}\underbrace{\omega\left(  \left[
b,a\right]  _{m},a_{n+r-m}\right)  }_{=0}\right) \\
&  =\lim\limits_{N\rightarrow\infty}r\sum\limits_{a\in B}\left[  \left[
b,a\right]  ,a\right]  _{n+r}=r\sum\limits_{a\in B}\left[  \left[  b,a\right]
,a\right]  _{n+r}.
\end{align*}
Thus, (\ref{pf.sugawara.b.9}) becomes%
\begin{align*}
&  \left[  b_{r},L_{n}\right] \\
&  =\dfrac{1}{2}\underbrace{\lim\limits_{N\rightarrow\infty}\sum
\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \sum\limits_{a\in
B}\left[  b,a\right]  _{r+m}a_{n-m}-\sum\limits_{a\in B}\left[  b,a\right]
_{m}a_{n+r-m}\right)  }_{=r\sum\limits_{a\in B}\left[  \left[  b,a\right]
,a\right]  _{n+r}}+rk\sum\limits_{a\in B}\left(  b,a\right)  a_{n+r}\\
&  =\dfrac{1}{2}r\sum\limits_{a\in B}\underbrace{\left[  \left[  b,a\right]
,a\right]  _{n+r}}_{=\left[  \left[  b,a\right]  ,a\right]  t^{n+r}}%
+rk\sum\limits_{a\in B}\left(  b,a\right)  \underbrace{a_{n+r}}_{=at^{n+r}}\\
&  =rt^{n+r}\underbrace{\left(  \dfrac{1}{2}\sum\limits_{a\in B}\left[
\left[  b,a\right]  ,a\right]  +k\sum\limits_{a\in B}\left(  b,a\right)
a\right)  }_{\substack{=b\\\text{(by Lemma \ref{lem.sugawara.Kil3}
\textbf{(b)})}}}=r\underbrace{t^{n+r}b}_{=b_{n+r}}=rb_{n+r}.
\end{align*}
This proves (\ref{pf.sugawara.step1}) in the case when $r\geq0$. The case when
$r\leq0$ is handled analogously (except that this time we have to apply Lemma
\ref{lem.telescope} to $u_{m}=\left[  b,a\right]  _{m}a_{n+r-m}$,
$\alpha=\dfrac{n}{2}+r$ and $\beta=\dfrac{n}{2}$ instead of applying it to
$u_{m}=\left[  b,a\right]  _{m}a_{n+r-m}$, $\alpha=\dfrac{n}{2}$ and
$\beta=\dfrac{n}{2}+r$). Altogether, the proof of (\ref{pf.sugawara.step1}) is
thus complete.

\textit{2nd step:} It is clear that%
\begin{equation}
\left[  L_{n},a_{m}\right]  =-ma_{n+m}\ \ \ \ \ \ \ \ \ \ \text{for any }%
a\in\mathfrak{g}\text{ and any integers }n\text{ and }m
\label{pf.sugawara.step2.am}%
\end{equation}
(since (\ref{pf.sugawara.step1}) (applied to $r=m$ and $a=b$) yields $\left[
a_{m},L_{n}\right]  =ma_{n+m}$, so that $\left[  L_{n},a_{m}\right]
=-\underbrace{\left[  a_{m},L_{n}\right]  }_{=ma_{n+m}}=-ma_{n+m}$). Also, it
is clear that%
\begin{equation}
\left[  L_{n},K\right]  =0\ \ \ \ \ \ \ \ \ \ \text{for any integer }n
\label{pf.sugawara.step2.K}%
\end{equation}
(since $K$ acts as a scalar on $M$).

\textit{3rd step:} Now, we will prove that%
\begin{equation}
\left[  L_{n},L_{m}\right]  =\left(  n-m\right)  L_{n+m}+\dfrac{n^{3}-n}%
{12}\delta_{n,-m}k\cdot\sum\limits_{a\in B}\left(  a,a\right)
\ \ \ \ \ \ \ \ \ \ \text{for any integers }n\text{ and }m
\label{pf.sugawara.step3}%
\end{equation}
(as an identity in $\operatorname*{End}M$).

\textit{Proof of (\ref{pf.sugawara.step3}):} We know that every $n\in
\mathbb{Z}$ satisfies%
\begin{equation}
L_{n}=\dfrac{1}{2}\sum\limits_{a\in B}\sum\limits_{m\in\mathbb{Z}}\left.
:a_{m}a_{n-m}:\right.  =\dfrac{1}{2}\sum\limits_{a\in B}\sum\limits_{m\in
\mathbb{Z}}\left.  :a_{-m}a_{n+m}:\right.  \label{pf.sugawara.step3.pf.1}%
\end{equation}
(here, we substituted $-m$ for $m$ in the second sum).

Repeat the Second Proof of Proposition \ref{prop.fockvir.answer2}, with the
following changes:

\begin{itemize}
\item Reprove Lemma \ref{lem.fockvir.welldef} with $F_{\mu}$ replaced by $M$
and with an additional ``Let $a\in\mathfrak{g}$ be arbitrary.'' condition.
(The proof will be slightly different from the proof of the original Lemma
\ref{lem.fockvir.welldef} because $M$ is no longer a polynomial ring, but this
time we can use the admissibility of $M$ instead.)

\item Replace every $F_{\mu}$ by $M$.

\item Instead of the equality (\ref{def.fockvir.def}), use the equality
(\ref{pf.sugawara.step3.pf.1}) (which differs from the equality
(\ref{def.fockvir.def}) only in the presence of a $\sum\limits_{a\in B}$
sign). As a consequence, $\sum\limits_{a\in B}$ signs need to be dragged along
through the computations (but they don't complicate the calculation).

\item Instead of using Remark \ref{rmk.fockvir.normal.mn}, use Remark
\ref{rmk.sugawara.normal.mn}.

\item Instead of using Remark \ref{rmk.fockvir.normal.comm} \textbf{(a)}, use
Remark \ref{rmk.sugawara.normal.comm}.

\item Instead of using Remark \ref{rmk.fockvir.normal.K}, use Remark
\ref{rmk.sugawara.normal.K}.

\item Instead of using Proposition \ref{prop.fockvir.answer1}, use
(\ref{pf.sugawara.step2.am}).

\item Instead of the equality $a_{m-\ell}a_{n+\ell}=\left.  :a_{m-\ell
}a_{n+\ell}:\right.  -\left(  n+\ell\right)  \left[  \ell<m\right]
\delta_{m,-n}\operatorname*{id}$, check the equality $a_{m-\ell}a_{n+\ell
}=\left.  :a_{m-\ell}a_{n+\ell}:\right.  -\left(  n+\ell\right)  \left[
\ell<m\right]  \delta_{m,-n}\left(  a,a\right)  k$ for every $a\in B$.

\item Instead of the equality $a_{-\ell}a_{m+n+\ell}=\left.  :a_{-\ell
}a_{m+n+\ell}:\right.  -\ell\left[  \ell<0\right]  \delta_{m,-n}%
\operatorname*{id}$, check the equality $a_{-\ell}a_{m+n+\ell}=\left.
:a_{-\ell}a_{m+n+\ell}:\right.  -\ell\left[  \ell<0\right]  \delta
_{m,-n}\left(  a,a\right)  k$ for every $a\in B$.
\end{itemize}

Once these changes (most of which are automatic) are made, we have obtained a
proof of (\ref{pf.sugawara.step3}).

\textit{4th step:} From (\ref{pf.sugawara.step3}), it is clear that the
endomorphisms $L_{n}$ for $n\in\mathbb{Z}$ give rise to a $\operatorname*{Vir}%
$-representation on $M$ with central charge%
\[
c=k\cdot\sum\limits_{a\in B}\left(  a,a\right)  .
\]
This proves Theorem \ref{thm.sugawara} \textbf{(c)}.

\textbf{(d)} From (\ref{pf.sugawara.step2.am}) and (\ref{pf.sugawara.step2.K}%
), it follows that the formulas for $L_{n}$ and $c$ we have given in Theorem
\ref{thm.sugawara} extend the action of $\widehat{\mathfrak{g}}$ on $M$ to an
action of $\operatorname*{Vir}\ltimes\widehat{\mathfrak{g}}$. Theorem
\ref{thm.sugawara} \textbf{(d)} thus is proven.

\begin{noncompile}
Here is the old proof of (\ref{pf.sugawara.step3}). Note that I don't
understand it and I am pretty sure it is partly wrong.

Let $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$. Now we must prove the Virasoro
relations $\left[  L_{n},L_{m}\right]  =\left(  n-m\right)  L_{n+m}+\left(
\text{something}\right)  $.

Let $R_{n,m}=\left[  L_{n},L_{m}\right]  -\left(  n-m\right)  L_{n+m}$. Since
$\left[  L_{n},a_{r}\right]  =-ra_{n+r}$, it is clear that $R_{n,m}$ commutes
with $a_{r}$ for all $a$ and $r$. In particular, this yields that $R_{n,m}$
commutes with $L_{0}$ (since $L_{0}$ is made out of $a_{r}$'s). But $\left[
L_{0},R_{n,m}\right]  =\left(  n+m\right)  R_{n,m}$ (since $\left[
a_{r},L_{0}\right]  =ra_{r}$ and thus $\left[  L_{n},L_{0}\right]  =nL_{n}$).
Hence, $R_{n,m}=0$ whenever $n+m\neq0$.

The only case that remains to be checked is $n+m=0$. So we need to compute
$\left[  L_{n},L_{-n}\right]  -2nL_{0}$.

We write%
\begin{align*}
&  \left[  L_{n},L_{-n}\right]  -2nL_{0}=R_{n,-n}\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}%
\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(  \left(
-m\right)  a_{n+m}a_{-n-m}+\left(  n+m\right)  a_{m}a_{-m}\right)  -2nL_{0}\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(
\sum\limits_{\left\vert m-\dfrac{3n}{2}\right\vert \leq N}\left(  -m+n\right)
a_{m}a_{-m}+\sum\limits_{\left\vert m-\dfrac{n}{2}\right\vert \leq N}\left(
n+m\right)  a_{m}a_{-m}\right)  -2nL_{0}\\
&  =\dfrac{1}{2}\lim\limits_{N\rightarrow\infty}\sum\limits_{a\in B}\left(
\underbrace{\sum\limits_{\dfrac{n}{2}-N\leq m<\dfrac{3n}{2}-N}\left(
m+n\right)  a_{m}a_{-m}}_{\rightarrow0}+\sum\limits_{\dfrac{n}{2}+N\leq
m<\dfrac{3n}{2}+N}\left(  -m+n\right)  a_{m}a_{-m}+\sum\limits_{1\leq
m\leq\dfrac{n}{2}+N}2nmk\left(  a,a\right)  \right) \\
&  =\operatorname*{constant}.
\end{align*}
We calculate this constant: It is enough to calculate it for $n=1$ and for
$n=2$. For $n=1$, it is $\dfrac{1}{2}\left(  -N\left(  N+1\right)  +N\left(
N+1\right)  \right)  \cdot k\sum\limits_{a\in B}\left(  a,a\right)  =0$. For
$n=2$, it is
\[
\dfrac{1}{2}\underbrace{\left(  -N\left(  N+2\right)  -\left(  N+1\right)
\left(  N+3\right)  +2\left(  N+2\right)  \left(  N+1\right)  \right)  }%
_{=1}\cdot k\sum\limits_{a\in B}\left(  a,a\right)  =\dfrac{1}{2}\cdot
k\sum\limits_{a\in B}\left(  a,a\right)  .
\]
Thus, $R_{1,-1}=0$ and $R_{2,-2}=\dfrac{1}{2}\cdot k\sum\limits_{a\in
B}\left(  a,a\right)  $. As a consequence, $R_{n,-n}=\dfrac{n^{3}-n}{12}%
k\sum\limits_{a\in B}\left(  a,a\right)  $. (We could have also obtained this
by direct computation.) This proves that, with $c=k\sum\limits_{a\in B}\left(
a,a\right)  $, we get a representation of $\operatorname*{Vir}$.
\end{noncompile}

\textbf{(e)} Theorem \ref{thm.sugawara} \textbf{(e)} follows immediately from
(\ref{pf.sugawara.step2.am}).

Thus, the proof of Theorem \ref{thm.sugawara} is complete.

We are now going to specialize these results to the case of $\mathfrak{g}$
being simple. In this case, the so-called \textit{dual Coxeter number} of the
simple Lie algebra $\mathfrak{g}$ comes into play. Let us explain what this is:

\begin{definition}
\label{def.dualcox}Let $\mathfrak{g}$ be a simple finite-dimensional Lie
algebra. Let $\theta$ be the maximal root of $\mathfrak{g}$. (In other words,
let $\theta$ be the highest weight of the adjoint representation of
$\mathfrak{g}$.) Let $\rho=\dfrac{1}{2}\sum\limits_{\substack{\alpha\text{
root of }\mathfrak{g}\text{;}\\\alpha>0}}\alpha$ be the half-sum of all
positive roots. The \textit{dual Coxeter number} $h^{\vee}$ of $\mathfrak{g}$
is defined by $h^{\vee}=1+\left(  \theta,\rho\right)  $. It is easy to show
that $h^{\vee}$ is a positive integer.
\end{definition}

\begin{definition}
\label{def.standform}Let $\mathfrak{g}$ be a simple finite-dimensional Lie
algebra. The \textit{standard form} on $\mathfrak{g}$ will mean the scalar
multiple of the Killing form under which $\left(  \alpha,\alpha\right)  $
(under the inverse form on $\mathfrak{g}^{\ast}$) equals $2$ for long roots
$\alpha$. (We do not care to define what a long root is, but it is enough to
say that the maximal root $\theta$ is a long root, and this is clearly enough
to define the standard form.)

(The \textit{inverse form} of a nondegenerate bilinear form $\left(
\cdot,\cdot\right)  $ on $\mathfrak{g}$ means the bilinear form on
$\mathfrak{g}^{\ast}=\mathfrak{h}^{\ast}\oplus\mathfrak{n}_{+}^{\ast}%
\oplus\mathfrak{n}_{-}^{\ast}$ obtained by dualizing the bilinear form
$\left(  \cdot,\cdot\right)  $ on $\mathfrak{g}=\mathfrak{h}\oplus
\mathfrak{n}_{+}\oplus\mathfrak{n}_{-}$ using itself.)

We are going to denote the standard form by $\left(  \cdot,\cdot\right)  $.
\end{definition}

\begin{lemma}
\label{lem.dualcox}Let $B$ be an orthonormal basis of $\mathfrak{g}$ with
respect to the standard form. Let $C=\sum\limits_{a\in B}a^{2}\in U\left(
\mathfrak{g}\right)  $. This element $C$ is known to be central in $U\left(
\mathfrak{g}\right)  $ (this is easily checked), and is called the
\textit{quadratic Casimir}.

Then:

\textbf{(1)} For every $\lambda\in\mathfrak{h}^{\ast}$, the element $C\in
U\left(  \mathfrak{g}\right)  $ acts on $L_{\lambda}$ by $\left(
\lambda,\lambda+2\rho\right)  \cdot\operatorname*{id}$. (Here, $L_{\lambda}$
means $L_{\lambda}^{+}$, but actually can be replaced by any highest-weight
module with highest weight $\lambda$.)

\textbf{(2)} The element $C\in U\left(  \mathfrak{g}\right)  $ acts on the
adjoint representation $\mathfrak{g}$ by $2h^{\vee}\cdot\operatorname*{id}$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.dualcox}.} If $\left(  b_{i}\right)  _{i\in
I}$ is any basis of $\mathfrak{g}$, and $\left(  b_{i}^{\ast}\right)  _{i\in
I}$ is the dual basis of $\mathfrak{g}$ with respect to the standard form
$\left(  \cdot,\cdot\right)  $, then%
\begin{equation}
C=\sum\limits_{i\in I}b_{i}b_{i}^{\ast}. \label{pf.dualcox.Csum}%
\end{equation}
\footnote{This is a well-known property of the quadratic Casimir.}

\textbf{(1)} Let $\lambda\in\mathfrak{h}^{\ast}$.

Let us refine the triangular decomposition $\mathfrak{g}=\mathfrak{h}%
\oplus\mathfrak{n}_{+}\oplus\mathfrak{n}_{-}$ to the weight space
decomposition $\mathfrak{g}=\mathfrak{h}\oplus\left(  \bigoplus\limits_{\alpha
>0}\mathfrak{g}_{\alpha}\right)  \oplus\left(  \bigoplus\limits_{\alpha
<0}\mathfrak{g}_{\alpha}\right)  $, where $\mathfrak{g}_{\alpha}%
=\mathbb{C}e_{\alpha}$ for roots $\alpha>0$, and $\mathfrak{g}_{-\alpha
}=\mathbb{C}f_{\alpha}$ for roots $\alpha>0$. (This is standard theory of
simple Lie algebras.) Normalize the $f_{\alpha}$ in such a way that $\left(
e_{\alpha},f_{\alpha}\right)  =1$. As usual, denote $h_{\alpha}=\left[
e_{\alpha},f_{\alpha}\right]  $ for every root $\alpha>0$.

Fix an orthonormal basis $\left(  x_{i}\right)  _{i\in\left\{
1,2,...,r\right\}  }$ of $\mathfrak{h}$. Clearly, $\left(  x_{i}\right)
_{i\in\left\{  1,2,...,r\right\}  }\cup\left(  e_{\alpha}\right)  _{\alpha
>0}\cup\left(  f_{\alpha}\right)  _{\alpha>0}$ (where the index $\alpha$ runs
over positive roots only) is a basis of $\mathfrak{g}$. Since%
\begin{align*}
\left(  e_{\alpha},x_{i}\right)   &  =\left(  f_{\alpha},x_{i}\right)
=0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{  1,2,...,r\right\}  \text{
and roots }\alpha>0;\\
\left(  e_{\alpha},f_{\beta}\right)   &  =0\ \ \ \ \ \ \ \ \ \ \text{for any
two distinct roots }\alpha>0\text{ and }\beta>0;\\
\left(  e_{\alpha},e_{\gamma}\right)   &  =\left(  f_{\alpha},f_{\gamma
}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for any roots }\alpha>0\text{ and
}\gamma>0;\\
\left(  x_{i},x_{j}\right)   &  =\delta_{i,j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i\in\left\{  1,2,...,r\right\}  \text{ and }j\in\left\{  1,2,...,r\right\}
;\\
\left(  e_{\alpha},f_{\alpha}\right)   &  =\left(  f_{\alpha},e_{\alpha
}\right)  =1\ \ \ \ \ \ \ \ \ \ \text{for any root }\alpha>0\text{,}%
\end{align*}
we see that $\left(  x_{i}\right)  _{i\in\left\{  1,2,...,r\right\}  }%
\cup\left(  f_{\alpha}\right)  _{\alpha>0}\cup\left(  e_{\alpha}\right)
_{\alpha>0}$ is the dual basis to this basis $\left(  x_{i}\right)
_{i\in\left\{  1,2,...,r\right\}  }\cup\left(  e_{\alpha}\right)  _{\alpha
>0}\cup\left(  f_{\alpha}\right)  _{\alpha>0}$ with respect to the standard
form $\left(  \cdot,\cdot\right)  $. Thus, (\ref{pf.dualcox.Csum}) yields%
\[
C=\sum\limits_{i=1}^{r}x_{i}^{2}+\sum\limits_{\alpha>0}\left(  f_{\alpha
}e_{\alpha}+e_{\alpha}f_{\alpha}\right)  ,
\]
so that (denoting $v_{\lambda}^{+}$ by $v_{\lambda}$) we have%
\begin{align*}
Cv_{\lambda}  &  =\sum\limits_{i=1}^{r}\underbrace{x_{i}^{2}v_{\lambda}%
}_{=\lambda\left(  x_{i}\right)  ^{2}v_{\lambda}}+\sum\limits_{\alpha
>0}\left(  f_{\alpha}e_{\alpha}+e_{\alpha}f_{\alpha}\right)  v_{\lambda
}=\underbrace{\sum\limits_{i=1}^{r}\lambda\left(  x_{i}\right)  ^{2}%
}_{=\left(  \lambda,\lambda\right)  }v_{\lambda}+\sum\limits_{\alpha>0}\left(
f_{\alpha}\underbrace{e_{\alpha}v_{\lambda}}_{=0}+\underbrace{e_{\alpha
}f_{\alpha}}_{=f_{\alpha}e_{\alpha}+\left[  e_{\alpha},f_{\alpha}\right]
}v_{\lambda}\right) \\
&  =\left(  \lambda,\lambda\right)  v_{\lambda}+\sum\limits_{\alpha>0}\left(
f_{\alpha}e_{\alpha}+\left[  e_{\alpha},f_{\alpha}\right]  \right)
v_{\lambda}\\
&  =\left(  \lambda,\lambda\right)  v_{\lambda}+\sum\limits_{\alpha
>0}f_{\alpha}\underbrace{e_{\alpha}v_{\lambda}}_{=0}+\sum\limits_{\alpha
>0}\underbrace{\left[  e_{\alpha},f_{\alpha}\right]  }_{=h_{\alpha}}%
v_{\lambda}\\
&  =\left(  \lambda,\lambda\right)  v_{\lambda}+\sum\limits_{\alpha
>0}\underbrace{h_{\alpha}v_{\lambda}}_{=\lambda\left(  h_{\alpha}\right)
v_{\lambda}}=\left(  \lambda,\lambda\right)  v_{\lambda}+\sum\limits_{\alpha
>0}\underbrace{\lambda\left(  h_{\alpha}\right)  }_{=\left(  \lambda
,\alpha\right)  }v_{\lambda}\\
&  =\left(  \lambda,\lambda\right)  v_{\lambda}+\sum\limits_{\alpha>0}\left(
\lambda,\alpha\right)  v_{\lambda}=\underbrace{\left(  \left(  \lambda
,\lambda\right)  +\sum\limits_{\alpha>0}\left(  \lambda,\alpha\right)
\right)  }_{\substack{=\left(  \lambda,\lambda+\sum\limits_{\alpha>0}%
\alpha\right)  =\left(  \lambda,\lambda+2\rho\right)  \\\text{(since }%
\sum\limits_{\alpha>0}\alpha=2\rho\text{)}}}v_{\lambda}=\left(  \lambda
,\lambda+2\rho\right)  v_{\lambda}.
\end{align*}
Thus, every $a\in U\left(  \mathfrak{g}\right)  $ satisfies
\begin{align*}
Cav_{\lambda}  &  =a\underbrace{Cv_{\lambda}}_{=\left(  \lambda,\lambda
+2\rho\right)  v_{\lambda}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }C\text{ is
central in }U\left(  \mathfrak{g}\right)  \right) \\
&  =\left(  \lambda,\lambda+2\rho\right)  av_{\lambda}.
\end{align*}
Hence, $C$ acts as $\left(  \lambda,\lambda+2\rho\right)  \cdot
\operatorname*{id}$ on $L_{\lambda}$ (because every element of $L_{\lambda}$
has the form $av_{\lambda}$ for some $a\in U\left(  \mathfrak{g}\right)  $).
This proves Lemma \ref{lem.dualcox} \textbf{(1)}.

\textbf{(2)} We have $\mathfrak{g}=L_{\theta}$, and thus Lemma
\ref{lem.dualcox} \textbf{(1)} yields%
\[
C\mid_{L_{\theta}}=\left(  \theta,\theta+2\rho\right)  =\underbrace{\left(
\theta,\theta\right)  }_{=2}+2\left(  \theta,\rho\right)  =2+2\left(
\theta,\rho\right)  =2h^{\vee}.
\]
This proves Lemma \ref{lem.dualcox} \textbf{(2)}.

Here is a little table of dual Coxeter numbers, depending on the root system
type of $\mathfrak{g}$:

For $A_{n-1}$, we have $h^{\vee}=n$.

For $B_{n}$, we have $h^{\vee}=2n-1$.

For $C_{n}$, we have $h^{\vee}=n+1$.

For $D_{n}$, we have $h^{\vee}=2n-2$.

For $E_{6}$, we have $h^{\vee}=12$.

For $E_{7}$, we have $h^{\vee}=18$.

For $E_{8}$, we have $h^{\vee}=30$.

For $F_{4}$, we have $h^{\vee}=9$.

For $G_{2}$, we have $h^{\vee}=4$.

Every Lie theorist is supposed to remember these by heart.

\begin{lemma}
\label{lem.dualcox.kil}Let $\mathfrak{g}$ be a simple finite-dimensional Lie
algebra. Then,%
\[
\operatorname*{Kil}\left(  a,b\right)  =2h^{\vee}\cdot\left(  a,b\right)
\ \ \ \ \ \ \ \ \ \ \text{for any }a,b\in\mathfrak{g}.
\]

\end{lemma}

\textit{Proof of Lemma \ref{lem.dualcox.kil}.} Let $B$ be an orthonormal basis
of $\mathfrak{g}$ with respect to the standard form. Define the quadratic
Casimir $C=\sum\limits_{a\in B}a^{2}$ as in Lemma \ref{lem.dualcox}. Then,%
\[
\operatorname*{Tr}\nolimits_{\mathfrak{g}}\left(  C\right)  =\sum\limits_{a\in
B}\underbrace{\operatorname*{Tr}\nolimits_{\mathfrak{g}}\left(  a^{2}\right)
}_{=\operatorname*{Tr}\left(  \left(  \operatorname*{ad}a\right)  \circ\left(
\operatorname*{ad}a\right)  \right)  =\operatorname*{Kil}\left(  a,a\right)
}=\sum\limits_{a\in B}\operatorname*{Kil}\left(  a,a\right)  .
\]
Comparing this with%
\begin{align*}
\operatorname*{Tr}\nolimits_{\mathfrak{g}}\left(  C\right)   &  =2h^{\vee
}\underbrace{\operatorname*{Tr}\nolimits_{\mathfrak{g}}\left(
\operatorname*{id}\right)  }_{=\dim\mathfrak{g}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }C\mid_{\mathfrak{g}}=2h^{\vee}\operatorname*{id}\text{ by Lemma
\ref{lem.dualcox} \textbf{(2)}}\right) \\
&  =2h^{\vee}\underbrace{\dim\mathfrak{g}}_{\substack{=\left\vert B\right\vert
=\sum\limits_{a\in B}1=\sum\limits_{a\in B}\left(  a,a\right)  \\\text{(since
every }a\in B\text{ satisfies }\left(  a,a\right)  =1\text{)}}}=2h^{\vee}%
\sum\limits_{a\in B}\left(  a,a\right)  ,
\end{align*}
we obtain $\sum\limits_{a\in B}\operatorname*{Kil}\left(  a,a\right)
=2h^{\vee}\sum\limits_{a\in B}\left(  a,a\right)  $. Since
$\operatorname*{Kil}$ is a scalar multiple of $\left(  \cdot,\cdot\right)  $
(because there is only one $\mathfrak{g}$-invariant symmetric bilinear form on
$\mathfrak{g}$ up to scaling), this yields $\operatorname*{Kil}=2h^{\vee}%
\cdot\left(  \cdot,\cdot\right)  $ (because $\sum\limits_{a\in B}%
\underbrace{\left(  a,a\right)  }_{=1}=\sum\limits_{a\in B}1=\left\vert
B\right\vert \neq0$). Lemma \ref{lem.dualcox.kil} is proven.

So let us now look at the Sugawara construction when $\mathfrak{g}$ is simple
finite-dimensional. First of all, $k$ is non-critical if and only if
$k\neq-h^{\vee}$. (The value $k=-h^{\vee}$ is called the \textit{critical
level}.)

If $B^{\prime}$ is an orthonormal basis under $\left(  \cdot,\cdot\right)  $
(rather than under $k\left(  \cdot,\cdot\right)  +\dfrac{1}{2}%
\operatorname*{Kil}=\left(  k+h^{\vee}\right)  \left(  \cdot,\cdot\right)  $),
then we have%
\begin{align}
L_{n}  &  =\dfrac{1}{2\left(  k+h^{\vee}\right)  }\sum\limits_{a\in B^{\prime
}}\sum\limits_{m\in\mathbb{Z}}\left.  :a_{m}a_{n-m}:\right.
\ \ \ \ \ \ \ \ \ \ \text{and}\nonumber\\
c  &  =\dfrac{k}{k+h^{\vee}}\underbrace{\sum\limits_{a\in B^{\prime}}\left(
a,a\right)  }_{\substack{=\left\vert B^{\prime}\right\vert \\\text{(since
}\left(  a,a\right)  =1\text{ for every }a\in B^{\prime}\text{)}}}=\dfrac
{k}{k+h^{\vee}}\underbrace{\left\vert B^{\prime}\right\vert }_{=\dim
\mathfrak{g}}=\dfrac{k\dim\mathfrak{g}}{k+h^{\vee}}.
\label{thm.sugawara.simple.c}%
\end{align}
In particular, this induces an internal grading on any $\widehat{\mathfrak{g}%
}$-module which is a quotient of $M_{\lambda}^{+}$ by eigenvalues of $L_{0}$,
whenever $\lambda$ is a weight of $\widehat{\mathfrak{g}}$. This is a grading
by complex numbers, since eigenvalues of $L_{0}$ are not necessarily integers.
(Note that this does not work for general admissible modules in lieu of
quotients of $M_{\lambda}^{+}$.)

What happens at the critical level $k=-h^{\vee}$ ? The above formulas with
$k+h^{\vee}$ in the denominators clearly don't work at this level anymore. We
can, however, remove the denominators, i. e., consider the operators%
\[
T_{n}=\dfrac{1}{2}\sum\limits_{a\in B^{\prime}}\sum\limits_{m\in\mathbb{Z}%
}\left.  :a_{m}a_{n-m}:\right.  .
\]
Then, the same calculations as we did in the proof of Theorem
\ref{thm.sugawara} tell us that these $T_{n}$ satisfy $\left[  T_{n}%
,a_{m}\right]  =0$ and $\left[  T_{n},T_{m}\right]  =0$; they are thus central
``elements'' of $U\left(  \widehat{\mathfrak{g}}\right)  $ (except that they
are not actually elements of $U\left(  \widehat{\mathfrak{g}}\right)  $, but
of some completion of $U\left(  \widehat{\mathfrak{g}}\right)  $ acting on
admissible modules).

For any complex numbers $\gamma_{1},\gamma_{2},\gamma_{3},...$, we can
construct a $\widehat{\mathfrak{g}}$-module $M_{\lambda}\diagup\left(
\sum\limits_{m\geq1}\left(  \left(  T_{m}-\gamma_{m}\right)  M_{\lambda
}\right)  \right)  $, which does not have a grading. So, at the critical
level, we do not automatically get gradings on quotients of $M_{\lambda}$
anymore. This is one reason why representations at the critical level are
considered more difficult than those at non-critical levels.

\subsection{The Sugawara construction and unitarity}

We now will show that the Sugawara construction preserves unitarity:

\begin{proposition}
Consider the situation of Theorem \ref{thm.sugawara}. If $M$ is a unitary
admissible module for $\widehat{\mathfrak{g}}$, then $M$ is a unitary
$\operatorname*{Vir}\ltimes\widehat{\mathfrak{g}}$-module. (We recall that the
Virasoro algebra had its unitary structure given by $L_{n}^{\dag}=L_{-n}$.)
\end{proposition}

But for $M$ to be unitary for $\widehat{\mathfrak{g}}$, we need $k\in
\mathbb{Z}_{+}$ (this is easy to prove; we proved it for $\mathfrak{sl}_{n}$,
and the general case is similar). Since for $k=0$, there is only the trivial
representation, we really must require $k\geq1$ to get something interesting.
And since $c=\dfrac{k\dim\mathfrak{g}}{k+h^{\vee}}$, the $c$ is then $\geq1$,
since $\dim\mathfrak{g}\geq1+h^{\vee}$. These modules are already known to us
to be unitary, so this construction does not help us in constructing new
unitary modules.

But there is a way to amend this by a variation of the Sugawara construction:
the Goddard-Kent-Olive construction.

\subsection{The Goddard-Kent-Olive construction (a.k.a. the coset
construction)}

\begin{definition}
\label{def.goddardkentolive}Let $\mathfrak{g}$ and $\mathfrak{p}$ be two
finite-dimensional Lie algebras such that $\mathfrak{g}\supseteq\mathfrak{p}$.
Let $\left(  \cdot,\cdot\right)  $ be a $\mathfrak{g}$-invariant form
(possibly degenerate) on $\mathfrak{g}$. We can restrict this form to
$\mathfrak{p}$, and obtain a $\mathfrak{p}$-invariant form on $\mathfrak{p}$.
Construct an affine Lie algebra $\widehat{\mathfrak{g}}$ as in Definition
\ref{def.sugawara} using the $\mathfrak{g}$-invariant form $\left(
\cdot,\cdot\right)  $ on $\mathfrak{g}$, and similarly construct an affine Lie
algebra $\widehat{\mathfrak{p}}$ using the restriction of this form to
$\mathfrak{p}$. Then, $\widehat{\mathfrak{g}}\supseteq\widehat{\mathfrak{p}}$.
Choose a level $k$ which is non-critical for both $\mathfrak{g}$ and
$\mathfrak{p}$.

Let $M$ be an admissible $\widehat{\mathfrak{g}}$-module at level $k$. Then,
$M$ automatically becomes an admissible $\widehat{\mathfrak{p}}$-module at
level $k$. Hence, on $M$, we have two Virasoro actions: one which is obtained
from the $\widehat{\mathfrak{g}}$-action, and one which is obtained from the
$\widehat{\mathfrak{p}}$-action. We will denote these actions by $\left(
L_{i}^{\mathfrak{g}}\right)  _{i\in\mathbb{Z}}$ and $\left(  L_{i}%
^{\mathfrak{p}}\right)  _{i\in\mathbb{Z}}$, respectively (that is, for every
$i\in\mathbb{Z}$, we denote by $L_{i}^{\mathfrak{g}}$ the action of $L_{i}%
\in\operatorname*{Vir}$ obtained from the $\widehat{\mathfrak{g}}$-module
structure on $M$, and we denote by $L_{i}^{\mathfrak{p}}$ the action of
$L_{i}\in\operatorname*{Vir}$ obtained from the $\widehat{\mathfrak{p}}%
$-module structure on $M$), and we will denote their central charges by
$c_{\mathfrak{g}}$ and $c_{\mathfrak{p}}$, respectively.
\end{definition}

\begin{theorem}
\label{thm.goddardkentolive}Consider the situation of Definition
\ref{def.goddardkentolive}. Let $L_{i}=L_{i}^{\mathfrak{g}}-L_{i}%
^{\mathfrak{p}}$ for all $i\in\mathbb{Z}$.

\textbf{(a)} Then, $\left(  L_{i}\right)  _{i\in\mathbb{Z}}$ is a
$\operatorname*{Vir}$-action on $M$ with central charge $c=c_{\mathfrak{g}%
}-c_{\mathfrak{p}}$.

\textbf{(b)} Also, $\left[  L_{n},\widehat{p}\right]  =0$ for all
$\widehat{p}\in\widehat{\mathfrak{p}}$ and $n\in\mathbb{Z}$.

\textbf{(c)} Moreover, $\left[  L_{n},L_{m}^{\mathfrak{p}}\right]  =0$ for all
$n\in\mathbb{Z}$ and $m\in\mathbb{Z}$.
\end{theorem}

\textit{Proof of Theorem \ref{thm.goddardkentolive}.} \textbf{(b)} Let
$n\in\mathbb{Z}$. Every $p\in\mathfrak{p}$ and $m\in\mathbb{Z}$ satisfy%
\[
\left[  \underbrace{L_{n}}_{=L_{n}^{\mathfrak{g}}-L_{n}^{\mathfrak{p}}}%
,p_{m}\right]  =\underbrace{\left[  L_{n}^{\mathfrak{g}},p_{m}\right]
}_{\substack{=-mp_{n+m}\\\text{(by Theorem \ref{thm.sugawara} \textbf{(e)}%
,}\\\text{applied to }p\text{ instead of }a\text{)}}}-\underbrace{\left[
L_{n}^{\mathfrak{p}},p_{m}\right]  }_{\substack{=-mp_{n+m}\\\text{(by Theorem
\ref{thm.sugawara} \textbf{(e)},}\\\text{applied to }p\text{ and }%
\mathfrak{p}\text{ instead of }a\text{ and }\mathfrak{g}\text{)}}}=\left(
-mp_{m+n}\right)  -\left(  -mp_{m+n}\right)  =0.
\]
Combined with the fact that $\left[  L_{n},K\right]  =0$ (this is trivial,
since $K$ acts as $k\cdot\operatorname*{id}$ on $M$), this yields that
$\left[  L_{n},\widehat{p}\right]  =0$ for all $\widehat{p}\in
\widehat{\mathfrak{p}}$ and $n\in\mathbb{Z}$ (because every $\widehat{p}%
\in\widehat{\mathfrak{p}}$ is a $\mathbb{C}$-linear combination of terms of
the form $p_{m}$ (with $p\in\mathfrak{p}$ and $m\in\mathbb{Z}$) and $K$).
Thus, Theorem \ref{thm.goddardkentolive} \textbf{(b)} is proven.

\textbf{(c)} Let $n\in\mathbb{Z}$. We recall that $L_{n}^{\mathfrak{p}}$ was
defined by $L_{n}^{\mathfrak{p}}=\dfrac{1}{2}\sum\limits_{a\in B}%
\sum\limits_{m\in\mathbb{Z}}\left.  :a_{m}a_{n-m}:\right.  $, where $B$ is an
orthonormal basis of $\mathfrak{p}$ with respect to a certain bilinear form on
$\mathfrak{p}$. Thus, $L_{n}^{\mathfrak{p}}$ is a sum of products of elements
of $\widehat{\mathfrak{p}}$ (or, more precisely, their actions on $M$).

Now, let $m\in\mathbb{Z}$. We have just seen that $L_{n}^{\mathfrak{p}}$ is a
sum of products of elements of $\widehat{\mathfrak{p}}$ (or, more precisely,
their actions on $M$). Similarly, $L_{m}^{\mathfrak{p}}$ is a sum of products
of elements of $\widehat{\mathfrak{p}}$ (or, more precisely, their actions on
$M$). Since we know that $L_{n}$ commutes with every element of
$\widehat{\mathfrak{p}}$ (due to Theorem \ref{thm.goddardkentolive}
\textbf{(b)}), this yields that $L_{n}$ commutes with $L_{m}^{\mathfrak{p}}$.
In other words, $\left[  L_{n},L_{m}^{\mathfrak{p}}\right]  =0$. Theorem
\ref{thm.goddardkentolive} \textbf{(c)} is thus established.

\textbf{(a)} Any $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ satisfy%
\begin{align*}
&  \left[  L_{n},\underbrace{L_{m}}_{=L_{m}^{\mathfrak{g}}-L_{m}%
^{\mathfrak{p}}}\right] \\
&  =\left[  L_{n},L_{m}^{\mathfrak{g}}-L_{m}^{\mathfrak{p}}\right]  =\left[
L_{n},L_{m}^{\mathfrak{g}}\right]  -\underbrace{\left[  L_{n},L_{m}%
^{\mathfrak{p}}\right]  }_{\substack{=0\\\text{(by Theorem
\ref{thm.goddardkentolive} \textbf{(c)})}}}=\left[  \underbrace{L_{n}}%
_{=L_{n}^{\mathfrak{g}}-L_{n}^{\mathfrak{p}}},L_{m}^{\mathfrak{g}}\right] \\
&  =\left[  L_{n}^{\mathfrak{g}}-L_{n}^{\mathfrak{p}},L_{m}^{\mathfrak{g}%
}\right]  =\left[  L_{n}^{\mathfrak{g}},L_{m}^{\mathfrak{g}}\right]
-\underbrace{\left[  L_{n}^{\mathfrak{p}},L_{m}^{\mathfrak{g}}\right]
}_{\substack{=\left[  L_{n}^{\mathfrak{p}},L_{m}^{\mathfrak{g}}-L_{m}%
^{\mathfrak{p}}\right]  +\left[  L_{n}^{\mathfrak{p}},L_{m}^{\mathfrak{p}%
}\right]  \\\text{(since }L_{m}^{\mathfrak{g}}=\left(  L_{m}^{\mathfrak{g}%
}-L_{m}^{\mathfrak{p}}\right)  +L_{m}^{\mathfrak{p}}\text{)}}}\\
&  =\left[  L_{n}^{\mathfrak{g}},L_{m}^{\mathfrak{g}}\right]  -\left[
L_{n}^{\mathfrak{p}},\underbrace{L_{m}^{\mathfrak{g}}-L_{m}^{\mathfrak{p}}%
}_{=L_{m}}\right]  -\left[  L_{n}^{\mathfrak{p}},L_{m}^{\mathfrak{p}}\right]
\\
&  =\underbrace{\left[  L_{n}^{\mathfrak{g}},L_{m}^{\mathfrak{g}}\right]
}_{\substack{=\left(  n-m\right)  L_{n+m}^{\mathfrak{g}}-\dfrac{n^{3}-n}%
{12}c_{\mathfrak{g}}\delta_{n,-m}\\\text{(by Theorem \ref{thm.sugawara}
\textbf{(c)})}}}-\underbrace{\left[  L_{n}^{\mathfrak{p}},L_{m}\right]
}_{=-\left[  L_{m},L_{n}^{\mathfrak{p}}\right]  }-\underbrace{\left[
L_{n}^{\mathfrak{p}},L_{m}^{\mathfrak{p}}\right]  }_{\substack{=\left(
n-m\right)  L_{n+m}^{\mathfrak{p}}-\dfrac{n^{3}-n}{12}c_{\mathfrak{p}}%
\delta_{n,-m}\\\text{(by Theorem \ref{thm.sugawara} \textbf{(c)}%
,}\\\text{applied to }\mathfrak{p}\text{ instead of }\mathfrak{g}\text{)}}}\\
&  =\left(  \left(  n-m\right)  L_{n+m}^{\mathfrak{g}}-\dfrac{n^{3}-n}%
{12}c_{\mathfrak{g}}\delta_{n,-m}\right)  +\left[  L_{m},L_{n}^{\mathfrak{p}%
}\right]  -\left(  \left(  n-m\right)  L_{n+m}^{\mathfrak{p}}-\dfrac{n^{3}%
-n}{12}c_{\mathfrak{p}}\delta_{n,-m}\right) \\
&  =\left(  n-m\right)  \underbrace{\left(  L_{n+m}^{\mathfrak{g}}%
-L_{n+m}^{\mathfrak{p}}\right)  }_{=L_{n+m}}-\dfrac{n^{3}-n}{12}\left(
c_{\mathfrak{g}}-c_{\mathfrak{p}}\right)  \delta_{n,-m}+\underbrace{\left[
L_{m},L_{n}^{\mathfrak{p}}\right]  }_{\substack{=0\\\text{(by Theorem
\ref{thm.goddardkentolive} \textbf{(c)},}\\\text{applied to }m\text{ and
}n\text{ instead of }n\text{ and }m\text{)}}}\\
&  =\left(  n-m\right)  L_{n+m}-\dfrac{n^{3}-n}{12}\left(  c_{\mathfrak{g}%
}-c_{\mathfrak{p}}\right)  \delta_{n,-m}.
\end{align*}
Hence, $\left(  L_{i}\right)  _{i\in\mathbb{Z}}$ is a $\operatorname*{Vir}%
$-action on $M$ with central charge $c=c_{\mathfrak{g}}-c_{\mathfrak{p}}$.
Theorem \ref{thm.goddardkentolive} \textbf{(a)} is thus proven. This completes
the proof of Theorem \ref{thm.goddardkentolive}.

\begin{example}
Let $\mathfrak{a}$ be a simple finite-dimensional Lie algebra. Let
$\mathfrak{g}=\mathfrak{a}\oplus\mathfrak{a}$, and let $\mathfrak{p}%
=\mathfrak{a}_{\operatorname*{diag}}\subseteq\mathfrak{a}\oplus\mathfrak{a}$
(where $\mathfrak{a}_{\operatorname*{diag}}$ denotes the Lie subalgebra
$\left\{  \left(  x,x\right)  \ \mid\ x\in\mathfrak{a}\right\}  $ of
$\mathfrak{a}\oplus\mathfrak{a}$). Consider the standard form $\left(
\cdot,\cdot\right)  $ on $\mathfrak{a}$. Define a symmetric bilinear form on
$\mathfrak{a}\oplus\mathfrak{a}$ as the direct sum of the standard forms on
$\mathfrak{a}$ and $\mathfrak{a}$.

Let $V^{\prime}$ and $V^{\prime\prime}$ be admissible $\widehat{\mathfrak{a}}%
$-modules at levels $k^{\prime}$ and $k^{\prime\prime}$. Theorem
\ref{thm.sugawara} endows these vector spaces $V^{\prime}$ and $V^{\prime
\prime}$ with $\operatorname*{Vir}$-module structures. These
$\operatorname*{Vir}$-module structures have central charges $c_{\mathfrak{a}%
}^{\prime}=\dfrac{k^{\prime}\dim\mathfrak{a}}{k^{\prime}+h^{\vee}}$ and
$c_{\mathfrak{a}}^{\prime\prime}=\dfrac{k^{\prime\prime}\dim\mathfrak{a}%
}{k^{\prime\prime}+h^{\vee}}$, respectively (by (\ref{thm.sugawara.simple.c}%
)). Let $\left(  L_{i}^{\prime}\right)  _{i\in\mathbb{Z}}$ and $\left(
L_{i}^{\prime\prime}\right)  _{i\in\mathbb{Z}}$ denote the actions of
$\operatorname*{Vir}$ on these modules.

Then, $V^{\prime}\otimes V^{\prime\prime}$ is an admissible
$\widehat{\mathfrak{g}}$-module at level $k^{\prime}+k^{\prime\prime}$. Thus,
by Theorem \ref{thm.sugawara}, this vector space $V^{\prime}\otimes
V^{\prime\prime}$ becomes a $\operatorname*{Vir}$-module. The action $\left(
L_{i}^{\mathfrak{g}}\right)  _{i\in\mathbb{Z}}$ of $\operatorname*{Vir}$ on
this $\operatorname*{Vir}$-module $V^{\prime}\otimes V^{\prime\prime}$ is
given by $L_{i}^{\mathfrak{g}}=L_{i}^{\prime}+L_{i}^{\prime\prime}$ (or, more
precisely, $L_{i}^{\mathfrak{g}}=L_{i}^{\prime}\otimes\operatorname*{id}%
+\operatorname*{id}\otimes L_{i}^{\prime\prime}$). The central charge
$c_{\mathfrak{g}}$ of this $\operatorname*{Vir}$-module $V^{\prime}\otimes
V^{\prime\prime}$ is
\[
c_{\mathfrak{g}}=c_{\mathfrak{a}}^{\prime}+c_{\mathfrak{a}}^{\prime\prime
}=\dfrac{k^{\prime}\dim\mathfrak{a}}{k^{\prime}+h^{\vee}}+\dfrac
{k^{\prime\prime}\dim\mathfrak{a}}{k^{\prime\prime}+h^{\vee}}.
\]


Since $\widehat{\mathfrak{p}}=\widehat{\mathfrak{a}}$ acts on $V^{\prime
}\otimes V^{\prime\prime}$ by diagonal action, we also get a
$\operatorname*{Vir}$-module structure $\left(  L_{i}^{\mathfrak{p}}\right)
_{i\in\mathbb{Z}}$ on $V^{\prime}\otimes V^{\prime\prime}$ by applying Theorem
\ref{thm.sugawara} to $\mathfrak{p}$ instead of $\mathfrak{g}$. The central
charge of this $\operatorname*{Vir}$-module is
\[
c_{\mathfrak{p}}=\dfrac{k^{\prime}+k^{\prime\prime}}{k^{\prime}+k^{\prime
\prime}+h^{\vee}}\dim\mathfrak{a}%
\]
(since the level of the $\widehat{\mathfrak{p}}$-module $V^{\prime}\otimes
V^{\prime\prime}$ is $k^{\prime}+k^{\prime\prime}$).

Thus, the central charge $c$ of the $\operatorname*{Vir}$-action on
$V^{\prime}\otimes V^{\prime\prime}$ given by Theorem
\ref{thm.goddardkentolive} is%
\begin{align*}
c  &  =c_{\mathfrak{a}}^{\prime}+c_{\mathfrak{a}}^{\prime\prime}%
-c_{\mathfrak{p}}=\dfrac{k^{\prime}\dim\mathfrak{a}}{k^{\prime}+h^{\vee}%
}+\dfrac{k^{\prime\prime}\dim\mathfrak{a}}{k^{\prime\prime}+h^{\vee}}%
-\dfrac{k^{\prime}+k^{\prime\prime}}{k^{\prime}+k^{\prime\prime}+h^{\vee}}%
\dim\mathfrak{a}\\
&  =\left(  \dfrac{k^{\prime}}{k^{\prime}+h^{\vee}}+\dfrac{k^{\prime\prime}%
}{k^{\prime\prime}+h^{\vee}}-\dfrac{k^{\prime}+k^{\prime\prime}}{k^{\prime
}+k^{\prime\prime}+h^{\vee}}\right)  \dim\mathfrak{a}.
\end{align*}


We can use this construction to obtain, for every positive integer $m$, a
unitary representation of $\operatorname*{Vir}$ with central charge
$1-\dfrac{6}{\left(  m+2\right)  \left(  m+3\right)  }$: In fact, let
$\mathfrak{a}=\mathfrak{sl}_{2}$, so that $h^{\vee}=2$, and let $k^{\prime}=1$
and $k^{\prime\prime}=m$. Then,%
\[
c=3\left(  \dfrac{1}{3}+\dfrac{m}{m+2}-\dfrac{m+1}{m+3}\right)  =1-\dfrac
{6}{\left(  m+2\right)  \left(  m+3\right)  }.
\]
So we get unitary representations of $\operatorname*{Vir}$ with central charge
$c$ for these values of $c$.
\end{example}

\subsection{\label{subsect.prelims}Preliminaries to simple and Kac-Moody Lie
algebras}

Our next goal is defining and studying the Kac-Moody Lie algebras. Before we
do this, however, we will recollect some properties of simple
finite-dimensional Lie algebras (which are, in some sense, the prototypical
Kac-Moody Lie algebras); and yet before that, we show some general results
from the theory of Lie algebras which will be used in our later proofs.

[This whole Section \ref{subsect.prelims} is written by Darij and aims at
covering the gap between introductory courses in Lie algebras and Etingof's
class. It states some folklore facts about Lie algebras which will be used later.]

\subsubsection{A basic property of
\texorpdfstring{$\mathfrak{sl}_{2}$}{sl-2}-modules}

We begin with a lemma from the representation theory of $\mathfrak{sl}_{2}$:

\begin{lemma}
\label{lem.serre-gen.sl2}Let $e$, $f$ and $h$ mean the classical basis
elements of $\mathfrak{sl}_{2}$. Let $\lambda\in\mathbb{C}$. We consider any
$\mathfrak{sl}_{2}$-module as a $U\left(  \mathfrak{sl}_{2}\right)  $-module.

\textbf{(a)} Let $V$ be an $\mathfrak{sl}_{2}$-module. Let $x\in V$ be such
that $ex=0$ and $hx=\lambda x$. Then, every $n\in\mathbb{N}$ satisfies
$e^{n}f^{n}x=n!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-n+1\right)
x$.

\textbf{(b)} Let $V$ be an $\mathfrak{sl}_{2}$-module. Let $x\in V$ be such
that $fx=0$ and $hx=\lambda x$. Then, every $n\in\mathbb{N}$ satisfies
$f^{n}e^{n}x=n!\lambda\left(  \lambda+1\right)  ...\left(  \lambda+n-1\right)
x$.

\textbf{(c)} Let $V$ be a finite-dimensional $\mathfrak{sl}_{2}$-module. Let
$x$ be a nonzero element of $V$ satisfying $ex=0$ and $hx=\lambda x$. Then,
$\lambda\in\mathbb{N}$ and $f^{\lambda+1}x=0$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.serre-gen.sl2}.} \textbf{(a)} \textit{1st
step:} We will see that%
\begin{equation}
hf^{m}x=\left(  \lambda-2m\right)  f^{m}x\ \ \ \ \ \ \ \ \ \ \text{for every
}m\in\mathbb{N}. \label{pf.serre-gen.sl2.1}%
\end{equation}


\textit{Proof of (\ref{pf.serre-gen.sl2.1}):} We will prove
(\ref{pf.serre-gen.sl2.1}) by induction over $m$:

\textit{Induction base:} For $m=0$, we have $hf^{m}x=hf^{0}x=hx=\lambda x$ and
$\left(  \lambda-2m\right)  f^{m}x=\left(  \lambda-2\cdot0\right)
f^{0}x=\lambda x$, so that $hf^{m}x=\left(  \lambda-2m\right)  f^{m}x$ holds
for $m=0$. In other words, (\ref{pf.serre-gen.sl2.1}) holds for $m=0$. This
completes the induction base.

\textit{Induction step:} Let $M\in\mathbb{N}$. Assume that
(\ref{pf.serre-gen.sl2.1}) holds for $m=M$. We must then prove that
(\ref{pf.serre-gen.sl2.1}) holds for $m=M+1$ as well.

Since (\ref{pf.serre-gen.sl2.1}) holds for $m=M$, we have $hf^{M}x=\left(
\lambda-2M\right)  f^{M}x$. Now,%
\begin{align*}
h\underbrace{f^{M+1}}_{=ff^{M}}x  &  =\underbrace{hf}_{=fh+\left[  h,f\right]
}f^{M}x=\left(  fh+\left[  h,f\right]  \right)  f^{M}x=f\underbrace{hf^{M}%
x}_{=\left(  \lambda-2M\right)  f^{M}x}+\underbrace{\left[  h,f\right]
}_{=-2f}f^{M}x\\
&  =\left(  \lambda-2M\right)  \underbrace{ff^{M}}_{=f^{M+1}}%
x-2\underbrace{ff^{M}}_{=f^{M+1}}x=\left(  \lambda-2M\right)  f^{M+1}%
x-2f^{M+1}x\\
&  =\underbrace{\left(  \lambda-2M-2\right)  }_{=\lambda-2\left(  M+1\right)
}f^{M+1}x=\left(  \lambda-2\left(  M+1\right)  \right)  f^{M+1}x.
\end{align*}
Thus, (\ref{pf.serre-gen.sl2.1}) holds for $m=M+1$ as well. This completes the
induction step. The induction proof of (\ref{pf.serre-gen.sl2.1}) is thus complete.

\textit{2nd step:} We will see that%
\begin{equation}
ef^{m}x=m\left(  \lambda-m+1\right)  f^{m-1}x\ \ \ \ \ \ \ \ \ \ \text{for
every positive }m\in\mathbb{N}. \label{pf.serre-gen.sl2.2}%
\end{equation}


\textit{Proof of (\ref{pf.serre-gen.sl2.2}):} We will prove
(\ref{pf.serre-gen.sl2.2}) by induction over $m$:

\textit{Induction base:} For $m=1$, we have%
\[
ef^{m}x=\underbrace{ef^{1}}_{=ef=\left[  e,f\right]  +fe}x=\left(  \left[
e,f\right]  +fe\right)  x=\underbrace{\left[  e,f\right]  }_{=h}%
x+f\underbrace{ex}_{=0}=hx+f0=hx=\lambda x
\]
and $m\left(  \lambda-m+1\right)  f^{m-1}x=1\underbrace{\left(  \lambda
-1+1\right)  }_{=\lambda}\underbrace{f^{1-1}}_{=1}x=\lambda x$, so that
$ef^{m}x=m\left(  \lambda-m+1\right)  f^{m-1}x$ holds for $m=1$. In other
words, (\ref{pf.serre-gen.sl2.2}) holds for $m=1$. This completes the
induction base.

\textit{Induction step:} Let $M\in\mathbb{N}$ be positive. Assume that
(\ref{pf.serre-gen.sl2.2}) holds for $m=M$. We must then prove that
(\ref{pf.serre-gen.sl2.2}) holds for $m=M+1$ as well.

Since (\ref{pf.serre-gen.sl2.2}) holds for $m=M$, we have $ef^{M}x=M\left(
\lambda-M+1\right)  f^{M-1}x$. Now,%
\begin{align*}
e\underbrace{f^{M+1}}_{=ff^{M}}x  &  =\underbrace{ef}_{=fe+\left[  e,f\right]
}f^{M}x=\left(  fe+\left[  e,f\right]  \right)  f^{M}x=f\underbrace{ef^{M}%
}_{=M\left(  \lambda-M+1\right)  f^{M-1}x}x+\underbrace{\left[  e,f\right]
}_{=h}f^{M}x\\
&  =M\left(  \lambda-M+1\right)  \underbrace{ff^{M-1}}_{=f^{M}}%
x+\underbrace{hf^{M}x}_{\substack{=\left(  \lambda-2M\right)  f^{M}%
x\\\text{(by (\ref{pf.serre-gen.sl2.1}), applied to }m=M\text{)}}}\\
&  =M\left(  \lambda-M+1\right)  f^{M}x+\left(  \lambda-2M\right)
f^{M}x=\underbrace{\left(  M\left(  \lambda-M+1\right)  +\left(
\lambda-2M\right)  \right)  }_{=\left(  M+1\right)  \left(  \lambda-\left(
M+1\right)  +1\right)  }f^{M}x\\
&  =\left(  M+1\right)  \left(  \lambda-\left(  M+1\right)  +1\right)  f^{M}x.
\end{align*}
Thus, (\ref{pf.serre-gen.sl2.2}) holds for $m=M+1$ as well. This completes the
induction step. The induction proof of (\ref{pf.serre-gen.sl2.2}) is thus complete.

\textit{3rd step:} We will see that%
\begin{equation}
e^{n}f^{n}x=n!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-n+1\right)
x\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{N}.
\label{pf.serre-gen.sl2.3}%
\end{equation}


\textit{Proof of (\ref{pf.serre-gen.sl2.3}):} We will prove
(\ref{pf.serre-gen.sl2.3}) by induction over $n$:

\textit{Induction base:} For $n=0$, we have $e^{n}f^{n}x=e^{0}f^{0}x=x$ and
$n!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-n+1\right)
x=\underbrace{0!}_{=1}\underbrace{\lambda\left(  \lambda-1\right)  ...\left(
\lambda-0+1\right)  }_{=\left(  \text{empty product}\right)  =1}x=x$, so that
$e^{n}f^{n}x=n!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-n+1\right)
x$ holds for $n=0$. In other words, (\ref{pf.serre-gen.sl2.3}) holds for
$n=0$. This completes the induction base.

\textit{Induction step:} Let $N\in\mathbb{N}$. Assume that
(\ref{pf.serre-gen.sl2.3}) holds for $n=N$. We must then prove that
(\ref{pf.serre-gen.sl2.3}) holds for $n=N+1$ as well.

Since (\ref{pf.serre-gen.sl2.3}) holds for $n=N$, we have $e^{N}%
f^{N}x=N!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-N+1\right)  x$.
Now,%
\begin{align*}
\underbrace{e^{N+1}}_{=e^{N}e}f^{N+1}x  &  =e^{N}\underbrace{ef^{N+1}%
x}_{\substack{=\left(  N+1\right)  \left(  \lambda-\left(  N+1\right)
+1\right)  f^{\left(  N+1\right)  -1}x\\\text{(by (\ref{pf.serre-gen.sl2.2}),
applied to }m=N+1\text{)}}}=\left(  N+1\right)  \left(  \lambda-\left(
N+1\right)  +1\right)  e^{N}\underbrace{f^{\left(  N+1\right)  -1}}_{=f^{N}%
}x\\
&  =\left(  N+1\right)  \left(  \lambda-\left(  N+1\right)  +1\right)
\underbrace{e^{N}f^{N}x}_{=N!\lambda\left(  \lambda-1\right)  ...\left(
\lambda-N+1\right)  x}\\
&  =\left(  N+1\right)  \left(  \lambda-\left(  N+1\right)  +1\right)  \cdot
N!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-N+1\right)  x\\
&  =\underbrace{\left(  \left(  N+1\right)  \cdot N!\right)  }_{=\left(
N+1\right)  !}\cdot\underbrace{\left(  \lambda\left(  \lambda-1\right)
...\left(  \lambda-N+1\right)  \right)  \cdot\left(  \lambda-\left(
N+1\right)  +1\right)  }_{=\lambda\left(  \lambda-1\right)  ...\left(
\lambda-\left(  N+1\right)  +1\right)  }x\\
&  =\left(  N+1\right)  !\lambda\left(  \lambda-1\right)  ...\left(
\lambda-\left(  N+1\right)  +1\right)  x.
\end{align*}
Thus, (\ref{pf.serre-gen.sl2.3}) holds for $n=N+1$ as well. This completes the
induction step. The induction proof of (\ref{pf.serre-gen.sl2.3}) is thus complete.

Lemma \ref{lem.serre-gen.sl2} \textbf{(a)} immediately follows from
(\ref{pf.serre-gen.sl2.3}).

\textbf{(b)} The proof of Lemma \ref{lem.serre-gen.sl2} \textbf{(b)} is
analogous to the proof of Lemma \ref{lem.serre-gen.sl2} \textbf{(a)}.

\textbf{(c)} By assumption, $\dim V<\infty$. Now, the endomorphism $h\mid_{V}$
of $V$ has at most $\dim V$ distinct eigenvalues (since an endomorphism of any
finite-dimensional vector space $W$ has at most $\dim W$ distinct
eigenvalues). From this, it is easy to conclude that $f^{\dim V}%
x=0$\ \ \ \ \footnote{\textit{Proof.} Assume the opposite. Then, $f^{\dim
V}x\neq0$.
\par
Now, let $m\in\left\{  0,1,...,\dim V\right\}  $ be arbitrary. We will prove
that $\lambda-2m$ is an eigenvalue of $h\mid_{V}$.
\par
In fact, $m\leq\dim V$, so that $f^{\dim V-m}\left(  f^{m}x\right)  =f^{\dim
V-m+m}x=f^{\dim V}x\neq0$ and thus $f^{m}x\neq0$. Since $hf^{m}x=\left(
\lambda-2m\right)  f^{m}x$ (by (\ref{pf.serre-gen.sl2.1})), this yields that
$f^{m}x$ is a nonzero eigenvector of $h\mid_{V}$ with eigenvalue $\lambda-2m$.
Thus, $\lambda-2m$ is an eigenvalue of $h\mid_{V}$.
\par
Now forget that we fixed $m$. Thus, we have proven that $\lambda-2m$ is an
eigenvalue of $h\mid_{V}$ for every $m\in\left\{  0,1,...,\dim V\right\}  $.
Thus we have found $\dim V+1$ pairwise distinct eigenvalues of $h\mid_{V}$.
This contradicts the fact that $h\mid_{V}$ has at most $\dim V$ distinct
eigenvalues. This contradiction shows that our assumption was wrong, qed.}.
Thus, there exists a smallest $m\in\mathbb{N}$ satisfying $f^{m}x=0$. Denote
this $m$ by $u$. Then, $f^{u}x=0$. Since $f^{0}x=x\neq0$, this $u$ is $\neq0$,
so that $f^{u-1}x$ is well-defined. Moreover, $f^{u-1}x\neq0$ (since $u$ is
the smallest $m\in\mathbb{N}$ satisfying $f^{m}x=0$).

Lemma \ref{lem.serre-gen.sl2} \textbf{(a)} (applied to $n=u$) yields
$e^{u}f^{u}x=u!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-u+1\right)
x$. Since $e^{u}\underbrace{f^{u}x}_{=0}=0$, this rewrites as $u!\lambda
\left(  \lambda-1\right)  ...\left(  \lambda-u+1\right)  x=0$. Since
$\operatorname*{char}\mathbb{C}=0$, we can divide this equation by $u!$, and
obtain $\lambda\left(  \lambda-1\right)  ...\left(  \lambda-u+1\right)  x=0$.
Since $x\neq0$, this yields $\lambda\left(  \lambda-1\right)  ...\left(
\lambda-u+1\right)  =0$. Thus, one of the numbers $\lambda$, $\lambda-1$,
$...$, $\lambda-u+1$ must be $0$. In other words, $\lambda\in\left\{
0,1,...,u-1\right\}  $. Hence, $\lambda\in\mathbb{N}$ and $\lambda\leq u-1$.

Applying (\ref{pf.serre-gen.sl2.1}) to $m=u-1$, we obtain $hf^{u-1}x=\left(
\lambda-2\left(  u-1\right)  \right)  f^{u-1}x$. Denote $\lambda-2\left(
u-1\right)  $ by $\mu$. Then, $hf^{u-1}x=\underbrace{\left(  \lambda-2\left(
u-1\right)  \right)  }_{=\mu}f^{u-1}x=\mu f^{u-1}x$. Also, $ff^{u-1}%
x=f^{u}x=0$. Thus, we can apply Lemma \ref{lem.serre-gen.sl2} \textbf{(b)} to
$\mu$, $f^{u-1}x$ and $u-1$ instead of $\lambda$, $x$ and $n$. Thus, we obtain%
\[
f^{u-1}e^{u-1}f^{u-1}x=\left(  u-1\right)  !\mu\left(  \mu+1\right)
...\left(  \mu+\left(  u-1\right)  -1\right)  f^{u-1}x.
\]
But $\mu=\underbrace{\lambda}_{\leq u-1}-2\left(  u-1\right)  \leq\left(
u-1\right)  -2\left(  u-1\right)  =-\left(  u-1\right)  $, so that each of the
integers $\mu$, $\mu+1$, $...$, $\mu+\left(  u-1\right)  -1$ is nonzero. Thus,
their product $\mu\left(  \mu+1\right)  ...\left(  \mu+\left(  u-1\right)
-1\right)  $ also is $\neq0$. Combined with $\left(  u-1\right)  !\neq0$, this
yields $\left(  u-1\right)  !\mu\left(  \mu+1\right)  ...\left(  \mu+\left(
u-1\right)  -1\right)  \neq0$. Combined with $f^{u-1}x\neq0$, this yields
$\left(  u-1\right)  !\mu\left(  \mu+1\right)  ...\left(  \mu+\left(
u-1\right)  -1\right)  f^{u-1}x\neq0$. Thus,%
\[
f^{u-1}e^{u-1}f^{u-1}x=\left(  u-1\right)  !\mu\left(  \mu+1\right)
...\left(  \mu+\left(  u-1\right)  -1\right)  f^{u-1}x\neq0,
\]
so that $e^{u-1}f^{u-1}x\neq0$.

But Lemma \ref{lem.serre-gen.sl2} \textbf{(a)} (applied to $n=u-1$) yields
$e^{u-1}f^{u-1}x=\left(  u-1\right)  !\lambda\left(  \lambda-1\right)
...\left(  \lambda-\left(  u-1\right)  +1\right)  x$. Thus,
\[
\left(  u-1\right)  !\lambda\left(  \lambda-1\right)  ...\left(
\lambda-\left(  u-1\right)  +1\right)  x=e^{u-1}f^{u-1}x\neq0.
\]
Hence, $\lambda\left(  \lambda-1\right)  ...\left(  \lambda-\left(
u-1\right)  +1\right)  \neq0$. Hence, $\dbinom{\lambda}{u-1}=\dfrac{1}{\left(
u-1\right)  !}\underbrace{\lambda\left(  \lambda-1\right)  ...\left(
\lambda-\left(  u-1\right)  +1\right)  }_{\neq0}\neq0$, so that $u-1\leq
\lambda$ (because otherwise, we would have $\dbinom{\lambda}{u-1}=0$,
contradicting $\dbinom{\lambda}{u-1}\neq0$). Combined with $u-1\geq\lambda$,
this yields $u-1=\lambda$. Thus, $u=\lambda+1$. Hence, $f^{u}x=0$ rewrites as
$f^{\lambda+1}x=0$. This proves Lemma \ref{lem.serre-gen.sl2} \textbf{(c)}.

\subsubsection{\texorpdfstring{$Q$}{Q}-graded Lie algebras}

The following generalization of the standard definition of a $\mathbb{Z}%
$-graded Lie algebra suggests itself:

\begin{definition}
\label{def.Q-graded.lie}Let $Q$ be an abelian group, written additively.

\textbf{(a)} A $Q$\textit{-graded vector space} will mean a vector space $V$
equipped with a family $\left(  V\left[  \alpha\right]  \right)  _{\alpha\in
Q}$ of vector subspaces $V\left[  \alpha\right]  $ of $V$ (indexed by elements
of $Q$) satisfying $V=\bigoplus\limits_{\alpha\in Q}V\left[  \alpha\right]  $.
For every $\alpha\in Q$, the subspace $V\left[  \alpha\right]  $ is called the
$\alpha$\textit{-th homogeneous component} of the $Q$-graded vector space $V$.
The family $\left(  V\left[  \alpha\right]  \right)  _{\alpha\in Q}$ is called
a $Q$\textit{-grading} on the vector space $V$.

\textbf{(b)} A $Q$\textit{-graded Lie algebra} will mean a Lie algebra
$\mathfrak{g}$ equipped with a family $\left(  \mathfrak{g}\left[
\alpha\right]  \right)  _{\alpha\in Q}$ of vector subspaces $\mathfrak{g}%
\left[  \alpha\right]  $ of $\mathfrak{g}$ (indexed by elements of $Q$)
satisfying $\mathfrak{g}=\bigoplus\limits_{\alpha\in Q}\mathfrak{g}\left[
\alpha\right]  $ and satisfying
\[
\left[  \mathfrak{g}\left[  \alpha\right]  ,\mathfrak{g}\left[  \beta\right]
\right]  \subseteq\mathfrak{g}\left[  \alpha+\beta\right]
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha,\beta\in Q\text{.}%
\]
In this case, $Q$ is called the \textit{root lattice} of this $Q$-graded Lie
algebra $\mathfrak{g}$. (This does not mean that $Q$ actually has to be a
lattice of roots of $\mathfrak{g}$, or that $Q$ must be related in any way to
the roots of $\mathfrak{g}$.) Clearly, any $Q$-graded Lie algebra is a
$Q$-graded vector space. Thus, the notion of the $\alpha$-th homogeneous
component of a $Q$-graded Lie algebra makes sense for every $\alpha\in Q$.
\end{definition}

\begin{Convention}
Whenever $Q$ is an abelian group, $\alpha$ is an element of $Q$, and $V$ is a
$Q$-graded vector space or a $Q$-graded Lie algebra, we will denote the
$\alpha$-th homogeneous component of $V$ by $V\left[  \alpha\right]  $.
\end{Convention}

In the context of a $Q$-graded vector space (or Lie algebra) $V$, one often
writes $V_{\alpha}$ instead of $V\left[  \alpha\right]  $ for the $\alpha$-th
homogeneous component of $V$. This notation, however, can sometimes be misunderstood.

When a group homomorphism from $Q$ to $\mathbb{Z}$ is given, a $Q$-graded Lie
algebra canonically becomes a $\mathbb{Z}$-graded Lie algebra:

\begin{proposition}
\label{prop.Q-graded.principal}Let $Q$ be an abelian group. Let $\ell
:Q\rightarrow\mathbb{Z}$ be a group homomorphism. Let $\mathfrak{g}$ be a
$Q$-graded Lie algebra.

\textbf{(a)} For every $m\in\mathbb{Z}$, the internal direct sum
$\bigoplus\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)
=m}}\mathfrak{g}\left[  \alpha\right]  $ is well-defined.

\textbf{(b)} Denote this internal direct sum $\bigoplus
\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m}}\mathfrak{g}%
\left[  \alpha\right]  $ by $\mathfrak{g}_{\left[  m\right]  }$. Then, the Lie
algebra $\mathfrak{g}$ equipped with the grading $\left(  \mathfrak{g}%
_{\left[  m\right]  }\right)  _{m\in\mathbb{Z}}$ is a $\mathbb{Z}$-graded Lie algebra.

(This grading $\left(  \mathfrak{g}_{\left[  m\right]  }\right)
_{m\in\mathbb{Z}}$ is called the \textit{principal grading} on $\mathfrak{g}$
induced by the given $Q$-grading on $\mathfrak{g}$ and the map $\ell$.)
\end{proposition}

\begin{vershort}
The proof of this proposition is straightforward and left to the reader.
\end{vershort}

\begin{verlong}
\textit{Proof of Proposition \ref{prop.Q-graded.principal}.} \textbf{(a)}
Since $\mathfrak{g}$ is $Q$-graded, we have
\[
\mathfrak{g}=\bigoplus\limits_{\alpha\in Q}\mathfrak{g}\left[  \alpha\right]
=\bigoplus\limits_{m\in\mathbb{Z}}\bigoplus\limits_{\substack{\alpha\in
Q;\\\ell\left(  \alpha\right)  =m}}\mathfrak{g}\left[  \alpha\right]  .
\]
Thus, the internal direct sum $\bigoplus\limits_{\substack{\alpha\in
Q;\\\ell\left(  \alpha\right)  =m}}\mathfrak{g}\left[  \alpha\right]  $ is
defined for every $m\in\mathbb{Z}$. This proves Proposition
\ref{prop.Q-graded.principal} \textbf{(a)}.

\textbf{(b)} We have
\[
\mathfrak{g}=\bigoplus\limits_{m\in\mathbb{Z}}\underbrace{\bigoplus
\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m}}\mathfrak{g}%
\left[  \alpha\right]  }_{=\mathfrak{g}_{\left[  m\right]  }}=\bigoplus
\limits_{m\in\mathbb{Z}}\mathfrak{g}_{\left[  m\right]  }.
\]
Also, every $m_{1}\in\mathbb{Z}$ and every $m_{2}\in\mathbb{Z}$ satisfy%
\[
\mathfrak{g}_{\left[  m_{1}\right]  }\mathfrak{g}_{\left[  m_{2}\right]
}\subseteq\mathfrak{g}_{\left[  m_{1}+m_{2}\right]  }%
\]
\footnote{\textit{Proof.} Let $m_{1}\in\mathbb{Z}$ and $m_{2}\in\mathbb{Z}$.
Then, the definition of $\mathfrak{g}_{\left[  m_{1}\right]  }$ yields
\begin{align*}
\mathfrak{g}_{\left[  m_{1}\right]  }  &  =\bigoplus\limits_{\substack{\alpha
\in Q;\\\ell\left(  \alpha\right)  =m_{1}}}\mathfrak{g}\left[  \alpha\right]
=\sum\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m_{1}%
}}\mathfrak{g}\left[  \alpha\right]  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
direct sums are sums}\right) \\
&  =\sum\limits_{\substack{\beta\in Q;\\\ell\left(  \beta\right)  =m_{1}%
}}\mathfrak{g}\left[  \beta\right]  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we
renamed the index }\alpha\text{ as }\beta\right)  .
\end{align*}
Also, the definition of $\mathfrak{g}_{\left[  m_{2}\right]  }$ yields%
\begin{align*}
\mathfrak{g}_{\left[  m_{2}\right]  }  &  =\bigoplus\limits_{\substack{\alpha
\in Q;\\\ell\left(  \alpha\right)  =m_{2}}}\mathfrak{g}\left[  \alpha\right]
=\sum\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m_{2}%
}}\mathfrak{g}\left[  \alpha\right]  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
direct sums are sums}\right) \\
&  =\sum\limits_{\substack{\gamma\in Q;\\\ell\left(  \gamma\right)  =m_{2}%
}}\mathfrak{g}\left[  \gamma\right]  \ \ \ \ \ \ \ \ \ \ \left(  \text{here,
we renamed the index }\alpha\text{ as }\gamma\right)  .
\end{align*}
Finally, the definition of $\mathfrak{g}_{\left[  m_{1}+m_{2}\right]  }$
yields%
\[
\mathfrak{g}_{\left[  m_{1}+m_{2}\right]  }=\bigoplus\limits_{\substack{\alpha
\in Q;\\\ell\left(  \alpha\right)  =m_{1}+m_{2}}}\mathfrak{g}\left[
\alpha\right]  =\sum\limits_{\substack{\alpha\in Q;\\\ell\left(
\alpha\right)  =m_{1}+m_{2}}}\mathfrak{g}\left[  \alpha\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since direct sums are sums}\right)  .
\]
\par
Every $\beta\in Q$ and $\gamma\in Q$ such that $\ell\left(  \beta\right)
=m_{1}$ and $\ell\left(  \gamma\right)  =m_{2}$ satisfy%
\begin{align*}
\ell\left(  \beta+\gamma\right)   &  =\underbrace{\ell\left(  \beta\right)
}_{=m_{1}}+\underbrace{\ell\left(  \gamma\right)  }_{=m_{2}}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\ell\text{ is a }\mathbb{Z}%
\text{-module homomorphism}\right) \\
&  =m_{1}+m_{2}.
\end{align*}
Thus, every $\beta\in Q$ and $\gamma\in Q$ such that $\ell\left(
\beta\right)  =m_{1}$ and $\ell\left(  \gamma\right)  =m_{2}$ satisfy%
\begin{equation}
\mathfrak{g}\left[  \beta+\gamma\right]  \subseteq\sum
\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m_{1}+m_{2}%
}}\mathfrak{g}\left[  \alpha\right]  =\mathfrak{g}_{\left[  m_{1}%
+m_{2}\right]  }. \label{pf.Q-graded.principal.1}%
\end{equation}
\par
Since $\mathfrak{g}_{\left[  m_{1}\right]  }=\sum\limits_{\substack{\beta\in
Q;\\\ell\left(  \beta\right)  =m_{1}}}\mathfrak{g}\left[  \beta\right]  $ and
$\mathfrak{g}_{\left[  m_{2}\right]  }=\sum\limits_{\substack{\gamma\in
Q;\\\ell\left(  \gamma\right)  =m_{2}}}\mathfrak{g}\left[  \gamma\right]  $,
we have%
\begin{align*}
\left[  \mathfrak{g}_{\left[  m_{1}\right]  },\mathfrak{g}_{\left[
m_{2}\right]  }\right]   &  =\left[  \sum\limits_{\substack{\beta\in
Q;\\\ell\left(  \beta\right)  =m_{1}}}\mathfrak{g}\left[  \beta\right]
,\sum\limits_{\substack{\gamma\in Q;\\\ell\left(  \gamma\right)  =m_{2}%
}}\mathfrak{g}\left[  \gamma\right]  \right]  =\sum\limits_{\substack{\beta\in
Q;\\\ell\left(  \beta\right)  =m_{1}}}\sum\limits_{\substack{\gamma\in
Q;\\\ell\left(  \gamma\right)  =m_{2}}}\underbrace{\left[  \mathfrak{g}\left[
\beta\right]  ,\mathfrak{g}\left[  \gamma\right]  \right]  }%
_{\substack{\subseteq\mathfrak{g}\left[  \beta+\gamma\right]  \\\text{(since
}\mathfrak{g}\text{ is a }Q\text{-graded Lie algebra)}}}\\
&  \subseteq\sum\limits_{\substack{\beta\in Q;\\\ell\left(  \beta\right)
=m_{1}}}\sum\limits_{\substack{\gamma\in Q;\\\ell\left(  \gamma\right)
=m_{2}}}\underbrace{\mathfrak{g}\left[  \beta+\gamma\right]  }%
_{\substack{\subseteq\mathfrak{g}_{\left[  m_{1}+m_{2}\right]  }\\\text{(by
(\ref{pf.Q-graded.principal.1}), since}\\\ell\left(  \beta\right)
=m_{1}\text{ and }\ell\left(  \gamma\right)  =m_{2}\text{)}}}\subseteq
\sum\limits_{\substack{\beta\in Q;\\\ell\left(  \beta\right)  =m_{1}}%
}\sum\limits_{\substack{\gamma\in Q;\\\ell\left(  \gamma\right)  =m_{2}%
}}\mathfrak{g}_{\left[  m_{1}+m_{2}\right]  }\\
&  \subseteq\mathfrak{g}_{\left[  m_{1}+m_{2}\right]  }%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{g}_{\left[  m_{1}%
+m_{2}\right]  }\text{ is a vector space}\right)  ,
\end{align*}
qed.}. Combined with the fact that $\mathfrak{g}=\bigoplus\limits_{m\in
\mathbb{Z}}\mathfrak{g}_{\left[  m\right]  }$, this yields that the Lie
algebra $\mathfrak{g}$ equipped with the family $\left(  \mathfrak{g}_{\left[
m\right]  }\right)  _{m\in\mathbb{Z}}$ is a $\mathbb{Z}$-graded Lie algebra.
This proves Proposition \ref{prop.Q-graded.principal}.
\end{verlong}

\subsubsection{A few lemmas on generating subspaces of Lie algebras}

We proceed with some facts about generating sets of Lie algebras (free or not):

\begin{lemma}
\label{lem.generation.1}Let $\mathfrak{g}$ be a Lie algebra, and let $T$ be a
vector subspace of $\mathfrak{g}$. Assume that $\mathfrak{g}$ is generated by
$T$ as a Lie algebra.

Let $U$ be a vector subspace of $\mathfrak{g}$ such that $T\subseteq U$ and
$\left[  T,U\right]  \subseteq U$. Then, $U=\mathfrak{g}$.
\end{lemma}

Notice that Lemma \ref{lem.generation.1} is not peculiar to Lie algebras. A
similar result holds (for instance) if ``Lie algebra'' is replaced by
``commutative nonunital algebra'' and ``$\left[  T,U\right]  $'' is replaced
by ``$TU$''.

The following proof is written merely for the sake of completeness;
intuitively, Lemma \ref{lem.generation.1} should be obvious from the
observation that all iterated Lie brackets of elements of $T$ can be written
as linear combinations of Lie brackets of the form $\left[  t_{1},\left[
t_{2},\left[  ...,\left[  t_{k-1},t_{k}\right]  \right]  \right]  \right]  $
(with $t_{1},t_{2},...,t_{k}\in T$) by applying the Jacobi identity iteratively.

\textit{Proof of Lemma \ref{lem.generation.1}.} Define a sequence $\left(
T_{n}\right)  _{n\geq1}$ of vector subspaces of $\mathfrak{g}$ recursively as
follows: Let $T_{1}=T$, and for every positive integer $n$, set $T_{n+1}%
=\left[  T,T_{n}\right]  $.

We have%
\begin{equation}
\left[  T_{i},T_{j}\right]  \subseteq T_{i+j}\ \ \ \ \ \ \ \ \ \ \text{for any
positive integers }i\text{ and }j\text{.} \label{pf.generation.1.additivity}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.generation.1.additivity}):} We will prove
(\ref{pf.generation.1.additivity}) by induction over $i$.
\par
\textit{Induction base:} For any positive integer $j$, we have $T_{j+1}%
=\left[  T,T_{j}\right]  $ (by the definition of $T_{j+1}$) and thus $\left[
\underbrace{T_{1}}_{=T},T_{j}\right]  =\left[  T,T_{j}\right]  =T_{j+1}%
=T_{1+j}$. In other words, (\ref{pf.generation.1.additivity}) holds for $i=1$.
This completes the induction base.
\par
\textit{Induction step:} Let $k$ be a positive integer. Assume that
(\ref{pf.generation.1.additivity}) is proven for $i=k$. We now will prove
(\ref{pf.generation.1.additivity}) for $i=k+1$.
\par
Since (\ref{pf.generation.1.additivity}) is proven for $i=k$, we have%
\begin{equation}
\left[  T_{k},T_{j}\right]  \subseteq T_{k+j}\ \ \ \ \ \ \ \ \ \ \text{for any
positive integer }j\text{.} \label{pf.generation.1.additivity.2}%
\end{equation}
\par
Now, let $j$ be a positive integer. Then, $T_{k+j+1}=\left[  T,T_{k+j}\right]
$ (by the definition of $T_{k+j+1}$) and $T_{j+1}=\left[  T,T_{j}\right]  $
(by the definition of $T_{j+1}$). Now, any $x\in T$, $y\in T_{k}$ and $z\in
T_{j}$ satisfy%
\begin{align*}
\left[  \left[  x,y\right]  ,z\right]   &  =-\underbrace{\left[  \left[
y,z\right]  ,x\right]  }_{=-\left[  x,\left[  y,z\right]  \right]  }-\left[
\underbrace{\left[  z,x\right]  }_{=-\left[  x,z\right]  },y\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the Jacobi identity}\right) \\
&  =\underbrace{-\left(  -\left[  x,\left[  y,z\right]  \right]  \right)
}_{=\left[  x,\left[  y,z\right]  \right]  }-\underbrace{\left[  -\left[
x,z\right]  ,y\right]  }_{=-\left[  \left[  x,z\right]  ,y\right]  =\left[
y,\left[  x,z\right]  \right]  }=\left[  \underbrace{x}_{\in T},\left[
\underbrace{y}_{\in T_{k}},\underbrace{z}_{\in T_{j}}\right]  \right]
-\left[  \underbrace{y}_{\in T_{k}},\left[  \underbrace{x}_{\in T}%
,\underbrace{z}_{\in T_{j}}\right]  \right] \\
&  \in\left[  T,\underbrace{\left[  T_{k},T_{j}\right]  }_{\substack{\subseteq
T_{k+j}\\\text{(by (\ref{pf.generation.1.additivity.2}))}}}\right]  +\left[
T_{k},\underbrace{\left[  T,T_{j}\right]  }_{=T_{j+1}}\right]  \subseteq
\underbrace{\left[  T,T_{k+j}\right]  }_{=T_{k+j+1}}+\underbrace{\left[
T_{k},T_{j+1}\right]  }_{\substack{\subseteq T_{k+j+1}\\\text{(by
(\ref{pf.generation.1.additivity.2}), applied to}\\j+1\text{ instead of
}j\text{)}}}\\
&  \subseteq T_{k+j+1}+T_{k+j+1}\subseteq T_{k+j+1}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }T_{k+j+1}\text{ is a vector space}\right) \\
&  =T_{\left(  k+1\right)  +j}.
\end{align*}
Hence, $\left[  \left[  T,T_{k}\right]  ,T_{j}\right]  \subseteq T_{\left(
k+1\right)  +j}$ (since $T_{\left(  k+1\right)  +j}$ is a vector space). Since
$\left[  T,T_{k}\right]  =T_{k+1}$ (by the definition of $T_{k+1}$), this
rewrites as $\left[  T_{k+1},T_{j}\right]  \subseteq T_{\left(  k+1\right)
+j}$. Since we have proven this for every positive integer $j$, we have thus
proven (\ref{pf.generation.1.additivity}) for $i=k+1$. The induction step is
thus complete. This finishes the proof of (\ref{pf.generation.1.additivity}).}
Now, let $S$ be the vector subspace $\sum\limits_{i\geq1}T_{i}$ of
$\mathfrak{g}$. Then, every positive integer $k$ satisfies $T_{k}\subseteq S$.
In particular, $T_{1}\subseteq S$. Since $S=\sum\limits_{i\geq1}T_{i}$ and
$S=\sum\limits_{i\geq1}T_{i}=\sum\limits_{j\geq1}T_{j}$, we have%
\[
\left[  S,S\right]  =\left[  \sum\limits_{i\geq1}T_{i},\sum\limits_{j\geq
1}T_{j}\right]  =\sum\limits_{i\geq1}\sum\limits_{j\geq1}\underbrace{\left[
T_{i},T_{j}\right]  }_{\substack{\subseteq T_{i+j}\subseteq S\\\text{(since
every positive}\\\text{integer }k\text{ satisfies }T_{k}\subseteq S\text{)}%
}}\subseteq\sum\limits_{i\geq1}\sum\limits_{j\geq1}S\subseteq S
\]
(since $S$ is a vector space). Thus, $S$ is a Lie subalgebra of $\mathfrak{g}%
$. Since $T=T_{1}\subseteq S$, this yields that $S$ is a Lie subalgebra of
$\mathfrak{g}$ containing $T$ as a subset. Since the smallest Lie subalgebra
of $\mathfrak{g}$ containing $T$ as a subset is $\mathfrak{g}$ itself (because
$\mathfrak{g}$ is generated by $T$ as a Lie algebra), this yields that
$S\supseteq\mathfrak{g}$. In other words, $S=\mathfrak{g}$.

Now, it is easy to see that%
\begin{equation}
T_{i}\subseteq U\text{ for every positive integer }i. \label{pf.generation.2}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.generation.2}):} We will prove
(\ref{pf.generation.2}) by induction over $i$.
\par
\textit{Induction base:} We have $T_{1}=T\subseteq U$. Thus,
(\ref{pf.generation.2}) holds for $i=1$. This completes the induction base.
\par
\textit{Induction step:} Let $k$ be a positive integer. Assume that
(\ref{pf.generation.2}) holds for $i=k$. We now will prove
(\ref{pf.generation.2}) for $i=k+1$.
\par
Since (\ref{pf.generation.2}) holds for $i=k$, we have $T_{k}\subseteq U$.
Since $T_{k+1}=\left[  T,T_{k}\right]  $ (by the definition of $T_{k+1}$), we
have $T_{k+1}=\left[  T,\underbrace{T_{k}}_{\subseteq U}\right]
\subseteq\left[  T,U\right]  \subseteq U$. In other words,
(\ref{pf.generation.2}) holds for $i=k+1$. This completes the induction step.
Thus, (\ref{pf.generation.2}) is proven.} Hence,%
\[
\mathfrak{g}=S=\sum\limits_{i\geq1}\underbrace{T_{i}}_{\subseteq U}%
\subseteq\sum\limits_{i\geq1}U\subseteq U
\]
(since $U$ is a vector space). Thus, $U=\mathfrak{g}$, and this proves Lemma
\ref{lem.generation.1}.

The next result is related:

\begin{theorem}
\label{thm.FreeLie.grading1}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie
algebra. Let $T$ be a vector subspace of $\mathfrak{g}\left[  1\right]  $ such
that $\mathfrak{g}$ is generated by $T$ as a Lie algebra. Then,
$T=\mathfrak{g}\left[  1\right]  $.
\end{theorem}

\begin{vershort}
The proof of this theorem proceeds by defining the sequence $\left(
T_{n}\right)  _{n\geq1}$ as in the proof of Lemma \ref{lem.generation.1}, and
showing that $T_{i}\subseteq\mathfrak{g}\left[  i\right]  $ for every positive
integer $i$. The details are left to the reader.
\end{vershort}

\begin{verlong}
\textit{Proof of Theorem \ref{thm.FreeLie.grading1}.} Define a sequence
$\left(  T_{n}\right)  _{n\geq1}$ of vector subspaces of $\mathfrak{g}$
recursively as follows: Let $T_{1}=T$, and for every positive integer $n$, set
$T_{n+1}=\left[  T,T_{n}\right]  $.

Let $S$ be the vector subspace $\sum\limits_{i\geq1}T_{i}$ of $\mathfrak{g}$.
Just as in the proof of Lemma \ref{lem.generation.1}, we can see that
$S=\mathfrak{g}$.

Let $\pi_{1}$ be the canonical projection from the graded vector space
$\mathfrak{g}$ on its $1$-th homogeneous component $\mathfrak{g}\left[
1\right]  $. Then, $\pi_{1}$ sends every homogeneous component of
$\mathfrak{g}$ other than $\mathfrak{g}\left[  1\right]  $ to $0$. In other
words, $\pi_{1}$ sends $\mathfrak{g}\left[  i\right]  $ to $0$ for every
integer $i\neq1$. In other words,%
\begin{equation}
\text{every integer }i\neq1\text{ satisfies }\pi_{1}\left(  \mathfrak{g}%
\left[  i\right]  \right)  =0. \label{pf.FreeLie.grading1}%
\end{equation}


On the other hand, since $\pi_{1}$ is a projection on $\mathfrak{g}\left[
1\right]  $, we have $\mathfrak{g}\left[  1\right]  =\pi_{1}\left(
\mathfrak{g}\right)  $.

Since $\pi_{1}$ is a projection on $\mathfrak{g}\left[  1\right]  $, we have%
\begin{equation}
\pi_{1}\left(  x\right)  =x\ \ \ \ \ \ \ \ \ \ \text{for every }%
x\in\mathfrak{g}\left[  1\right]  . \label{pf.FreeLie.grading0}%
\end{equation}


Now, it is easy to see that%
\begin{equation}
T_{i}\subseteq\mathfrak{g}\left[  i\right]  \ \ \ \ \ \ \ \ \ \ \text{for
every positive integer }i. \label{pf.FreeLie.grading2}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.FreeLie.grading2}):} We will prove
(\ref{pf.FreeLie.grading2}) by induction over $i$.
\par
\textit{Induction base:} We have $T_{1}=T\subseteq\mathfrak{g}\left[
1\right]  $. Thus, (\ref{pf.FreeLie.grading2}) is proven for $i=1$. This
completes the induction base.
\par
\textit{Induction step:} Let $n$ be a positive integer. Assume that
(\ref{pf.FreeLie.grading2}) holds for $i=n$. We now must prove that
(\ref{pf.FreeLie.grading2}) also holds for $i=n+1$.
\par
Since (\ref{pf.FreeLie.grading2}) holds for $i=n$, we have $T_{n}%
\subseteq\mathfrak{g}\left[  n\right]  $. By the definition of $T_{n+1}$, we
have
\begin{align*}
T_{n+1}  &  =\left[  \underbrace{T}_{\subseteq\mathfrak{g}\left[  1\right]
},\underbrace{T_{n}}_{\subseteq\mathfrak{g}\left[  n\right]  }\right]
\subseteq\left[  \mathfrak{g}\left[  1\right]  ,\mathfrak{g}\left[  n\right]
\right]  \subseteq\mathfrak{g}\left[  1+n\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\mathfrak{g}\text{ is a }\mathbb{Z}\text{-graded Lie
algebra}\right) \\
&  =\mathfrak{g}\left[  n+1\right]  .
\end{align*}
Thus, (\ref{pf.FreeLie.grading2}) also holds for $i=n+1$. This completes the
induction step. The induction proof of (\ref{pf.FreeLie.grading2}) is thus
complete.} Hence, for every positive integer $i\geq2$, we have%
\[
\pi_{1}\left(  \underbrace{T_{i}}_{\subseteq\mathfrak{g}\left[  i\right]
}\right)  \subseteq\pi_{1}\left(  \mathfrak{g}\left[  i\right]  \right)  =0
\]
(by (\ref{pf.FreeLie.grading1}), since $i\neq1$). Hence,%
\begin{align*}
\mathfrak{g}\left[  1\right]   &  =\pi_{1}\left(  \underbrace{\mathfrak{g}%
}_{=S=\sum\limits_{i\geq1}T_{i}}\right)  =\pi_{1}\left(  \sum\limits_{i\geq
1}T_{i}\right)  =\sum\limits_{i\geq1}\pi_{1}\left(  T_{i}\right)  =\pi
_{1}\left(  T_{1}\right)  +\sum\limits_{i\geq2}\underbrace{\pi_{1}\left(
T_{i}\right)  }_{\substack{=0\\\text{(since }i\geq2\text{)}}}\\
&  =\pi_{1}\left(  T_{1}\right)  +\underbrace{\sum\limits_{i\geq2}0}_{=0}%
=\pi_{1}\left(  T_{1}\right)  =\left\{  \underbrace{\pi_{1}\left(  x\right)
}_{\substack{=x\\\text{(by (\ref{pf.FreeLie.grading0}), since}\\x\in
T_{1}=T\subseteq\mathfrak{g}\left[  1\right]  \text{)}}}\ \mid\ x\in
T_{1}\right\}  =\left\{  x\ \mid\ x\in T_{1}\right\}  =T_{1}=T.
\end{align*}
This proves Theorem \ref{thm.FreeLie.grading1}.
\end{verlong}

Generating subspaces can help in proving that Lie algebra homomorphisms are
$Q$-graded:

\begin{proposition}
\label{prop.generation.Q-gr}Let $\mathfrak{g}$ and $\mathfrak{h}$ be two
$Q$-graded Lie algebras. Let $T$ be a $Q$-graded vector subspace of
$\mathfrak{g}$. Assume that $\mathfrak{g}$ is generated by $T$ as a Lie algebra.

Let $f:\mathfrak{g}\rightarrow\mathfrak{h}$ be a Lie algebra homomorphism.
Assume that $f\mid_{T}:T\rightarrow\mathfrak{h}$ is a $Q$-graded map.

Then, the map $f$ is $Q$-graded.
\end{proposition}

\begin{vershort}
The proof of this is left to the reader.
\end{vershort}

\begin{verlong}
\textit{Proof of Proposition \ref{prop.generation.Q-gr}.} For every $\alpha\in
Q$, let $P_{\alpha}$ be the vector subspace $\left(  \mathfrak{g}\left[
\alpha\right]  \right)  \cap f^{-1}\left(  \mathfrak{h}\left[  \alpha\right]
\right)  $ of $\mathfrak{g}$. Then,%
\begin{equation}
\left[  P_{\alpha},P_{\beta}\right]  \subseteq P_{\alpha+\beta}%
\ \ \ \ \ \ \ \ \ \ \text{for any }\alpha\in Q\text{ and }\beta\in Q.
\label{pf.generation.Q-gr.PaPb}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.generation.Q-gr.PaPb}):} Let $\alpha\in Q$
and $\beta\in Q$. Let $x\in P_{\alpha}$ and $y\in P_{\beta}$. Then, $x\in
P_{\alpha}=\left(  \mathfrak{g}\left[  \alpha\right]  \right)  \cap
f^{-1}\left(  \mathfrak{h}\left[  \alpha\right]  \right)  $ (by the definition
of $P_{\alpha}$), so that $x\in\mathfrak{g}\left[  \alpha\right]  $ and $x\in
f^{-1}\left(  \mathfrak{h}\left[  \alpha\right]  \right)  $. Also, $y\in
P_{\beta}=\left(  \mathfrak{g}\left[  \beta\right]  \right)  \cap
f^{-1}\left(  \mathfrak{h}\left[  \beta\right]  \right)  $ (by the definition
of $P_{\beta}$), so that $y\in\mathfrak{g}\left[  \beta\right]  $ and $y\in
f^{-1}\left(  \mathfrak{h}\left[  \beta\right]  \right)  $. From $x\in
f^{-1}\left(  \mathfrak{h}\left[  \alpha\right]  \right)  $, we obtain
$f\left(  x\right)  \in\mathfrak{h}\left[  \alpha\right]  $. From $y\in
f^{-1}\left(  \mathfrak{h}\left[  \beta\right]  \right)  $, we get $f\left(
y\right)  \in\mathfrak{h}\left[  \beta\right]  $. Now,%
\begin{align*}
f\left(  \left[  x,y\right]  \right)   &  =\left[  \underbrace{f\left(
x\right)  }_{\in\mathfrak{h}\left[  \alpha\right]  },\underbrace{f\left(
y\right)  }_{\in\mathfrak{h}\left[  \beta\right]  }\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }f\text{ is a Lie algebra
homomorphism}\right) \\
&  \in\left[  \mathfrak{h}\left[  \alpha\right]  ,\mathfrak{h}\left[
\beta\right]  \right]  \subseteq\mathfrak{h}\left[  \alpha+\beta\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{h}\text{ is a
}Q\text{-graded Lie algebra}\right)  ,
\end{align*}
and thus $\left[  x,y\right]  \in f^{-1}\left(  \mathfrak{h}\left[
\alpha+\beta\right]  \right)  $. Combined with%
\[
\left[  \underbrace{x}_{\in\mathfrak{g}\left[  \alpha\right]  },\underbrace{y}%
_{\in\mathfrak{g}\left[  \beta\right]  }\right]  \in\left[  \mathfrak{g}%
\left[  \alpha\right]  ,\mathfrak{g}\left[  \beta\right]  \right]
\subseteq\mathfrak{g}\left[  \alpha+\beta\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\mathfrak{g}\text{ is a }Q\text{-graded Lie algebra}\right)  ;
\]
this yields $\left[  x,y\right]  \in\left(  \mathfrak{g}\left[  \alpha
+\beta\right]  \right)  \cap f^{-1}\left(  \mathfrak{h}\left[  \alpha
+\beta\right]  \right)  $. But since $P_{\alpha+\beta}=\left(  \mathfrak{g}%
\left[  \alpha+\beta\right]  \right)  \cap f^{-1}\left(  \mathfrak{h}\left[
\alpha+\beta\right]  \right)  $ (by the definition of $P_{\alpha+\beta}$),
this rewrites as $\left[  x,y\right]  \in P_{\alpha+\beta}$.
\par
Now forget that we fixed $x$ and $y$. We thus have proven that every $x\in
P_{\alpha}$ and $y\in P_{\beta}$ satisfy $\left[  x,y\right]  \in
P_{\alpha+\beta}$. Since $P_{\alpha+\beta}$ is a vector space, this yields
$\left[  P_{\alpha},P_{\beta}\right]  \subseteq P_{\alpha+\beta}$. This proves
(\ref{pf.generation.Q-gr.PaPb}).}

Now, let $P$ be the vector subspace $\sum\limits_{\alpha\in Q}P_{\alpha}$ of
$\mathfrak{g}$. Then,%
\begin{equation}
P_{\alpha}\subseteq P\text{ for every }\alpha\in Q\text{.}
\label{pf.generation.Q-gr.tauto}%
\end{equation}


But since $P=\sum\limits_{\alpha\in Q}P_{\alpha}$ and $P=\sum\limits_{\alpha
\in Q}P_{\alpha}=\sum\limits_{\beta\in Q}P_{\beta}$ (here, we renamed the
summation index $\alpha$ as $\beta$), we have%
\begin{align*}
\left[  P,P\right]   &  =\left[  \sum\limits_{\alpha\in Q}P_{\alpha}%
,\sum\limits_{\beta\in Q}P_{\beta}\right]  =\sum\limits_{\alpha\in Q}%
\sum\limits_{\beta\in Q}\underbrace{\left[  P_{\alpha},P_{\beta}\right]
}_{\substack{\subseteq P_{\alpha+\beta}\\\text{(by
(\ref{pf.generation.Q-gr.PaPb}))}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since the
Lie bracket is bilinear}\right) \\
&  \subseteq\sum\limits_{\alpha\in Q}\sum\limits_{\beta\in Q}%
\underbrace{P_{\alpha+\beta}}_{\substack{\subseteq P\\\text{(by
(\ref{pf.generation.Q-gr.tauto}), applied to}\\\alpha+\beta\text{ instead of
}\alpha\text{)}}}\subseteq\sum\limits_{\alpha\in Q}\sum\limits_{\beta\in
Q}P\subseteq P\ \ \ \ \ \ \ \ \ \ \left(  \text{since }P\text{ is a vector
space}\right)  .
\end{align*}
As a consequence, $P$ is a Lie subalgebra of $\mathfrak{g}$.

Since $T$ is a $Q$-graded vector subspace, we have $T=\bigoplus\limits_{\alpha
\in Q}T\left[  \alpha\right]  $, and every $\alpha\in Q$ satisfies $T\left[
\alpha\right]  \subseteq\mathfrak{g}\left[  \alpha\right]  $.

Now, $T\subseteq P$\ \ \ \ \footnote{\textit{Proof.} Let $\alpha\in Q$. Let
$x\in T\left[  \alpha\right]  $. Then, $\left(  f\mid_{T}\right)  \left(
x\right)  \in\mathfrak{h}\left[  \alpha\right]  $ (since $f\mid_{T}$ is
$Q$-graded). Thus, $f\left(  x\right)  =\left(  f\mid_{T}\right)  \left(
x\right)  \in\mathfrak{h}\left[  \alpha\right]  $, so that $x\in f^{-1}\left(
\mathfrak{h}\left[  \alpha\right]  \right)  $. Combined with $x\in T\left[
\alpha\right]  \subseteq\mathfrak{g}\left[  \alpha\right]  $, this yields
$x\in\left(  \mathfrak{g}\left[  \alpha\right]  \right)  \cap f^{-1}\left(
\mathfrak{h}\left[  \alpha\right]  \right)  =P_{\alpha}$.
\par
Now forget that we fixed $x$. We thus have proven that every $x\in T\left[
\alpha\right]  $ satisfies $x\in P_{\alpha}$. In other words, $T\left[
\alpha\right]  \subseteq P_{\alpha}$.
\par
Now forget that we fixed $\alpha$. We thus have proven that $T\left[
\alpha\right]  \subseteq P_{\alpha}$ for every $\alpha\in Q$. But
\begin{align*}
T  &  =\bigoplus\limits_{\alpha\in Q}T\left[  \alpha\right]  =\sum
\limits_{\alpha\in Q}\underbrace{T\left[  \alpha\right]  }_{\subseteq
P_{\alpha}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since direct sums are
sums}\right) \\
&  \subseteq\sum\limits_{\alpha\in Q}P_{\alpha}=P,
\end{align*}
qed.}. Hence, $P$ is a Lie subalgebra of $\mathfrak{g}$ containing $T$ as a
subset. But since every Lie subalgebra of $\mathfrak{g}$ containing $T$ as a
subset must be $\mathfrak{g}$ (because $\mathfrak{g}$ is generated by $T$ as a
Lie algebra), this yields that $P=\mathfrak{g}$.

Now, let $\beta\in Q$ be arbitrary. Let $x\in\mathfrak{g}\left[  \beta\right]
$. Then, $x\in\mathfrak{g}\left[  \beta\right]  \subseteq\mathfrak{g}%
=P=\sum\limits_{\alpha\in Q}P_{\alpha}=P_{\beta}+\sum\limits_{\substack{\alpha
\in Q;\\\alpha\neq\beta}}P_{\alpha}$. Hence, there exist some $y\in P_{\beta}$
and some $z\in\sum\limits_{\substack{\alpha\in Q;\\\alpha\neq\beta}}P_{\alpha
}$ such that $x=y+z$. Consider these $y$ and $z$. From $x=y+z$, we obtain
$x-y=z$. But since $\mathfrak{g}$ is $Q$-graded, we have
\[
\mathfrak{g}=\bigoplus\limits_{\alpha\in Q}\mathfrak{g}\left[  \alpha\right]
=\left(  \mathfrak{g}\left[  \beta\right]  \right)  \oplus
\underbrace{\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha\neq\beta
}}\mathfrak{g}\left[  \alpha\right]  }_{\substack{=\sum
\limits_{\substack{\alpha\in Q;\\\alpha\neq\beta}}\mathfrak{g}\left[
\alpha\right]  \\\text{(since direct sums are sums)}}}=\left(  \mathfrak{g}%
\left[  \beta\right]  \right)  \oplus\left(  \sum\limits_{\substack{\alpha\in
Q;\\\alpha\neq\beta}}\mathfrak{g}\left[  \alpha\right]  \right)  .
\]
Thus, the internal direct sum $\left(  \mathfrak{g}\left[  \beta\right]
\right)  \oplus\left(  \sum\limits_{\substack{\alpha\in Q;\\\alpha\neq\beta
}}\mathfrak{g}\left[  \alpha\right]  \right)  $ is well-defined, so that
$\left(  \mathfrak{g}\left[  \beta\right]  \right)  \cap\left(  \sum
\limits_{\substack{\alpha\in Q;\\\alpha\neq\beta}}\mathfrak{g}\left[
\alpha\right]  \right)  =0$.

By the definition of $P_{\beta}$, we have $P_{\beta}=\left(  \mathfrak{g}%
\left[  \beta\right]  \right)  \cap f^{-1}\left(  \mathfrak{h}\left[
\beta\right]  \right)  \subseteq\mathfrak{g}\left[  \beta\right]  $. Hence,
$y\in P_{\beta}\subseteq\mathfrak{g}\left[  \beta\right]  $. Combined with
$x\in\mathfrak{g}\left[  \beta\right]  $, this yields $x-y\in\mathfrak{g}%
\left[  \beta\right]  -\mathfrak{g}\left[  \beta\right]  \subseteq
\mathfrak{g}\left[  \beta\right]  $ (since $\mathfrak{g}\left[  \beta\right]
$ is a vector space). Since $x-y=z$, this rewrites as $z\in\mathfrak{g}\left[
\beta\right]  $. Combined with $z\in\sum\limits_{\substack{\alpha\in
Q;\\\alpha\neq\beta}}\underbrace{P_{\alpha}}_{\substack{\subseteq
\mathfrak{g}\left[  \alpha\right]  \\\text{(this is proven in the
same}\\\text{way as we showed }P_{\beta}\subseteq\mathfrak{g}\left[
\beta\right]  \text{)}}}\subseteq\sum\limits_{\substack{\alpha\in
Q;\\\alpha\neq\beta}}\mathfrak{g}\left[  \alpha\right]  $, this yields
$z\in\left(  \mathfrak{g}\left[  \beta\right]  \right)  \cap\left(
\sum\limits_{\substack{\alpha\in Q;\\\alpha\neq\beta}}\mathfrak{g}\left[
\alpha\right]  \right)  =0$. Hence, $z=0$. Thus, $x-y=z=0$, so that $x=y\in
P_{\beta}=\left(  \mathfrak{g}\left[  \beta\right]  \right)  \cap
f^{-1}\left(  \mathfrak{h}\left[  \beta\right]  \right)  \subseteq
f^{-1}\left(  \mathfrak{h}\left[  \beta\right]  \right)  $, hence $f\left(
x\right)  \in\mathfrak{h}\left[  \beta\right]  $.

Now forget that we fixed $x$. We thus have proven that $f\left(  x\right)
\in\mathfrak{h}\left[  \beta\right]  $ for every $x\in\mathfrak{g}\left[
\beta\right]  $. In other words, $f\left(  \mathfrak{g}\left[  \beta\right]
\right)  \subseteq\mathfrak{h}\left[  \beta\right]  $.

Now forget that we fixed $\beta$. We thus have shown that $f\left(
\mathfrak{g}\left[  \beta\right]  \right)  \subseteq\mathfrak{h}\left[
\beta\right]  $ for every $\beta\in Q$.\ In other words, the map $f$ is
$Q$-graded. This proves Proposition \ref{prop.generation.Q-gr}.
\end{verlong}

Next, a result on free Lie algebras:

\begin{proposition}
\label{prop.Ufree}Let $V$ be a vector space. We let $\operatorname*{FreeLie}V$
denote the free Lie algebra on the vector space $V$ (not on the set $V$), and
let $T\left(  V\right)  $ denote the tensor algebra of $V$. Then, there exists
a canonical algebra isomorphism $U\left(  \operatorname*{FreeLie}V\right)
\rightarrow T\left(  V\right)  $, which commutes with the canonical injections
of $V$ into $U\left(  \operatorname*{FreeLie}V\right)  $ and into $T\left(
V\right)  $.
\end{proposition}

We are going to prove Proposition \ref{prop.Ufree} by combining the universal
properties of the universal enveloping algebra, the free Lie algebra, and the
tensor algebra. Let us first formulate these properties. First, the universal
property of the universal enveloping algebra:

\begin{theorem}
\label{thm.universal.U}Let $\mathfrak{g}$ be a Lie algebra. We denote by
$\iota_{\mathfrak{g}}^{U}:\mathfrak{g}\rightarrow U\left(  \mathfrak{g}%
\right)  $ the canonical map from $\mathfrak{g}$ into $U\left(  \mathfrak{g}%
\right)  $. (This map $\iota_{\mathfrak{g}}^{U}$ is injective by the
Poincar\'{e}-Birkhoff-Witt theorem, but this is not relevant to the current
theorem.) For any algebra $B$ and any Lie algebra homomorphism $f:\mathfrak{g}%
\rightarrow B$ (where the Lie algebra structure on $B$ is defined by the
commutator of the multiplication of $B$), there exists a unique algebra
homomorphism $F:U\left(  \mathfrak{g}\right)  \rightarrow B$ satisfying
$f=F\circ\iota_{\mathfrak{g}}^{U}$.
\end{theorem}

Next, the universal property of the free Lie algebra:

\begin{theorem}
\label{thm.universal.FreeLie}Let $V$ be a vector space. We denote by
$\iota_{V}^{\operatorname*{FreeLie}}:V\rightarrow\operatorname*{FreeLie}V$ the
canonical map from $V$ into $\operatorname*{FreeLie}V$. (The construction of
$\operatorname*{FreeLie}V$ readily shows that this map $\iota_{V}%
^{\operatorname*{FreeLie}}$ is injective.) For any Lie algebra $\mathfrak{h}$
and any linear map $f:V\rightarrow\mathfrak{h}$, there exists a unique Lie
algebra homomorphism $F:\operatorname*{FreeLie}V\rightarrow\mathfrak{h}$
satisfying $f=F\circ\iota_{V}^{\operatorname*{FreeLie}}$.
\end{theorem}

Finally, the universal property of the tensor algebra:

\begin{theorem}
\label{thm.universal.tensor}Let $V$ be a vector space. We denote by $\iota
_{V}^{T}:V\rightarrow T\left(  V\right)  $ the canonical map from $V$ into
$T\left(  V\right)  $. (This map $\iota_{V}^{T}$ is known to be injective.)
For any algebra $B$ and any linear map $f:V\rightarrow B$, there exists a
unique algebra homomorphism $F:T\left(  V\right)  \rightarrow B$ satisfying
$f=F\circ\iota_{V}^{T}$.
\end{theorem}

\textit{Proof of Proposition \ref{prop.Ufree}.} The algebra $T\left(
V\right)  $ canonically becomes a Lie algebra (by defining the Lie bracket on
$T\left(  V\right)  $ as the commutator of the multiplication). Similarly, the
algebra $U\left(  \operatorname*{FreeLie}V\right)  $ becomes a Lie algebra.

Applying Theorem \ref{thm.universal.FreeLie} to $\mathfrak{h}=T\left(
V\right)  $ and $f=\iota_{V}^{T}$, we obtain that there exists a unique Lie
algebra homomorphism $F:\operatorname*{FreeLie}V\rightarrow T\left(  V\right)
$ satisfying $\iota_{V}^{T}=F\circ\iota_{V}^{\operatorname*{FreeLie}}$. Denote
this Lie algebra homomorphism $F$ by $h$. Then, $h:\operatorname*{FreeLie}%
V\rightarrow T\left(  V\right)  $ is a Lie algebra homomorphism satisfying
$\iota_{V}^{T}=h\circ\iota_{V}^{\operatorname*{FreeLie}}$.

Applying Theorem \ref{thm.universal.U} to $\mathfrak{g}%
=\operatorname*{FreeLie}V$, $B=T\left(  V\right)  $ and $f=h$, we obtain that
there exists a unique algebra homomorphism $F:U\left(  \operatorname*{FreeLie}%
V\right)  \rightarrow T\left(  V\right)  $ satisfying $h=F\circ\iota
_{\operatorname*{FreeLie}V}^{U}$. Denote this algebra homomorphism $F$ by
$\alpha$. Then, $\alpha:U\left(  \operatorname*{FreeLie}V\right)  \rightarrow
T\left(  V\right)  $ is an algebra homomorphism satisfying $h=\alpha\circ
\iota_{\operatorname*{FreeLie}V}^{U}$.

Applying Theorem \ref{thm.universal.tensor} to $B=U\left(
\operatorname*{FreeLie}V\right)  $ and $f=\iota_{\operatorname*{FreeLie}V}%
^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}$, we obtain that there exists a
unique algebra homomorphism $F:T\left(  V\right)  \rightarrow U\left(
\operatorname*{FreeLie}V\right)  $ satisfying $\iota_{\operatorname*{FreeLie}%
V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}=F\circ\iota_{V}^{T}$. Denote
this algebra homomorphism $F$ by $\beta$. Then, $\beta:T\left(  V\right)
\rightarrow U\left(  \operatorname*{FreeLie}V\right)  $ is an algebra
homomorphism satisfying $\iota_{\operatorname*{FreeLie}V}^{U}\circ\iota
_{V}^{\operatorname*{FreeLie}}=\beta\circ\iota_{V}^{T}$.

Both $\alpha$ and $\beta$ are algebra homomorphisms, and therefore Lie algebra
homomorphisms. Also, $\iota_{\operatorname*{FreeLie}V}^{U}$ is a Lie algebra homomorphism.

We have%
\[
\beta\circ\underbrace{\alpha\circ\iota_{\operatorname*{FreeLie}V}^{U}}%
_{=h}\circ\iota_{V}^{\operatorname*{FreeLie}}=\beta\circ\underbrace{h\circ
\iota_{V}^{\operatorname*{FreeLie}}}_{=\iota_{V}^{T}}=\beta\circ\iota_{V}%
^{T}=\iota_{\operatorname*{FreeLie}V}^{U}\circ\iota_{V}%
^{\operatorname*{FreeLie}}%
\]
and%
\[
\alpha\circ\underbrace{\beta\circ\iota_{V}^{T}}_{=\iota
_{\operatorname*{FreeLie}V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}%
}=\underbrace{\alpha\circ\iota_{\operatorname*{FreeLie}V}^{U}}_{=h}\circ
\iota_{V}^{\operatorname*{FreeLie}}=h\circ\iota_{V}^{\operatorname*{FreeLie}%
}=\iota_{V}^{T}.
\]


Now, applying Theorem \ref{thm.universal.FreeLie} to $\mathfrak{h}=U\left(
\operatorname*{FreeLie}V\right)  $ and $f=\iota_{\operatorname*{FreeLie}V}%
^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}$, we obtain that there exists a
unique Lie algebra homomorphism $F:\operatorname*{FreeLie}V\rightarrow
U\left(  \operatorname*{FreeLie}V\right)  $ satisfying $\iota
_{\operatorname*{FreeLie}V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}%
=F\circ\iota_{V}^{\operatorname*{FreeLie}}$. Thus, any two Lie algebra
homomorphisms $F:\operatorname*{FreeLie}V\rightarrow U\left(
\operatorname*{FreeLie}V\right)  $ satisfying $\iota_{\operatorname*{FreeLie}%
V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}=F\circ\iota_{V}%
^{\operatorname*{FreeLie}}$ must be equal. Since $\beta\circ\alpha\circ
\iota_{\operatorname*{FreeLie}V}^{U}$ and $\iota_{\operatorname*{FreeLie}%
V}^{U}$ are two such Lie algebra homomorphisms (because we know that
$\beta\circ\alpha\circ\iota_{\operatorname*{FreeLie}V}^{U}\circ\iota
_{V}^{\operatorname*{FreeLie}}=\iota_{\operatorname*{FreeLie}V}^{U}\circ
\iota_{V}^{\operatorname*{FreeLie}}$ and clearly $\iota
_{\operatorname*{FreeLie}V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}%
=\iota_{\operatorname*{FreeLie}V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}%
$), this yields that $\beta\circ\alpha\circ\iota_{\operatorname*{FreeLie}%
V}^{U}$ and $\iota_{\operatorname*{FreeLie}V}^{U}$ must be equal. In other
words,%
\[
\beta\circ\alpha\circ\iota_{\operatorname*{FreeLie}V}^{U}=\iota
_{\operatorname*{FreeLie}V}^{U}.
\]


Next, applying Theorem \ref{thm.universal.U} to $\mathfrak{g}%
=\operatorname*{FreeLie}V$, $B=U\left(  \operatorname*{FreeLie}V\right)  $ and
$f=\iota_{\operatorname*{FreeLie}V}^{U}$, we obtain that there exists a unique
algebra homomorphism $F:U\left(  \operatorname*{FreeLie}V\right)  \rightarrow
U\left(  \operatorname*{FreeLie}V\right)  $ satisfying $\iota
_{\operatorname*{FreeLie}V}^{U}=F\circ\iota_{\operatorname*{FreeLie}V}^{U}$.
Thus, any two algebra homomorphisms $F:U\left(  \operatorname*{FreeLie}%
V\right)  \rightarrow U\left(  \operatorname*{FreeLie}V\right)  $ satisfying
$\iota_{\operatorname*{FreeLie}V}^{U}=F\circ\iota_{\operatorname*{FreeLie}%
V}^{U}$ must be equal. Since $\beta\circ\alpha$ and $\operatorname*{id}%
\nolimits_{U\left(  \operatorname*{FreeLie}V\right)  }$ are two such algebra
homomorphisms (because $\beta\circ\alpha\circ\iota_{\operatorname*{FreeLie}%
V}^{U}=\iota_{\operatorname*{FreeLie}V}^{U}$ and $\operatorname*{id}%
\nolimits_{U\left(  \operatorname*{FreeLie}V\right)  }\circ\iota
_{\operatorname*{FreeLie}V}^{U}=\iota_{\operatorname*{FreeLie}V}^{U}$), this
yields that $\beta\circ\alpha$ and $\operatorname*{id}\nolimits_{U\left(
\operatorname*{FreeLie}V\right)  }$ must be equal. Thus,%
\[
\beta\circ\alpha=\operatorname*{id}\nolimits_{U\left(  \operatorname*{FreeLie}%
V\right)  }.
\]


On the other hand, applying Theorem \ref{thm.universal.tensor} to $B=T\left(
V\right)  $ and $f=\iota_{V}^{T}$, we obtain that there exists a unique
algebra homomorphism $F:T\left(  V\right)  \rightarrow T\left(  V\right)  $
satisfying $\iota_{V}^{T}=F\circ\iota_{V}^{T}$. Therefore, any two algebra
homomorphisms $F:T\left(  V\right)  \rightarrow T\left(  V\right)  $
satisfying $\iota_{V}^{T}=F\circ\iota_{V}^{T}$ must be equal. Since
$\alpha\circ\beta$ and $\operatorname*{id}\nolimits_{T\left(  V\right)  }$ are
two such algebra homomorphisms (because we know that $\alpha\circ\beta
\circ\iota_{V}^{T}=\iota_{V}^{T}$ and $\operatorname*{id}\nolimits_{T\left(
V\right)  }\circ\iota_{V}^{T}=\iota_{V}^{T}$), this yields that $\alpha
\circ\beta$ and $\operatorname*{id}\nolimits_{T\left(  V\right)  }$ must be
equal. In other words, $\alpha\circ\beta=\operatorname*{id}\nolimits_{T\left(
V\right)  }$. Combined with $\beta\circ\alpha=\operatorname*{id}%
\nolimits_{U\left(  \operatorname*{FreeLie}V\right)  }$, this yields that
$\alpha$ and $\beta$ are mutually inverse, and thus $\alpha$ and $\beta$ are
algebra isomorphisms. Hence, $\alpha:U\left(  \operatorname*{FreeLie}V\right)
\rightarrow T\left(  V\right)  $ is a canonical algebra isomorphism. Also,
$\alpha$ commutes with the canonical injections of $V$ into $U\left(
\operatorname*{FreeLie}V\right)  $ and into $T\left(  V\right)  $, because%
\[
\underbrace{\alpha\circ\iota_{\operatorname*{FreeLie}V}^{U}}_{=h}\circ
\iota_{V}^{\operatorname*{FreeLie}}=h\circ\iota_{V}^{\operatorname*{FreeLie}%
}=\iota_{V}^{T}.
\]
Hence, there exists a canonical algebra isomorphism $U\left(
\operatorname*{FreeLie}V\right)  \rightarrow T\left(  V\right)  $, which
commutes with the canonical injections of $V$ into $U\left(
\operatorname*{FreeLie}V\right)  $ and into $T\left(  V\right)  $ (namely,
$\alpha$). Proposition \ref{prop.Ufree} is proven.

\begin{verlong}
There is a special version of Proposition \ref{prop.Ufree} available for
graded vector spaces:

\begin{proposition}
\label{prop.Ufree.gr}Let $Q$ be an abelian group. Let $V$ be a $Q$-graded
vector space. Let us use the notations of Proposition \ref{prop.Ufree}. Then,
the canonical algebra isomorphism $U\left(  \operatorname*{FreeLie}V\right)
\rightarrow T\left(  V\right)  $ constructed in Proposition \ref{prop.Ufree}
is an isomorphism of $Q$\textbf{-graded} algebras.
\end{proposition}

One way to prove Proposition \ref{prop.Ufree.gr} is to scatter the word
``graded'' across the proof of Proposition \ref{prop.Ufree}; of course, we
would need the graded analogues of Theorems \ref{thm.universal.tensor},
\ref{thm.universal.U} and \ref{thm.universal.FreeLie} for this to work. Here
is a slightly different way, which will require only the graded version of
Theorem \ref{thm.universal.tensor}:

\begin{theorem}
\label{thm.universal.tensor.gr}Let $Q$ be an abelian group. Let $V$ be a
$Q$-graded vector space. We denote by $\iota_{V}^{T}:V\rightarrow T\left(
V\right)  $ the canonical map from $V$ into $T\left(  V\right)  $. (This map
$\iota_{V}^{T}$ is known to be injective.) Let $B$ be any $Q$-graded algebra,
and $f:V\rightarrow B$ be any $Q$-graded linear map. According to Theorem
\ref{thm.universal.tensor}, there exists a unique algebra homomorphism
$F:T\left(  V\right)  \rightarrow B$ satisfying $f=F\circ\iota_{V}^{T}$. This
homomorphism $F$ is $Q$-graded.
\end{theorem}

\textit{Proof of Theorem \ref{thm.universal.tensor.gr}.} Consider the unique
algebra homomorphism $F:T\left(  V\right)  \rightarrow B$ satisfying
$f=F\circ\iota_{V}^{T}$. We need to show that this $F$ is $Q$-graded.

For every $n\in\mathbb{N}$ and every $\left(  q_{1},q_{2},...,q_{n}\right)
\in Q^{n}$ and every $w\in\left(  V\left[  q_{1}\right]  \right)
\otimes\left(  V\left[  q_{2}\right]  \right)  \otimes...\otimes\left(
V\left[  q_{n}\right]  \right)  $, we have%
\begin{equation}
F\left(  w\right)  \in B\left[  q_{1}+q_{2}+...+q_{n}\right]  .
\label{pf.universal.tensor.gr.1}%
\end{equation}


\textit{Proof of (\ref{pf.universal.tensor.gr.1}):} We will treat the map
$\iota_{V}^{T}$ as an inclusion map, so that $\iota_{V}^{T}\left(  x\right)
=x$ for every $x\in V$.

Let $n\in\mathbb{N}$ and $\left(  q_{1},q_{2},...,q_{n}\right)  \in Q^{n}$.

We need to prove the relation (\ref{pf.universal.tensor.der.gr.1}) for all
$w\in\left(  V\left[  q_{1}\right]  \right)  \otimes\left(  V\left[
q_{2}\right]  \right)  \otimes...\otimes\left(  V\left[  q_{n}\right]
\right)  $. In order to achieve this, it is enough to prove the relation
(\ref{pf.universal.tensor.der.gr.1}) for all pure tensors $w\in\left(
V\left[  q_{1}\right]  \right)  \otimes\left(  V\left[  q_{2}\right]  \right)
\otimes...\otimes\left(  V\left[  q_{n}\right]  \right)  $ (because every
tensor is a linear combination of pure tensors, but the relation
(\ref{pf.universal.tensor.gr.1}) is linear in $w$). Thus, we can assume WLOG
that $w$ is a pure tensor. Assume this. Then, there exists a $\left(
v_{1},v_{2},...,v_{n}\right)  \in\left(  V\left[  q_{1}\right]  \right)
\times\left(  V\left[  q_{2}\right]  \right)  \times...\times\left(  V\left[
q_{n}\right]  \right)  $ such that $w=v_{1}\otimes v_{2}\otimes...\otimes
v_{n}$. Consider this $\left(  v_{1},v_{2},...,v_{n}\right)  $. We have
$w=v_{1}\otimes v_{2}\otimes...\otimes v_{n}=v_{1}v_{2}...v_{n}$ (since the
multiplication on the algebra $T\left(  V\right)  $ is given by the tensor
product). On the other hand, every $i\in\left\{  1,2,...,n\right\}  $
satisfies $v_{i}\in V\left[  q_{i}\right]  \subseteq V$, and thus $\iota
_{V}^{T}\left(  v_{i}\right)  =v_{i}$ (since $\iota_{V}^{T}\left(  x\right)
=x$ for every $x\in V$), so that $\underbrace{f}_{=F\circ\iota_{V}^{T}}\left(
v_{i}\right)  =\left(  F\circ\iota_{V}^{T}\right)  \left(  v_{i}\right)
=F\left(  \underbrace{\iota_{V}^{T}\left(  v_{i}\right)  }_{=v_{i}}\right)
=F\left(  v_{i}\right)  $. Thus, $\left(  f\left(  v_{1}\right)  ,f\left(
v_{2}\right)  ,...,f\left(  v_{n}\right)  \right)  =\left(  F\left(
v_{1}\right)  ,F\left(  v_{2}\right)  ,...,F\left(  v_{n}\right)  \right)  $,
so that $f\left(  v_{1}\right)  f\left(  v_{2}\right)  ...f\left(
v_{n}\right)  =F\left(  v_{1}\right)  F\left(  v_{2}\right)  ...F\left(
v_{n}\right)  $. Hence,%
\begin{align*}
F\left(  w\right)   &  =F\left(  v_{1}v_{2}...v_{n}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }w=v_{1}v_{2}...v_{n}\right) \\
&  =F\left(  v_{1}\right)  F\left(  v_{2}\right)  ...F\left(  v_{n}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }F\text{ is an algebra homomorphism}%
\right) \\
&  =f\left(  v_{1}\right)  f\left(  v_{2}\right)  ...f\left(  v_{n}\right)  .
\end{align*}
But every $i\in\left\{  1,2,...,n\right\}  $ satisfies $f\left(  v_{i}\right)
\in B\left[  q_{i}\right]  $ (because $v_{i}\in V\left[  q_{i}\right]  $ and
since $f$ is $Q$-graded). Hence, $\left(  f\left(  v_{1}\right)  ,f\left(
v_{2}\right)  ,...,f\left(  v_{n}\right)  \right)  \in\left(  B\left[
q_{1}\right]  \right)  \times\left(  B\left[  q_{2}\right]  \right)
\times...\times\left(  B\left[  q_{n}\right]  \right)  $. Thus,
\[
f\left(  v_{1}\right)  f\left(  v_{2}\right)  ...f\left(  v_{n}\right)
\in\left(  B\left[  q_{1}\right]  \right)  \left(  B\left[  q_{2}\right]
\right)  ...\left(  B\left[  q_{n}\right]  \right)  \subseteq B\left[
q_{1}+q_{2}+...+q_{n}\right]
\]
(since $B$ is a graded algebra). Altogether, we now have%
\[
F\left(  w\right)  =f\left(  v_{1}\right)  f\left(  v_{2}\right)  ...f\left(
v_{n}\right)  \in B\left[  q_{1}+q_{2}+...+q_{n}\right]  .
\]
This proves (\ref{pf.universal.tensor.gr.1}).

Now, let $q\in Q$. By the definition of the grading on a tensor product, we
have%
\[
V^{\otimes n}\left[  q\right]  =\bigoplus\limits_{\substack{\left(
q_{1},q_{2},...,q_{n}\right)  \in Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}\left(
V\left[  q_{1}\right]  \right)  \otimes\left(  V\left[  q_{2}\right]  \right)
\otimes...\otimes\left(  V\left[  q_{n}\right]  \right)
\]
for every $n\in\mathbb{N}$. On the other hand, $T\left(  V\right)
=\bigoplus\limits_{n\in\mathbb{N}}V^{\otimes n}$ (where the direct sum is a
direct sum of graded vector spaces), so that%
\begin{align*}
\left(  T\left(  V\right)  \right)  \left[  q\right]   &  =\left(
\bigoplus\limits_{n\in\mathbb{N}}V^{\otimes n}\right)  \left[  q\right]
=\bigoplus\limits_{n\in\mathbb{N}}\underbrace{V^{\otimes n}\left[  q\right]
}_{=\bigoplus\limits_{\substack{\left(  q_{1},q_{2},...,q_{n}\right)  \in
Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}\left(  V\left[  q_{1}\right]  \right)
\otimes\left(  V\left[  q_{2}\right]  \right)  \otimes...\otimes\left(
V\left[  q_{n}\right]  \right)  }\\
&  =\bigoplus\limits_{n\in\mathbb{N}}\bigoplus\limits_{\substack{\left(
q_{1},q_{2},...,q_{n}\right)  \in Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}\left(
V\left[  q_{1}\right]  \right)  \otimes\left(  V\left[  q_{2}\right]  \right)
\otimes...\otimes\left(  V\left[  q_{n}\right]  \right) \\
&  =\sum\limits_{n\in\mathbb{N}}\sum\limits_{\substack{\left(  q_{1}%
,q_{2},...,q_{n}\right)  \in Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}\left(  V\left[
q_{1}\right]  \right)  \otimes\left(  V\left[  q_{2}\right]  \right)
\otimes...\otimes\left(  V\left[  q_{n}\right]  \right)
\end{align*}
(since direct sums are sums). Thus,%
\begin{align*}
&  F\left(  \left(  T\left(  V\right)  \right)  \left[  q\right]  \right)
=F\left(  \sum\limits_{n\in\mathbb{N}}\sum\limits_{\substack{\left(
q_{1},q_{2},...,q_{n}\right)  \in Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}\left(
V\left[  q_{1}\right]  \right)  \otimes\left(  V\left[  q_{2}\right]  \right)
\otimes...\otimes\left(  V\left[  q_{n}\right]  \right)  \right) \\
&  =\sum\limits_{n\in\mathbb{N}}\sum\limits_{\substack{\left(  q_{1}%
,q_{2},...,q_{n}\right)  \in Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}%
}\underbrace{F\left(  \left(  V\left[  q_{1}\right]  \right)  \otimes\left(
V\left[  q_{2}\right]  \right)  \otimes...\otimes\left(  V\left[
q_{n}\right]  \right)  \right)  }_{\substack{\subseteq B\left[  q_{1}%
+q_{2}+...+q_{n}\right]  \\\text{(since (\ref{pf.universal.tensor.gr.1})
yields that }F\left(  w\right)  \in B\left[  q_{1}+q_{2}+...+q_{n}\right]
\\\text{for every }w\in\left(  V\left[  q_{1}\right]  \right)  \otimes\left(
V\left[  q_{2}\right]  \right)  \otimes...\otimes\left(  V\left[
q_{n}\right]  \right)  \text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }F\text{ is linear}\right) \\
&  \subseteq\sum\limits_{n\in\mathbb{N}}\sum\limits_{\substack{\left(
q_{1},q_{2},...,q_{n}\right)  \in Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}B\left[
\underbrace{q_{1}+q_{2}+...+q_{n}}_{=q}\right]  =\sum\limits_{n\in\mathbb{N}%
}\sum\limits_{\substack{\left(  q_{1},q_{2},...,q_{n}\right)  \in
Q^{n};\\q_{1}+q_{2}+...+q_{n}=q}}B\left[  q\right]  \subseteq B\left[
q\right]
\end{align*}
(since $B\left[  q\right]  $ is a vector space).

Now forget that we fixed $q$. We thus have shown that $F\left(  \left(
T\left(  V\right)  \right)  \left[  q\right]  \right)  \subseteq B\left[
q\right]  $. The map $F$ therefore is $Q$-graded. Theorem
\ref{thm.universal.tensor.gr} is thus proven.

\textit{Proof of Proposition \ref{prop.Ufree.gr}.} Define the maps $\alpha$
and $\beta$ as in the proof of Proposition \ref{prop.Ufree}. Then, $\beta$ is
the unique algebra homomorphism $F:T\left(  V\right)  \rightarrow U\left(
\operatorname*{FreeLie}V\right)  $ satisfying $\iota_{\operatorname*{FreeLie}%
V}^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}=F\circ\iota_{V}^{T}$. Hence,
Theorem \ref{thm.universal.tensor.gr} (applied to $B=U\left(
\operatorname*{FreeLie}V\right)  $ and $f=\iota_{\operatorname*{FreeLie}V}%
^{U}\circ\iota_{V}^{\operatorname*{FreeLie}}$) yields that this homomorphism
$\beta$ is $Q$-graded. Also, we have seen in the proof of Proposition
\ref{prop.Ufree} that $\beta$ is an algebra isomorphism, and that $\alpha$ and
$\beta$ are mutually inverse.

Since $\alpha$ and $\beta$ are mutually inverse, we have $\alpha=\beta^{-1}$,
so that $\alpha$ is the inverse of a $Q$-graded algebra isomorphism (because
$\beta$ is a $Q$-graded algebra isomorphism). Thus, $\alpha$ itself is
$Q$-graded (because any inverse of a $Q$-graded isomorphism must itself be
$Q$-graded). Since $\alpha$ is the canonical algebra isomorphism $U\left(
\operatorname*{FreeLie}V\right)  \rightarrow T\left(  V\right)  $ constructed
in Proposition \ref{prop.Ufree}, this yields that the canonical algebra
isomorphism $U\left(  \operatorname*{FreeLie}V\right)  \rightarrow T\left(
V\right)  $ constructed in Proposition \ref{prop.Ufree} is $Q$-graded. Hence,
the canonical algebra isomorphism $U\left(  \operatorname*{FreeLie}V\right)
\rightarrow T\left(  V\right)  $ constructed in Proposition \ref{prop.Ufree}
is an isomorphism of $Q$-graded algebras. Proposition \ref{prop.Ufree.gr} is proven.
\end{verlong}

\subsubsection{Universality of the tensor algebra with respect to derivations}

Next, let us notice that the universal property of the tensor algebra (Theorem
\ref{thm.universal.tensor}) has an analogue for derivations in lieu of algebra homomorphisms:

\begin{theorem}
\label{thm.universal.tensor.der}Let $V$ be a vector space. We denote by
$\iota_{V}^{T}:V\rightarrow T\left(  V\right)  $ the canonical map from $V$
into $T\left(  V\right)  $. (This map $\iota_{V}^{T}$ is known to be
injective.) For any $T\left(  V\right)  $-bimodule $M$ and any linear map
$f:V\rightarrow M$, there exists a unique derivation $F:T\left(  V\right)
\rightarrow M$ satisfying $f=F\circ\iota_{V}^{T}$.
\end{theorem}

It should be noticed that ``derivation'' means ``$\mathbb{C}$-linear
derivation'' here.

Before we prove this theorem, let us extend its uniqueness part a bit:

\begin{proposition}
\label{prop.derivation.unique}Let $A$ be an algebra. Let $M$ be an
$A$-bimodule, and $d:A\rightarrow M$ and $e:A\rightarrow M$ two derivations.
Let $S$ be a subset of $A$ which generates $A$ as an algebra. Assume that
$d\mid_{S}=e\mid_{S}$. Then, $d=e$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.derivation.unique}.} Let $U$ be the
subset $\operatorname*{Ker}\left(  d-e\right)  $ of $A$. Clearly, $U$ is a
vector space (since $d-e$ is a linear map (since $d$ and $e$ are linear)).

It is known that any derivation $f:A\rightarrow M$ satisfies $f\left(
1\right)  =0$. Applying this to $f=d$, we get $d\left(  1\right)  =0$.
Similarly, $e\left(  1\right)  =0$. Thus, $\left(  d-e\right)  \left(
1\right)  =\underbrace{d\left(  1\right)  }_{=0}-\underbrace{e\left(
1\right)  }_{=0}=0$, so that $1\in\operatorname*{Ker}\left(  d-e\right)  =U$.

Now let $b\in U$ and $c\in U$. Since $b\in U=\operatorname*{Ker}\left(
d-e\right)  $, we have $\left(  d-e\right)  \left(  b\right)  =0$. Thus,
$d\left(  b\right)  -e\left(  b\right)  =\left(  d-e\right)  \left(  b\right)
=0$, so that $d\left(  b\right)  =e\left(  b\right)  $. Similarly, $d\left(
c\right)  =e\left(  c\right)  $.

Now, since $d$ is a derivation, the Leibniz formula yields $d\left(
bc\right)  =d\left(  b\right)  \cdot c+b\cdot d\left(  c\right)  $. Similarly,
$e\left(  bc\right)  =e\left(  b\right)  \cdot c+b\cdot e\left(  c\right)  $.
Hence,%
\begin{align*}
\left(  d-e\right)  \left(  bc\right)   &  =\underbrace{d\left(  bc\right)
}_{=d\left(  b\right)  \cdot c+b\cdot d\left(  c\right)  }%
-\underbrace{e\left(  bc\right)  }_{=e\left(  b\right)  \cdot c+b\cdot
e\left(  c\right)  }=\left(  \underbrace{d\left(  b\right)  }_{=e\left(
b\right)  }\cdot c+b\cdot\underbrace{d\left(  c\right)  }_{=e\left(  c\right)
}\right)  -\left(  e\left(  b\right)  \cdot c+b\cdot e\left(  c\right)
\right) \\
&  =\left(  e\left(  b\right)  \cdot c+b\cdot e\left(  c\right)  \right)
-\left(  e\left(  b\right)  \cdot c+b\cdot e\left(  c\right)  \right)  =0.
\end{align*}
In other words, $bc\in\operatorname*{Ker}\left(  d-e\right)  =U$.

Now forget that we fixed $b$ and $c$. We have thus showed that any $b\in U$
and $c\in U$ satisfy $bc\in U$. Combined with the fact that $U$ is a vector
space and that $1\in U$, this yields that $U$ is a subalgebra of $A$. Since
$S\subseteq U$ (because every $s\in S$ satisfies%
\[
\left(  d-e\right)  \left(  s\right)  =\underbrace{d\left(  s\right)
}_{=\left(  d\mid_{S}\right)  \left(  s\right)  }-\underbrace{e\left(
s\right)  }_{=\left(  e\mid_{S}\right)  \left(  s\right)  }%
=\underbrace{\left(  d\mid_{S}\right)  }_{=e\mid_{S}}\left(  s\right)
-\left(  e\mid_{S}\right)  \left(  s\right)  =\left(  e\mid_{S}\right)
\left(  s\right)  -\left(  e\mid_{S}\right)  \left(  s\right)  =0
\]
and thus $s\in\operatorname*{Ker}\left(  d-e\right)  =U$), this yields that
$U$ is a subalgebra of $A$ containing $S$ as a subset. But since the smallest
subalgebra of $A$ containing $S$ as a subset is $A$ itself (because $S$
generates $A$ as an algebra), this yields that $U\supseteq A$. Hence,
$A\subseteq U=\operatorname*{Ker}\left(  d-e\right)  $, so that $d-e=0$ and
thus $d=e$. Proposition \ref{prop.derivation.unique} is proven.

\textit{Proof of Theorem \ref{thm.universal.tensor.der}.} For any
$n\in\mathbb{N}$, we can define a linear map $\Phi_{n}:V^{\otimes
n}\rightarrow M$ by the equation%
\begin{equation}
\left(
\begin{array}
[c]{r}%
\Phi_{n}\left(  v_{1}\otimes v_{2}\otimes...\otimes v_{n}\right)
=\sum\limits_{k=1}^{n}v_{1}\cdot v_{2}\cdot...\cdot v_{k-1}\cdot f\left(
v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot v_{n}\\
\text{for all }v_{1},v_{2},...,v_{n}\in V
\end{array}
\right)  \label{pf.universal.tensor.der.Phin}%
\end{equation}
(by the universal property of the tensor product, since the term
$\sum\limits_{k=1}^{n}v_{1}\cdot v_{2}\cdot...\cdot v_{k-1}\cdot f\left(
v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot v_{n}$ is clearly
multilinear in $v_{1}$, $v_{2}$, $...$, $v_{n}$). Define this map $\Phi_{n}$.
Let $\Phi$ be the map $\bigoplus\limits_{n\in\mathbb{N}}\Phi_{n}%
:\bigoplus\limits_{n\in\mathbb{N}}V^{\otimes n}\rightarrow M$. Then, every
$n\in\mathbb{N}$ and every $v_{1},v_{2},...,v_{n}$ satisfy%
\begin{align}
\Phi\left(  v_{1}\otimes v_{2}\otimes...\otimes v_{n}\right)   &  =\Phi
_{n}\left(  v_{1}\otimes v_{2}\otimes...\otimes v_{n}\right) \nonumber\\
&  =\sum\limits_{k=1}^{n}v_{1}\cdot v_{2}\cdot...\cdot v_{k-1}\cdot f\left(
v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot v_{n}.
\label{pf.universal.tensor.der.Phi}%
\end{align}


Since $\bigoplus\limits_{n\in\mathbb{N}}V^{\otimes n}=T\left(  V\right)  $,
the map $\Phi$ is a map from $T\left(  V\right)  $ to $M$. We will now prove
that $\Phi$ is a derivation. In fact, in order to prove this, we must show
that%
\begin{equation}
\Phi\left(  ab\right)  =\Phi\left(  a\right)  \cdot b+a\cdot\Phi\left(
b\right)  \ \ \ \ \ \ \ \ \ \ \text{for any }a\in T\left(  V\right)  \text{
and }b\in T\left(  V\right)  . \label{pf.universal.tensor.der.Phider}%
\end{equation}


\textit{Proof of (\ref{pf.universal.tensor.der.Phider}):} Every element of
$T\left(  V\right)  $ is a linear combination of elements of $V^{\otimes n}$
for various $n\in\mathbb{N}$ (because $T\left(  V\right)  =\bigoplus
\limits_{n\in\mathbb{N}}V^{\otimes n}$). Meanwhile, every element of
$V^{\otimes n}$ for any $n\in\mathbb{N}$ is a linear combination of pure
tensors. Combining these two observations, we see that every element of
$T\left(  V\right)  $ is a linear combination of pure tensors.

We need to prove the equation (\ref{pf.universal.tensor.der.Phider}) for all
$a\in T\left(  V\right)  $ and $b\in T\left(  V\right)  $. Since this equation
is linear in each of $a$ and $b$, we can WLOG assume that $a$ and $b$ are pure
tensors (since every element of $T\left(  V\right)  $ is a linear combination
of pure tensors). Assume this. Then, $a$ is a pure tensor, so that there
exists an $n\in\mathbb{N}$ and some $v_{1},v_{2},...,v_{n}\in V$ satisfying
$a=v_{1}\otimes v_{2}\otimes...\otimes v_{n}$. Consider this $n$ and these
$v_{1},v_{2},...,v_{n}$. Also, $b$ is a pure tensor, so that there exists an
$m\in\mathbb{N}$ and some $w_{1},w_{2},...,w_{m}\in V$ satisfying
$b=w_{1}\otimes w_{2}\otimes...\otimes w_{m}$. Consider this $m$ and these
$w_{1},w_{2},...,w_{m}$.

By (\ref{pf.universal.tensor.der.Phi}) (applied to $m$ and $w_{1}%
,w_{2},...,w_{m}$ instead of $n$ and $v_{1},v_{2},...,v_{n}$), we have%
\begin{align*}
\Phi\left(  w_{1}\otimes w_{2}\otimes...\otimes w_{m}\right)   &
=\sum\limits_{k=1}^{m}w_{1}\cdot w_{2}\cdot...\cdot w_{k-1}\cdot f\left(
w_{k}\right)  \cdot w_{k+1}\cdot w_{k+2}\cdot...\cdot w_{m}\\
&  =\sum\limits_{k=n+1}^{n+m}w_{1}\cdot w_{2}\cdot...\cdot w_{k-n-1}\cdot
f\left(  w_{k-n}\right)  \cdot w_{k-n+1}\cdot w_{k-n+2}\cdot...\cdot w_{m}%
\end{align*}
(here, we substituted $k-n$ for $k$ in the sum).

Let $\left(  u_{1},u_{2},...,u_{n+m}\right)  $ be the $\left(  n+m\right)
$-tuple $\left(  v_{1},v_{2},...,v_{n},w_{1},w_{2},...,w_{m}\right)  $. Then,
\[
u_{1}\otimes u_{2}\otimes...\otimes u_{n+m}=\underbrace{v_{1}\otimes
v_{2}\otimes...\otimes v_{n}}_{=a}\otimes\underbrace{w_{1}\otimes w_{2}%
\otimes...\otimes w_{m}}_{=b}=a\otimes b=ab.
\]


By (\ref{pf.universal.tensor.der.Phi}) (applied to $n+m$ and $u_{1}%
,u_{2},...,u_{n+m}$ instead of $n$ and $v_{1},v_{2},...,v_{n}$), we have%
\begin{align*}
&  \Phi\left(  u_{1}\otimes u_{2}\otimes...\otimes u_{n+m}\right) \\
&  =\sum\limits_{k=1}^{n+m}u_{1}\cdot u_{2}\cdot...\cdot u_{k-1}\cdot f\left(
u_{k}\right)  \cdot u_{k+1}\cdot u_{k+2}\cdot...\cdot u_{n+m}\\
&  =\sum\limits_{k=1}^{n}\underbrace{u_{1}\cdot u_{2}\cdot...\cdot
u_{k-1}\cdot f\left(  u_{k}\right)  \cdot u_{k+1}\cdot u_{k+2}\cdot...\cdot
u_{n+m}}_{\substack{=v_{1}\cdot v_{2}\cdot...\cdot v_{k-1}\cdot f\left(
v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot v_{n}\cdot w_{1}\cdot
w_{2}\cdot...\cdot w_{m}\\\text{(since }\left(  u_{1},u_{2},...,u_{n+m}%
\right)  =\left(  v_{1},v_{2},...,v_{n},w_{1},w_{2},...,w_{m}\right)  \text{
and }k\leq n\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{k=n+1}^{n+m}\underbrace{u_{1}\cdot
u_{2}\cdot...\cdot u_{k-1}\cdot f\left(  u_{k}\right)  \cdot u_{k+1}\cdot
u_{k+2}\cdot...\cdot u_{n+m}}_{\substack{=v_{1}\cdot v_{2}\cdot...\cdot
v_{n}\cdot w_{1}\cdot w_{2}\cdot...\cdot w_{k-n-1}\cdot f\left(
w_{k-n}\right)  \cdot w_{k-n+1}\cdot w_{k-n+2}\cdot...\cdot w_{m}%
\\\text{(since }\left(  u_{1},u_{2},...,u_{n+m}\right)  =\left(  v_{1}%
,v_{2},...,v_{n},w_{1},w_{2},...,w_{m}\right)  \text{ and }k>n\text{)}}}\\
&  =\sum\limits_{k=1}^{n}v_{1}\cdot v_{2}\cdot...\cdot v_{k-1}\cdot f\left(
v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot v_{n}\cdot
\underbrace{w_{1}\cdot w_{2}\cdot...\cdot w_{m}}_{=w_{1}\otimes w_{2}%
\otimes...\otimes w_{m}=b}\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{k=n+1}^{n+m}\underbrace{v_{1}\cdot
v_{2}\cdot...\cdot v_{n}}_{=v_{1}\otimes v_{2}\otimes...\otimes v_{n}=a}\cdot
w_{1}\cdot w_{2}\cdot...\cdot w_{k-n-1}\cdot f\left(  w_{k-n}\right)  \cdot
w_{k-n+1}\cdot w_{k-n+2}\cdot...\cdot w_{m}\\
&  =\sum\limits_{k=1}^{n}v_{1}\cdot v_{2}\cdot...\cdot v_{k-1}\cdot f\left(
v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot v_{n}\cdot b\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{k=n+1}^{n+m}a\cdot w_{1}\cdot w_{2}%
\cdot...\cdot w_{k-n-1}\cdot f\left(  w_{k-n}\right)  \cdot w_{k-n+1}\cdot
w_{k-n+2}\cdot...\cdot w_{m}\\
&  =\underbrace{\left(  \sum\limits_{k=1}^{n}v_{1}\cdot v_{2}\cdot...\cdot
v_{k-1}\cdot f\left(  v_{k}\right)  \cdot v_{k+1}\cdot v_{k+2}\cdot...\cdot
v_{n}\right)  }_{\substack{=\Phi\left(  v_{1}\otimes v_{2}\otimes...\otimes
v_{n}\right)  \\\text{(by (\ref{pf.universal.tensor.der.Phi}))}}}\cdot b\\
&  \ \ \ \ \ \ \ \ \ \ +a\cdot\underbrace{\left(  \sum\limits_{k=n+1}%
^{n+m}w_{1}\cdot w_{2}\cdot...\cdot w_{k-n-1}\cdot f\left(  w_{k-n}\right)
\cdot w_{k-n+1}\cdot w_{k-n+2}\cdot...\cdot w_{m}\right)  }_{=\Phi\left(
w_{1}\otimes w_{2}\otimes...\otimes w_{m}\right)  }\\
&  =\Phi\left(  \underbrace{v_{1}\otimes v_{2}\otimes...\otimes v_{n}}%
_{=a}\right)  \cdot b+a\cdot\Phi\left(  \underbrace{w_{1}\otimes w_{2}%
\otimes...\otimes w_{m}}_{=b}\right)  =\Phi\left(  a\right)  \cdot
b+a\cdot\Phi\left(  b\right)  .
\end{align*}
Thus, (\ref{pf.universal.tensor.der.Phider}) is proven.

Now that we know that $\Phi$ satisfies (\ref{pf.universal.tensor.der.Phider}),
we conclude that $\Phi$ is a derivation.

Next, notice that every $v\in V$ satisfies $\iota_{V}^{T}\left(  v\right)  =v$
(since $\iota_{V}^{T}$ is just the inclusion map). Hence, every $v\in V$
satisfies%
\begin{align*}
\left(  \Phi\circ\iota_{V}^{T}\right)  \left(  v\right)   &  =\Phi\left(
\underbrace{\iota_{V}^{T}\left(  v\right)  }_{\substack{=v}}\right)
=\Phi\left(  v\right) \\
&  =\sum\limits_{k=1}^{1}f\left(  v\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.universal.tensor.der.Phi}), applied to }n=1\text{ and }%
v_{1}=v\right) \\
&  =f\left(  v\right)  .
\end{align*}
Thus, $\Phi\circ\iota_{V}^{T}=f$.

So we know that $\Phi$ is a derivation satisfying $f=\Phi\circ\iota_{V}^{T}$.
Thus, we have shown that there exists a derivation $F:T\left(  V\right)
\rightarrow M$ satisfying $f=F\circ\iota_{V}^{T}$ (namely, $F=\Phi$). In order
to complete the proof of Theorem \ref{thm.universal.tensor.der}, we only need
to check that this derivation is unique. In other words, we need to check that
whenever a derivation $F:T\left(  V\right)  \rightarrow M$ satisfies
$f=F\circ\iota_{V}^{T}$, we must have $F=\Phi$. Let us prove this now. Let
$F:T\left(  V\right)  \rightarrow M$ be any derivation satisfying
$f=F\circ\iota_{V}^{T}$. Then, every $v\in V$ satisfies%
\begin{align*}
\left(  F\mid_{V}\right)  \left(  v\right)   &  =F\left(  \underbrace{v}%
_{=\iota_{V}^{T}\left(  v\right)  }\right)  =F\left(  \iota_{V}^{T}\left(
v\right)  \right)  =\underbrace{\left(  F\circ\iota_{V}^{T}\right)  }%
_{=f=\Phi\circ\iota_{V}^{T}}\left(  v\right)  =\left(  \Phi\circ\iota_{V}%
^{T}\right)  \left(  v\right) \\
&  =\Phi\left(  \underbrace{\iota_{V}^{T}\left(  v\right)  }_{=v}\right)
=\Phi\left(  v\right)  =\left(  \Phi\mid_{V}\right)  \left(  v\right)  .
\end{align*}
Thus, $F\mid_{V}=\Phi\mid_{V}$. Proposition \ref{prop.derivation.unique}
(applied to $A=T\left(  V\right)  $, $d=F$, $e=\Phi$ and $S=V$) thus yields
$F=\Phi$ (since $V$ generates $T\left(  V\right)  $ as an algebra). This
completes the proof of Theorem \ref{thm.universal.tensor.der} (as we have seen above).

\begin{verlong}
We record a graded version of Theorem \ref{thm.universal.tensor.der}:

\begin{theorem}
\label{thm.universal.tensor.der.gr}Let $Q$ be an abelian group. Let $V$ be a
$Q$-graded vector space. We denote by $\iota_{V}^{T}:V\rightarrow T\left(
V\right)  $ the canonical map from $V$ into $T\left(  V\right)  $. (This map
$\iota_{V}^{T}$ is known to be injective and $Q$-graded.) For any $Q$-graded
$T\left(  V\right)  $-bimodule $M$ and any $Q$-graded linear map
$f:V\rightarrow M$, there exists a unique $Q$-graded derivation $F:T\left(
V\right)  \rightarrow M$ satisfying $f=F\circ\iota_{V}^{T}$.
\end{theorem}

\textit{Proof of Theorem \ref{thm.universal.tensor.der.gr}.} We will treat the
map $\iota_{V}^{T}$ as an inclusion map, so that $\iota_{V}^{T}\left(
x\right)  =x$ for every $x\in V$.

Define the map $\Phi$ as in the proof of Theorem
\ref{thm.universal.tensor.der}. As we have seen in the proof of Theorem
\ref{thm.universal.tensor.der}, this map $\Phi$ is a derivation $T\left(
V\right)  \rightarrow M$ satisfying $f=\Phi\circ\iota_{V}^{T}$. We will now
prove that $\Phi$ is $Q$-graded.

For every $Q$-graded vector space $W$ and every $q\in Q$, let $\pi_{q}^{W}$ be
the canonical projection from $W$ to the $q$-th homogeneous component
$W\left[  q\right]  $. Of course, for every $Q$-graded vector space $W$ and
every $w\in W$, we have%
\begin{equation}
w=\sum\limits_{q\in Q}\pi_{q}^{W}\left(  w\right)  .
\label{pf.universal.tensor.der.gr.0}%
\end{equation}
Let us notice that for every $Q$-graded vector space $W$ and any two distinct
elements $p$ and $q$ of $Q$, we have%
\begin{equation}
\pi_{q}^{W}\left(  W\left[  p\right]  \right)  =0
\label{pf.universal.tensor.der.gr.0a}%
\end{equation}
(because $\pi_{q}^{W}$ is the projection of the $Q$-graded vector space $W$
onto its $q$-th homogeneous component $W\left[  q\right]  $, while $W\left[
p\right]  $ is a homogeneous component of $W$ distinct from $W\left[
q\right]  $).

For every $q\in Q$, let $\Phi_{q}$ be the linear map $\left(  T\left(
V\right)  \right)  \left[  q\right]  \rightarrow M\left[  q\right]  $ defined
by%
\[
\left(  \Phi_{q}\left(  x\right)  =\pi_{q}^{M}\left(  \Phi\left(  x\right)
\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in\left(  T\left(  V\right)
\right)  \left[  q\right]  \right)  .
\]
Then, the direct sum $\bigoplus\limits_{q\in Q}\Phi_{q}:\bigoplus\limits_{q\in
Q}\left(  T\left(  V\right)  \right)  \left[  q\right]  \rightarrow
\bigoplus\limits_{q\in Q}M\left[  q\right]  $ is a $Q$-graded linear map from
$T\left(  V\right)  $ to $M$ (since $\bigoplus\limits_{q\in Q}\left(  T\left(
V\right)  \right)  \left[  q\right]  =T\left(  V\right)  $ and $\bigoplus
\limits_{q\in Q}M\left[  q\right]  =M$). Denote this map $\bigoplus
\limits_{q\in Q}\Phi_{q}$ by $\Phi^{\prime}$.

Every $r\in Q$ and every $x\in\left(  T\left(  V\right)  \right)  \left[
r\right]  $ satisfy%
\begin{align}
\Phi^{\prime}\left(  x\right)   &  =\left(  \bigoplus\limits_{q\in Q}%
\Phi\left[  q\right]  \right)  \left(  x\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\Phi^{\prime}=\bigoplus\limits_{q\in Q}\Phi\left[  q\right]
\right) \nonumber\\
&  =\Phi_{r}\left(  x\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }%
x\in\left(  T\left(  V\right)  \right)  \left[  r\right]  \right) \nonumber\\
&  =\pi_{r}^{M}\left(  \Phi\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\Phi_{r}\right)  .
\label{pf.universal.tensor.der.gr.1}%
\end{align}


Now, every $r\in Q$ and every $x\in V\left[  r\right]  $ satisfy%
\begin{align*}
\left(  \Phi^{\prime}\circ\iota_{V}^{T}\right)  \left(  x\right)   &
=\Phi^{\prime}\left(  \underbrace{\iota_{V}^{T}\left(  x\right)  }%
_{=x}\right)  =\Phi^{\prime}\left(  x\right) \\
&  =\pi_{r}^{M}\left(  \Phi\left(  \underbrace{x}_{=\iota_{V}^{T}\left(
x\right)  }\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.universal.tensor.der.gr.1}) (since }x\in V\left[  r\right]
\subseteq\left(  T\left(  V\right)  \right)  \left[  r\right]  \text{)}\right)
\\
&  =\pi_{r}^{M}\left(  \underbrace{\Phi\left(  \iota_{V}^{T}\left(  x\right)
\right)  }_{=\left(  \Phi\circ\iota_{V}^{T}\right)  \left(  x\right)
}\right)  =\pi_{r}^{M}\left(  \underbrace{\left(  \Phi\circ\iota_{V}%
^{T}\right)  }_{=f}\left(  x\right)  \right)  =\pi_{r}^{M}\left(  f\left(
x\right)  \right)  =f\left(  x\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }f\left(  x\right)  \in M\left[  r\right]  \text{ (because
}f\text{ is }Q\text{-graded and }x\in V\left[  r\right]  \text{), and thus}\\
\text{the projection }\pi_{r}^{M}\text{ onto }M\left[  r\right]  \text{ leaves
}f\left(  x\right)  \text{ invariant}%
\end{array}
\right)  .
\end{align*}
Thus, $\Phi^{\prime}\circ\iota_{V}^{T}=f$.

We will next show that $\Phi^{\prime}$ is a derivation. Indeed, in order to
prove this, we must show that%
\begin{equation}
\Phi^{\prime}\left(  ab\right)  =\Phi^{\prime}\left(  a\right)  \cdot
b+a\cdot\Phi^{\prime}\left(  b\right)  \ \ \ \ \ \ \ \ \ \ \text{for any }a\in
T\left(  V\right)  \text{ and }b\in T\left(  V\right)  .
\label{pf.universal.tensor.der.gr.2}%
\end{equation}


\textit{Proof of (\ref{pf.universal.tensor.der.gr.2}):} We need to prove the
equation (\ref{pf.universal.tensor.der.gr.2}) for all $a\in T\left(  V\right)
$ and $b\in T\left(  V\right)  $. Since this equation is linear in each of $a$
and $b$, we can WLOG assume that $a$ and $b$ are homogeneous (since every
element of $T\left(  V\right)  $ is a linear combination of homogeneous
elements). Assume this. Then, $a$ is homogeneous, so there exists a $p\in Q$
such that $a\in\left(  T\left(  V\right)  \right)  \left[  p\right]  $.
Consider this $p$. Since $b$ is homogeneous, there exists an $r\in Q$ such
that $b\in\left(  T\left(  V\right)  \right)  \left[  r\right]  $. Consider
this $r$. Since $a\in\left(  T\left(  V\right)  \right)  \left[  p\right]  $
and $b\in\left(  T\left(  V\right)  \right)  \left[  r\right]  $, we have
$ab\in\left(  T\left(  V\right)  \right)  \left[  p+r\right]  $ (since
$T\left(  V\right)  $ is a $Q$-graded algebra), so that%
\begin{align*}
\Phi^{\prime}\left(  ab\right)   &  =\pi_{p+r}^{M}\left(  \underbrace{\Phi
\left(  ab\right)  }_{\substack{=\Phi\left(  a\right)  \cdot b+a\cdot
\Phi\left(  b\right)  \\\text{(since }\Phi\text{ is a derivation)}}}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.universal.tensor.der.gr.1}),
applied to }ab\text{ and }p+r\text{ instead of }x\text{ and }r\right) \\
&  =\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot b+a\cdot\Phi\left(
b\right)  \right)  =\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot b\right)
+\pi_{p+r}^{M}\left(  a\cdot\Phi\left(  b\right)  \right)  .
\end{align*}
Now, it is easy to see that $\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot
b\right)  =\pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot
b$\ \ \ \ \footnote{\textit{Proof.} Applying
(\ref{pf.universal.tensor.der.gr.0}) to $W=M$ and $w=\Phi\left(  a\right)  $,
we obtain $\Phi\left(  a\right)  =\sum\limits_{q\in Q}\pi_{q}^{M}\left(
\Phi\left(  a\right)  \right)  $, so that%
\begin{align*}
\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot b\right)   &  =\pi_{p+r}%
^{M}\left(  \sum\limits_{q\in Q}\pi_{q}^{M}\left(  \Phi\left(  a\right)
\right)  \cdot b\right)  =\sum\limits_{q\in Q}\pi_{p+r}^{M}\left(  \pi_{q}%
^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right) \\
&  =\pi_{p+r}^{M}\left(  \pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)
\cdot b\right)  +\sum\limits_{\substack{q\in Q;\\q\neq p}}\pi_{p+r}^{M}\left(
\pi_{q}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right)  .
\end{align*}
\par
Now, for every $q\in Q$, we have $\underbrace{\pi_{q}^{M}\left(  \Phi\left(
a\right)  \right)  }_{\substack{\in M\left[  q\right]  \\\text{(since }\pi
_{q}^{M}\text{ is a}\\\text{projection on }M\left[  q\right]  \text{)}}%
}\cdot\underbrace{b}_{\in\left(  T\left(  V\right)  \right)  \left[  r\right]
}\in\left(  M\left[  q\right]  \right)  \cdot\left(  \left(  T\left(
V\right)  \right)  \left[  r\right]  \right)  \subseteq M\left[  q+r\right]  $
(since $M$ is a graded $T\left(  V\right)  $-bimodule). For every $q\in Q$
satisfying $q+r\neq p+r$, we have $\pi_{p+r}^{W}\left(  M\left[  q+r\right]
\right)  =0$ (by (\ref{pf.universal.tensor.der.gr.0a}), applied to $M$, $p+r$
and $q+r$ instead of $W$, $q$ and $p$). Thus,%
\[
\sum\limits_{\substack{q\in Q;\\q\neq p}}\pi_{p+r}^{M}\left(  \underbrace{\pi
_{q}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b}_{\in M\left[
q+r\right]  }\right)  \in\sum\limits_{\substack{q\in Q;\\q\neq p}%
}\underbrace{\pi_{p+r}^{M}\left(  M\left[  q+r\right]  \right)  }%
_{\substack{=0\\\text{(since }q+r\neq p+r\\\text{(because }q\neq p\text{))}%
}}=\sum\limits_{\substack{q\in Q;\\q\neq p}}0=0,
\]
so that $\sum\limits_{\substack{q\in Q;\\q\neq p}}\pi_{p+r}^{M}\left(  \pi
_{q}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right)  =0$. Hence,%
\[
\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot b\right)  =\pi_{p+r}%
^{M}\left(  \pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right)
+\underbrace{\sum\limits_{\substack{q\in Q;\\q\neq p}}\pi_{p+r}^{M}\left(
\pi_{q}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right)  }_{=0}%
=\pi_{p+r}^{M}\left(  \pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot
b\right)  .
\]
On the other hand, $\underbrace{\pi_{p}^{M}\left(  \Phi\left(  a\right)
\right)  }_{\substack{\in M\left[  p\right]  \\\text{(since }\pi_{p}^{M}\text{
is a}\\\text{projection on }M\left[  p\right]  \text{)}}}\cdot\underbrace{b}%
_{\in\left(  T\left(  V\right)  \right)  \left[  r\right]  }\in\left(
M\left[  p\right]  \right)  \cdot\left(  \left(  T\left(  V\right)  \right)
\left[  r\right]  \right)  \subseteq M\left[  p+r\right]  $ (since $M$ is a
graded $T\left(  V\right)  $-bimodule). Thus, $\pi_{p+r}^{M}\left(  \pi
_{p}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right)  =\pi_{p}%
^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b$ (because $\pi_{p+r}^{M}$
is a projection on $M\left[  p+r\right]  $ and thus leaves every element in
$M\left[  p+r\right]  $ fixed). Hence,%
\[
\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot b\right)  =\pi_{p+r}%
^{M}\left(  \pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b\right)
=\pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  \cdot b,
\]
qed.}. Since $\pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  =\Phi^{\prime
}\left(  a\right)  $ (because (\ref{pf.universal.tensor.der.gr.1}) (applied to
$a$ and $p$ instead of $x$ and $r$) yields $\Phi^{\prime}\left(  a\right)
=\pi_{p}^{M}\left(  \Phi\left(  a\right)  \right)  $), this rewrites as
$\pi_{p+r}^{M}\left(  \Phi\left(  a\right)  \cdot b\right)  =\Phi^{\prime
}\left(  a\right)  \cdot b$. The same argument (but with the right action of
$T\left(  V\right)  $ on $M$ replaced by left action) shows that $\pi
_{p+r}^{M}\left(  b\cdot\Phi\left(  a\right)  \right)  =b\cdot\Phi^{\prime
}\left(  a\right)  $. If we apply this equality to $a$, $b$, $p$ and $r$ in
lieu of $b$, $a$, $r$ and $p$, we obtain $\pi_{r+p}^{M}\left(  a\cdot
\Phi\left(  b\right)  \right)  =a\cdot\Phi^{\prime}\left(  b\right)  $. In
other words, $\pi_{p+r}^{M}\left(  a\cdot\Phi\left(  b\right)  \right)
=a\cdot\Phi^{\prime}\left(  b\right)  $. Thus,%
\begin{align*}
\Phi^{\prime}\left(  ab\right)   &  =\underbrace{\pi_{p+r}^{M}\left(
\Phi\left(  a\right)  \cdot b\right)  }_{=\Phi^{\prime}\left(  a\right)  \cdot
b}+\underbrace{\pi_{p+r}^{M}\left(  a\cdot\Phi\left(  b\right)  \right)
}_{=a\cdot\Phi^{\prime}\left(  b\right)  }\\
&  =\Phi^{\prime}\left(  a\right)  \cdot b+a\cdot\Phi^{\prime}\left(
b\right)  .
\end{align*}
This proves (\ref{pf.universal.tensor.der.gr.2}).

From (\ref{pf.universal.tensor.der.gr.2}), it becomes clear that $\Phi
^{\prime}$ is a derivation. Since $\Phi^{\prime}$ also is $Q$-graded and
satisfies $f=\Phi^{\prime}\circ\iota_{V}^{T}$, we thus conclude that there
exists a $Q$-graded derivation $F:T\left(  V\right)  \rightarrow M$ satisfying
$f=F\circ\iota_{V}^{T}$ (namely, $F=\Phi$). Combining this with the fact that
there exists \textbf{at most one} $Q$-graded derivation $F:T\left(  V\right)
\rightarrow M$ satisfying $f=F\circ\iota_{V}^{T}$%
\ \ \ \ \footnote{\textit{Proof.} Theorem \ref{thm.universal.tensor.der}
yields that there exists a unique derivation $F:T\left(  V\right)  \rightarrow
M$ satisfying $f=F\circ\iota_{V}^{T}$. Hence, there exists at most one
derivation $F:T\left(  V\right)  \rightarrow M$ satisfying $f=F\circ\iota
_{V}^{T}$. In particular, there exists at most one $Q$-graded derivation
$F:T\left(  V\right)  \rightarrow M$ satisfying $f=F\circ\iota_{V}^{T}$,
qed.}, we conclude that there exists \textbf{a unique} $Q$-graded derivation
$F:T\left(  V\right)  \rightarrow M$ satisfying $f=F\circ\iota_{V}^{T}$.
Theorem \ref{thm.universal.tensor.der.gr} is proven.
\end{verlong}

We will later use a corollary of Proposition \ref{prop.derivation.unique}:

\begin{corollary}
\label{cor.derivation.unique.ihg}Let $A$ be an algebra. Let $B$ be a
subalgebra of $A$. Let $C$ be a subalgebra of $B$. Let $d:A\rightarrow A$ be a
derivation of the algebra $A$. Let $S$ be a subset of $C$ which generates $C$
as an algebra. Assume that $d\left(  S\right)  \subseteq B$. Then, $d\left(
C\right)  \subseteq B$.
\end{corollary}

\textit{Proof of Corollary \ref{cor.derivation.unique.ihg}.} Since $C\subseteq
B\subseteq A$, the vector spaces $A$ and $B$ become $C$-modules.

Let $\pi:A\rightarrow A\diagup B$ be the canonical projection. Clearly, $\pi$
is a $C$-module homomorphism, and satisfies $\operatorname*{Ker}\pi=B$. Let
$d^{\prime}:C\rightarrow A\diagup B$ be the restriction of the map $\pi\circ
d:A\rightarrow A\diagup B$ to $C$. It is easy to see that $d^{\prime
}:C\rightarrow A\diagup B$ is a derivation\footnote{\textit{Proof.} Every
$x\in C$ and $y\in C$ satisfy%
\begin{align*}
d^{\prime}\left(  xy\right)   &  =\left(  \pi\circ d\right)  \left(
xy\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }d^{\prime}\text{ is the
restriction of }\pi\circ d\text{ to }C\right) \\
&  =\pi\left(  \underbrace{d\left(  xy\right)  }_{\substack{=d\left(
x\right)  \cdot y+x\cdot d\left(  y\right)  \\\text{(since }d\text{ is a
derivation)}}}\right)  =\pi\left(  d\left(  x\right)  \cdot y+x\cdot d\left(
y\right)  \right) \\
&  =\underbrace{\pi\left(  d\left(  x\right)  \cdot y\right)  }%
_{\substack{=\pi\left(  d\left(  x\right)  \right)  \cdot y\\\text{(since }%
\pi\text{ is a }C\text{-module}\\\text{homomorphism)}}}+\underbrace{\pi\left(
x\cdot d\left(  y\right)  \right)  }_{\substack{=x\cdot\pi\left(  d\left(
y\right)  \right)  \\\text{(since }\pi\text{ is a }C\text{-module}%
\\\text{homomorphism)}}}\\
&  =\underbrace{\pi\left(  d\left(  x\right)  \right)  }_{\substack{=\left(
\pi\circ d\right)  \left(  x\right)  =d^{\prime}\left(  x\right)
\\\text{(since }d^{\prime}\text{ is the restriction of}\\\pi\circ d\text{ to
}C\text{, and since }x\in C\text{)}}}\cdot y+x\cdot\underbrace{\pi\left(
d\left(  y\right)  \right)  }_{\substack{=\left(  \pi\circ d\right)  \left(
y\right)  =d^{\prime}\left(  y\right)  \\\text{(since }d^{\prime}\text{ is the
restriction of}\\\pi\circ d\text{ to }C\text{, and since }y\in C\text{)}%
}}=d^{\prime}\left(  x\right)  \cdot y+x\cdot d^{\prime}\left(  y\right)  .
\end{align*}
Thus, $d^{\prime}$ is a derivation, qed.}. On the other hand, $0:C\rightarrow
A\diagup B$ is a derivation as well. Every $s\in S$ satisfies%
\begin{align*}
\left(  d^{\prime}\mid_{S}\right)  \left(  s\right)   &  =d^{\prime}\left(
s\right)  =\left(  \pi\circ d\right)  \left(  s\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }d^{\prime}\text{ is the restriction
of }\pi\circ d\text{ to }C\right) \\
&  =\pi\left(  d\left(  s\right)  \right)  =0\ \ \ \ \ \ \ \ \ \ \left(
\text{since }d\left(  \underbrace{s}_{\in S}\right)  \in d\left(  S\right)
\subseteq B=\operatorname*{Ker}\pi\right) \\
&  =0\left(  s\right)  =\left(  0\mid_{S}\right)  \left(  s\right)  .
\end{align*}
Thus, $d^{\prime}\mid_{S}=0\mid_{S}$. Proposition \ref{prop.derivation.unique}
(applied to $C$, $A\diagup M$, $d^{\prime}$ and $0$ instead of $A$, $M$, $d$
and $e$) therefore yields that $d^{\prime}=0$ on $C$. But since $d^{\prime}$
is the restriction of $\pi\circ d$ to $C$, we have $d^{\prime}=\left(
\pi\circ d\right)  \mid_{C}$. Thus, $\left(  \pi\circ d\right)  \mid
_{C}=d^{\prime}=0$, so that $\left(  \pi\circ d\right)  \left(  C\right)  =0$.
Thus, $\pi\left(  d\left(  C\right)  \right)  =\left(  \pi\circ d\right)
\left(  C\right)  =0$, so that $d\left(  C\right)  \subseteq
\operatorname*{Ker}\pi=B$. Corollary \ref{cor.derivation.unique.ihg} is
therefore proven.

\begin{corollary}
\label{cor.derivation.Lie.semidir}Let $\mathfrak{g}$ be a Lie algebra. Let
$\mathfrak{h}$ be a vector space equipped with both a Lie algebra structure
and a $\mathfrak{g}$-module structure. Assume that $\mathfrak{g}$ acts on
$\mathfrak{h}$ by derivations. Consider the semidirect product $\mathfrak{g}%
\ltimes\mathfrak{h}$ defined as in Definition \ref{def.semidir.lielie}
\textbf{(b)}. Consider $\mathfrak{g}$ as a Lie subalgebra of $\mathfrak{g}%
\ltimes\mathfrak{h}$. Consider $\mathfrak{g}\ltimes\mathfrak{h}$ as a Lie
subalgebra of $U\left(  \mathfrak{g}\ltimes\mathfrak{h}\right)  $ (where the
Lie bracket on $U\left(  \mathfrak{g}\ltimes\mathfrak{h}\right)  $ is defined
as the commutator of the multiplication). Consider $\mathfrak{h}$ as a Lie
subalgebra of $\mathfrak{g}\ltimes\mathfrak{h}$, whence $U\left(
\mathfrak{h}\right)  $ becomes a subalgebra of $U\left(  \mathfrak{g}%
\ltimes\mathfrak{h}\right)  $.

Then, $\left[  \mathfrak{g},U\left(  \mathfrak{h}\right)  \right]  \subseteq
U\left(  \mathfrak{h}\right)  $ (as subsets of $U\left(  \mathfrak{g}%
\ltimes\mathfrak{h}\right)  $).
\end{corollary}

\textit{Proof of Corollary \ref{cor.derivation.Lie.semidir}.} Let
$x\in\mathfrak{g}$. Define a map $\xi:U\left(  \mathfrak{g}\ltimes
\mathfrak{h}\right)  \rightarrow U\left(  \mathfrak{g}\ltimes\mathfrak{h}%
\right)  $ by%
\[
\left(  \xi\left(  y\right)  =\left[  x,y\right]
\ \ \ \ \ \ \ \ \ \ \text{for every }y\in U\left(  \mathfrak{g}\ltimes
\mathfrak{h}\right)  \right)  .
\]
Then, $\xi$ is clearly a derivation of the algebra $U\left(  \mathfrak{g}%
\ltimes\mathfrak{h}\right)  $.

We are identifying $\mathfrak{g}$ with a Lie subalgebra of $\mathfrak{g}%
\ltimes\mathfrak{h}$. Clearly, $x\in\mathfrak{g}$ corresponds to $\left(
x,0\right)  \in\mathfrak{g}\ltimes\mathfrak{h}$ under this identification.

We are also identifying $\mathfrak{h}$ with a Lie subalgebra of $\mathfrak{g}%
\ltimes\mathfrak{h}$. Every $y\in\mathfrak{h}$ corresponds to $\left(
0,y\right)  \in\mathfrak{g}\ltimes\mathfrak{h}$ under this identification.

Thus, every $y\in\mathfrak{h}$ satisfies%
\begin{align*}
\left[  \underbrace{x}_{=\left(  x,0\right)  },\underbrace{y}_{=\left(
0,y\right)  }\right]   &  =\left[  \left(  x,0\right)  ,\left(  0,y\right)
\right]  =\left(  \underbrace{\left[  x,0\right]  }_{=0},\underbrace{\left[
0,y\right]  }_{=0}+x\rightharpoonup y-\underbrace{0\rightharpoonup0}%
_{=0}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the Lie bracket on
}\mathfrak{g}\ltimes\mathfrak{h}\right) \\
&  =\left(  0,x\rightharpoonup y\right)  =x\rightharpoonup y\in\mathfrak{h}.
\end{align*}
Hence, $\xi\left(  y\right)  =\left[  x,y\right]  \in\mathfrak{h}$ for every
$y\in\mathfrak{h}$. Thus, $\xi\left(  \mathfrak{h}\right)  \subseteq
\mathfrak{h}\subseteq U\left(  \mathfrak{h}\right)  $.

Now, we notice that the subset $\mathfrak{h}$ of $U\left(  \mathfrak{h}%
\right)  $ generates $U\left(  \mathfrak{h}\right)  $ as an algebra. Thus,
Corollary \ref{cor.derivation.unique.ihg} (applied to $A=U\left(
\mathfrak{g}\ltimes\mathfrak{h}\right)  $, $B=U\left(  \mathfrak{h}\right)  $,
$C=U\left(  \mathfrak{h}\right)  $, $d=\xi$ and $S=\mathfrak{h}$) yields
$\xi\left(  U\left(  \mathfrak{h}\right)  \right)  \subseteq U\left(
\mathfrak{h}\right)  $. Hence, every $u\in U\left(  \mathfrak{h}\right)  $
satisfies $\xi\left(  u\right)  \in U\left(  \mathfrak{h}\right)  $. But since
$\xi\left(  u\right)  =\left[  x,u\right]  $ (by the definition of $\xi$),
this yields that every $u\in U\left(  \mathfrak{h}\right)  $ satisfies
$\left[  x,u\right]  \in U\left(  \mathfrak{h}\right)  $.

Now forget that we fixed $x$. We thus have shown that every $x\in\mathfrak{g}$
and every $u\in U\left(  \mathfrak{h}\right)  $ satisfy $\left[  x,u\right]
\in U\left(  \mathfrak{h}\right)  $. Thus, $\left[  \mathfrak{g},U\left(
\mathfrak{h}\right)  \right]  \subseteq U\left(  \mathfrak{h}\right)  $ (since
$U\left(  \mathfrak{h}\right)  $ is a vector space). This proves Corollary
\ref{cor.derivation.Lie.semidir}.

\subsubsection{Universality of the free Lie algebra with respect to
derivations}

Both Theorem \ref{thm.universal.tensor.der} and Proposition
\ref{prop.derivation.unique} have analogues pertaining to Lie algebras in lieu
of (associative) algebras.\footnote{Notice that the Lie-algebraic analogue of
a derivation from an algebra $A$ into an $A$-bimodule is a $1$-cocycle from a
Lie algebra $\mathfrak{g}$ into a $\mathfrak{g}$-module.} We are going to
formulate both of these analogues, but we start with that of Proposition
\ref{prop.derivation.unique}, since it is the one we will find utile in our
study of Kac-Moody Lie algebras:

\begin{proposition}
\label{prop.derivation.Lie.unique}Let $\mathfrak{g}$ be a Lie algebra. Let $M$
be a $\mathfrak{g}$-module, and $d:\mathfrak{g}\rightarrow M$ and
$e:\mathfrak{g}\rightarrow M$ two $1$-cocycles. Let $S$ be a subset of
$\mathfrak{g}$ which generates $\mathfrak{g}$ as a Lie algebra. Assume that
$d\mid_{S}=e\mid_{S}$. Then, $d=e$.
\end{proposition}

\begin{vershort}
The proof of Proposition \ref{prop.derivation.Lie.unique} is analogous to that
of Proposition \ref{prop.derivation.unique}.
\end{vershort}

\begin{verlong}
The proof of Proposition \ref{prop.derivation.Lie.unique} is analogous to that
of Proposition \ref{prop.derivation.unique}. Here are its details:

\textit{Proof of Proposition \ref{prop.derivation.Lie.unique}.} Let $U$ be the
subset $\operatorname*{Ker}\left(  d-e\right)  $ of $\mathfrak{g}$. Clearly,
$U$ is a vector space (since $d-e$ is a linear map (since $d$ and $e$ are linear)).

Let $b\in U$ and $c\in U$. Since $b\in U=\operatorname*{Ker}\left(
d-e\right)  $, we have $\left(  d-e\right)  \left(  b\right)  =0$. Thus,
$d\left(  b\right)  -e\left(  b\right)  =\left(  d-e\right)  \left(  b\right)
=0$, so that $d\left(  b\right)  =e\left(  b\right)  $. Similarly, $d\left(
c\right)  =e\left(  c\right)  $.

Now, since $d$ is a $1$-cocycle, we have $d\left(  \left[  b,c\right]
\right)  =\left[  d\left(  b\right)  ,c\right]  +\left[  b,d\left(  c\right)
\right]  $ (by the definition of $1$-cocycles). Similarly, $e\left(  \left[
b,c\right]  \right)  =\left[  e\left(  b\right)  ,c\right]  +\left[
b,e\left(  c\right)  \right]  $. Hence,%
\begin{align*}
\left(  d-e\right)  \left(  \left[  b,c\right]  \right)   &
=\underbrace{d\left(  \left[  b,c\right]  \right)  }_{=\left[  d\left(
b\right)  ,c\right]  +\left[  b,d\left(  c\right)  \right]  }%
-\underbrace{e\left(  \left[  b,c\right]  \right)  }_{=\left[  e\left(
b\right)  ,c\right]  +\left[  b,e\left(  c\right)  \right]  }=\left(  \left[
\underbrace{d\left(  b\right)  }_{=e\left(  b\right)  },c\right]  +\left[
b,\underbrace{d\left(  c\right)  }_{=e\left(  c\right)  }\right]  \right)
-\left(  \left[  e\left(  b\right)  ,c\right]  +\left[  b,e\left(  c\right)
\right]  \right) \\
&  =\left(  \left[  e\left(  b\right)  ,c\right]  +\left[  b,e\left(
c\right)  \right]  \right)  -\left(  \left[  e\left(  b\right)  ,c\right]
+\left[  b,e\left(  c\right)  \right]  \right)  =0.
\end{align*}
In other words, $\left[  b,c\right]  \in\operatorname*{Ker}\left(  d-e\right)
=U$.

Now forget that we fixed $b$ and $c$. We have thus showed that any $b\in U$
and $c\in U$ satisfy $\left[  b,c\right]  \in U$. Combined with the fact that
$U$ is a vector space, this yields that $U$ is a Lie subalgebra of
$\mathfrak{g}$. Since $S\subseteq U$ (because every $s\in S$ satisfies%
\[
\left(  d-e\right)  \left(  s\right)  =\underbrace{d\left(  s\right)
}_{=\left(  d\mid_{S}\right)  \left(  s\right)  }-\underbrace{e\left(
s\right)  }_{=\left(  e\mid_{S}\right)  \left(  s\right)  }%
=\underbrace{\left(  d\mid_{S}\right)  }_{=e\mid_{S}}\left(  s\right)
-\left(  e\mid_{S}\right)  \left(  s\right)  =\left(  e\mid_{S}\right)
\left(  s\right)  -\left(  e\mid_{S}\right)  \left(  s\right)  =0
\]
and thus $s\in\operatorname*{Ker}\left(  d-e\right)  =U$), this yields that
$U$ is a Lie subalgebra of $\mathfrak{g}$ containing $S$ as a subset. But
since the smallest Lie subalgebra of $\mathfrak{g}$ containing $S$ as a subset
is $\mathfrak{g}$ itself (because $S$ generates $\mathfrak{g}$ as a Lie
algebra), this yields that $U\supseteq\mathfrak{g}$. Hence, $\mathfrak{g}%
\subseteq U=\operatorname*{Ker}\left(  d-e\right)  $, so that $d-e=0$ and thus
$d=e$. Proposition \ref{prop.derivation.Lie.unique} is proven.
\end{verlong}

\begin{verlong}
An analogue of Theorem \ref{thm.universal.tensor.der.gr} for Lie algebras can
also be given, and is left to the reader.
\end{verlong}

We record a corollary of Proposition \ref{prop.derivation.Lie.unique}:

\begin{corollary}
\label{cor.derivation.Lie.unique.ihg}Let $\mathfrak{g}$ be a Lie algebra. Let
$\mathfrak{h}$ be a Lie subalgebra of $\mathfrak{g}$. Let $\mathfrak{i}$ be a
Lie subalgebra of $\mathfrak{h}$. Let $d:\mathfrak{g}\rightarrow\mathfrak{g}$
be a derivation of the Lie algebra $\mathfrak{g}$. Let $S$ be a subset of
$\mathfrak{i}$ which generates $\mathfrak{i}$ as a Lie algebra. Assume that
$d\left(  S\right)  \subseteq\mathfrak{h}$. Then, $d\left(  \mathfrak{i}%
\right)  \subseteq\mathfrak{h}$.
\end{corollary}

\begin{vershort}
This corollary is analogous to Corollary \ref{cor.derivation.unique.ihg}, and
proven accordingly.
\end{vershort}

\begin{verlong}
This corollary is analogous to Corollary \ref{cor.derivation.unique.ihg}, and
proven accordingly:

\textit{Proof of Corollary \ref{cor.derivation.Lie.unique.ihg}.} We regard
$\mathfrak{g}$ as a $\mathfrak{g}$-module by means of the adjoint action.
Since $\mathfrak{i}\subseteq\mathfrak{h}\subseteq\mathfrak{g}$, the
$\mathfrak{g}$-module $\mathfrak{g}$ thus becomes an $\mathfrak{i}$-module.

We also regard $\mathfrak{h}$ as an $\mathfrak{h}$-module by means of the
adjoint action. Since $\mathfrak{i}\subseteq\mathfrak{h}$, the $\mathfrak{h}%
$-module $\mathfrak{h}$ thus becomes an $\mathfrak{i}$-module.

Let $\pi:\mathfrak{g}\rightarrow\mathfrak{g}\diagup\mathfrak{h}$ be the
canonical projection. Clearly, $\pi$ is an $\mathfrak{i}$-module homomorphism,
and satisfies $\operatorname*{Ker}\pi=\mathfrak{h}$. Let $d^{\prime
}:\mathfrak{i}\rightarrow\mathfrak{g}\diagup\mathfrak{h}$ be the restriction
of the map $\pi\circ d:\mathfrak{g}\rightarrow\mathfrak{g}\diagup\mathfrak{h}$
to $\mathfrak{i}$. It is easy to see that $d^{\prime}:\mathfrak{i}%
\rightarrow\mathfrak{g}\diagup\mathfrak{h}$ is a $1$%
-cocycle\footnote{\textit{Proof.} Every $x\in\mathfrak{i}$ and $y\in
\mathfrak{i}$ satisfy%
\begin{align*}
d^{\prime}\left(  \left[  x,y\right]  \right)   &  =\left(  \pi\circ d\right)
\left(  \left[  x,y\right]  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}d^{\prime}\text{ is the restriction of }\pi\circ d\text{ to }\mathfrak{i}%
\right) \\
&  =\pi\left(  \underbrace{d\left(  \left[  x,y\right]  \right)
}_{\substack{=\left[  d\left(  x\right)  ,y\right]  +\left[  x,d\left(
y\right)  \right]  \\\text{(since }d\text{ is a derivation)}}}\right)
=\pi\left(  \underbrace{\left[  d\left(  x\right)  ,y\right]  }_{=-\left[
y,d\left(  x\right)  \right]  }+\left[  x,d\left(  y\right)  \right]  \right)
\\
&  =\pi\left(  -\underbrace{\left[  y,d\left(  x\right)  \right]
}_{\substack{=y\rightharpoonup\left(  d\left(  x\right)  \right)
\\\text{(since }\mathfrak{g}\text{ is a }\mathfrak{g}\text{-module}\\\text{by
the adjoint action)}}}+\underbrace{\left[  x,d\left(  y\right)  \right]
}_{\substack{=x\rightharpoonup\left(  d\left(  y\right)  \right)
\\\text{(since }\mathfrak{g}\text{ is a }\mathfrak{g}\text{-module}\\\text{by
the adjoint action)}}}\right) \\
&  =\pi\left(  -y\rightharpoonup\left(  d\left(  x\right)  \right)
+x\rightharpoonup\left(  d\left(  y\right)  \right)  \right) \\
&  =-\underbrace{\pi\left(  y\rightharpoonup\left(  d\left(  x\right)
\right)  \right)  }_{\substack{=y\rightharpoonup\left(  \pi\left(  d\left(
x\right)  \right)  \right)  \\\text{(since }\pi\text{ is an }\mathfrak{i}%
\text{-module homomorphism)}}}+\underbrace{\pi\left(  x\rightharpoonup\left(
d\left(  y\right)  \right)  \right)  }_{\substack{=x\rightharpoonup\left(
\pi\left(  d\left(  y\right)  \right)  \right)  \\\text{(since }\pi\text{ is
an }\mathfrak{i}\text{-module homomorphism)}}}\\
&  =-y\rightharpoonup\left(  \underbrace{\pi\left(  d\left(  x\right)
\right)  }_{\substack{=\left(  \pi\circ d\right)  \left(  x\right)
=d^{\prime}\left(  x\right)  \\\text{(since }d^{\prime}\text{ is the
restriction of}\\\pi\circ d\text{ to }\mathfrak{i}\text{, and since }%
x\in\mathfrak{i}\text{)}}}\right)  +x\rightharpoonup\left(  \underbrace{\pi
\left(  d\left(  y\right)  \right)  }_{\substack{=\left(  \pi\circ d\right)
\left(  y\right)  =d^{\prime}\left(  y\right)  \\\text{(since }d^{\prime
}\text{ is the restriction of}\\\pi\circ d\text{ to }\mathfrak{i}\text{, and
since }y\in\mathfrak{i}\text{)}}}\right) \\
&  =-y\rightharpoonup\left(  d^{\prime}\left(  x\right)  \right)
+x\rightharpoonup\left(  d^{\prime}\left(  y\right)  \right)
=x\rightharpoonup\left(  d^{\prime}\left(  y\right)  \right)
-y\rightharpoonup\left(  d^{\prime}\left(  x\right)  \right)  .
\end{align*}
Thus, $d^{\prime}$ is a $1$-cocycle, qed.}. On the other hand, $0:\mathfrak{i}%
\rightarrow\mathfrak{g}\diagup\mathfrak{h}$ is a $1$-cocycle as well. Every
$s\in S$ satisfies%
\begin{align*}
\left(  d^{\prime}\mid_{S}\right)  \left(  s\right)   &  =d^{\prime}\left(
s\right)  =\left(  \pi\circ d\right)  \left(  s\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }d^{\prime}\text{ is the restriction
of }\pi\circ d\text{ to }\mathfrak{i}\right) \\
&  =\pi\left(  d\left(  s\right)  \right)  =0\ \ \ \ \ \ \ \ \ \ \left(
\text{since }d\left(  \underbrace{s}_{\in S}\right)  \in d\left(  S\right)
\subseteq\mathfrak{h}=\operatorname*{Ker}\pi\right) \\
&  =0\left(  s\right)  =\left(  0\mid_{S}\right)  \left(  s\right)  .
\end{align*}
Thus, $d^{\prime}\mid_{S}=0\mid_{S}$. Proposition
\ref{prop.derivation.Lie.unique} (applied to $\mathfrak{i}$, $\mathfrak{g}%
\diagup\mathfrak{h}$, $d^{\prime}$ and $0$ instead of $\mathfrak{g}$, $M$, $d$
and $e$) therefore yields that $d^{\prime}=0$ on $\mathfrak{i}$. But since
$d^{\prime}$ is the restriction of $\pi\circ d$ to $\mathfrak{i}$, we have
$d^{\prime}=\left(  \pi\circ d\right)  \mid_{\mathfrak{i}}$. Thus, $\left(
\pi\circ d\right)  \mid_{\mathfrak{i}}=d^{\prime}=0$, so that $\left(
\pi\circ d\right)  \left(  \mathfrak{i}\right)  =0$. Thus, $\pi\left(
d\left(  \mathfrak{i}\right)  \right)  =\left(  \pi\circ d\right)  \left(
\mathfrak{i}\right)  =0$, so that $d\left(  \mathfrak{i}\right)
\subseteq\operatorname*{Ker}\pi=\mathfrak{h}$. Corollary
\ref{cor.derivation.Lie.unique.ihg} is therefore proven.
\end{verlong}

Let us now state the analogue of Proposition \ref{prop.derivation.unique} in
the Lie-algebraic setting:

\begin{theorem}
\label{thm.universal.FreeLie.der}Let $V$ be a vector space. We denote by
$\iota_{V}^{\operatorname*{FreeLie}}:V\rightarrow\operatorname*{FreeLie}V$ the
canonical map from $V$ into $\operatorname*{FreeLie}V$. (This map $\iota
_{V}^{\operatorname*{FreeLie}}$ is easily seen to be injective.) For any
$\operatorname*{FreeLie}V$-module $M$ and any linear map $f:V\rightarrow M$,
there exists a unique $1$-cocycle $F:\operatorname*{FreeLie}V\rightarrow M$
satisfying $f=F\circ\iota_{V}^{\operatorname*{FreeLie}}$.
\end{theorem}

\begin{vershort}
Although we will not use this theorem anywhere in the following, let us
briefly discuss how it is proven. Theorem \ref{thm.universal.FreeLie.der}
cannot be proven as directly as we proved Theorem
\ref{thm.universal.tensor.der}. Instead, a way to prove Theorem
\ref{thm.universal.FreeLie.der} is by using the following lemma:
\end{vershort}

\begin{verlong}
Although we will not use this theorem anywhere in the following, let us
discuss how it is proven. Theorem \ref{thm.universal.FreeLie.der} cannot be
proven as directly as we proved Theorem \ref{thm.universal.tensor.der}.
Instead, a way to prove Theorem \ref{thm.universal.FreeLie.der} is by using
the following lemma:
\end{verlong}

\begin{lemma}
\label{lem.semidir.coc-to-deriv}Let $\mathfrak{g}$ be a Lie algebra. Let $M$
be a $\mathfrak{g}$-module. Define the semidirect product $\mathfrak{g}\ltimes
M$ as in Definition \ref{def.semidir}. Let $\varphi:\mathfrak{g}\rightarrow M$
be a linear map. Then, $\varphi:\mathfrak{g}\rightarrow M$ is a $1$-cocycle if
and only if the map%
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)
\]
is a Lie algebra homomorphism.
\end{lemma}

\begin{vershort}
This lemma helps reducing Theorem \ref{thm.universal.FreeLie.der} to Theorem
\ref{thm.universal.FreeLie}. We leave the details of this proof (both of the
lemma and of Theorem \ref{thm.universal.FreeLie.der}) to the reader.
\end{vershort}

\begin{verlong}
We will use this lemma to reduce Theorem \ref{thm.universal.FreeLie.der} to
Theorem \ref{thm.universal.FreeLie}; let us, however, first establish the
lemma itself:

\textit{Proof of Lemma \ref{lem.semidir.coc-to-deriv}.} Let $\Phi$ denote the
map
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)  .
\]
Clearly, the map $\Phi$ is linear.

We will now prove the following two assertions:

\textit{Assertion }$\mathfrak{K}_{1}$\textit{:} If $\varphi:\mathfrak{g}%
\rightarrow M$ is a $1$-cocycle, then $\Phi$ is a Lie algebra homomorphism.

\textit{Assertion }$\mathfrak{K}_{2}$\textit{:} If $\Phi$ is a Lie algebra
homomorphism, then $\varphi:\mathfrak{g}\rightarrow M$ is a $1$-cocycle.

\textit{Proof of Assertion }$\mathfrak{K}_{1}$\textit{:} Assume that
$\varphi:\mathfrak{g}\rightarrow M$ is a $1$-cocycle. By the definition of
``$1$-cocycle'', this means that
\[
\varphi\left(  \left[  a,b\right]  \right)  =a\rightharpoonup\varphi\left(
b\right)  -b\rightharpoonup\varphi\left(  a\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}\text{ and }b\in
\mathfrak{g}.
\]


Let $a\in\mathfrak{g}$ and $b\in\mathfrak{g}$. By the definition of $\Phi$, we
have $\Phi\left(  a\right)  =\left(  a,\varphi\left(  a\right)  \right)  $ and
$\Phi\left(  b\right)  =\left(  b,\varphi\left(  b\right)  \right)  $. Thus,%
\[
\left[  \underbrace{\Phi\left(  a\right)  }_{=\left(  a,\varphi\left(
a\right)  \right)  },\underbrace{\Phi\left(  b\right)  }_{=\left(
b,\varphi\left(  b\right)  \right)  }\right]  =\left[  \left(  a,\varphi
\left(  a\right)  \right)  ,\left(  b,\varphi\left(  b\right)  \right)
\right]  =\left(  \left[  a,b\right]  ,a\rightharpoonup\varphi\left(
b\right)  -b\rightharpoonup\varphi\left(  a\right)  \right)
\]
(by the definition of the semidirect product $\mathfrak{g}\ltimes M$). On the
other hand, the definition of $\Phi$ yields
\[
\Phi\left(  \left[  a,b\right]  \right)  =\left(  \left[  a,b\right]
,\underbrace{\varphi\left(  \left[  a,b\right]  \right)  }_{=a\rightharpoonup
\varphi\left(  b\right)  -b\rightharpoonup\varphi\left(  a\right)  }\right)
=\left(  \left[  a,b\right]  ,a\rightharpoonup\varphi\left(  b\right)
-b\rightharpoonup\varphi\left(  a\right)  \right)  =\left[  \Phi\left(
a\right)  ,\Phi\left(  b\right)  \right]  .
\]


Now forget that we fixed $a$ and $b$. We thus have shown that every
$a\in\mathfrak{g}$ and $b\in\mathfrak{g}$ satisfy $\Phi\left(  \left[
a,b\right]  \right)  =\left[  \Phi\left(  a\right)  ,\Phi\left(  b\right)
\right]  $. Since $\Phi$ is linear, this yields that $\Phi$ is a Lie algebra
homomorphism. This proves Assertion $\mathfrak{K}_{1}$.

\textit{Proof of Assertion }$\mathfrak{K}_{2}$\textit{:} Assume that $\Phi$ is
a Lie algebra homomorphism. Thus,%
\[
\Phi\left(  \left[  a,b\right]  \right)  =\left[  \Phi\left(  a\right)
,\Phi\left(  b\right)  \right]  \ \ \ \ \ \ \ \ \ \ \text{for all }%
a\in\mathfrak{g}\text{ and }b\in\mathfrak{g}.
\]


Now let $a\in\mathfrak{g}$ and $b\in\mathfrak{g}$. By the definition of $\Phi
$, we have the three equalities $\Phi\left(  a\right)  =\left(  a,\varphi
\left(  a\right)  \right)  $, $\Phi\left(  b\right)  =\left(  b,\varphi\left(
b\right)  \right)  $ and $\Phi\left(  \left[  a,b\right]  \right)  =\left(
\left[  a,b\right]  ,\varphi\left(  \left[  a,b\right]  \right)  \right)  $.
Thus,%
\begin{align*}
\left(  \left[  a,b\right]  ,\varphi\left(  \left[  a,b\right]  \right)
\right)   &  =\Phi\left(  \left[  a,b\right]  \right)  =\left[
\underbrace{\Phi\left(  a\right)  }_{=\left(  a,\varphi\left(  a\right)
\right)  },\underbrace{\Phi\left(  b\right)  }_{=\left(  b,\varphi\left(
b\right)  \right)  }\right] \\
&  =\left[  \left(  a,\varphi\left(  a\right)  \right)  ,\left(
b,\varphi\left(  b\right)  \right)  \right]  =\left(  \left[  a,b\right]
,a\rightharpoonup\varphi\left(  b\right)  -b\rightharpoonup\varphi\left(
a\right)  \right)
\end{align*}
(by the definition of the semidirect product $\mathfrak{g}\ltimes M$). Hence,
$\varphi\left(  \left[  a,b\right]  \right)  =a\rightharpoonup\varphi\left(
b\right)  -b\rightharpoonup\varphi\left(  a\right)  $.

Now forget that we fixed $a$ and $b$. We thus have shown that%
\[
\varphi\left(  \left[  a,b\right]  \right)  =a\rightharpoonup\varphi\left(
b\right)  -b\rightharpoonup\varphi\left(  a\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}\text{ and }b\in
\mathfrak{g}.
\]
By the definition of ``$1$-cocycle'', this means exactly that $\varphi
:\mathfrak{g}\rightarrow M$ is a $1$-cocycle (since we already know that
$\varphi$ is linear). We have therefore shown that $\varphi:\mathfrak{g}%
\rightarrow M$ is a $1$-cocycle. This proves Assertion $\mathfrak{K}_{2}$.

Combining Assertion $\mathfrak{K}_{1}$ with Assertion $\mathfrak{K}_{2}$, we
conclude that $\varphi:\mathfrak{g}\rightarrow M$ is a $1$-cocycle if and only
if $\Phi$ is a Lie algebra homomorphism. Since $\Phi$ is the map%
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)  ,
\]
this rewrites as follows: $\varphi:\mathfrak{g}\rightarrow M$ is a $1$-cocycle
if and only if the map%
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)
\]
is a Lie algebra homomorphism. This proves Lemma
\ref{lem.semidir.coc-to-deriv}.

\textit{Proof of Theorem \ref{thm.universal.FreeLie.der}.} Fix a
$\operatorname*{FreeLie}V$-module $M$ and any linear map $f:V\rightarrow M$.

Let $\mathfrak{g}=\operatorname*{FreeLie}V$. Let $\pi_{1}:\mathfrak{g}\ltimes
M\rightarrow\mathfrak{g}$ be the canonical projection on the first addend.
Then, $\pi_{1}$ is known to be a Lie algebra homomorphism. Let $\pi
_{2}:\mathfrak{g}\ltimes M\rightarrow M$ be the canonical projection on the
second addend.

Regard the canonical injection $\iota_{V}^{\operatorname*{FreeLie}%
}:V\rightarrow\operatorname*{FreeLie}V=\mathfrak{g}$ as an inclusion. Let
$\psi$ be the map%
\[
V\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto\left(
x,f\left(  x\right)  \right)  .
\]
This map $\psi$ is clearly linear. Thus, Theorem \ref{thm.universal.FreeLie}
(applied to $\mathfrak{g}\ltimes M$ and $\psi$ instead of $\mathfrak{h}$ and
$f$) yields that there exists a unique Lie algebra homomorphism
$F:\operatorname*{FreeLie}V\rightarrow\mathfrak{g}\ltimes M$ satisfying
$\psi=F\circ\iota_{V}^{\operatorname*{FreeLie}}$. Denote this $F$ by $\Psi$.
Thus, $\Psi:\operatorname*{FreeLie}V\rightarrow\mathfrak{g}\ltimes M$ is a Lie
algebra homomorphism satisfying $\psi=\Psi\circ\iota_{V}%
^{\operatorname*{FreeLie}}$.

Since $\pi_{1}$ and $\Psi$ are Lie algebra homomorphisms, their composition
$\pi_{1}\circ\Psi:\operatorname*{FreeLie}V\rightarrow\mathfrak{g}$ must also
be a Lie algebra homomorphism. Note that $\operatorname*{id}%
\nolimits_{\mathfrak{g}}$ also is a Lie algebra homomorphism from
$\operatorname*{FreeLie}V$ to $\mathfrak{g}$ (since $\mathfrak{g}%
=\operatorname*{FreeLie}V$).

Every $x\in V$ satisfies $\iota_{V}^{\operatorname*{FreeLie}}\left(  x\right)
=x$ (since we regard the map $\iota_{V}^{\operatorname*{FreeLie}}$ as an
inclusion). But every $x\in V$ satisfies%
\[
\left(  \pi_{1}\circ\psi\right)  \left(  x\right)  =\pi_{1}\left(
\underbrace{\psi\left(  x\right)  }_{\substack{=\left(  x,f\left(  x\right)
\right)  \\\text{(by the definition of }\psi\text{)}}}\right)  =\pi_{1}\left(
x,f\left(  x\right)  \right)  =x
\]
(since $\pi_{1}:\mathfrak{g}\ltimes M\rightarrow\mathfrak{g}$ was defined as
the canonical projection on the first addend). Thus, every $x\in V$ satisfies
$\left(  \pi_{1}\circ\psi\right)  \left(  x\right)  =x=\iota_{V}%
^{\operatorname*{FreeLie}}\left(  x\right)  $. Hence, $\pi_{1}\circ\psi
=\iota_{V}^{\operatorname*{FreeLie}}$.

Applying Theorem \ref{thm.universal.FreeLie} to $\mathfrak{g}$ and $\pi
_{1}\circ\psi$ instead of $\mathfrak{h}$ and $f$, we conclude that there
exists a unique Lie algebra homomorphism $F:\operatorname*{FreeLie}%
V\rightarrow\mathfrak{g}$ satisfying $\pi_{1}\circ\psi=F\circ\iota
_{V}^{\operatorname*{FreeLie}}$. Hence, if $F_{1}$ and $F_{2}$ are two Lie
algebra homomorphisms $\operatorname*{FreeLie}V\rightarrow\mathfrak{g}$
satisfying $\pi_{1}\circ\psi=F_{1}\circ\iota_{V}^{\operatorname*{FreeLie}}$
and $\pi_{1}\circ\psi=F_{2}\circ\iota_{V}^{\operatorname*{FreeLie}}$, then we
must have $F_{1}=F_{2}$. Applying this to $F_{1}=\pi_{1}\circ\Psi$ and
$F_{2}=\operatorname*{id}\nolimits_{\mathfrak{g}}$ (since $\pi_{1}%
\circ\underbrace{\psi}_{=\Psi\circ\iota_{V}^{\operatorname*{FreeLie}}}=\pi
_{1}\circ\Psi\circ\iota_{V}^{\operatorname*{FreeLie}}$ and $\pi_{1}\circ
\psi=\iota_{V}^{\operatorname*{FreeLie}}=\operatorname*{id}%
\nolimits_{\mathfrak{g}}\circ\iota_{V}^{\operatorname*{FreeLie}}$), we obtain
$\pi_{1}\circ\Psi=\operatorname*{id}\nolimits_{\mathfrak{g}}$.

Now, let $\varphi$ denote the linear map $\pi_{2}\circ\Psi
:\operatorname*{FreeLie}V\rightarrow M$. Since $\operatorname*{FreeLie}%
V=\mathfrak{g}$, this map $\varphi$ is a linear map $\mathfrak{g}\rightarrow
M$. We shall now show that this map $\varphi$ is a $1$-cocycle satisfying
$f=\varphi\circ\iota_{V}^{\operatorname*{FreeLie}}$.

Indeed, every $x\in\mathfrak{g}$ satisfies%
\[
\Psi\left(  x\right)  =\left(  x,\varphi\left(  x\right)  \right)
\]
\footnote{\textit{Proof.} Let $x\in\mathfrak{g}$. Then, $x\in\mathfrak{g}%
=\operatorname*{FreeLie}V$, so that $\Psi\left(  x\right)  $ is an element of
$\mathfrak{g}\ltimes M$. Hence, we can write $\Psi\left(  x\right)  $ in the
form $\Psi\left(  x\right)  =\left(  y,z\right)  $ for some $y\in\mathfrak{g}$
and $z\in M$ (by the definition of $\mathfrak{g}\ltimes M$). Consider these
$y$ and $z$. Since $\Psi\left(  x\right)  =\left(  y,z\right)  $, we have
$\pi_{1}\left(  \Psi\left(  x\right)  \right)  =\pi_{1}\left(  y,z\right)  =y$
(since $\pi_{1}:\mathfrak{g}\ltimes M\rightarrow\mathfrak{g}$ is the canonical
projection on the first addend) and $\pi_{2}\left(  \Psi\left(  x\right)
\right)  =\pi_{2}\left(  y,z\right)  =z$ (since $\pi_{2}:\mathfrak{g}\ltimes
M\rightarrow M$ is the canonical projection on the second addend). But now,
$y=\pi_{1}\left(  \Psi\left(  x\right)  \right)  =\underbrace{\left(  \pi
_{1}\circ\Psi\right)  }_{=\operatorname*{id}\nolimits_{\mathfrak{g}}}\left(
x\right)  =x$ and $z=\pi_{2}\left(  \Psi\left(  x\right)  \right)
=\underbrace{\left(  \pi_{2}\circ\Psi\right)  }_{=\varphi}\left(  x\right)  $,
so we have $\Psi\left(  x\right)  =\left(  \underbrace{y}_{=x},\underbrace{z}%
_{=\varphi\left(  x\right)  }\right)  =\left(  x,\varphi\left(  x\right)
\right)  $, qed.}. In other words, $\Psi$ is the map
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)  .
\]
Since we know that $\Psi$ is a Lie algebra homomorphism, we thus conclude that
the map
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)
\]
is a Lie algebra homomorphism. Hence, $\varphi:\mathfrak{g}\rightarrow M$ is a
$1$-cocycle (because Lemma \ref{lem.semidir.coc-to-deriv} yields that
$\varphi:\mathfrak{g}\rightarrow M$ is a $1$-cocycle if and only if the map%
\[
\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,\ \ \ \ \ \ \ \ \ \ x\mapsto
\left(  x,\varphi\left(  x\right)  \right)
\]
is a Lie algebra homomorphism). In other words, $\varphi
:\operatorname*{FreeLie}V\rightarrow M$ is a $1$-cocycle (since $\mathfrak{g}%
=\operatorname*{FreeLie}V$).

Every $x\in V$ satisfies%
\begin{align*}
\left(  \underbrace{\varphi}_{=\pi_{2}\circ\Psi}\circ\iota_{V}%
^{\operatorname*{FreeLie}}\right)  \left(  x\right)   &  =\left(  \pi_{2}%
\circ\underbrace{\Psi\circ\iota_{V}^{\operatorname*{FreeLie}}}_{=\psi}\right)
\left(  x\right)  =\left(  \pi_{2}\circ\psi\right)  \left(  x\right)  =\pi
_{2}\left(  \underbrace{\psi\left(  x\right)  }_{\substack{=\left(  x,f\left(
x\right)  \right)  \\\text{(by the definition of }\psi\text{)}}}\right) \\
&  =\pi_{2}\left(  x,f\left(  x\right)  \right)  =f\left(  x\right)
\end{align*}
(since $\pi_{2}:\mathfrak{g}\ltimes M\rightarrow M$ was defined as the
canonical projection on the second addend). Thus, $\varphi\circ\iota
_{V}^{\operatorname*{FreeLie}}=f$.

Altogether, we know that $\varphi:\operatorname*{FreeLie}V\rightarrow M$ is a
$1$-cocycle satisfying $f=\varphi\circ\iota_{V}^{\operatorname*{FreeLie}}$. We
thus conclude that there exists a $1$-cocycle $F:\operatorname*{FreeLie}%
V\rightarrow M$ satisfying $f=F\circ\iota_{V}^{\operatorname*{FreeLie}}$
(namely, $F=\varphi$).

Now, let us prove the uniqueness of such an $F$.

Let $F$ be a $1$-cocycle $\operatorname*{FreeLie}V\rightarrow M$ satisfying
$f=F\circ\iota_{V}^{\operatorname*{FreeLie}}$. We will prove that $F=\varphi$.

Recall that the free Lie algebra $\operatorname*{FreeLie}V$ is generated by
its subset $V$ as a Lie algebra. Every $x\in V$ satisfies%
\[
\underbrace{f}_{=F\circ\iota_{V}^{\operatorname*{FreeLie}}}\left(  x\right)
=\left(  F\circ\iota_{V}^{\operatorname*{FreeLie}}\right)  \left(  x\right)
=F\left(  \underbrace{\iota_{V}^{\operatorname*{FreeLie}}\left(  x\right)
}_{=x}\right)  =F\left(  x\right)  =\left(  F\mid_{V}\right)  \left(
x\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }x\in V\right)
\]
and%
\[
\underbrace{f}_{=\varphi\circ\iota_{V}^{\operatorname*{FreeLie}}}\left(
x\right)  =\left(  \varphi\circ\iota_{V}^{\operatorname*{FreeLie}}\right)
\left(  x\right)  =\varphi\left(  \underbrace{\iota_{V}%
^{\operatorname*{FreeLie}}\left(  x\right)  }_{=x}\right)  =\varphi\left(
x\right)  =\left(  \varphi\mid_{V}\right)  \left(  x\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }x\in V\right)  .
\]
Thus, every $x\in V$ satisfies $\left(  F\mid_{V}\right)  \left(  x\right)
=f\left(  x\right)  =\left(  \varphi\mid_{V}\right)  \left(  x\right)  $.
Hence, $F\mid_{V}=\varphi\mid_{V}$. Thus, Proposition
\ref{prop.derivation.Lie.unique} (applied to $\operatorname*{FreeLie}V$, $F$,
$\varphi$ and $V$ instead of $\mathfrak{g}$, $d$, $e$ and $S$) yields that
$F=\varphi$.

Now forget that we fixed $F$. We thus have proven that every $1$-cocycle
$F:\operatorname*{FreeLie}V\rightarrow M$ satisfying $f=F\circ\iota
_{V}^{\operatorname*{FreeLie}}$ must satisfy $F=\varphi$. Hence, there exists
at most one $1$-cocycle $F:\operatorname*{FreeLie}V\rightarrow M$ satisfying
$f=F\circ\iota_{V}^{\operatorname*{FreeLie}}$. Combined with the fact that
there exists a $1$-cocycle $F:\operatorname*{FreeLie}V\rightarrow M$
satisfying $f=F\circ\iota_{V}^{\operatorname*{FreeLie}}$ (this fact was proven
above), this yields that there exists a unique $1$-cocycle
$F:\operatorname*{FreeLie}V\rightarrow M$ satisfying $f=F\circ\iota
_{V}^{\operatorname*{FreeLie}}$. This proves Theorem
\ref{thm.universal.FreeLie.der}.
\end{verlong}

An alternative way to prove Theorem \ref{thm.universal.FreeLie.der} is the
following: Apply Theorem \ref{thm.universal.tensor.der} to construct a
derivation $F:T\left(  V\right)  \rightarrow M$ (of algebras) satisfying
$f=F\circ\iota_{V}^{T}$, and then identify $\operatorname*{FreeLie}V$ with a
Lie subalgebra of $T\left(  V\right)  $ (because Proposition \ref{prop.Ufree}
$U\left(  \operatorname*{FreeLie}V\right)  \cong T\left(  V\right)  $, and
because the Poincar\'{e}-Birkhoff-Witt theorem entails an injection
$\operatorname*{FreeLie}V\rightarrow U\left(  \operatorname*{FreeLie}V\right)
$). Then, restricting the derivation $F:T\left(  V\right)  \rightarrow M$ to
$\operatorname*{FreeLie}V$, we obtain a $1$-cocycle $\operatorname*{FreeLie}%
V\rightarrow M$ with the required properties. The uniqueness part of Theorem
\ref{thm.universal.FreeLie.der} is easy (and follows from Proposition
\ref{prop.derivation.Lie.unique} below). This proof of Theorem
\ref{thm.universal.FreeLie.der} has the disadvantage that it makes use of the
Poincar\'{e}-Birkhoff-Witt theorem, which does not generalize to the case of
Lie algebras over rings (whereas Theorem \ref{thm.universal.FreeLie.der} does
generalize to this case).

\subsubsection{Derivations from grading}

The following simple lemma will help us defining derivations on Lie algebras:

\begin{lemma}
\label{lem.deriv.grading}Let $Q$ be an abelian group. Let $s\in
\operatorname*{Hom}\left(  Q,\mathbb{C}\right)  $ be a group homomorphism. Let
$\mathfrak{n}$ be a $Q$-graded Lie algebra. Let $\eta:\mathfrak{n}%
\rightarrow\mathfrak{n}$ be a linear map satisfying%
\begin{equation}
\eta\left(  x\right)  =s\left(  w\right)  \cdot x\ \ \ \ \ \ \ \ \ \ \text{for
every }w\in Q\text{ and every }x\in\mathfrak{n}\left[  w\right]  .
\label{lem.deriv.grading.1}%
\end{equation}
Then, $\eta$ is a derivation (of Lie algebras).
\end{lemma}

\textit{Proof of Lemma \ref{lem.deriv.grading}.} In order to prove that $\eta$
is a derivation, we need to check that
\begin{equation}
\eta\left(  \left[  a,b\right]  \right)  =\left[  \eta\left(  a\right)
,b\right]  +\left[  a,\eta\left(  b\right)  \right]
\ \ \ \ \ \ \ \ \ \ \text{for any }a\in\mathfrak{n}\text{ and }b\in
\mathfrak{n}. \label{pf.deriv.grading.1}%
\end{equation}
Let us prove the equation (\ref{pf.deriv.grading.1}). Since this equation is
linear in each of $a$ and $b$, we can WLOG assume that $a$ and $b$ are
homogeneous (because any element of $\mathfrak{n}$ is a sum of homogeneous
elements). So, assume this. We will write the binary operation of the group
$Q$ as addition. Since $a$ is homogeneous, we have $a\in\mathfrak{n}\left[
u\right]  $ for some $u\in Q$. Consider this $u$. Since $b$ is homogeneous, we
have $b\in\mathfrak{n}\left[  v\right]  $ for some $v\in Q$. Fix this $v$.
Thus, $\left[  a,b\right]  \in\mathfrak{n}\left[  u+v\right]  $ (since
$a\in\mathfrak{n}\left[  u\right]  $ and $b\in\mathfrak{n}\left[  v\right]  $
and since $\mathfrak{n}$ is $Q$-graded). Thus, (\ref{lem.deriv.grading.1})
(applied to $x=a+b$ and $w=u+v$) yields $\eta\left(  \left[  a,b\right]
\right)  =\underbrace{s\left(  u+v\right)  }_{\substack{=s\left(  u\right)
+s\left(  v\right)  \\\text{(since }s\text{ is a group}\\\text{homomorphism)}%
}}\cdot\left[  a,b\right]  =\left(  s\left(  u\right)  +s\left(  v\right)
\right)  \cdot\left[  a,b\right]  $. On the other hand,
(\ref{lem.deriv.grading.1}) (applied to $x=a$ and $w=u$) yields $\eta\left(
a\right)  =s\left(  u\right)  \cdot a$. Also, (\ref{lem.deriv.grading.1})
(applied to $x=b$ and $y=v$) yields $\eta\left(  b\right)  =s\left(  v\right)
\cdot b$. Now,%
\[
\left[  \underbrace{\eta\left(  a\right)  }_{=s\left(  u\right)  \cdot
a},b\right]  +\left[  a,\underbrace{\eta\left(  b\right)  }_{=s\left(
v\right)  \cdot b}\right]  =s\left(  u\right)  \cdot\left[  a,b\right]
+s\left(  v\right)  \cdot\left[  a,b\right]  =\left(  s\left(  u\right)
+s\left(  v\right)  \right)  \cdot\left[  a,b\right]  =\eta\left(  \left[
a,b\right]  \right)  .
\]
This proves (\ref{pf.deriv.grading.1}). Now that (\ref{pf.deriv.grading.1}) is
proven, we conclude that $\eta$ is a derivation. Lemma \ref{lem.deriv.grading}
is proven.

\subsubsection{The commutator of derivations}

The following proposition is the classical analogue of Proposition
\ref{prop.commutator.derivs} for algebras in lieu of Lie algebras:

\begin{proposition}
\label{prop.commutator.derivs.alg}Let $A$ be an algebra. Let $f:A\rightarrow
A$ and $g:A\rightarrow A$ be two derivations of $A$. Then, $\left[
f,g\right]  $ is a derivation of $A$. (Here, the Lie bracket is to be
understood as the Lie bracket on $\operatorname*{End}A$, so that we have
$\left[  f,g\right]  =f\circ g-g\circ f$.)
\end{proposition}

The proof of this is completely analogous to that of Proposition
\ref{prop.commutator.derivs}. Moreover, by the same argument, the following
slight generalization of Proposition \ref{prop.commutator.derivs.alg} can be shown:

\begin{proposition}
\label{prop.commutator.derivs.alg.2}Let $A$ be a subalgebra of an algebra $B$.
Let $f:A\rightarrow B$ and $g:B\rightarrow B$ be two derivations such that
$g\left(  A\right)  \subseteq A$. Then, $f\circ\left(  g\mid_{A}\right)
-g\circ f:A\rightarrow B$ is a derivation.
\end{proposition}

\begin{verlong}
\textit{Proof of Proposition \ref{prop.commutator.derivs.alg.2}.} Let $a\in A$
and $b\in A$. Since $f$ is a derivation, we have $f\left(  ab\right)
=f\left(  a\right)  \cdot b+a\cdot f\left(  b\right)  $. Thus,%
\begin{align*}
\left(  g\circ f\right)  \left(  ab\right)   &  =g\left(  \underbrace{f\left(
ab\right)  }_{=f\left(  a\right)  \cdot b+a\cdot f\left(  b\right)  }\right)
=g\left(  f\left(  a\right)  \cdot b+a\cdot f\left(  b\right)  \right) \\
&  =\underbrace{g\left(  f\left(  a\right)  \cdot b\right)  }%
_{\substack{=g\left(  f\left(  a\right)  \right)  \cdot b+f\left(  a\right)
\cdot g\left(  b\right)  \\\text{(since }g\text{ is a derivation)}%
}}+\underbrace{g\left(  a\cdot f\left(  b\right)  \right)  }%
_{\substack{=g\left(  a\right)  \cdot f\left(  b\right)  +a\cdot g\left(
f\left(  b\right)  \right)  \\\text{(since }g\text{ is a derivation)}}}\\
&  =\underbrace{g\left(  f\left(  a\right)  \right)  }_{=\left(  g\circ
f\right)  \left(  a\right)  }\cdot b+f\left(  a\right)  \cdot g\left(
b\right)  +g\left(  a\right)  \cdot f\left(  b\right)  +a\cdot
\underbrace{g\left(  f\left(  b\right)  \right)  }_{=\left(  g\circ f\right)
\left(  b\right)  }\\
&  =\left(  g\circ f\right)  \left(  a\right)  \cdot b+f\left(  a\right)
\cdot g\left(  b\right)  +g\left(  a\right)  \cdot f\left(  b\right)
+a\cdot\left(  g\circ f\right)  \left(  b\right)  .
\end{align*}
Let us notice that $f\left(  g\left(  a\right)  \right)  $ and $f\left(
g\left(  b\right)  \right)  $ are well-defined (since $g\left(  \underbrace{a}%
_{\in A}\right)  \in g\left(  A\right)  \subseteq A$ and $g\left(
\underbrace{b}_{\in A}\right)  \in g\left(  A\right)  \subseteq A$). Since $g$
is a derivation, we have $g\left(  ab\right)  =g\left(  a\right)  \cdot
b+a\cdot g\left(  b\right)  $. Thus,%
\begin{align*}
\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(  ab\right)   &
=f\left(  \underbrace{\left(  g\mid_{A}\right)  \left(  ab\right)
}_{=g\left(  ab\right)  =g\left(  a\right)  \cdot b+a\cdot g\left(  b\right)
}\right)  =f\left(  g\left(  a\right)  \cdot b+a\cdot g\left(  b\right)
\right) \\
&  =\underbrace{f\left(  g\left(  a\right)  \cdot b\right)  }%
_{\substack{=f\left(  g\left(  a\right)  \right)  \cdot b+g\left(  a\right)
\cdot f\left(  b\right)  \\\text{(since }g\text{ is a derivation)}%
}}+\underbrace{f\left(  a\cdot g\left(  b\right)  \right)  }%
_{\substack{=f\left(  a\right)  \cdot g\left(  b\right)  +a\cdot f\left(
g\left(  b\right)  \right)  \\\text{(since }g\text{ is a derivation)}}}\\
&  =f\left(  \underbrace{g\left(  a\right)  }_{=\left(  g\mid_{A}\right)
\left(  a\right)  }\right)  \cdot b+g\left(  a\right)  \cdot f\left(
b\right)  +f\left(  a\right)  \cdot g\left(  b\right)  +a\cdot f\left(
\underbrace{g\left(  b\right)  }_{=\left(  g\mid_{A}\right)  \left(  b\right)
}\right) \\
&  =\underbrace{f\left(  \left(  g\mid_{A}\right)  \left(  a\right)  \right)
}_{=\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(  a\right)  }\cdot
b+g\left(  a\right)  \cdot f\left(  b\right)  +f\left(  a\right)  \cdot
g\left(  b\right)  +a\cdot\underbrace{f\left(  \left(  g\mid_{A}\right)
\left(  b\right)  \right)  }_{=\left(  f\circ\left(  g\mid_{A}\right)
\right)  \left(  b\right)  }\\
&  =\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(  a\right)  \cdot
b+g\left(  a\right)  \cdot f\left(  b\right)  +f\left(  a\right)  \cdot
g\left(  b\right)  +a\cdot\left(  f\circ\left(  g\mid_{A}\right)  \right)
\left(  b\right)  .
\end{align*}


Thus,%
\begin{align*}
&  \left(  f\circ\left(  g\mid_{A}\right)  -g\circ f\right)  \left(  ab\right)
\\
&  =\underbrace{\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(
ab\right)  }_{=\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(
a\right)  \cdot b+g\left(  a\right)  \cdot f\left(  b\right)  +f\left(
a\right)  \cdot g\left(  b\right)  +a\cdot\left(  f\circ\left(  g\mid
_{A}\right)  \right)  \left(  b\right)  }-\underbrace{\left(  g\circ f\right)
\left(  ab\right)  }_{=\left(  g\circ f\right)  \left(  a\right)  \cdot
b+f\left(  a\right)  \cdot g\left(  b\right)  +g\left(  a\right)  \cdot
f\left(  b\right)  +a\cdot\left(  g\circ f\right)  \left(  b\right)  }\\
&  =\left(  \left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(  a\right)
\cdot b+g\left(  a\right)  \cdot f\left(  b\right)  +f\left(  a\right)  \cdot
g\left(  b\right)  +a\cdot\left(  f\circ\left(  g\mid_{A}\right)  \right)
\left(  b\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ -\left(  \left(  g\circ f\right)  \left(  a\right)
\cdot b+f\left(  a\right)  \cdot g\left(  b\right)  +g\left(  a\right)  \cdot
f\left(  b\right)  +a\cdot\left(  g\circ f\right)  \left(  b\right)  \right)
\\
&  =\underbrace{\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(
a\right)  \cdot b-\left(  g\circ f\right)  \left(  a\right)  \cdot
b}_{=\left(  \left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(
a\right)  -\left(  g\circ f\right)  \left(  a\right)  \right)  \cdot
b}+\underbrace{a\cdot\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(
b\right)  -a\cdot\left(  g\circ f\right)  \left(  b\right)  }_{=a\cdot\left(
\left(  f\circ\left(  g\mid_{A}\right)  \right)  \left(  b\right)  -\left(
g\circ f\right)  \left(  b\right)  \right)  }\\
&  =\underbrace{\left(  \left(  f\circ\left(  g\mid_{A}\right)  \right)
\left(  a\right)  -\left(  g\circ f\right)  \left(  a\right)  \right)
}_{=\left(  f\circ\left(  g\mid_{A}\right)  -g\circ f\right)  \left(
a\right)  }\cdot b+a\cdot\underbrace{\left(  \left(  f\circ\left(  g\mid
_{A}\right)  \right)  \left(  b\right)  -\left(  g\circ f\right)  \left(
b\right)  \right)  }_{=\left(  f\circ\left(  g\mid_{A}\right)  -g\circ
f\right)  \left(  b\right)  }\\
&  =\left(  f\circ\left(  g\mid_{A}\right)  -g\circ f\right)  \left(
a\right)  \cdot b+a\cdot\left(  f\circ\left(  g\mid_{A}\right)  -g\circ
f\right)  \left(  b\right)  .
\end{align*}
We have thus proven that any $a\in A$ and $b\in A$ satisfy $\left(
f\circ\left(  g\mid_{A}\right)  -g\circ f\right)  \left(  ab\right)  =\left(
f\circ\left(  g\mid_{A}\right)  -g\circ f\right)  \left(  a\right)  \cdot
b+a\cdot\left(  f\circ\left(  g\mid_{A}\right)  -g\circ f\right)  \left(
b\right)  $. In other words, $f\circ\left(  g\mid_{A}\right)  -g\circ f$ is a
derivation. This proves Proposition \ref{prop.commutator.derivs.alg.2}.

\textit{Proof of Proposition \ref{prop.commutator.derivs.alg}.} Applying
Proposition \ref{prop.commutator.derivs.alg.2} to $B=A$, we obtain that
$f\circ\left(  g\mid_{A}\right)  -g\circ f:A\rightarrow A$ is a derivation
(since $g\left(  A\right)  \subseteq A$). In other words, $\left[  f,g\right]
$ is a derivation (since $f\circ\underbrace{\left(  g\mid_{A}\right)  }%
_{=g}-g\circ f=f\circ g-g\circ f=\left[  f,g\right]  $). Hence, Proposition
\ref{prop.commutator.derivs.alg} is proven.
\end{verlong}

\protect\begin{noncompile}
\subsubsection{Extending degree-zero invariant forms on graded Lie algebras}

In this subsection we will collect some results on how to construct a
degree-$0$ invariant bilinear form on a graded Lie algebra if we are given its
values on the first few homogeneous components and we know that these
homogeneous components generate the whole Lie algebra. Our main results will
be the following two theorems:

\begin{theorem}
[...][ext]
\end{theorem}

\begin{theorem}
[...][symmetry gives symmetry]
\end{theorem}

These two theorems will be later applied to Kac-Moody algebras, on which it
will allow the construction of an invariant form. Nevertheless I (Darij) am
going to prove them in full generality (at least, the greatest generality
known to me) and full detail, seeing that most references known to me offer
neither. However, I don't know of any application of these theorems beyond the
case of Kac-Moody algebras.

We start with the easiest part: the uniqueness of the extended form. We state
it in probably the most general form:

\begin{proposition}
\label{prop.bilext.uni1}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie
algebra over a field $k$. Let $M$ and $N$ be two $\mathbb{Z}$-graded
$\mathfrak{g}$-modules. Let $K\in\mathbb{N}$ be a nonnegative integer. Assume
that every integer $n>K$ satisfies%
\begin{equation}
N\left[  -n\right]  =\sum\limits_{i=1}^{n-1}\mathfrak{g}\left[  -i\right]
\rightharpoonup N\left[  -n+i\right]  . \label{prop.bilext.uni1.gen1}%
\end{equation}
\footnotemark\ For every $n\in\left\{  1,2,...,K\right\}  $, let $\beta_{n}$
be a $k$-bilinear form $M\left[  n\right]  \times N\left[  -n\right]
\rightarrow k$. Then, there exists \textbf{at most} one sequence $\left(
\gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps satisfying the
following three properties \ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2
and \ref{prop.bilext.uni1}.3:

\textit{Property \ref{prop.bilext.uni1}.1:} For every positive integer $n$,
the map $\gamma_{n}$ is a $k$-bilinear form $M\left[  n\right]  \times
N\left[  -n\right]  \rightarrow k$.

\textit{Property \ref{prop.bilext.uni1}.2:} We have $\gamma_{n}=\beta_{n}$ for
every $n\in\left\{  1,2,...,K\right\}  $.

\textit{Property \ref{prop.bilext.uni1}.3:} Every positive integer $n$, every
$i\in\left\{  1,2,...,n-1\right\}  $, every $x\in\mathfrak{g}\left[
-i\right]  $, every $a\in M\left[  n\right]  $ and every $b\in N\left[
-n+i\right]  $ satisfy%
\begin{equation}
\gamma_{n-i}\left(  x\rightharpoonup a,b\right)  +\gamma_{n}\left(
a,x\rightharpoonup b\right)  =0. \label{prop.bilext.uni1.main}%
\end{equation}

\end{proposition}

\footnotetext{Here and in the following, we are using the notation introduced
in Definition \ref{def.liesubspace}.}\ This proposition is rather
straightforward to prove by induction:

\begin{vershort}
\textit{Proof of Proposition \ref{prop.bilext.uni1}.} Let $\left(  \delta
_{1},\delta_{2},\delta_{3},...\right)  $ and $\left(  \varepsilon
_{1},\varepsilon_{2},\varepsilon_{3},...\right)  $ be two sequences $\left(
\gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps satisfying the
properties \ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and
\ref{prop.bilext.uni1}.3. All we need to prove is that $\left(  \delta
_{1},\delta_{2},\delta_{3},...\right)  =\left(  \varepsilon_{1},\varepsilon
_{2},\varepsilon_{3},...\right)  $. That is, all we need to prove is that
$\delta_{n}=\varepsilon_{n}$ for every positive integer $n$.

We are going to prove this by strong induction over $n$. This means that we
fix a positive integer $n$ and are going to show that $\delta_{n}%
=\varepsilon_{n}$ assuming that $\delta_{n^{\prime}}=\varepsilon_{n^{\prime}}$
holds for every positive integer $n^{\prime}<n$.

First of all, if $n\leq K$, then $n\in\left\{  1,2,...,K\right\}  $. Hence, if
$n\leq K$, then Property \ref{prop.bilext.uni1}.2 (which by assumption holds
both for $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  =\left(
\delta_{1},\delta_{2},\delta_{3},...\right)  $ and for $\left(  \gamma
_{1},\gamma_{2},\gamma_{3},...\right)  =\left(  \varepsilon_{1},\varepsilon
_{2},\varepsilon_{3},...\right)  $) yields $\delta_{n}=\beta_{n}$ and
$\varepsilon_{n}=\beta_{n}$. Thus, if $n\leq K$, we have $\delta_{n}=\beta
_{n}=\varepsilon_{n}$, which means that our induction step is complete in this
case. Thus, for the rest of this proof, we will WLOG assume that $n>K$. This
entails that (\ref{prop.bilext.uni1.gen1}) holds.

In order to prove that $\delta_{n}=\varepsilon_{n}$, we have to show that
$\delta_{n}\left(  a,b\right)  =\varepsilon_{n}\left(  a,b\right)  $ for every
$a\in M\left[  n\right]  $ and $b\in N\left[  -n\right]  $. So let $a\in
M\left[  n\right]  $ and $b\in N\left[  -n\right]  $ be arbitrary. Then,%
\[
b\in N\left[  -n\right]  =\sum\limits_{i=1}^{n-1}\mathfrak{g}\left[
-i\right]  \rightharpoonup N\left[  -n+i\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{prop.bilext.uni1.gen1})}\right)
\]
In other words, $b$ is a sum of elements of $\mathfrak{g}\left[  -i\right]
\rightharpoonup N\left[  -n+i\right]  $ for varying $i\in\left\{
1,2,...,n-1\right\}  $. Since the identity that we want to prove (that is,
$\delta_{n}\left(  a,b\right)  =\varepsilon_{n}\left(  a,b\right)  $) is
$k$-linear in $b$, we can therefore WLOG assume that $b\in\mathfrak{g}\left[
-i\right]  \rightharpoonup N\left[  -n+i\right]  $. Assume this. Then, $b$ is
a $k$-linear combination of elements of the form $z\rightharpoonup u$ with
$z\in\mathfrak{g}\left[  -i\right]  $ and $u\in N\left[  -n+i\right]  $.
Again, by linearity, we can WLOG assume that $b$ is such an element (rather
than only a $k$-linear combination). Assume this. So we have
$b=z\rightharpoonup u$ for some $z\in\mathfrak{g}\left[  -i\right]  $ and
$u\in N\left[  -n+i\right]  $. Considering this $z$ and this $u$, we have
$\delta_{n}\left(  a,b\right)  =\delta_{n}\left(  a,z\rightharpoonup u\right)
$.

But we know that $\left(  \delta_{1},\delta_{2},\delta_{3},...\right)  $ is a
sequence $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps
satisfying Property \ref{prop.bilext.uni1}.3. Hence, we can apply Property
\ref{prop.bilext.uni1}.3 to $\delta_{j}$, $z$ and $u$ instead of $\gamma_{j}$,
$x$ and $b$, and this yields $\delta_{n-i}\left(  z\rightharpoonup a,u\right)
+\delta_{n}\left(  a,z\rightharpoonup u\right)  =0$. Thus, $\delta_{n}\left(
a,z\rightharpoonup u\right)  =-\delta_{n-i}\left(  z\rightharpoonup
a,u\right)  $.

Altogether, $\delta_{n}\left(  a,b\right)  =\delta_{n}\left(
a,z\rightharpoonup u\right)  =-\delta_{n-i}\left(  z\rightharpoonup
a,u\right)  $. The same argument, applied to $\varepsilon_{j}$ instead of
$\delta_{j}$, shows that $\varepsilon_{n}\left(  a,b\right)  =-\varepsilon
_{n-i}\left(  z\rightharpoonup a,u\right)  $. But recall the induction
hypothesis saying that $\delta_{n^{\prime}}=\varepsilon_{n^{\prime}}$ holds
for every positive integer $n^{\prime}<n$. This yields $\delta_{n-i}%
=\varepsilon_{n-i}$ (since $n-i<n$). Thus,%
\[
\delta_{n}\left(  a,b\right)  =-\underbrace{\delta_{n-i}}_{=\varepsilon_{n-i}%
}\left(  z\rightharpoonup a,u\right)  =-\varepsilon_{n-i}\left(
z\rightharpoonup a,u\right)  =\varepsilon_{n}\left(  a,b\right)  .
\]
This is exactly what we needed to prove to complete the induction step. Hence,
we have shown that $\delta_{n}=\varepsilon_{n}$ for every positive integer
$n$, and the proof of Proposition \ref{prop.bilext.uni1} is complete.
\end{vershort}

\begin{verlong}
\textit{Proof of Proposition \ref{prop.bilext.uni1}.} Let $\left(  \delta
_{1},\delta_{2},\delta_{3},...\right)  $ and $\left(  \varepsilon
_{1},\varepsilon_{2},\varepsilon_{3},...\right)  $ be two sequences $\left(
\gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps satisfying the
properties \ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and
\ref{prop.bilext.uni1}.3. We are going to prove that $\left(  \delta
_{1},\delta_{2},\delta_{3},...\right)  =\left(  \varepsilon_{1},\varepsilon
_{2},\varepsilon_{3},...\right)  $.

We know that $\left(  \delta_{1},\delta_{2},\delta_{3},...\right)  $ is a
sequence $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps
satisfying the property \ref{prop.bilext.uni1}.3. Hence, we can apply Property
\ref{prop.bilext.uni1}.3 to $\left(  \gamma_{1},\gamma_{2},\gamma
_{3},...\right)  =\left(  \delta_{1},\delta_{2},\delta_{3},...\right)  $. As a
result, we conclude that every positive integer $n$, every $i\in\left\{
1,2,...,n-1\right\}  $, every $x\in\mathfrak{g}\left[  -i\right]  $, every
$a\in M\left[  n\right]  $ and every $b\in N\left[  -n+i\right]  $ satisfy%
\[
\delta_{n-i}\left(  x\rightharpoonup a,b\right)  +\delta_{n}\left(
a,x\rightharpoonup b\right)  =0.
\]
In other words, every positive integer $n$, every $i\in\left\{
1,2,...,n-1\right\}  $, every $x\in\mathfrak{g}\left[  -i\right]  $, every
$a\in M\left[  n\right]  $ and every $b\in N\left[  -n+i\right]  $ satisfy%
\begin{equation}
\delta_{n}\left(  a,x\rightharpoonup b\right)  =-\delta_{n-i}\left(
x\rightharpoonup a,b\right)  . \label{prop.bilext.uni1.prop3d}%
\end{equation}


The same argument (but with $\delta_{j}$ replaced by $\varepsilon_{j}$) yields
that every positive integer $n$, every $i\in\left\{  1,2,...,n-1\right\}  $,
every $x\in\mathfrak{g}\left[  -i\right]  $, every $a\in M\left[  n\right]  $
and every $b\in N\left[  -n+i\right]  $ satisfy%
\begin{equation}
\varepsilon_{n}\left(  a,x\rightharpoonup b\right)  =-\varepsilon_{n-i}\left(
x\rightharpoonup a,b\right)  . \label{prop.bilext.uni1.prop3e}%
\end{equation}


Now, we will show that
\begin{equation}
\delta_{n}=\varepsilon_{n}\ \ \ \ \ \ \ \ \ \ \text{for every positive integer
}n\text{.} \label{pf.bilext.uni1.claim}%
\end{equation}


\textit{Proof of (\ref{pf.bilext.uni1.claim}):} We will prove
(\ref{pf.bilext.uni1.claim}) by strong induction over $n$:

\textit{Induction step:}\footnote{A strong induction needs no induction base.}
Let $\mathbf{n}$ be a positive integer. Assume that
(\ref{pf.bilext.uni1.claim}) holds whenever $n<\mathbf{n}$. We now will prove
that (\ref{pf.bilext.uni1.claim}) holds when $n=\mathbf{n}$.

We will show that $\delta_{\mathbf{n}}=\varepsilon_{\mathbf{n}}$.

We distinguish between two cases:

\textit{Case 1:} We have $\mathbf{n}\leq K$.

\textit{Case 2:} We have $\mathbf{n}>K$.

Let us consider Case 1 first. In this case, $\mathbf{n}\leq K$. Thus,
$\mathbf{n}\in\left\{  1,2,...,K\right\}  $. Hence, we can apply Property
\ref{prop.bilext.uni1}.2 to $\left(  \gamma_{1},\gamma_{2},\gamma
_{3},...\right)  =\left(  \delta_{1},\delta_{2},\delta_{3},...\right)  $ and
$n=\mathbf{n}$ (because we know that $\left(  \delta_{1},\delta_{2},\delta
_{3},...\right)  $ is a sequence $\left(  \gamma_{1},\gamma_{2},\gamma
_{3},...\right)  $ of maps satisfying Property \ref{prop.bilext.uni1}.2). As a
consequence, we obtain $\delta_{\mathbf{n}}=\beta_{\mathbf{n}}$. The same
argument (but with $\delta_{i}$ replaced by $\varepsilon_{i}$) yields that
$\varepsilon_{\mathbf{n}}=\beta_{\mathbf{n}}$. Hence, $\delta_{\mathbf{n}%
}=\beta_{\mathbf{n}}=\varepsilon_{\mathbf{n}}$.

We have thus proven $\delta_{\mathbf{n}}=\varepsilon_{\mathbf{n}}$ in Case 1.

Now, let us consider Case 2. In this case, $\mathbf{n}>K$.

Let $a\in M\left[  \mathbf{n}\right]  $. We are first going to show that
\begin{equation}
\delta_{\mathbf{n}}\left(  a,b\right)  =\varepsilon_{\mathbf{n}}\left(
a,b\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }i\in\left\{
1,2,...,\mathbf{n}-1\right\}  \text{ and }b\in\mathfrak{g}\left[  -i\right]
\rightharpoonup N\left[  -\mathbf{n}+i\right]  \text{.}
\label{pf.bilext.uni1.1}%
\end{equation}


\textit{Proof of (\ref{pf.bilext.uni1.1}):} Let $i\in\left\{
1,2,...,\mathbf{n}-1\right\}  $ and $b\in\mathfrak{g}\left[  -i\right]
\rightharpoonup N\left[  -\mathbf{n}+i\right]  $. By the definition of
$\mathfrak{g}\left[  -i\right]  \rightharpoonup N\left[  -\mathbf{n}+i\right]
$, we know that $\mathfrak{g}\left[  -i\right]  \rightharpoonup N\left[
-\mathbf{n}+i\right]  $ is the $k$-linear span of all elements of the form
$y\rightharpoonup u$ with $y\in\mathfrak{g}\left[  -i\right]  $ and $u\in
N\left[  -\mathbf{n}+i\right]  $. Hence, the elements of $\mathfrak{g}\left[
-i\right]  \rightharpoonup N\left[  -\mathbf{n}+i\right]  $ are $k$-linear
combinations of elements of the form $z\rightharpoonup u$ with $z\in
\mathfrak{g}\left[  -i\right]  $ and $u\in N\left[  -\mathbf{n}+i\right]  $.
Since $b$ is an element of $\mathfrak{g}\left[  -i\right]  \rightharpoonup
N\left[  -\mathbf{n}+i\right]  $, this yields that $b$ is a $k$-linear
combination of elements of the form $z\rightharpoonup u$ with $z\in
\mathfrak{g}\left[  -i\right]  $ and $u\in M\left[  -\mathbf{n}+i\right]  $.
In other words, there exist an $L\in\mathbb{N}$, some elements $\lambda_{1}$,
$\lambda_{2}$, $...$, $\lambda_{L}$ of $k$, some elements $z_{1}$, $z_{2}$,
$...$, $z_{L}$ of $\mathfrak{g}\left[  -i\right]  $ and some elements $u_{1}$,
$u_{2}$, $...$, $u_{L}$ of $M\left[  -\mathbf{n}+i\right]  $ such that
$b=\sum\limits_{\ell=1}^{L}\lambda_{\ell}z_{\ell}\rightharpoonup u_{\ell}$.
Consider this $L$, these $\lambda_{1}$, $\lambda_{2}$, $...$, $\lambda_{L}$,
these $z_{1}$, $z_{2}$, $...$, $z_{L}$, and these $u_{1}$, $u_{2}$, $...$,
$u_{L}$.

Since $b=\sum\limits_{\ell=1}^{L}\lambda_{\ell}z_{\ell}\rightharpoonup
u_{\ell}$, we have
\begin{align}
\delta_{\mathbf{n}}\left(  a,b\right)   &  =\delta_{\mathbf{n}}\left(
a,\sum\limits_{\ell=1}^{L}\lambda_{\ell}z_{\ell}\rightharpoonup u_{\ell
}\right)  =\sum\limits_{\ell=1}^{L}\lambda_{\ell}\underbrace{\delta
_{\mathbf{n}}\left(  a,z_{\ell}\rightharpoonup u_{\ell}\right)  }%
_{\substack{=-\delta_{\mathbf{n}-i}\left(  z_{\ell}\rightharpoonup a,u_{\ell
}\right)  \\\text{(by (\ref{pf.bilext.uni1.prop1delta}), applied to
}\mathbf{n}\text{, }i\text{, }z_{\ell}\text{, }a\text{ and }u_{\ell
}\\\text{instead of }n\text{, }i\text{, }x\text{, }a\text{ and }b\text{)}%
}}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\delta_{\mathbf{n}}\text{ is
}k\text{-bilinear}\right)  .\nonumber\\
&  =\sum\limits_{\ell=1}^{L}\left(  -\delta_{\mathbf{n}-i}\left(  z_{\ell
}\rightharpoonup a,u_{\ell}\right)  \right)  . \label{pf.bilext.uni1.3}%
\end{align}
The same argument (but with $\delta_{j}$ replaced by $\varepsilon_{j}$) yields%
\begin{equation}
\varepsilon_{\mathbf{n}}\left(  a,b\right)  =\sum\limits_{\ell=1}^{L}\left(
-\varepsilon_{\mathbf{n}-i}\left(  z_{\ell}\rightharpoonup a,u_{\ell}\right)
\right)  . \label{pf.bilext.uni1.4}%
\end{equation}
But since $i\in\left\{  1,2,...,\mathbf{n}-1\right\}  $, we have $i>0$, so
that $\mathbf{n}-i<\mathbf{n}$. Hence, (\ref{pf.bilext.uni1.claim}) holds for
$n=\mathbf{n}-i$ (because we have assumed that (\ref{pf.bilext.uni1.claim})
holds whenever $n<\mathbf{n}$). In other words, $\delta_{\mathbf{n}%
-i}=\varepsilon_{\mathbf{n}-i}$. Now, (\ref{pf.bilext.uni1.3}) becomes%
\[
\delta_{\mathbf{n}}\left(  a,b\right)  =\sum\limits_{\ell=1}^{L}\left(
-\underbrace{\delta_{\mathbf{n}-i}}_{=\varepsilon_{\mathbf{n}-i}}\left(
z_{\ell}\rightharpoonup a,u_{\ell}\right)  \right)  =\sum\limits_{\ell=1}%
^{L}\left(  -\varepsilon_{\mathbf{n}-i}\left(  z_{\ell}\rightharpoonup
a,u_{\ell}\right)  \right)  =\varepsilon_{\mathbf{n}}\left(  a,b\right)
\]
(by (\ref{pf.bilext.uni1.4})). This proves (\ref{pf.bilext.uni1.1}).

Now, let $b$ be any element of $N\left[  -\mathbf{n}\right]  $. Since
$\mathbf{n}>K$, we can apply (\ref{prop.bilext.uni1.gen1}) to $n=\mathbf{n}$.
As a result, we obtain%
\[
N\left[  -\mathbf{n}\right]  =\sum\limits_{i=1}^{\mathbf{n}-1}\mathfrak{g}%
\left[  -i\right]  \rightharpoonup N\left[  -\mathbf{n}+i\right]  .
\]
Hence,%
\[
b\in N\left[  -\mathbf{n}\right]  =\sum\limits_{i=1}^{\mathbf{n}%
-1}\mathfrak{g}\left[  -i\right]  \rightharpoonup N\left[  -\mathbf{n}%
+i\right]  .
\]
Thus, there exists an $\left(  \mathbf{n}-1\right)  $-tuple $\left(
b_{1},b_{2},...,b_{\mathbf{n}-1}\right)  $ of elements of $N$ such that
$\left(  \text{every }i\in\left\{  1,2,...,\mathbf{n}-1\right\}  \text{
satisfies }b_{i}\in\mathfrak{g}\left[  -i\right]  \rightharpoonup N\left[
-\mathbf{n}+i\right]  \right)  $ and $b=\sum\limits_{i=1}^{\mathbf{n}-1}b_{i}%
$. Consider this $\left(  \mathbf{n}-1\right)  $-tuple $\left(  b_{1}%
,b_{2},...,b_{\mathbf{n}-1}\right)  $. Since $b=\sum\limits_{i=1}%
^{\mathbf{n}-1}b_{i}$, we have%
\begin{align*}
\delta_{\mathbf{n}}\left(  a,b\right)   &  =\delta_{\mathbf{n}}\left(
a,\sum\limits_{i=1}^{\mathbf{n}-1}b_{i}\right)  =\sum\limits_{i=1}%
^{\mathbf{n}-1}\underbrace{\delta_{\mathbf{n}}\left(  a,b_{i}\right)
}_{\substack{=\varepsilon_{\mathbf{n}}\left(  a,b_{i}\right)  \\\text{(by
(\ref{pf.bilext.uni1.1}) (applied to }b_{i}\text{ instead of }b\text{)}%
\\\text{(since }b_{i}\in\mathfrak{g}\left[  -i\right]  \rightharpoonup
N\left[  -\mathbf{n}+i\right]  \text{))}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }\delta_{\mathbf{n}}\text{ is }k\text{-linear}\right) \\
&  =\sum\limits_{i=1}^{\mathbf{n}-1}\varepsilon_{\mathbf{n}}\left(
a,b_{i}\right)  =\varepsilon_{\mathbf{n}}\left(  a,\underbrace{\sum
\limits_{i=1}^{\mathbf{n}-1}b_{i}}_{=b}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\varepsilon_{\mathbf{n}}\text{ is }k\text{-linear}\right) \\
&  =\varepsilon_{\mathbf{n}}\left(  a,b\right)  .
\end{align*}


Now, forget that we fixed $a$ and $b$. We thus have shown that $\delta
_{\mathbf{n}}\left(  a,b\right)  =\varepsilon_{\mathbf{n}}\left(  a,b\right)
$ for every $a\in M\left[  \mathbf{n}\right]  $ and $b\in N\left[
-\mathbf{n}\right]  $. In other words, $\delta_{\mathbf{n}}=\varepsilon
_{\mathbf{n}}$. We have thus proven $\delta_{\mathbf{n}}=\varepsilon
_{\mathbf{n}}$ in Case 2.

Hence, $\delta_{\mathbf{n}}=\varepsilon_{\mathbf{n}}$ is proven in each of the
Cases 1 and 2. Since the Cases 1 and 2 cover all possibilities, this yields
that $\delta_{\mathbf{n}}=\varepsilon_{\mathbf{n}}$ always holds. In other
words, (\ref{pf.bilext.uni1.claim}) holds when $n=\mathbf{n}$. This completes
the induction step. The induction proof of (\ref{pf.bilext.uni1.claim}) is
thus complete.

From (\ref{pf.bilext.uni1.claim}), we immediately obtain $\left(  \delta
_{1},\delta_{2},\delta_{3},...\right)  =\left(  \varepsilon_{1},\varepsilon
_{2},\varepsilon_{3},...\right)  $.

Now, forget that we fixed $\left(  \delta_{1},\delta_{2},\delta_{3}%
,...\right)  $ and $\left(  \varepsilon_{1},\varepsilon_{2},\varepsilon
_{3},...\right)  $. We thus have shown that if $\left(  \delta_{1},\delta
_{2},\delta_{3},...\right)  $ and $\left(  \varepsilon_{1},\varepsilon
_{2},\varepsilon_{3},...\right)  $ are two sequences $\left(  \gamma
_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps satisfying the properties
\ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}%
.3, then $\left(  \delta_{1},\delta_{2},\delta_{3},...\right)  =\left(
\varepsilon_{1},\varepsilon_{2},\varepsilon_{3},...\right)  $. In other words,
any two sequences $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of
maps satisfying the properties \ref{prop.bilext.uni1}.1,
\ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}.3 must be equal. In other
words, there exists at most one sequence $\left(  \gamma_{1},\gamma_{2}%
,\gamma_{3},...\right)  $ of maps satisfying the properties
\ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}%
.3. This proves Proposition \ref{prop.bilext.uni1}.
\end{verlong}

We will now supplement this proposition with a corresponding existence
statement, albeit one that requires more assumptions:

\begin{proposition}
\label{prop.bilext.1}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra
over a field $k$. Let $M$ and $N$ be two $\mathbb{Z}$-graded $\mathfrak{g}%
$-modules. Let $K\in\mathbb{N}$ be a nonnegative integer. Assume that every
integer $n>K$ satisfies%
\begin{equation}
N\left[  -n\right]  =\sum\limits_{i=1}^{n-1}\mathfrak{g}\left[  -i\right]
\rightharpoonup N\left[  -n+i\right]  . \label{prop.bilext.1.gen1}%
\end{equation}
Assume further that every integer $n>K$ satisfies%
\begin{equation}
M\left[  n\right]  =\sum\limits_{i=1}^{n-1}\mathfrak{g}\left[  i\right]
\rightharpoonup M\left[  n-i\right]  . \label{prop.bilext.1.gen2}%
\end{equation}
For every $i\in\left\{  1,2,...,K\right\}  $, let $\beta_{i}$ be a
$k$-bilinear form $M\left[  i\right]  \times N\left[  -i\right]  \rightarrow
k$. Assume that every $n\in\left\{  1,2,...,K\right\}  $, every $i\in\left\{
1,2,...,n-1\right\}  $, every $x\in\mathfrak{g}\left[  -i\right]  $, every
$a\in M\left[  n\right]  $ and every $b\in N\left[  -n+i\right]  $ satisfy%
\begin{equation}
\beta_{n-i}\left(  x\rightharpoonup a,b\right)  +\beta_{n}\left(
a,x\rightharpoonup b\right)  =0. \label{prop.bilext.1.main}%
\end{equation}


Then, there exists \textbf{one and only one} sequence $\left(  \gamma
_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps satisfying the three
properties \ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and
\ref{prop.bilext.uni1}.3. (See Proposition \ref{prop.bilext.uni1} for the
statements of these three properties.)
\end{proposition}

Before we prove this, we will need two lemmas:

\begin{lemma}
\label{lem.bilext.1.1}Let $p\in\mathbb{N}$. Let $k$ be a field. Let $W$ be a
$k$-vector space. Let $V_{1}$, $V_{2}$, $...$, $V_{p}$ be $k$-vector spaces.
For every $i\in\left\{  1,2,...,p\right\}  $, let $f_{i}:V_{i}\rightarrow W$
be a $k$-linear map. We denote by $\sum\limits_{i=1}^{p}f_{i}$ the map
$\bigoplus\limits_{i=1}^{p}V_{i}\rightarrow W$ obtained from the maps
$f_{i}:V_{i}\rightarrow W$ through the universal property of the direct sum
$\bigoplus\limits_{i=1}^{p}V_{i}$. (This is the map which sends every $\left(
v_{i}\right)  _{i\in\left\{  1,2,...,p\right\}  }\in\bigoplus\limits_{i=1}%
^{p}V_{i}$ to $\sum\limits_{i=1}^{p}f_{i}\left(  v_{i}\right)  $.) Then,%
\[
\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus\limits_{i=1}%
^{p}V_{i}\right)  =\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  .
\]

\end{lemma}

Lemma \ref{lem.bilext.1.1} is just a basic fact from linear algebra.

\begin{verlong}
\textit{Proof of Lemma \ref{lem.bilext.1.1}.} Let $w\in\left(  \sum
\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus\limits_{i=1}^{p}V_{i}\right)
$. Then, there exists a $v\in\bigoplus\limits_{i=1}^{p}V_{i}$ such that
$w=\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  v\right)  $. Consider
this $v$.

Since $v\in\bigoplus\limits_{i=1}^{p}V_{i}$, we know that $v$ can be written
in the form $v=\left(  v_{i}\right)  _{i\in\left\{  1,2,...,p\right\}  }$,
where $v_{1}$, $v_{2}$, $...$, $v_{p}$ are vectors in $V_{1}$, $V_{2}$, $...$,
$V_{p}$, respectively. Consider these $v_{1}$, $v_{2}$, $...$, $v_{p}$.

Now,%
\begin{align*}
w  &  =\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  v\right)  =\left(
\sum\limits_{i=1}^{p}f_{i}\right)  \left(  \left(  v_{i}\right)
_{i\in\left\{  1,2,...,p\right\}  }\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }v=\left(  v_{i}\right)  _{i\in\left\{  1,2,...,p\right\}
}\right) \\
&  =\sum\limits_{i=1}^{p}f_{i}\left(  \underbrace{v_{i}}_{\in V_{i}}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\sum\limits_{i=1}%
^{p}f_{i}\right) \\
&  \in\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  .
\end{align*}


Now, forget that we fixed $w$. We thus have shown that $\left(  \sum
\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus\limits_{i=1}^{p}V_{i}\right)
\subseteq\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  $.

On the other hand, let $u\in\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  $.
Then, there exists a family $\left(  u_{i}\right)  _{i\in\left\{
1,2,...,p\right\}  }$ of elements of $W$ which satisfies $u=\sum
\limits_{i=1}^{p}u_{i}$, $\left(  u_{i}\in f_{i}\left(  V_{i}\right)  \text{
for every }i\in\left\{  1,2,...,p\right\}  \right)  $ and $\left(  \text{all
but finitely many }i\in\left\{  1,2,...,p\right\}  \text{ satisfy }%
u_{i}=0\right)  $\ \ \ \ \footnote{The third of these conditions is a
tautology, of course.}. Consider such a family $\left(  u_{i}\right)
_{i\in\left\{  1,2,...,p\right\}  }$. We know that for every $i\in\left\{
1,2,...,p\right\}  $, there exists an $x\in V_{i}$ such that $u_{i}%
=f_{i}\left(  x\right)  $ (because $u_{i}\in f_{i}\left(  V_{i}\right)  $).
Denote this $x$ by $x_{i}$. Then, for every $i\in\left\{  1,2,...,p\right\}
$, we have $x_{i}\in V_{i}$ and $u_{i}=f_{i}\left(  x_{i}\right)  $.

But $\bigoplus\limits_{i=1}^{p}V_{i}=\prod\limits_{i=1}^{p}V_{i}$ (because a
direct sum of finitely many $k$-vector spaces is the same as their direct
product) and $\left(  x_{i}\right)  _{i\in\left\{  1,2,...,p\right\}  }%
\in\prod\limits_{i=1}^{p}V_{i}$ (since $x_{i}\in V_{i}$ for every
$i\in\left\{  1,2,...,p\right\}  $). Hence,
\[
\left(  x_{i}\right)  _{i\in\left\{  1,2,...,p\right\}  }\in\prod
\limits_{i=1}^{p}V_{i}=\bigoplus\limits_{i=1}^{p}V_{i},
\]
so that $\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  \left(
x_{i}\right)  _{i\in\left\{  1,2,...,p\right\}  }\right)  $ is well-defined.
By the definition of $\sum\limits_{i=1}^{p}f_{i}$, we have%
\[
\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  \left(  x_{i}\right)
_{i\in\left\{  1,2,...,p\right\}  }\right)  =\sum\limits_{i=1}^{p}f_{i}\left(
x_{i}\right)  ,
\]
so that%
\[
u=\sum\limits_{i=1}^{p}\underbrace{u_{i}}_{=f_{i}\left(  x_{i}\right)  }%
=\sum\limits_{i=1}^{p}f_{i}\left(  x_{i}\right)  =\left(  \sum\limits_{i=1}%
^{p}f_{i}\right)  \left(  \left(  x_{i}\right)  _{i\in\left\{
1,2,...,p\right\}  }\right)  \in\left(  \sum\limits_{i=1}^{p}f_{i}\right)
\left(  \bigoplus\limits_{i=1}^{p}V_{i}\right)  .
\]


Now, forget that we fixed $u$. We thus have shown that every $u\in
\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  $ satisfies $u\in\left(
\sum\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus\limits_{i=1}^{p}%
V_{i}\right)  $. In other words, $\sum\limits_{i=1}^{p}f_{i}\left(
V_{i}\right)  \subseteq\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(
\bigoplus\limits_{i=1}^{p}V_{i}\right)  $. Combining this with $\left(
\sum\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus\limits_{i=1}^{p}%
V_{i}\right)  \subseteq\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  $, we
obtain $\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus
\limits_{i=1}^{p}V_{i}\right)  =\sum\limits_{i=1}^{p}f_{i}\left(
V_{i}\right)  $. This proves Lemma \ref{lem.bilext.1.1}.
\end{verlong}

\begin{lemma}
\label{lem.bilext.1.2}Let $\mathfrak{g}$ be a $\mathbb{Z}$-graded Lie algebra
over a field $k$. Let $M$ and $N$ be two $\mathbb{Z}$-graded $\mathfrak{g}%
$-modules. Let $\mathbf{n}$ be a nonnegative integer. Let $\left(  \gamma
_{1},\gamma_{2},...,\gamma_{\mathbf{n}-1}\right)  $ be a sequence of maps such
that the two properties \ref{prop.bilext.uni1}.1 and \ref{prop.bilext.uni1}.3
are satisfied for all $n\leq\mathbf{n}-1$.

[...]
\end{lemma}

\textit{Proof of Lemma \ref{lem.bilext.1.2}.} [...]

\textit{Proof of Proposition \ref{prop.bilext.1}.} From Proposition
\ref{prop.bilext.uni1}, we know that there exists \textbf{at most} one
sequence $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  $ of maps
satisfying the three properties \ref{prop.bilext.uni1}.1,
\ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}.3. It thus remains to show
that there exists \textbf{at least} one such sequence. So let us construct
such a sequence.

We will construct a sequence $\left(  \gamma_{1},\gamma_{2},\gamma
_{3},...\right)  $ of maps satisfying the three properties
\ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}%
.3 recursively, more precisely by strong induction. This means that we will
assume that $\mathbf{n}$ is a positive integer and we are given a sequence
$\left(  \gamma_{1},\gamma_{2},...,\gamma_{\mathbf{n}-1}\right)  $ of maps
satisfying the three properties \ref{prop.bilext.uni1}.1,
\ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}.3 for all $n\leq
\mathbf{n}-1$\ \ \ \ \footnote{When I say ``for all $n\leq\mathbf{n}-1$'', I
don't mean to remove the conditions imposed on $n$ in the properties
\ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}%
.3, but I just mean to add the extra condition that $n\leq\mathbf{n}-1$ to the
existing conditions. So, for example, saying that Property
\ref{prop.bilext.uni1}.2 holds for all $n\leq\mathbf{n}-1$ is equivalent to
saying that $\gamma_{n}=\beta_{n}$ for every $n\in\left\{  1,2,...,K\right\}
$ satisfying $n\leq\mathbf{n}-1$, but not to saying that $\gamma_{n}=\beta
_{n}$ for all positive integers $n$ whatsoever satisfying $n\leq\mathbf{n}%
-1$.}, and we will show how to construct a new map $\gamma_{\mathbf{n}}$ which
extends this sequence to a sequence $\left(  \gamma_{1},\gamma_{2}%
,...,\gamma_{\mathbf{n}}\right)  $ of maps satisfying the three properties
\ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}%
.3 for all $n\leq\mathbf{n}$. This will allow recursively constructing maps
$\gamma_{1}$, $\gamma_{2}$, $\gamma_{3}$, $...$ in such a way that the
resulting sequence $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  $
satisfies the three properties \ref{prop.bilext.uni1}.1,
\ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}.3 for all $n$. This will
show that there exists at least one such sequence.

So, let us perform the induction step in the recursive construction of the
sequence $\left(  \gamma_{1},\gamma_{2},\gamma_{3},...\right)  $. Let
$\mathbf{n}$ be a positive integer. Assume that we are given a sequence
$\left(  \gamma_{1},\gamma_{2},...,\gamma_{\mathbf{n}-1}\right)  $ of maps
satisfying the three properties \ref{prop.bilext.uni1}.1,
\ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}.3 for all $n\leq
\mathbf{n}-1$. We need to construct a new map $\gamma_{\mathbf{n}}$ which
extends this sequence to a sequence $\left(  \gamma_{1},\gamma_{2}%
,...,\gamma_{\mathbf{n}}\right)  $ of maps satisfying the three properties
\ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and \ref{prop.bilext.uni1}%
.3 for all $n\leq\mathbf{n}$.

Let us define the map $\gamma_{\mathbf{n}}:M\left[  \mathbf{n}\right]  \times
N\left[  -\mathbf{n}\right]  \rightarrow k$ as follows:

Let us distinguish between two cases:

\textit{Case 1:} We have $\mathbf{n}\in\left\{  1,2,...,K\right\}  $.

\textit{Case 2:} We have $\mathbf{n}\notin\left\{  1,2,...,K\right\}  $.

Let us consider Case 1 first. In this case, $\mathbf{n}\in\left\{
1,2,...,K\right\}  $. Thus, $\beta_{\mathbf{n}}$ is a well-defined map
$M\left[  \mathbf{n}\right]  \times N\left[  -\mathbf{n}\right]  \rightarrow
k$. Hence, we can just define $\gamma_{\mathbf{n}}$ to be $\beta_{\mathbf{n}}%
$. Define $\gamma_{\mathbf{n}}$ this way. Thus, $\gamma_{\mathbf{n}}$ is
defined in Case 1. (We will later prove that the sequence $\left(  \gamma
_{1},\gamma_{2},...,\gamma_{\mathbf{n}}\right)  $ satisfies the three
properties \ref{prop.bilext.uni1}.1, \ref{prop.bilext.uni1}.2 and
\ref{prop.bilext.uni1}.3 for all $n\leq\mathbf{n}$.)

Let us now consider Case 2. In this case, $\mathbf{n}\notin\left\{
1,2,...,K\right\}  $, so that $\mathbf{n}>K$ (since $\mathbf{n}$ is a positive integer).

Let $i\in\left\{  1,2,...,\mathbf{n}-1\right\}  $. Then, $\mathbf{n}%
-i\in\left\{  1,2,...,\mathbf{n}-1\right\}  $. In other words, $\mathbf{n}-i$
is a positive integer satisfying $\mathbf{n}-i\leq\mathbf{n}-1$. Hence,
Property \ref{prop.bilext.uni1}.1 is satisfied for $n=\mathbf{n}-i$ (because
we have assumed that Property \ref{prop.bilext.uni1}.1 is satisfied for all
$n\leq\mathbf{n}-1$). Hence, we can apply Property \ref{prop.bilext.uni1}.1 to
$n=\mathbf{n}-i$. We thus conclude that the map $\gamma_{\mathbf{n}-i}$ is a
$k$-bilinear form $M\left[  \mathbf{n}-i\right]  \times N\left[  -\left(
\mathbf{n}-i\right)  \right]  \rightarrow k$. In other words, the map
$\gamma_{\mathbf{n}-i}$ is a $k$-bilinear form $M\left[  \mathbf{n}-i\right]
\times N\left[  -\mathbf{n}+i\right]  \rightarrow k$.

Define a map $\xi_{i}:\mathfrak{g}\left[  -i\right]  \times N\left[
-\mathbf{n}+i\right]  \rightarrow\operatorname*{Hom}\left(  M\left[
\mathbf{n}\right]  ,k\right)  $ as follows: For every $\left(  x,b\right)
\in\mathfrak{g}\left[  -i\right]  \times N\left[  -\mathbf{n}+i\right]  $,
define $\xi_{i}\left(  x,b\right)  $ to be the map%
\begin{align*}
M\left[  \mathbf{n}\right]   &  \rightarrow k,\\
a  &  \mapsto\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b\right)  .
\end{align*}
This is well-defined\footnote{\textit{Proof.} For every $\left(  x,b\right)
\in\mathfrak{g}\left[  -i\right]  \times N\left[  -\mathbf{n}+i\right]  $, the
map%
\begin{align*}
M\left[  \mathbf{n}\right]   &  \rightarrow k,\\
a  &  \mapsto\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b\right)
\end{align*}
is $k$-linear (since $\gamma_{\mathbf{n}-i}$ and the action of $\mathfrak{g}$
on $M$ are both $k$-bilinear), and hence is an element of $\operatorname*{Hom}%
\left(  M\left[  \mathbf{n}\right]  ,k\right)  $. Hence, $\xi_{i}$ is
well-defined.}. Thus, we have defined a map $\xi_{i}$.

For every $\left(  x,b\right)  \in\mathfrak{g}\left[  -i\right]  \times
N\left[  -\mathbf{n}+i\right]  $, we know that $\xi_{i}\left(  x,b\right)  $
is the map%
\begin{align*}
M\left[  \mathbf{n}\right]   &  \rightarrow k,\\
a  &  \mapsto\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b\right)
\end{align*}
(because this is how we have defined $\xi_{i}\left(  x,b\right)  $). In other
words, for every $\left(  x,b\right)  \in\mathfrak{g}\left[  -i\right]  \times
N\left[  -\mathbf{n}+i\right]  $, we have%
\begin{equation}
\left(  \xi_{i}\left(  x,b\right)  \right)  \left(  a\right)  =\gamma
_{\mathbf{n}-i}\left(  x\rightharpoonup a,b\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }a\in M\left[  \mathbf{n}\right]  .
\label{pf.bilext.1.xi_i}%
\end{equation}


The map $\xi_{i}$ is $k$-bilinear\footnote{\textit{Proof.} \textbf{a)} Let
$x_{1}$ and $x_{2}$ be elements of $\mathfrak{g}\left[  -i\right]  $. Let
$\lambda_{1}$ and $\lambda_{2}$ be elements of $k$. Let $b$ be an element of
$N\left[  -\mathbf{n}+i\right]  $. Since $x_{1}\in\mathfrak{g}\left[
-i\right]  $ and $x_{2}\in\mathfrak{g}\left[  -i\right]  $, we have
$\lambda_{1}x_{1}+\lambda_{2}x_{2}\in\mathfrak{g}\left[  -i\right]  $, so that
$\left(  \lambda_{1}x_{1}+\lambda_{2}x_{2},b\right)  \in\mathfrak{g}\left[
-i\right]  \times N\left[  -\mathbf{n}+i\right]  $. Thus, every $a\in M\left[
\mathbf{n}\right]  $ satisfies%
\begin{align}
&  \left(  \xi_{i}\left(  \lambda_{1}x_{1}+\lambda_{2}x_{2},b\right)  \right)
\left(  a\right) \nonumber\\
&  =\gamma_{\mathbf{n}-i}\left(  \underbrace{\left(  \lambda_{1}x_{1}%
+\lambda_{2}x_{2}\right)  \rightharpoonup a}_{=\lambda_{1}x_{1}\rightharpoonup
a+\lambda_{2}x_{2}\rightharpoonup a},b\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.bilext.1.xi_i}), applied to }x=\lambda_{1}x_{1}+\lambda
_{2}x_{2}\right) \nonumber\\
&  =\gamma_{\mathbf{n}-i}\left(  \lambda_{1}x_{1}\rightharpoonup a+\lambda
_{2}x_{2}\rightharpoonup a,b\right)  =\lambda_{1}\gamma_{\mathbf{n}-i}\left(
x_{1}\rightharpoonup a,b\right)  +\lambda_{2}\gamma_{\mathbf{n}-i}\left(
x_{2}\rightharpoonup a,b\right) \label{pf.bilext.1.1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\gamma_{\mathbf{n}-i}\text{ is a
}k\text{-bilinear map}\right)  .\nonumber
\end{align}
On the other hand, every $a\in M\left[  \mathbf{n}\right]  $ satisfies
\begin{equation}
\left(  \xi_{i}\left(  x_{1},b\right)  \right)  \left(  a\right)
=\gamma_{\mathbf{n}-i}\left(  x_{1}\rightharpoonup a,b\right)
\label{pf.bilext.1.1b}%
\end{equation}
(by (\ref{pf.bilext.1.xi_i}), applied to $x=x_{1}$) and
\begin{equation}
\left(  \xi_{i}\left(  x_{2},b\right)  \right)  \left(  a\right)
=\gamma_{\mathbf{n}-i}\left(  x_{2}\rightharpoonup a,b\right)
\label{pf.bilext.1.1c}%
\end{equation}
(by (\ref{pf.bilext.1.xi_i}), applied to $x=x_{2}$). Hence, every $a\in
M\left[  \mathbf{n}\right]  $ satisfies
\begin{align*}
&  \left(  \xi_{i}\left(  \lambda_{1}x_{1}+\lambda_{2}x_{2},b\right)  \right)
\left(  a\right) \\
&  =\lambda_{1}\underbrace{\gamma_{\mathbf{n}-i}\left(  x_{1}\rightharpoonup
a,b\right)  }_{\substack{=\left(  \xi_{i}\left(  x_{1},b\right)  \right)
\left(  a\right)  \\\text{(by (\ref{pf.bilext.1.1b}))}}}+\lambda
_{2}\underbrace{\gamma_{\mathbf{n}-i}\left(  x_{2}\rightharpoonup a,b\right)
}_{\substack{=\left(  \xi_{i}\left(  x_{2},b\right)  \right)  \left(
a\right)  \\\text{(by (\ref{pf.bilext.1.1c}))}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.bilext.1.1})}\right) \\
&  =\lambda_{1}\left(  \xi_{i}\left(  x_{1},b\right)  \right)  \left(
a\right)  +\lambda_{2}\left(  \xi_{i}\left(  x_{2},b\right)  \right)  \left(
a\right)  =\left(  \lambda_{1}\xi_{i}\left(  x_{1},b\right)  +\lambda_{2}%
\xi_{i}\left(  x_{2},b\right)  \right)  \left(  a\right)  .
\end{align*}
In other words, $\xi_{i}\left(  \lambda_{1}x_{1}+\lambda_{2}x_{2},b\right)
=\lambda_{1}\xi_{i}\left(  x_{1},b\right)  +\lambda_{2}\xi_{i}\left(
x_{2},b\right)  $.
\par
Now, forget that we fixed $x_{1}$, $x_{2}$, $\lambda_{1}$, $\lambda_{2}$ and
$b$. We thus have proven that $\xi_{i}\left(  \lambda_{1}x_{1}+\lambda
_{2}x_{2},b\right)  =\lambda_{1}\xi_{i}\left(  x_{1},b\right)  +\lambda_{2}%
\xi_{i}\left(  x_{2},b\right)  $ for all $x_{1}\in\mathfrak{g}\left[
-i\right]  $, $x_{2}\in\mathfrak{g}\left[  -i\right]  $, $\lambda_{1}\in k$,
$\lambda_{2}\in k$ and $b\in N\left[  -\mathbf{n}+i\right]  $. In other words,
the map $\xi_{i}$ is $k$-linear in its first argument.
\par
\textbf{b)} Now, let $b_{1}$ and $b_{2}$ be elements of $N\left[
-\mathbf{n}+i\right]  $. Let $\mu_{1}$ and $\mu_{2}$ be elements of $k$. Let
$x$ be an element of $\mathfrak{g}\left[  -i\right]  $. Since $b_{1}\in
N\left[  -\mathbf{n}+i\right]  $ and $b_{2}\in N\left[  -\mathbf{n}+i\right]
$, we have $\mu_{1}b_{1}+\mu_{2}b_{2}\in N\left[  -\mathbf{n}+i\right]  $, so
that $\left(  x,\mu_{1}b_{1}+\mu_{2}b_{2}\right)  \in\mathfrak{g}\left[
-i\right]  \times N\left[  -\mathbf{n}+i\right]  $. Thus, every $a\in M\left[
\mathbf{n}\right]  $ satisfies%
\begin{align}
&  \left(  \xi_{i}\left(  x,\mu_{1}b_{1}+\mu_{2}b_{2}\right)  \right)  \left(
a\right) \nonumber\\
&  =\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,\mu_{1}b_{1}+\mu_{2}%
b_{2}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.bilext.1.xi_i}),
applied to }b=\mu_{1}b_{1}+\mu_{2}b_{2}\right) \nonumber\\
&  =\mu_{1}\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b_{1}\right)
+\mu_{2}\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b_{2}\right)
\label{pf.bilext.1.2}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\gamma_{\mathbf{n}-i}\text{ is a
}k\text{-bilinear map}\right)  .\nonumber
\end{align}
On the other hand, every $a\in M\left[  \mathbf{n}\right]  $ satisfies
\begin{equation}
\left(  \xi_{i}\left(  x,b_{1}\right)  \right)  \left(  a\right)
=\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b_{1}\right)
\label{pf.bilext.1.2b}%
\end{equation}
(by (\ref{pf.bilext.1.xi_i}), applied to $b=b_{1}$) and
\begin{equation}
\left(  \xi_{i}\left(  x,b_{2}\right)  \right)  \left(  a\right)
=\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b_{2}\right)
\label{pf.bilext.1.2c}%
\end{equation}
(by (\ref{pf.bilext.1.xi_i}), applied to $b=b_{2}$). Hence, every $a\in
M\left[  \mathbf{n}\right]  $ satisfies
\begin{align*}
&  \left(  \xi_{i}\left(  x,\mu_{1}b_{1}+\mu_{2}b_{2}\right)  \right)  \left(
a\right) \\
&  =\mu_{1}\underbrace{\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup
a,b_{1}\right)  }_{\substack{=\left(  \xi_{i}\left(  x,b_{1}\right)  \right)
\left(  a\right)  \\\text{(by (\ref{pf.bilext.1.2b}))}}}+\mu_{2}%
\underbrace{\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup a,b_{2}\right)
}_{\substack{=\left(  \xi_{i}\left(  x,b_{2}\right)  \right)  \left(
a\right)  \\\text{(by (\ref{pf.bilext.1.2c}))}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.bilext.1.2})}\right) \\
&  =\mu_{1}\left(  \xi_{i}\left(  x,b_{1}\right)  \right)  \left(  a\right)
+\mu_{2}\left(  \xi_{i}\left(  x,b_{2}\right)  \right)  \left(  a\right)
=\left(  \mu_{1}\xi_{i}\left(  x,b_{1}\right)  +\mu_{2}\xi_{i}\left(
x,b_{2}\right)  \right)  \left(  a\right)  .
\end{align*}
In other words, $\xi_{i}\left(  x,\mu_{1}b_{1}+\mu_{2}b_{2}\right)  =\mu
_{1}\xi_{i}\left(  x,b_{1}\right)  +\mu_{2}\xi_{i}\left(  x,b_{2}\right)  $.
\par
Now, forget that we fixed $b_{1}$, $b_{2}$, $\mu_{1}$, $\mu_{2}$ and $x$. We
thus have proven that $\xi_{i}\left(  x,\mu_{1}b_{1}+\mu_{2}b_{2}\right)
=\mu_{1}\xi_{i}\left(  x,b_{1}\right)  +\mu_{2}\xi_{i}\left(  x,b_{2}\right)
$ for all $b_{1}\in N\left[  -\mathbf{n}+i\right]  $, $b_{2}\in N\left[
-\mathbf{n}+i\right]  $, $\mu_{1}\in k$, $\mu_{2}\in k$ and $x\in
\mathfrak{g}\left[  -i\right]  $. In other words, the map $\xi_{i}$ is
$k$-linear in its second argument.
\par
\textbf{c)} Now, we know that the map $\xi_{i}$ is $k$-linear in its first
argument and $k$-linear in its second argument. Hence, the map $\xi_{i}$ is
$k$-bilinear, qed.}. Hence, by the universal property of the tensor product,
this map $\xi_{i}:\mathfrak{g}\left[  -i\right]  \times N\left[
-\mathbf{n}+i\right]  \rightarrow\operatorname*{Hom}\left(  M\left[
\mathbf{n}\right]  ,k\right)  $ gives rise to a $k$-linear map $\Xi
_{i}:\mathfrak{g}\left[  -i\right]  \otimes N\left[  -\mathbf{n}+i\right]
\rightarrow\operatorname*{Hom}\left(  M\left[  \mathbf{n}\right]  ,k\right)  $
satisfying%
\[
\left(  \Xi_{i}\left(  x\otimes b\right)  =\xi_{i}\left(  x,b\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }\left(  x,b\right)  \in\mathfrak{g}%
\left[  -i\right]  \times N\left[  -\mathbf{n}+i\right]  \right)  .
\]
Consider this map $\Xi_{i}$. Then, every $x\in\mathfrak{g}\left[  -i\right]  $
and $b\in N\left[  -\mathbf{n}+i\right]  $ satisfy%
\[
\Xi_{i}\left(  x\otimes b\right)  =\xi_{i}\left(  x,b\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(  x,b\right)  \in
\mathfrak{g}\left[  -i\right]  \times N\left[  -\mathbf{n}+i\right]  \text{
(since }x\in\mathfrak{g}\left[  -i\right]  \text{ and }b\in N\left[
-\mathbf{n}+i\right]  \text{)}\right)  .
\]
Thus, every $x\in\mathfrak{g}\left[  -i\right]  $, $b\in N\left[
-\mathbf{n}+i\right]  $ and $a\in M\left[  \mathbf{n}\right]  $ satisfy%
\begin{equation}
\left(  \underbrace{\Xi_{i}\left(  x\otimes b\right)  }_{=\xi_{i}\left(
x,b\right)  }\right)  \left(  a\right)  =\left(  \xi_{i}\left(  x,b\right)
\right)  \left(  a\right)  =\gamma_{\mathbf{n}-i}\left(  x\rightharpoonup
a,b\right)  \label{pf.bilext.1.Xi_i}%
\end{equation}
(by (\ref{pf.bilext.1.xi_i})).

Now, forget that we fixed $i$. We thus have defined a $k$-linear map $\Xi
_{i}:\mathfrak{g}\left[  -i\right]  \otimes N\left[  -\mathbf{n}+i\right]
\rightarrow\operatorname*{Hom}\left(  M\left[  \mathbf{n}\right]  ,k\right)  $
for every $i\in\left\{  1,2,...,\mathbf{n}-1\right\}  $. Consider the map
$\sum\limits_{i=1}^{\mathbf{n}-1}\Xi_{i}$ (defined in the same way as the map
$\sum\limits_{i=1}^{p}f_{i}$ in Lemma \ref{lem.bilext.1.1}). Denote this map
by $\Xi$. Thus, $\Xi=\sum\limits_{i=1}^{\mathbf{n}-1}\Xi_{i}$.

On the other hand, let $i\in\left\{  1,2,...,\mathbf{n}-1\right\}  $ again.
Define a map $\omega_{i}:\mathfrak{g}\left[  -i\right]  \times N\left[
-\mathbf{n}+i\right]  \rightarrow N\left[  -\mathbf{n}\right]  $ by%
\begin{equation}
\left(  \omega_{i}\left(  x,b\right)  =x\rightharpoonup
b\ \ \ \ \ \ \ \ \ \ \text{for all }\left(  x,b\right)  \in\mathfrak{g}\left[
-i\right]  \times N\left[  -\mathbf{n}+i\right]  \right)  .
\label{pf.bilext.1.omega_i}%
\end{equation}
This is well-defined\footnote{\textit{Proof.} For every $\left(  x,b\right)
\in\mathfrak{g}\left[  -i\right]  \times N\left[  -\mathbf{n}+i\right]  $, the
element $x\rightharpoonup b$ lies in $N\left[  -\mathbf{n}\right]  $ (because
we have $\left(  x,b\right)  \in\mathfrak{g}\left[  -i\right]  \times N\left[
-\mathbf{n}+i\right]  $, so that $x\in\mathfrak{g}\left[  -i\right]  $ and
$b\in N\left[  -\mathbf{n}+i\right]  $, so that
\begin{align*}
\underbrace{x}_{\in\mathfrak{g}\left[  -i\right]  }\rightharpoonup
\underbrace{b}_{\in N\left[  -\mathbf{n}+i\right]  }  &  \in\mathfrak{g}%
\left[  -i\right]  \rightharpoonup N\left[  -\mathbf{n}+i\right]  \subseteq
N\left[  \underbrace{\left(  -i\right)  +\left(  -\mathbf{n}+i\right)
}_{=-\mathbf{n}}\right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }N\text{ is a }\mathbb{Z}%
\text{-graded }\mathfrak{g}\text{-module}\right) \\
&  =N\left[  -\mathbf{n}\right]
\end{align*}
). Hence, $\omega_{i}$ is well-defined, qed.}. We have thus defined a map
$\omega_{i}$.

[...]

According to Lemma \ref{lem.bilext.1.1} (applied to $p=\mathbf{n}-1$,
$W=\operatorname*{Hom}\left(  M\left[  \mathbf{n}\right]  ,k\right)  $,
$V_{i}=\mathfrak{g}\left[  -i\right]  \otimes N\left[  -\mathbf{n}+i\right]  $
and $f_{i}=\Xi_{i}$), we have%
\[
\left(  \sum\limits_{i=1}^{\mathbf{n}-1}\Xi_{i}\right)  \left(  \bigoplus
\limits_{i=1}^{\mathbf{n}-1}V_{i}\right)  =\sum\limits_{i=1}^{\mathbf{n}-1}%
\Xi_{i}\left(  V_{i}\right)
\]


[Quote]Let $p\in\mathbb{N}$. Let $k$ be a field. Let $W$ be a $k$-vector
space. Let $V_{1}$, $V_{2}$, $...$, $V_{p}$ be $k$-vector spaces. For every
$i\in\left\{  1,2,...,p\right\}  $, let $f_{i}:V_{i}\rightarrow W$ be a
$k$-linear map. We denote by $\sum\limits_{i=1}^{p}f_{i}$ the map
$\bigoplus\limits_{i=1}^{p}V_{i}\rightarrow W$ obtained from the maps
$f_{i}:V_{i}\rightarrow W$ through the universal property of the direct sum
$\bigoplus\limits_{i=1}^{p}V_{i}$. (This is the map which sends every $\left(
v_{i}\right)  _{i\in\left\{  1,2,...,p\right\}  }\in\bigoplus\limits_{i=1}%
^{p}V_{i}$ to $\sum\limits_{i=1}^{p}f_{i}\left(  v_{i}\right)  $.) Then,%
\[
\left(  \sum\limits_{i=1}^{p}f_{i}\right)  \left(  \bigoplus\limits_{i=1}%
^{p}V_{i}\right)  =\sum\limits_{i=1}^{p}f_{i}\left(  V_{i}\right)  .
\]


[...]

Let $a\in M\left[  \mathbf{n}\right]  $ and $b\in N\left[  -\mathbf{n}\right]
$.

[...]

[...] [...]
\end{noncompile}

\subsection{Simple Lie algebras: a recollection}

The Kac-Moody Lie algebras form a class of Lie algebras which contains all
simple finite-dimensional and all affine Lie algebras, but also many more.
Before we start studying them, let us recall some facts about simple Lie algebras:

Let $\mathfrak{g}$ be a finite-dimensional simple Lie algebra over
$\mathbb{C}$. A \textit{Cartan subalgebra} of $\mathfrak{g}$ means a maximal
commutative Lie subalgebra which consists of semisimple\footnote{An element of
a Lie algebra is said to be \textit{semisimple} if and only if its action on
the adjoint representation is a semisimple operator.} elements. There are
usually many Cartan subalgebras of $\mathfrak{g}$, but they are all conjugate
under the action of the corresponding Lie group $G$ (which satisfies
$\mathfrak{g}=\operatorname*{Lie}G$, and can be defined as the connected
component of the identity in the group $\operatorname*{Aut}\mathfrak{g}$).
Thus, there is no loss of generality in picking one such subalgebra. So pick a
Cartan subalgebra $\mathfrak{h}$ of $\mathfrak{g}$. We denote the dimension
$\dim\mathfrak{h}$ by $n$ and also by $\operatorname*{rank}\mathfrak{g}$. This
dimension $\dim\mathfrak{h}=\operatorname*{rank}\mathfrak{g}$ is called the
\textit{rank} of $\mathfrak{g}$. The restriction of the Killing form on
$\mathfrak{g}$ to $\mathfrak{h}\times\mathfrak{h}$ is a nondegenerate
symmetric bilinear form on $\mathfrak{h}$.

For every $\alpha\in\mathfrak{h}^{\ast}$, we can define a vector subspace
$\mathfrak{g}_{\alpha}$ of $\mathfrak{g}$ by
\[
\mathfrak{g}_{\alpha}=\left\{  a\in\mathfrak{g}\ \mid\ \left[  h,a\right]
=\alpha\left(  h\right)  a\text{ for all }h\in\mathfrak{h}\right\}  .
\]
It can be shown that $\mathfrak{g}_{0}=\mathfrak{h}$. Now we let $\Delta$ be
the finite subset $\left\{  \alpha\in\mathfrak{h}^{\ast}\diagdown\left\{
0\right\}  \ \mid\ \mathfrak{g}_{\alpha}\neq0\right\}  $ of $\mathfrak{h}%
^{\ast}\diagdown\left\{  0\right\}  $. Then, $\mathfrak{g}=\mathfrak{h}%
\oplus\bigoplus\limits_{\alpha\in\Delta}\mathfrak{g}_{\alpha}$ (as a direct
sum of vector spaces). The subset $\Delta$ is called the \textit{root system}
of $\mathfrak{g}$. The elements of $\Delta$ are called the \textit{roots} of
$\mathfrak{g}$. It is known that for each $\alpha\in\Delta$, the vector space
$\mathfrak{g}_{\alpha}$ is one-dimensional and can be written as
$\mathfrak{g}_{\alpha}=\mathbb{C}e_{\alpha}$ for some particular $e_{\alpha
}\in\mathfrak{g}_{\alpha}$.

We want to use the decomposition $\mathfrak{g}=\mathfrak{h}\oplus
\bigoplus\limits_{\alpha\in\Delta}\mathfrak{g}_{\alpha}$ in order to construct
a triangular decomposition of $\mathfrak{g}$. This can be done with the
grading which we constructed in Proposition \ref{prop.grad.g}, but let us do
it again now, with more elementary means: Fix an $\overline{h}\in\mathfrak{h}$
such that every $\alpha\in\Delta$ satisfies $\alpha\left(  \overline
{h}\right)  \in\mathbb{R}\diagdown\left\{  0\right\}  $ (it can be seen that
such $\overline{h}$ exists). Define $\Delta_{+}=\left\{  \alpha\in\Delta
\ \mid\ \alpha\left(  \overline{h}\right)  >0\right\}  $ and $\Delta
_{-}=\left\{  \alpha\in\Delta\ \mid\ \alpha\left(  \overline{h}\right)
<0\right\}  $. Then, $\Delta$ is the union of two disjoint subsets $\Delta
_{+}$ and $\Delta_{-}$, and we have $\Delta_{+}=-\Delta_{-}$. The triangular
decomposition of $\mathfrak{g}$ is now defined as $\mathfrak{g}=\mathfrak{n}%
_{-}\oplus\mathfrak{h}\oplus\mathfrak{n}_{+}$, where $\mathfrak{n}%
_{-}=\bigoplus\limits_{\alpha\in\Delta_{-}}\mathfrak{g}_{\alpha}$ and
$\mathfrak{n}_{+}=\bigoplus\limits_{\alpha\in\Delta_{+}}\mathfrak{g}_{\alpha}%
$. This decomposition depends on the choice of $\overline{h}$ (and
$\mathfrak{h}$, of course). The elements of $\Delta_{+}$ are called
\textit{positive roots} of $\mathfrak{g}$, and the elements of $\Delta_{-}$
are called \textit{negative roots} of $\mathfrak{g}$. If $\alpha$ is a root of
$\mathfrak{g}$, then we write $\alpha>0$ if $\alpha$ is a positive root, and
we write $\alpha<0$ if $\alpha$ is a negative root.

Let us now construct the grading on $\mathfrak{g}$ which yields this
triangular decomposition $\mathfrak{g}=\mathfrak{n}_{-}\oplus\mathfrak{h}%
\oplus\mathfrak{n}_{+}$. This grading was already constructed in Proposition
\ref{prop.grad.g}, but now we are going to do this in detail:

We define the \textit{simple roots} of $\mathfrak{g}$ as the elements of
$\Delta_{+}$ which cannot be written as sums of more than one element of
$\Delta_{+}$. It can be shown that there are exactly $n$ of these simple
roots, and they form a basis of $\mathfrak{h}^{\ast}$. Denote these simple
roots as $\alpha_{1}$, $\alpha_{2}$, $...$, $\alpha_{n}$. Every root
$\alpha\in\Delta_{+}$ can now be written in the form $\alpha=\sum
\limits_{i=1}^{n}k_{i}\left(  \alpha\right)  \alpha_{i}$ for a unique
$n$-tuple $\left(  k_{1}\left(  \alpha\right)  ,k_{2}\left(  \alpha\right)
,...,k_{n}\left(  \alpha\right)  \right)  $ of nonnegative integers.

For all $\alpha,\beta\in\Delta$ with $\alpha+\beta\notin\Delta\cup\left\{
0\right\}  $, we have $\left[  \mathfrak{g}_{\alpha},\mathfrak{g}_{\beta
}\right]  =0$. For all $\alpha,\beta\in\mathfrak{h}^{\ast}$, we have $\left[
\mathfrak{g}_{\alpha},\mathfrak{g}_{\beta}\right]  \subseteq\mathfrak{g}%
_{\alpha+\beta}$. In particular, for every $\alpha\in\mathfrak{h}^{\ast}$, we
have $\left[  \mathfrak{g}_{\alpha},\mathfrak{g}_{-\alpha}\right]
\subseteq\mathfrak{h}$. Better yet, we can show that for every $\alpha
\in\Delta$, there exists some nonzero $h_{\alpha}\in\mathfrak{h}$ such that
$\left[  \mathfrak{g}_{\alpha},\mathfrak{g}_{-\alpha}\right]  =\mathbb{C}%
h_{\alpha}$.

For every $i\in\left\{  1,2,...,n\right\}  $, pick a generator $e_{i}$ of the
vector space $\mathfrak{g}_{\alpha_{i}}$ and a generator $f_{i}$ of the vector
space $\mathfrak{g}_{-\alpha_{i}}$.

It is possible to normalize $e_{i}$ and $f_{i}$ in such a way that $\left[
h_{i},e_{i}\right]  =2e_{i}$ and $\left[  h_{i},f_{i}\right]  =-2f_{i}$, where
$h_{i}=\left[  e_{i},f_{i}\right]  $. This $h_{i}$ will, of course, lie in
$\mathfrak{h}$ and be a scalar multiple of $h_{\alpha_{i}}$. We can normalize
$h_{\alpha_{i}}$ in such a way that $h_{i}=h_{\alpha_{i}}$. We suppose that
all these normalizations are done. Then:

\begin{proposition}
\label{prop.serre-gen.1}With the notations introduced above, we have:

\textbf{(a)} The family $\left(  h_{1},h_{2},...,h_{n}\right)  $ is a basis of
$\mathfrak{h}$.

\textbf{(b)} For any $i$ and $j$ in $\left\{  1,2,...,n\right\}  $, denote
$\alpha_{j}\left(  h_{i}\right)  $ by $a_{i,j}$. The Lie algebra
$\mathfrak{g}$ is generated (as a Lie algebra) by the elements $e_{i}$,
$f_{i}$ and $h_{i}$ with $i\in\left\{  1,2,...,n\right\}  $ (a total of $3n$
elements), and the following relations hold:%
\begin{align*}
\left[  h_{i},h_{j}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  h_{i},e_{j}\right]   &  =\alpha_{j}\left(  h_{i}\right)  e_{j}%
=a_{i,j}e_{j}\ \ \ \ \ \ \ \ \ \ \text{for all }i,j\in\left\{
1,2,...,n\right\}  ;\\
\left[  h_{i},f_{j}\right]   &  =-\alpha_{j}\left(  h_{i}\right)
f_{j}=a_{i,j}f_{j}\ \ \ \ \ \ \ \ \ \ \text{for all }i,j\in\left\{
1,2,...,n\right\}  ;\\
\left[  e_{i},f_{j}\right]   &  =\delta_{i,j}h_{i}%
\ \ \ \ \ \ \ \ \ \ \text{for all }i,j\in\left\{  1,2,...,n\right\}  .
\end{align*}
(This does not mean that no more relations hold. In fact, additional
relations, the so-called Serre relations, do hold in $\mathfrak{g}$; we will
see these relations later, in Theorem \ref{thm.serre-gen.2}.)

The $n\times n$ matrix $A=\left(  a_{i,j}\right)  _{1\leq i,j\leq n}$ is
called the \textit{Cartan matrix} of $\mathfrak{g}$.

Let $\left(  \cdot,\cdot\right)  $ denote the standard form on $\mathfrak{g}$
(defined in Definition \ref{def.standform}). Then, $\left(  \cdot
,\cdot\right)  $ is a nonzero scalar multiple of the Killing form on
$\mathfrak{g}$ (since any two nonzero invariant symmetric bilinear forms on
$\mathfrak{g}$ are scalar multiples of each other). Hence, the restriction of
$\left(  \cdot,\cdot\right)  $ to $\mathfrak{h}\times\mathfrak{h}$ is
nondegenerate (since the restriction of the Killing form to $\mathfrak{h}%
\times\mathfrak{h}$ is nondegenerate). Thus, this restriction gives rise to a
vector space isomorphism $\mathfrak{h}\rightarrow\mathfrak{h}^{\ast}$. This
isomorphism sends $h_{i}$ to $\alpha_{i}^{\vee}=\dfrac{2\alpha_{i}}{\left(
\alpha_{i},\alpha_{i}\right)  }$ for every $i$ (where we denote by $\left(
\cdot,\cdot\right)  $ not only the standard form, but also the inverse form of
its restriction to $\mathfrak{h}$). Thus, $a_{i,j}=\alpha_{j}\left(
h_{i}\right)  =\dfrac{2\left(  \alpha_{j},\alpha_{i}\right)  }{\left(
\alpha_{i},\alpha_{i}\right)  }$ for all $i$ and $j$. (Note that the latter
equality would still hold if $\left(  \cdot,\cdot\right)  $ would mean the
Killing form rather than the standard form.)

The elements $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ are called \textit{Chevalley
generators} of $\mathfrak{g}$.

\textbf{Properties of the matrix }$A$\textbf{:}

\textbf{1)} We have $a_{i,i}=2$ for all $i\in\left\{  1,2,...,n\right\}  $.

\textbf{2)} Any two distinct $i\in\left\{  1,2,...,n\right\}  $ and
$j\in\left\{  1,2,...,n\right\}  $ satisfy $a_{i,j}\leq0$ and $a_{i,j}%
\in\mathbb{Z}$. Also, $a_{i,j}=0$ if and only if $a_{j,i}=0$.

\textbf{3)} The matrix $A$ is indecomposable (i. e., if conjugation of $A$ by
a permutation matrix brings $A$ into a block-diagonal form $\left(
\begin{array}
[c]{cc}%
A_{1} & 0\\
0 & A_{2}%
\end{array}
\right)  $, then either $A_{1}$ or $A_{2}$ is a $0\times0$ matrix).

\textbf{4)} The matrix $A$ is positive. Here is what we mean by this: There
exists a diagonal $n\times n$ matrix $D$ with positive diagonal entries such
that $DA$ is a symmetric and positive definite matrix.
\end{proposition}

\begin{theorem}
An $n\times n$ matrix $A=\left(  a_{i,j}\right)  _{1\leq i,j\leq n}$ satisfies
the four properties \textbf{1)}, \textbf{2)}, \textbf{3)} and \textbf{4)} of
Proposition \ref{prop.serre-gen.1} if and only if it is a Cartan matrix of a
simple Lie algebra.
\end{theorem}

Such matrices (and thus, simple finite-dimensional Lie algebras) can be
encoded by so-called \textit{Dynkin diagrams}. The \textit{Dynkin diagram} of
a simple Lie algebra $\mathfrak{g}$ is defined as the graph with vertex set
$\left\{  1,2,...,n\right\}  $, and the following rules for drawing
edges\footnote{The notion of a graph we are using here is slightly different
from the familiar notions of a graph in graph theory, since this graph can
have both directed and undirected edges.}:

\begin{itemize}
\item If $a_{i,j}=0$, then the vertices $i$ and $j$ are not connected by any
edge (directed or undirected).

\item If $a_{i,j}=a_{j,i}=-1$, then the vertices $i$ and $j$ are connected by
exactly one edge, and this edge is undirected.

\item If $a_{i,j}=-2$ and $a_{j,i}=-1$, then the vertices $i$ and $j$ are
connected by two directed edges from $j$ to $i$ (and no other edges).

\item If $a_{i,j}=-3$ and $a_{j,i}=-1$, then the vertices $i$ and $j$ are
connected by three directed edges from $j$ to $i$ (and no other edges).
\end{itemize}

Here is a classification of simple finite-dimensional Lie algebras by their
Dynkin diagrams:

$A_{n}=\mathfrak{sl}\left(  n+1\right)  $ for $n\geq1$; the Dynkin diagram is
$%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
%{-}[r] & \circ\ar@{-}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
{-}[r] & \circ\ar@{-}[r] & \circ}%
%EndExpansion
$ (with $n$ nodes).

$B_{n}=\mathfrak{so}\left(  2n+1\right)  $ for $n\geq2$; the Dynkin diagram is
$%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
%{-}[r] & \circ\ar@{=>}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
{-}[r] & \circ\ar@{=>}[r] & \circ}%
%EndExpansion
$ (with $n$ nodes, only the last edge being directed and double). (Note that
$\mathfrak{so}\left(  3\right)  \cong\mathfrak{sl}\left(  2\right)  $.)

$C_{n}=\mathfrak{sp}\left(  2n\right)  $ for $n\geq2$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
%{-}[r] & \circ\ar@{<=}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
{-}[r] & \circ\ar@{<=}[r] & \circ}%
%EndExpansion
$ (with $n$ nodes, only the last edge being directed and double). (Note that
$\mathfrak{sp}\left(  2\right)  \cong\mathfrak{sl}\left(  2\right)  $ and
$\mathfrak{sp}\left(  4\right)  \cong\mathfrak{so}\left(  5\right)  $.)

$D_{n}=\mathfrak{so}\left(  2n\right)  $ for $n\geq4$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%& & & & & \circ\\
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
%{-}[r] & \circ\ar@{-}[ru] \ar@{-}[rd] \\
%& & & & & \circ}}}%
%BeginExpansion
\xymatrix{
& & & & & \circ\\
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
{-}[r] & \circ\ar@{-}[ru] \ar@{-}[rd] \\
& & & & & \circ}%
%EndExpansion
$ (with $n$ nodes). (Note that $\mathfrak{so}\left(  4\right)  \cong%
\mathfrak{sl}\left(  2\right)  \oplus\mathfrak{sl}\left(  2\right)  $ and
$\mathfrak{so}\left(  6\right)  \cong\mathfrak{sl}\left(  4\right)  $.)

Exceptional Lie algebras:

$E_{6}$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%& & \circ\ar@{-}[d] & & \\
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ
%}}}%
%BeginExpansion
\xymatrix{
& & \circ\ar@{-}[d] & & \\
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ}%
%EndExpansion
$.

$E_{7}$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%& & \circ\ar@{-}[d] & & & \\
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}%
%[r] & \circ\ar@{-}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
& & \circ\ar@{-}[d] & & & \\
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}%
[r] & \circ\ar@{-}[r] & \circ}%
%EndExpansion
$.

$E_{8}$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%& & \circ\ar@{-}[d] & & & & \\
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}%
%[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
& & \circ\ar@{-}[d] & & & & \\
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{-}%
[r] & \circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ}%
%EndExpansion
$.

$F_{4}$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%\circ\ar@{-}[r] & \circ\ar@{=>}[r] & \circ\ar@{-}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
\circ\ar@{-}[r] & \circ\ar@{=>}[r] & \circ\ar@{-}[r] & \circ}%
%EndExpansion
$.

$G_{2}$; the Dynkin diagram is $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%\circ& \circ\ar@3{->}[l]
%}}}%
%BeginExpansion
\xymatrix{
\circ& \circ\ar@3{->}[l]
}%
%EndExpansion
$.

Now to the Serre relations, which we have not yet written down:

\begin{theorem}
\label{thm.serre-gen.2}Let $\mathfrak{g}$ be a simple finite-dimensional Lie
algebra. Use the notations introduced in Proposition \ref{prop.serre-gen.1}.

\textbf{(a)} Let $i$ and $j$ be two distinct elements of $\left\{
1,2,...,n\right\}  $. Then, in $\mathfrak{g}$, we have $\left(
\operatorname*{ad}\left(  e_{i}\right)  \right)  ^{1-a_{i,j}}e_{j}=0$ and
$\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j}%
=0$. These relations (totalling up to $2n\left(  n-1\right)  $ relations,
because there are $n\left(  n-1\right)  $ pairs $\left(  i,j\right)  $ of
distinct elements of $\left\{  1,2,...,n\right\}  $) are called the
\textit{Serre relations} for $\mathfrak{g}$.

\textbf{(b)} Combined with the relations%
\begin{equation}
\left\{
\begin{array}
[c]{l}%
\left[  h_{i},h_{j}\right]  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  h_{i},e_{j}\right]  =a_{i,j}e_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  h_{i},f_{j}\right]  =-a_{i,j}f_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  e_{i},f_{j}\right]  =\delta_{i,j}h_{i}\ \ \ \ \ \ \ \ \ \ \text{for
all }i,j\in\left\{  1,2,...,n\right\}
\end{array}
\right.  \label{nonserre-relations}%
\end{equation}
of Proposition \ref{prop.serre-gen.1}, the Serre relations form a set of
defining relations for $\mathfrak{g}$. This means that, if
$\widetilde{\mathfrak{g}}$ denotes the quotient Lie algebra
\[
\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  ,
\]
then $\widetilde{\mathfrak{g}}\diagup\left(  \text{Serre relations}\right)
\cong\mathfrak{g}$. (Here, $\operatorname*{FreeLie}\left(  h_{i},f_{i}%
,e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  $ denotes the free Lie
algebra with $3n$ generators $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$,
$f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$.)
\end{theorem}

\begin{remark}
If $\mathfrak{g}\cong\mathfrak{sl}_{2}$, then $\mathfrak{g}$ has no Serre
relations (because $n=1$), and thus the claim of Theorem \ref{thm.serre-gen.2}
\textbf{(b)} rewrites as $\widetilde{\mathfrak{g}}\cong\mathfrak{g}$ (where
$\widetilde{\mathfrak{g}}$ is defined as in Theorem \ref{thm.serre-gen.2}).
But in all other cases, the Lie algebra $\widetilde{\mathfrak{g}}$ is
infinite-dimensional, and while it clearly projects onto $\mathfrak{g}$, it is
much bigger than $\mathfrak{g}$.
\end{remark}

We will give a partial proof of Theorem \ref{thm.serre-gen.2}: We will only
prove part \textbf{(a)}.

\textit{Proof of Theorem \ref{thm.serre-gen.2} \textbf{(a)}.} Define a
$\mathbb{C}$-linear map%
\begin{align*}
\Phi_{i}:\mathfrak{sl}_{2}  &  \rightarrow\mathfrak{g},\\
e  &  \mapsto e_{i},\\
f  &  \mapsto f_{i},\\
h  &  \mapsto h_{i}.
\end{align*}
Since $\left[  e_{i},f_{i}\right]  =h_{i}$, $\left[  h_{i},e_{i}\right]
=2e_{i}$ and $\left[  h_{i},f_{i}\right]  =-2f_{i}$, this map $\Phi_{i}$ is a
Lie algebra homomorphism.

But $\mathfrak{g}$ is a $\mathfrak{g}$-module (by the adjoint representation
of $\mathfrak{g}$), and thus becomes an $\mathfrak{sl}_{2}$-module by means of
$\Phi_{i}:\mathfrak{sl}_{2}\rightarrow\mathfrak{g}$. This $\mathfrak{sl}_{2}%
$-module satisfies%
\[
ef_{j}=\underbrace{\left(  \Phi_{i}\left(  e\right)  \right)  }_{=e_{i}}%
f_{j}=\left(  \operatorname*{ad}\left(  e_{i}\right)  \right)  f_{j}=\left[
e_{i},f_{j}\right]  =0\ \ \ \ \ \ \ \ \ \ \left(  \text{since }i\neq j\right)
\]
and%
\[
hf_{j}=\underbrace{\left(  \Phi_{i}\left(  h\right)  \right)  }_{=h_{i}}%
f_{j}=\left(  \operatorname*{ad}\left(  h_{i}\right)  \right)  f_{j}=\left[
h_{i},f_{j}\right]  =-a_{i,j}f_{j}.
\]
Hence, Lemma \ref{lem.serre-gen.sl2} \textbf{(c)} (applied to $V=\mathfrak{g}%
$, $\lambda=-a_{i,j}$ and $x=f_{j}$) yields that $-a_{i,j}\in\mathbb{N}$ and
$f^{-a_{i,j}+1}f_{j}=0$. Since%
\[
f^{-a_{i,j}+1}f_{j}=f^{1-a_{i,j}}f_{j}=\left(  \underbrace{\Phi_{i}\left(
f\right)  }_{=f_{i}}\right)  ^{1-a_{i,j}}f_{j}=\left(  \operatorname*{ad}%
\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j},
\]
this rewrites as $\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)
^{1-a_{i,j}}f_{j}=0$. Similarly, $\left(  \operatorname*{ad}\left(
e_{i}\right)  \right)  ^{1-a_{i,j}}e_{j}=0$. Theorem \ref{thm.serre-gen.2}
\textbf{(a)} is thus proven.

As we said, we are not going to prove Theorem \ref{thm.serre-gen.2}
\textbf{(b)} here.

\subsection{\textbf{[unfinished]} Kac-Moody Lie algebras: definition and
construction}

Now forget about our simple Lie algebra $\mathfrak{g}$. Let us first define
the notion of contragredient Lie algebras by axioms; we will construct these
algebras later.

\begin{definition}
\label{def.contragredient}Suppose that $A=\left(  a_{i,j}\right)  _{1\leq
i,j\leq n}$ is any $n\times n$ matrix of complex numbers.

Let $Q$ be the free abelian group generated by $n$ symbols $\alpha_{1}$,
$\alpha_{2}$, $...$, $\alpha_{n}$ (that is, $Q=\mathbb{Z}\alpha_{1}%
\oplus\mathbb{Z}\alpha_{2}\oplus...\oplus\mathbb{Z}\alpha_{n}$). These symbols
are just symbols, not weights of any Lie algebra (at the moment). We write the
group $Q$ additively.

A \textit{contragredient Lie algebra} corresponding to $A$ is a $Q$-graded
$\mathbb{C}$-Lie algebra $\mathfrak{g}$ which is (as a Lie algebra) generated
by some elements $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ which satisfy the following three conditions:

\textbf{(1)} These elements satisfy the relations (\ref{nonserre-relations}).

\textbf{(2)} The vector space $\mathfrak{g}\left[  0\right]  $ has $\left(
h_{1},h_{2},...,h_{n}\right)  $ as a $\mathbb{C}$-vector space basis, and we
have $\mathfrak{g}\left[  \alpha_{i}\right]  =\mathbb{C}e_{i}$ and
$\mathfrak{g}\left[  -\alpha_{i}\right]  =\mathbb{C}f_{i}$ for all
$i\in\left\{  1,2,...,n\right\}  $.

\textbf{(3)} Every nonzero $Q$-graded ideal in $\mathfrak{g}$ has a nonzero
intersection with $\mathfrak{g}\left[  0\right]  $.

(Here, we are using the notation $\mathfrak{g}\left[  \alpha\right]  $ for the
$\alpha$-th homogeneous component of the $Q$-graded Lie algebra $\mathfrak{g}%
$, just as in Definition \ref{def.Q-graded.lie}.)

Just as in the case of $\mathbb{Z}$-graded Lie algebras, we will denote
$\mathfrak{g}\left[  0\right]  $ by $\mathfrak{h}$.
\end{definition}

Note that the condition \textbf{(3)} is satisfied for simple
finite-dimensional Lie algebras $\mathfrak{g}$ (graded by their weight spaces,
where $Q$ is the root lattice\footnote{in the meaning which this word has in
the theory of simple Lie algebras} of $\mathfrak{g}$, and $A$ is the Cartan
matrix); hence, simple finite-dimensional Lie algebras (graded by their weight
spaces) are contragredient.

\begin{theorem}
\label{thm.g(A).exuni}Let $A=\left(  a_{i,j}\right)  _{1\leq i,j\leq n}$ be a
(fixed) $n\times n$ matrix of complex numbers.

\textbf{(a)} Then, there exists a unique (up to $Q$-graded isomorphism
respecting the generators $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$,
$...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$) contragredient Lie algebra
$\mathfrak{g}$ corresponding to $A$.

\textbf{(b)} If $A$ is a Cartan matrix, then the contragredient Lie algebra
$\mathfrak{g}$ corresponding to $A$ is finite-dimensional and simple.
\end{theorem}

\begin{definition}
Let $A$ be an $n\times n$ matrix of complex numbers. Then, the unique (up to
isomorphism) contragredient Lie algebra $\mathfrak{g}$ corresponding to $A$ is
denoted by $\mathfrak{g}\left(  A\right)  $.
\end{definition}

The proof of Theorem \ref{thm.g(A).exuni} rests upon the following fact:

\begin{theorem}
\label{thm.gtilde}Let $A=\left(  a_{i,j}\right)  _{1\leq i,j\leq n}$ be an
$n\times n$ matrix of complex numbers. Let $e_{1}$, $e_{2}$, $...$, $e_{n}$,
$f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ be $3n$
distinct symbols (which are, a priori, new and unrelated to the vectors
$e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$,
$h_{2}$, $...$, $h_{n}$ in Definition \ref{def.contragredient}). Let
$\widetilde{\mathfrak{g}}$ be the quotient Lie algebra
\[
\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  .
\]
(Here, $\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  $ denotes the free Lie algebra with $3n$
generators $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$,
$h_{1}$, $h_{2}$, $...$, $h_{n}$.)

By abuse of notation, we will denote the projections of the elements $e_{1}$,
$e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$,
$...$, $h_{n}$ onto the quotient Lie algebra $\widetilde{\mathfrak{g}}$ by the
same letters $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$.

Let $Q$ be the free abelian group generated by $n$ symbols $\alpha_{1}$,
$\alpha_{2}$, $...$, $\alpha_{n}$ (that is, $Q=\mathbb{Z}\alpha_{1}%
\oplus\mathbb{Z}\alpha_{2}\oplus...\oplus\mathbb{Z}\alpha_{n}$). These symbols
are just symbols, not weights of any Lie algebra (at the moment).

\textbf{(a)} We can make $\widetilde{\mathfrak{g}}$ uniquely into a $Q$-graded
Lie algebra by setting%
\[
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}  .
\]


\textbf{(b)} Let $\widetilde{\mathfrak{n}}_{+}=\operatorname*{FreeLie}\left(
e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  $ (this means the free
Lie algebra with $n$ generators $e_{1}$, $e_{2}$, $...$, $e_{n}$).

Let $\widetilde{\mathfrak{n}}_{-}=\operatorname*{FreeLie}\left(  f_{i}%
\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  $ (this means the free Lie
algebra with $n$ generators $f_{1}$, $f_{2}$, $...$, $f_{n}$).

Let $\widetilde{\mathfrak{h}}$ be the free vector space with basis
$h_{1},h_{2},...,h_{n}$. Consider $\widetilde{\mathfrak{h}}$ as an abelian Lie algebra.

Then, we have well-defined canonical Lie algebra homomorphisms $\iota
_{+}:\widetilde{\mathfrak{n}}_{+}\rightarrow\widetilde{\mathfrak{g}}$ and
$\iota_{-}:\widetilde{\mathfrak{n}}_{-}\rightarrow\widetilde{\mathfrak{g}}$
given by sending the generators $e_{1}$, $e_{2}$, $...$, $e_{n}$ (in the case
of $\iota_{+}$), respectively, $f_{1}$, $f_{2}$, $...$, $f_{n}$ (in the case
of $\iota_{-}$) to the corresponding generators $e_{1}$, $e_{2}$, $...$,
$e_{n}$ (in the case of $\iota_{+}$), respectively, $f_{1}$, $f_{2}$, $...$,
$f_{n}$ (in the case of $\iota_{-}$). Moreover, we have a well-defined linear
map $\iota_{0}:\widetilde{\mathfrak{h}}\rightarrow\widetilde{\mathfrak{g}}$
given by sending the generators $h_{1}$, $h_{2}$, $...$, $h_{n}$ to $h_{1}$,
$h_{2}$, $...$, $h_{n}$, respectively.

These maps $\iota_{+}$, $\iota_{-}$ and $\iota_{0}$ are injective Lie algebra homomorphisms.

\textbf{(c)} We have $\widetilde{\mathfrak{g}}=\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  \oplus\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $.

\textbf{(d)} Both $\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
\oplus\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ and $\iota
_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ are Lie subalgebras of
$\widetilde{\mathfrak{g}}$.

\textbf{(e)} The $0$-th homogeneous component of $\widetilde{\mathfrak{g}}$
(in the $Q$-grading) is $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $.
That is, $\widetilde{\mathfrak{g}}\left[  0\right]  =\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $. Moreover,%
\[
\bigoplus_{\substack{\alpha\text{ is a }\mathbb{Z}\text{-linear combination}%
\\\text{of }\alpha_{1}\text{, }\alpha_{2}\text{, }...\text{, }\alpha_{n}\text{
with nonnegative}\\\text{coefficients; }\alpha\neq0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]  =\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
\]
and%
\[
\bigoplus_{\substack{\alpha\text{ is a }\mathbb{Z}\text{-linear combination}%
\\\text{of }\alpha_{1}\text{, }\alpha_{2}\text{, }...\text{, }\alpha_{n}\text{
with nonpositive}\\\text{coefficients; }\alpha\neq0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]  =\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
.
\]


\textbf{(f)} There exists an involutive Lie algebra automorphism of
$\widetilde{\mathfrak{g}}$ which sends $e_{1}$, $e_{2}$, $...$, $e_{n}$,
$f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ to $f_{1}$,
$f_{2}$, $...$, $f_{n}$, $e_{1}$, $e_{2}$, $...$, $e_{n}$, $-h_{1}$, $-h_{2}$,
$...$, $-h_{n}$, respectively.

\textbf{(g)} Every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  =\mathbb{C}e_{i}$ and
$\widetilde{\mathfrak{g}}\left[  -\alpha_{i}\right]  =\mathbb{C}f_{i}$.

\textbf{(h)} Let $I$ be the sum of all $Q$-graded ideals in
$\widetilde{\mathfrak{g}}$ which have zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $. Then, $I$ itself is a $Q$-graded ideal in
$\widetilde{\mathfrak{g}}$ which has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $.

\textbf{(i)} Let $\mathfrak{g}=\widetilde{\mathfrak{g}}\diagup I$. Clearly,
$\mathfrak{g}$ is a $Q$-graded Lie algebra. The projections of the elements
$e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$,
$h_{2}$, $...$, $h_{n}$ of $\widetilde{\mathfrak{g}}$ on the quotient Lie
algebra $\widetilde{\mathfrak{g}}\diagup I=\mathfrak{g}$ will still be denoted
by $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}%
$, $h_{2}$, $...$, $h_{n}$. Then, $\mathfrak{g}$ is a contragredient Lie
algebra corresponding to $A$.
\end{theorem}

\begin{definition}
Let $A$ be an $n\times n$ matrix of complex numbers. Then, the Lie algebra
$\widetilde{\mathfrak{g}}$ defined in Theorem \ref{thm.gtilde} is denoted by
$\widetilde{\mathfrak{g}}\left(  A\right)  $.
\end{definition}

\textit{Proof of Theorem \ref{thm.gtilde}.} First of all, for the sake of
clarity, let us make a convention: In the following proof, the word ``Lie
derivation'' will always mean ``derivation of Lie algebras'', whereas the word
``derivation'' without the word ``Lie'' directly in front of it will always
mean ``derivation of algebras''. The only exception to this will be the
formulation ``$\mathfrak{a}$ acts on $\mathfrak{b}$ by derivations'' where
$\mathfrak{a}$ and $\mathfrak{b}$ are two Lie algebras; this formulation has
been defined in Definition \ref{def.semidir.lielie} \textbf{(a)}.

\bigskip

\begin{vershort}
\textbf{(f)} The relations%
\[
\left\{
\begin{array}
[c]{l}%
\left[  -h_{i},-h_{j}\right]  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  -h_{i},f_{j}\right]  =a_{i,j}f_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  -h_{i},e_{j}\right]  =-a_{i,j}e_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  f_{i},e_{j}\right]  =\delta_{i,j}\left(  -h_{i}\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }i,j\in\left\{  1,2,...,n\right\}
\end{array}
\right.
\]
are satisfied in $\widetilde{\mathfrak{g}}$ (since they are easily seen to be
equivalent to the relations (\ref{nonserre-relations}), and the relations
(\ref{nonserre-relations}) are satisfied in $\widetilde{\mathfrak{g}}$ by the
definition of $\widetilde{\mathfrak{g}}$). Hence, we can define a Lie algebra
homomorphism
\[
\omega:\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  \rightarrow\widetilde{\mathfrak{g}}%
\]
by requiring%
\[
\left\{
\begin{array}
[c]{c}%
\omega\left(  e_{i}\right)  =f_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\omega\left(  f_{i}\right)  =e_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\omega\left(  h_{i}\right)  =-h_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}
\end{array}
\right.  .
\]
Consider this $\omega$. Since $\operatorname*{FreeLie}\left(  h_{i}%
,f_{i},e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  \diagup\left(
\text{the relations (\ref{nonserre-relations})}\right)
=\widetilde{\mathfrak{g}}$, this homomorphism $\omega$ is a Lie algebra
endomorphism of $\widetilde{\mathfrak{g}}$. It is easy to see that the Lie
algebra homomorphisms $\omega^{2}$ and $\operatorname*{id}$ are equal on the
generators $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$,
$h_{1}$, $h_{2}$, $...$, $h_{n}$ of $\widetilde{\mathfrak{g}}$. Hence, these
must be identical, i. e., we have $\omega^{2}=\operatorname*{id}$. Thus,
$\omega$ is an involutive Lie algebra automorphism of $\widetilde{\mathfrak{g}%
}$, and as we know from its definition, it sends $e_{1}$, $e_{2}$, $...$,
$e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ to
$f_{1}$, $f_{2}$, $...$, $f_{n}$, $e_{1}$, $e_{2}$, $...$, $e_{n}$, $-h_{1}$,
$-h_{2}$, $...$, $-h_{n}$, respectively. This proves Theorem \ref{thm.gtilde}
\textbf{(f)}.
\end{vershort}

\begin{verlong}
\textbf{(f)} Let us notice that the relations (\ref{nonserre-relations}) are
equivalent to the relations%
\begin{equation}
\left\{
\begin{array}
[c]{l}%
\left[  -h_{i},-h_{j}\right]  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  -h_{i},f_{j}\right]  =a_{i,j}f_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  -h_{i},e_{j}\right]  =-a_{i,j}e_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  f_{i},e_{j}\right]  =\delta_{i,j}\left(  -h_{i}\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }i,j\in\left\{  1,2,...,n\right\}
\end{array}
\right.  \label{nonserre-relations2}%
\end{equation}
\footnote{\textit{Proof.} We will show that the assertion
\begin{equation}
\left(  \left[  e_{i},f_{j}\right]  =\delta_{i,j}h_{i}\text{ for all }%
i,j\in\left\{  1,2,...,n\right\}  \right)  \label{pf.gtilde.equiv.1}%
\end{equation}
is equivalent to the assertion
\begin{equation}
\left(  \left[  f_{i},e_{j}\right]  =\delta_{i,j}\left(  -h_{i}\right)
\ \text{for all }i,j\in\left\{  1,2,...,n\right\}  \right)  .
\label{pf.gtilde.equiv.2}%
\end{equation}
\par
If (\ref{pf.gtilde.equiv.1}) holds, then (\ref{pf.gtilde.equiv.2}) holds as
well (because if (\ref{pf.gtilde.equiv.1}) holds, then any $i,j\in\left\{
1,2,...,n\right\}  $ satisfy%
\begin{align*}
-\left[  f_{i},e_{j}\right]   &  =\left[  e_{j},f_{i}\right]
=\underbrace{\delta_{j,i}}_{=\delta_{i,j}=\left\{
\begin{array}
[c]{c}%
1,\text{ if }i=j;\\
0,\text{ if }i\neq j
\end{array}
\right.  }h_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.gtilde.equiv.1}),
applied to }i\text{ and }j\text{ instead of }j\text{ and }i\right) \\
&  =\left\{
\begin{array}
[c]{c}%
1,\text{ if }i=j;\\
0,\text{ if }i\neq j
\end{array}
\right.  h_{j}=\left\{
\begin{array}
[c]{c}%
h_{j},\text{ if }i=j;\\
0,\text{ if }i\neq j
\end{array}
\right.  =\left\{
\begin{array}
[c]{c}%
h_{i},\text{ if }i=j;\\
0,\text{ if }i\neq j
\end{array}
\right. \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }j=i\text{ in the case when
}i=j\right) \\
&  =\underbrace{\left\{
\begin{array}
[c]{c}%
1,\text{ if }i=j;\\
0,\text{ if }i\neq j
\end{array}
\right.  }_{=\delta_{i,j}}h_{i}=\delta_{i,j}h_{i}%
\end{align*}
and thus $\left[  f_{i},e_{j}\right]  =-\delta_{i,j}h_{i}=\delta_{i,j}\left(
-h_{i}\right)  $). Similarly, if (\ref{pf.gtilde.equiv.2}) holds, then
(\ref{pf.gtilde.equiv.1}) holds as well. Thus, the assertion
(\ref{pf.gtilde.equiv.1}) is equivalent to the assertion
(\ref{pf.gtilde.equiv.2}). In other words, the fourth of the four relations
(\ref{nonserre-relations}) is equivalent to the fourth of the four relations
(\ref{nonserre-relations2}). But it is easy to see that the second of the four
relations (\ref{nonserre-relations}) is equivalent to the third of the four
relations (\ref{nonserre-relations2}). Similarly, the third of the four
relations (\ref{nonserre-relations}) is equivalent to the second of the four
relations (\ref{nonserre-relations2}). Finally, the first of the four
relations (\ref{nonserre-relations}) is equivalent to the first of the four
relations (\ref{nonserre-relations2}). Altogether, we thus conclude that the
relations (\ref{nonserre-relations}) are equivalent to the relations
(\ref{nonserre-relations2}), qed.}. Hence,
\begin{align*}
\widetilde{\mathfrak{g}}  &  =\operatorname*{FreeLie}\left(  h_{i},f_{i}%
,e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  \diagup\left(
\text{the relations (\ref{nonserre-relations})}\right) \\
&  =\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations2})}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the relations
(\ref{nonserre-relations}) are equivalent to the relations
(\ref{nonserre-relations2})}\right)  .
\end{align*}
Hence, the relations (\ref{nonserre-relations2}) are satisfied in
$\widetilde{\mathfrak{g}}$.

Now, we can define a Lie algebra homomorphism
\[
\Omega:\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \rightarrow\widetilde{\mathfrak{g}}%
\]
by requiring%
\begin{equation}
\left\{
\begin{array}
[c]{c}%
\Omega\left(  e_{i}\right)  =f_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\Omega\left(  f_{i}\right)  =e_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\Omega\left(  h_{i}\right)  =-h_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}
\end{array}
\right.  \label{pf.gtilde.OMEGA}%
\end{equation}
(because we can define a Lie algebra homomorphism from a Lie algebra by
arbitrarily choosing its values on the free generators). Define this $\Omega$.
Then, $\Omega$ sends the relations (\ref{nonserre-relations}) to the relations
(\ref{nonserre-relations2}). Since the relations (\ref{nonserre-relations2})
are satisfied in $\widetilde{\mathfrak{g}}$, this yields that the Lie algebra
homomorphism $\Omega$ factors through the factor Lie algebra%
\[
\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  .
\]
In other words, there exists a unique Lie algebra homomorphism%
\[
\omega:\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  \rightarrow\widetilde{\mathfrak{g}}%
\]
satisfying $\omega\circ\pi=\Omega$, where
\begin{align*}
\pi:  &  \operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right) \\
&  \rightarrow\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid
\ i\in\left\{  1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)
\end{align*}
is the canonical projection. Consider this $\omega$. Since \newline%
$\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  =\widetilde{\mathfrak{g}}$, this $\omega$
is a Lie algebra homomorphism from $\widetilde{\mathfrak{g}}$ to
$\widetilde{\mathfrak{g}}$. Due to $\omega\circ\pi=\Omega$ and because of
(\ref{pf.gtilde.OMEGA}), we have%
\begin{equation}
\left\{
\begin{array}
[c]{c}%
\omega\left(  e_{i}\right)  =f_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\omega\left(  f_{i}\right)  =e_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\omega\left(  h_{i}\right)  =-h_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}
\end{array}
\right.  . \label{pf.gtilde.omega}%
\end{equation}
Thus, $\omega$ sends $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$,
$...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ to $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $e_{1}$, $e_{2}$, $...$, $e_{n}$, $-h_{1}$, $-h_{2}$, $...$, $-h_{n}%
$, respectively.

The elements $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ generate $\widetilde{\mathfrak{g}}$
as a Lie algebra\footnote{This is because $\widetilde{\mathfrak{g}%
}=\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  $.}. In other words, the subset $\left\{
e_{1},e_{2},...,e_{n},f_{1},f_{2},...,f_{n},h_{1},h_{2},...,h_{n}\right\}  $
generates $\widetilde{\mathfrak{g}}$ as a Lie algebra.

The maps $\omega^{2}$ and $\operatorname*{id}$ are equal to each other on the
set $\left\{  e_{1},e_{2},...,e_{n},f_{1},f_{2},...,f_{n},h_{1},h_{2}%
,...,h_{n}\right\}  $\ \ \ \ \footnote{\textit{Proof.} Let $x\in\left\{
e_{1},e_{2},...,e_{n},f_{1},f_{2},...,f_{n},h_{1},h_{2},...,h_{n}\right\}  $.
We will prove that $\omega^{2}\left(  x\right)  =\operatorname*{id}\left(
x\right)  $.
\par
Indeed, since $x\in\left\{  e_{1},e_{2},...,e_{n},f_{1},f_{2},...,f_{n}%
,h_{1},h_{2},...,h_{n}\right\}  =\left\{  e_{1},e_{2},...,e_{n}\right\}
\cup\left\{  f_{1},f_{2},...,f_{n}\right\}  \cup\left\{  h_{1},h_{2}%
,...,h_{n}\right\}  $, we must be in one of the three following three cases:
\par
\textit{Case 1:} We have $x\in\left\{  e_{1},e_{2},...,e_{n}\right\}  $.
\par
\textit{Case 2:} We have $x\in\left\{  f_{1},f_{2},...,f_{n}\right\}  $.
\par
\textit{Case 3:} We have $x\in\left\{  h_{1},h_{2},...,h_{n}\right\}  $.
\par
Let us first consider Case 1. In this case, $x\in\left\{  e_{1},e_{2}%
,...,e_{n}\right\}  $. Thus, there exists an $i\in\left\{  1,2,...,n\right\}
$ such that $x=e_{i}$. Consider this $i$. From $x=e_{i}$, we obtain
$\omega\left(  x\right)  =\omega\left(  e_{i}\right)  =f_{i}$ and thus
$\omega^{2}\left(  x\right)  =\omega\left(  \underbrace{\omega\left(
x\right)  }_{=f_{i}}\right)  =\omega\left(  f_{i}\right)  =e_{i}%
=x=\operatorname*{id}\left(  x\right)  $. Thus, $\omega^{2}\left(  x\right)
=\operatorname*{id}\left(  x\right)  $ is proven in Case 1.
\par
Let us next consider Case 2. In this case, $x\in\left\{  f_{1},f_{2}%
,...,f_{n}\right\}  $. Thus, there exists an $i\in\left\{  1,2,...,n\right\}
$ such that $x=f_{i}$. Consider this $i$. From $x=f_{i}$, we obtain
$\omega\left(  x\right)  =\omega\left(  f_{i}\right)  =e_{i}$ and thus
$\omega^{2}\left(  x\right)  =\omega\left(  \underbrace{\omega\left(
x\right)  }_{=e_{i}}\right)  =\omega\left(  e_{i}\right)  =f_{i}%
=x=\operatorname*{id}\left(  x\right)  $. Thus, $\omega^{2}\left(  x\right)
=\operatorname*{id}\left(  x\right)  $ is proven in Case 2.
\par
Let us first consider Case 3. In this case, $x\in\left\{  h_{1},h_{2}%
,...,h_{n}\right\}  $. Thus, there exists an $i\in\left\{  1,2,...,n\right\}
$ such that $x=h_{i}$. Consider this $i$. From $x=h_{i}$, we obtain
$\omega\left(  x\right)  =\omega\left(  h_{i}\right)  =-h_{i}$ and thus
$\omega^{2}\left(  x\right)  =\omega\left(  \underbrace{\omega\left(
x\right)  }_{=-h_{i}}\right)  =\omega\left(  -h_{i}\right)
=-\underbrace{\omega\left(  h_{i}\right)  }_{=-h_{i}}=-\left(  -h_{i}\right)
=h_{i}=x=\operatorname*{id}\left(  x\right)  $. Thus, $\omega^{2}\left(
x\right)  =\operatorname*{id}\left(  x\right)  $ is proven in Case 3.
\par
Hence, the equality $\omega^{2}\left(  x\right)  =\operatorname*{id}\left(
x\right)  $ is proven in each of the three Cases 1, 2 and 3. Since these three
cases cover all possibilities, this yields that $\omega^{2}\left(  x\right)
=\operatorname*{id}\left(  x\right)  $ always holds.
\par
Now forget that we fixed $x$. Thus, we have shown that $\omega^{2}\left(
x\right)  =\operatorname*{id}\left(  x\right)  $ for every $x\in\left\{
e_{1},e_{2},...,e_{n},f_{1},f_{2},...,f_{n},h_{1},h_{2},...,h_{n}\right\}  $.
In other words, the maps $\omega^{2}$ and $\operatorname*{id}$ are equal to
each other on the set $\left\{  e_{1},e_{2},...,e_{n},f_{1},f_{2}%
,...,f_{n},h_{1},h_{2},...,h_{n}\right\}  $, qed.}. Since this set $\left\{
e_{1},e_{2},...,e_{n},f_{1},f_{2},...,f_{n},h_{1},h_{2},...,h_{n}\right\}  $
generates $\widetilde{\mathfrak{g}}$ as a Lie algebra, this yields that the
maps $\omega^{2}$ and $\operatorname*{id}$ are equal to each other on a
generating set of the Lie algebra $\widetilde{\mathfrak{g}}$. We also know
that $\omega^{2}$ and $\operatorname*{id}$ are Lie algebra homomorphisms
(since $\omega$ is a Lie algebra homomorphism).

Now, it is well-known that if two Lie algebra homomorphisms from a Lie algebra
$\mathfrak{i}$ to another Lie algebra are equal to each other on a generating
set of the Lie algebra $\mathfrak{i}$, then these two homomorphisms must be
identical. Applied to our two Lie algebra homomorphisms $\omega^{2}$ and
$\operatorname*{id}$ (which, as we know, are equal to each other on a
generating set of the Lie algebra $\widetilde{\mathfrak{g}}$), we conclude
that the two homomorphisms $\omega^{2}$ and $\operatorname*{id}$ must be
identical. In other words, $\omega^{2}=\operatorname*{id}$. Hence, $\omega$ is
an involutive automorphism of the Lie algebra $\widetilde{\mathfrak{g}}$.

Thus, there exists an involutive Lie algebra automorphism of
$\widetilde{\mathfrak{g}}$ which sends $e_{1}$, $e_{2}$, $...$, $e_{n}$,
$f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ to $f_{1}$,
$f_{2}$, $...$, $f_{n}$, $e_{1}$, $e_{2}$, $...$, $e_{n}$, $-h_{1}$, $-h_{2}$,
$...$, $-h_{n}$, respectively (namely, $\omega$). This proves Theorem
\ref{thm.gtilde} \textbf{(f)}.
\end{verlong}

\bigskip

\textbf{(a)} In order to define a $Q$-grading on a free Lie algebra, it is
enough to choose the degrees of its free generators. Thus, we can define a
$Q$-grading on the Lie algebra $\operatorname*{FreeLie}\left(  h_{i}%
,f_{i},e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  $ by setting%
\[
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}  .
\]
The relations (\ref{nonserre-relations}) are homogeneous with respect to this
$Q$-grading; hence, the quotient Lie algebra $\operatorname*{FreeLie}\left(
h_{i},f_{i},e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)
\diagup\left(  \text{the relations (\ref{nonserre-relations})}\right)  $
inherits the $Q$-grading from $\operatorname*{FreeLie}\left(  h_{i}%
,f_{i},e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  $. Since this
quotient Lie algebra is $\widetilde{\mathfrak{g}}$, we thus have constructed a
$Q$-grading on $\widetilde{\mathfrak{g}}$ which satisfies%
\begin{equation}
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}  . \label{pf.gtilde.a.1}%
\end{equation}
Since this grading is clearly the only one to satisfy (\ref{pf.gtilde.a.1})
(because $\widetilde{\mathfrak{g}}$ is generated as a Lie algebra by $e_{1}$,
$e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$,
$...$, $h_{n}$), this proves Theorem \ref{thm.gtilde} \textbf{(a)}.

\bigskip

\textbf{(b)} \underline{\textit{1st step: Definitions and identifications.}}

Let $N_{+}$ be the free vector space with basis $e_{1},e_{2},...,e_{n}$. Since
$\widetilde{\mathfrak{n}}_{+}=\operatorname*{FreeLie}\left(  e_{i}\ \mid
\ i\in\left\{  1,2,...,n\right\}  \right)  $, we then have a canonical
isomorphism $\widetilde{\mathfrak{n}}_{+}\cong\operatorname*{FreeLie}\left(
N_{+}\right)  $ (where $\operatorname*{FreeLie}\left(  N_{+}\right)  $ means
the free Lie algebra over the vector space (not the set) $N_{+}$). We identify
$\widetilde{\mathfrak{n}}_{+}$ with $\operatorname*{FreeLie}\left(
N_{+}\right)  $ along this isomorphism. Due to the construction of the free
Lie algebra, we have a canonical injection $N_{+}\rightarrow
\operatorname*{FreeLie}\left(  N_{+}\right)  =\widetilde{\mathfrak{n}}_{+}$.
We will regard this injection as an inclusion (so that $N_{+}\subseteq
\widetilde{\mathfrak{n}}_{+}$).

By Proposition \ref{prop.Ufree} (applied to $V=N_{+}$), there exists a
canonical algebra isomorphism $U\left(  \operatorname*{FreeLie}\left(
N_{+}\right)  \right)  \rightarrow T\left(  N_{+}\right)  $. We identify
$U\left(  \widetilde{\mathfrak{n}}_{+}\right)  =U\left(
\operatorname*{FreeLie}\left(  N_{+}\right)  \right)  $ with $T\left(
N_{+}\right)  $ along this isomorphism.

Let $N_{-}$ be the free vector space with basis $f_{1},f_{2},...,f_{n}$. Since
$\widetilde{\mathfrak{n}}_{-}=\operatorname*{FreeLie}\left(  f_{i}\ \mid
\ i\in\left\{  1,2,...,n\right\}  \right)  $, we then have a canonical
isomorphism $\widetilde{\mathfrak{n}}_{-}\cong\operatorname*{FreeLie}\left(
N_{-}\right)  $ (where $\operatorname*{FreeLie}\left(  N_{-}\right)  $ means
the free Lie algebra over the vector space (not the set) $N_{-}$). We identify
$\widetilde{\mathfrak{n}}_{-}$ with $\operatorname*{FreeLie}\left(
N_{-}\right)  $ along this isomorphism. Due to the construction of the free
Lie algebra, we have a canonical injection $N_{-}\rightarrow
\operatorname*{FreeLie}\left(  N_{-}\right)  =\widetilde{\mathfrak{n}}_{-}$.
We will regard this injection as an inclusion (so that $N_{-}\subseteq
\widetilde{\mathfrak{n}}_{-}$).

By Proposition \ref{prop.Ufree} (applied to $V=N_{-}$), there exists a
canonical algebra isomorphism $U\left(  \operatorname*{FreeLie}\left(
N_{-}\right)  \right)  \rightarrow T\left(  N_{-}\right)  $. We identify
$U\left(  \widetilde{\mathfrak{n}}_{-}\right)  =U\left(
\operatorname*{FreeLie}\left(  N_{-}\right)  \right)  $ with $T\left(
N_{-}\right)  $ along this isomorphism.

A consequence of the Poincar\'{e}-Birkhoff-Witt theorem says that for any Lie
algebra $\mathfrak{i}$, the canonical map $\mathfrak{i}\rightarrow U\left(
\mathfrak{i}\right)  $ is injective. Thus, the canonical map
$\widetilde{\mathfrak{n}}_{+}\rightarrow U\left(  \widetilde{\mathfrak{n}}%
_{+}\right)  $ and the canonical map $\widetilde{\mathfrak{n}}_{-}\rightarrow
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ are injective. We will
therefore regard these maps as inclusions.

Let us identify the group $Q$ with $\mathbb{Z}^{n}$ by means of identifying
$\alpha_{i}$ with the column vector $e_{i}=\left(  \underbrace{0,0,...,0}%
_{i-1\text{ zeroes}},1,\underbrace{0,0,...,0}_{n-i\text{ zeroes}}\right)
^{T}$ for every $i\in\left\{  1,2,...,n\right\}  $. As a consequence, for
every $i\in\left\{  1,2,...,n\right\}  $, the row vector $e_{i}^{T}A$ is an
element of the group $\operatorname*{Hom}\left(  Q,\mathbb{C}\right)  $ of
group homomorphisms from $Q$ to $\mathbb{C}$. Thus, for every $w\in Q$ and
every $i\in\left\{  1,2,...,n\right\}  $, the product $e_{i}^{T}Aw$ is a
complex number.

\bigskip

\underline{\textit{2nd step: Defining a }$Q$\textit{-grading on }%
$\widetilde{\mathfrak{n}}_{-}$\textit{.}}

Let us define a $Q$-grading on the vector space $N_{-}$ by setting%
\[
\deg\left(  f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{for all }%
i\in\left\{  1,2,...,n\right\}  .
\]
(This is well-defined since $\left(  f_{1},f_{2},...,f_{n}\right)  $ is a
basis of $N_{-}$.) Then, the free Lie algebra $\operatorname*{FreeLie}\left(
N_{-}\right)  =\widetilde{\mathfrak{n}}_{-}$ canonically becomes a $Q$-graded
Lie algebra, and the grading on this Lie algebra also satisfies%
\[
\deg\left(  f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{for all }%
i\in\left\{  1,2,...,n\right\}  .
\]
(This grading clearly makes the map $\iota_{-}$ graded. We will not use this
fact, however.) We will later use this grading to define certain Lie
derivations $\eta_{1}$, $\eta_{2}$, $...$, $\eta_{n}$ of the Lie algebra
$\widetilde{\mathfrak{n}}_{-}$.

\bigskip

\underline{\textit{3rd step: Defining an }$\widetilde{\mathfrak{h}}%
$\textit{-module }$\widetilde{\mathfrak{n}}_{-}$\textit{.}}

For every $i\in\left\{  1,2,...,n\right\}  $, let us define a linear map
$\eta_{i}:\widetilde{\mathfrak{n}}_{-}\rightarrow\widetilde{\mathfrak{n}}_{-}$
by setting%
\begin{equation}
\left(  \eta_{i}\left(  x\right)  =\left(  e_{i}^{T}Aw\right)  \cdot
x\ \ \ \ \ \ \ \ \ \ \text{for every }w\in Q\text{ and every }x\in
\widetilde{\mathfrak{n}}_{-}\left[  w\right]  \right)  .
\label{pf.gtilde.b.eta.def}%
\end{equation}
This map $\eta_{i}$ is well-defined (because in order to define a linear map
from a $Q$-graded vector space, it is enough to define it linearly on every
homogeneous component) and graded (because it multiplies any homogeneous
element of $\widetilde{\mathfrak{n}}_{-}$ by a scalar). Actually, $\eta_{i}$
acts as a scalar on each homogeneous component of $\widetilde{\mathfrak{n}%
}_{-}$. Moreover, for every $i\in\left\{  1,2,...,n\right\}  $, Lemma
\ref{lem.deriv.grading} (applied to $s=e_{i}^{T}A$, $\mathfrak{n}%
=\widetilde{\mathfrak{n}}_{-}$ and $\eta=\eta_{i}$) yields that $\eta_{i}$ is
a Lie derivation. That is, $\eta_{i}\in\operatorname*{Der}\left(
\widetilde{\mathfrak{n}}_{-}\right)  $. One can directly see that%
\begin{equation}
\eta_{i}\left(  f_{j}\right)  =-a_{i,j}f_{j}\ \ \ \ \ \ \ \ \ \ \text{for any
}i\in\left\{  1,2,...,n\right\}  \text{ and }j\in\left\{  1,2,...,n\right\}
\label{pf.gtilde.b.eta.fj}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.gtilde.b.eta.fj}):} Let $i\in\left\{
1,2,...,n\right\}  $ and $j\in\left\{  1,2,...,n\right\}  $. By the definition
of our grading on $\widetilde{\mathfrak{n}}_{-}$, we have $\deg\left(
f_{j}\right)  =-\underbrace{\alpha_{j}}_{=e_{j}}=-e_{j}$, so that $f_{j}%
\in\widetilde{\mathfrak{n}}_{-}\left[  -e_{j}\right]  $. Hence,
(\ref{pf.gtilde.b.eta.def}) (applied to $x=f_{j}$ and $w=-\alpha_{j}$) yields
$\eta_{i}\left(  f_{j}\right)  =\left(  e_{i}^{T}A\left(  -e_{j}\right)
\right)  \cdot f_{j}=-\underbrace{\left(  e_{i}^{T}Ae_{j}\right)  }_{=a_{i,j}%
}\cdot f_{j}=-a_{i,j}f_{j}$. This proves (\ref{pf.gtilde.b.eta.fj}).}.

[Note that, while we defined the $\eta_{i}$ using the grading, there is also
an alternative way to define them, by applying Theorem
\ref{thm.universal.FreeLie.der}.]

It is easy to see that
\begin{equation}
\left[  \eta_{i},\eta_{j}\right]  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
i\in\left\{  1,2,...,n\right\}  \text{ and }j\in\left\{  1,2,...,n\right\}
\label{pf.gtilde.b.eta.commute}%
\end{equation}
(since each of the maps $\eta_{i}$ and $\eta_{j}$ acts as a scalar on each
homogeneous component of $\widetilde{\mathfrak{n}}_{-}$).

Define a linear map $\Xi:\widetilde{\mathfrak{h}}\rightarrow
\operatorname*{Der}\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ by%
\[
\left(  \Xi\left(  h_{i}\right)  =\eta_{i}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\left\{  1,2,...,n\right\}  \right)
\]
(this map is well-defined, since $\left(  h_{1},h_{2},...,h_{n}\right)  $ is a
basis of $\widetilde{\mathfrak{h}}$). Then, $\Xi$ is a Lie algebra
homomorphism (this follows from (\ref{pf.gtilde.b.eta.commute})), and thus
makes $\widetilde{\mathfrak{n}}_{-}$ into an $\widetilde{\mathfrak{h}}$-module
on which $\widetilde{\mathfrak{h}}$ acts by derivations. Thus, a Lie algebra
$\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}$ is well-defined
(according to Definition \ref{def.semidir.lielie}). Both Lie algebras
$\widetilde{\mathfrak{h}}$ and $\widetilde{\mathfrak{n}}_{-}$ canonically
inject (by Lie algebra homomorphisms) into this Lie algebra
$\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}$. Therefore, both
$\widetilde{\mathfrak{h}}$ and $\widetilde{\mathfrak{n}}_{-}$ will be
considered as Lie subalgebras of $\widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}$.

In the Lie algebra $\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}$, every $i\in\left\{  1,2,...,n\right\}  $ and $j\in\left\{
1,2,...,n\right\}  $ satisfy%
\begin{align}
\left[  h_{i},f_{j}\right]   &  =h_{i}\rightharpoonup f_{j}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{where }\rightharpoonup\text{ denotes the
action of }\widetilde{\mathfrak{h}}\text{ on }\widetilde{\mathfrak{n}}%
_{-}\right) \nonumber\\
&  =\underbrace{\left(  \Xi\left(  h_{i}\right)  \right)  }_{=\eta_{i}}\left(
f_{j}\right)  =\eta_{i}\left(  f_{j}\right)  =-a_{i,j}f_{j}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.gtilde.b.eta.fj})}\right)  .
\label{pf.gtilde.b.semidir.ij}%
\end{align}
From (\ref{nonserre-relations}), we see that the same relation is satisfied in
the Lie algebra $\widetilde{\mathfrak{g}}$.

Since $\widetilde{\mathfrak{n}}_{-}$ is a Lie subalgebra of
$\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}$, the universal
enveloping algebra $U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ is a
subalgebra of $U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  $. This makes $U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ into a $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $-bimodule. Since $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  =T\left(  N_{-}\right)  $, this means
that $U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  $ is a $T\left(  N_{-}\right)  $-bimodule.

\bigskip

\underline{\textit{4th step: Defining an action of }$\widetilde{\mathfrak{g}}$
\textit{on }$U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  $\textit{.}}

We are going to construct an action of the Lie algebra
$\widetilde{\mathfrak{g}}$ on $U\left(  \widetilde{\mathfrak{h}}%
\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ (but not by derivations). First,
let us define some further maps.

Let $\iota_{N_{-}}^{T}:N_{-}\rightarrow T\left(  N_{-}\right)  $ be the
canonical inclusion map. Notice that we are regarding $\iota_{N_{-}}^{T}$ as
an inclusion.

\begin{vershort}
For every $i\in\left\{  1,2,...,n\right\}  $, let us define a
derivation\footnote{Here, by ``derivation'', we mean a derivation of algebras,
not of Lie algebras.} $\varepsilon_{i}:U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ by requiring that%
\[
\left(  \varepsilon_{i}\left(  f_{j}\right)  =\delta_{i,j}h_{i}%
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\left\{  1,2,...,n\right\}  \right)
.
\]
\footnote{Why is this well-defined? We know that $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  =T\left(  N_{-}\right)  $. Hence, (by
Theorem \ref{thm.universal.tensor.der}, applied to $V=N_{-}$ and $M=U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $) we can
lift any linear map $f:N_{-}\rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ to a derivation $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \rightarrow U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $. Taking
$f$ equal to the linear map $N_{-}\rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ which sends every $f_{j}$ to
$\delta_{i,j}h_{i}$, we obtain a derivation $U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ which sends every $f_{j}$ to
$\delta_{i,j}h_{i}$. This is why $\varepsilon_{i}$ is well-defined.}
\end{vershort}

\begin{verlong}
For every $i\in\left\{  1,2,...,n\right\}  $, let $\varepsilon_{i}^{\prime
}:N_{-}\rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ be the linear map defined by%
\[
\left(  \varepsilon_{i}^{\prime}\left(  f_{j}\right)  =\delta_{i,j}%
h_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\left\{  1,2,...,n\right\}
\right)
\]
(this map is well-defined, since $\left(  f_{1},f_{2},...,f_{n}\right)  $ is a
basis of $N_{-}$).

For every $i\in\left\{  1,2,...,n\right\}  $, there exists a unique
derivation\footnote{Here, by ``derivation'', we mean a derivation of algebras,
not of Lie algebras.} $F:T\left(  N_{-}\right)  \rightarrow U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $
satisfying $\varepsilon_{i}^{\prime}=F\circ\iota_{N_{-}}^{T}$ (according to
Theorem \ref{thm.universal.tensor.der}, applied to $V=N_{-}$, $M=U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ and
$f=\varepsilon_{i}^{\prime}$). Denote this derivation by $\varepsilon_{i}$.
Thus, for every $i\in\left\{  1,2,...,n\right\}  $, the map $\varepsilon
_{i}:T\left(  N_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ is a derivation satisfying
$\varepsilon_{i}^{\prime}=\varepsilon_{i}\circ\iota_{N_{-}}^{T}$. Since
$T\left(  N_{-}\right)  =U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $, this
map $\varepsilon_{i}$ is thus a derivation $U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $. Clearly, every $i\in\left\{
1,2,...,n\right\}  $ and $j\in\left\{  1,2,...,n\right\}  $ satisfy%
\begin{equation}
\varepsilon_{i}\left(  f_{j}\right)  =\delta_{i,j}h_{i}
\label{pf.gtilde.b.epsilon.fj}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.gtilde.b.epsilon.fj}):} Let $i\in\left\{
1,2,...,n\right\}  $ and $j\in\left\{  1,2,...,n\right\}  $. Then,
$\iota_{N_{-}}^{T}\left(  f_{j}\right)  =f_{j}$ (since we regard $\iota
_{N_{-}}^{T}$ as an inclusion). But since $\varepsilon_{i}^{\prime
}=\varepsilon_{i}\circ\iota_{N_{-}}^{T}$, we have $\varepsilon_{i}^{\prime
}\left(  f_{j}\right)  =\left(  \varepsilon_{i}\circ\iota_{N_{-}}^{T}\right)
\left(  f_{j}\right)  =\varepsilon_{i}\left(  \underbrace{\iota_{N_{-}}%
^{T}\left(  f_{j}\right)  }_{=f_{j}}\right)  =\varepsilon_{i}\left(
f_{j}\right)  $. Thus, $\varepsilon_{i}\left(  f_{j}\right)  =\varepsilon
_{i}^{\prime}\left(  f_{j}\right)  =\delta_{i,j}h_{i}$. This proves
(\ref{pf.gtilde.b.epsilon.fj}).}.
\end{verlong}

Let $\rho:U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(
\widetilde{\mathfrak{h}}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ be the vector space
homomorphism defined by%
\[
\rho\left(  \alpha\otimes\beta\right)  =\alpha\beta
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  \text{ and }\beta\in U\left(  \widetilde{\mathfrak{h}}\right)
\]
(this is clearly well-defined). Since $\widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}=\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}$ as vector spaces, Corollary \ref{cor.U(X)U} (applied
to $k=\mathbb{C}$, $\mathfrak{c}=\widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}$, $\mathfrak{a}=\widetilde{\mathfrak{n}}_{-}$ and
$\mathfrak{b}=\widetilde{\mathfrak{h}}$) yields that $\rho$ is an isomorphism
of filtered vector spaces, of left $U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  $-modules and of right $U\left(  \widetilde{\mathfrak{h}}\right)
$-modules. Thus, $\rho^{-1}$ also is an isomorphism of filtered vector spaces,
of left $U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $-modules and of right
$U\left(  \widetilde{\mathfrak{h}}\right)  $-modules.

\begin{vershort}
For every $i\in\left\{  1,2,...,n\right\}  $, define a linear map
$E_{i}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ by%
\begin{equation}
\left(  E_{i}\left(  u_{-}u_{0}\right)  =\varepsilon_{i}\left(  u_{-}\right)
u_{0}\ \ \ \ \ \ \ \ \ \ \text{for every }u_{-}\in U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \text{ and }u_{0}\in U\left(
\widetilde{\mathfrak{h}}\right)  \right)  . \label{pf.gtilde.b.Ei.short}%
\end{equation}
\footnote{Why is this well-defined? Since $\rho$ is an isomorphism, we have
$U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)
\cong U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(
\widetilde{\mathfrak{h}}\right)  $. In order to define a linear map $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(  \widetilde{\mathfrak{h}%
}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $, we just need to take a bilinear map
$U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \times U\left(
\widetilde{\mathfrak{h}}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ and apply the universal
property of the tensor product. Taking%
\[
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \times U\left(
\widetilde{\mathfrak{h}}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  ,\ \ \ \ \ \ \ \ \ \ \left(
u_{-},u_{0}\right)  \mapsto\varepsilon_{i}\left(  u_{-}\right)  u_{0}%
\]
as this bilinear map, we obtain (by the universal property) a linear map
$U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(
\widetilde{\mathfrak{h}}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ which sends $u_{-}\otimes
u_{0}$ to $\varepsilon_{i}\left(  u_{-}\right)  u_{0}$ for every $u_{-}\in
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and $u_{0}\in U\left(
\widetilde{\mathfrak{h}}\right)  $. Composing this map with the isomorphism
$\rho^{-1}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{n}}_{-}\right)
\otimes U\left(  \widetilde{\mathfrak{h}}\right)  $, we obtain a linear map
$U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)
\rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  $ which sends $u_{-}u_{0}$ to $\varepsilon_{i}\left(
u_{-}\right)  u_{0}$ for every $u_{-}\in U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  $ and $u_{0}\in U\left(  \widetilde{\mathfrak{h}}\right)  $.
Therefore, $E_{i}$ is well-defined.}
\end{vershort}

\begin{verlong}
Let $\mu:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \otimes U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  \rightarrow U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ be the
multiplication map of the algebra $U\left(  \widetilde{\mathfrak{h}}%
\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $. We consider $U\left(
\widetilde{\mathfrak{h}}\right)  $ as a subalgebra of $U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ (since
$\widetilde{\mathfrak{h}}$ is a Lie subalgebra of $\widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}$).

For every $i\in\left\{  1,2,...,n\right\}  $, define a linear map
$E_{i}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ by $E_{i}=\mu\circ\left(
\varepsilon_{i}\otimes\operatorname*{id}\right)  \circ\rho^{-1}$. Then,
$E_{i}$ is a right $U\left(  \widetilde{\mathfrak{h}}\right)  $-module
homomorphism (because all of $\mu$, $\varepsilon_{i}\otimes\operatorname*{id}$
and $\rho^{-1}$ are right $U\left(  \widetilde{\mathfrak{h}}\right)  $-module
homomorphisms). Also, every $u_{-}\in U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  $ and $u_{0}\in U\left(  \widetilde{\mathfrak{h}}\right)  $
satisfy%
\begin{equation}
E_{i}\left(  u_{-}u_{0}\right)  =\varepsilon_{i}\left(  u_{-}\right)  u_{0}
\label{pf.gtilde.b.Ei}%
\end{equation}
\footnote{\textit{Proof.} Let $u_{-}\in U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  $ and $u_{0}\in U\left(  \widetilde{\mathfrak{h}}\right)  $.
Since $E_{i}=\mu\circ\left(  \varepsilon_{i}\otimes\operatorname*{id}\right)
\circ\rho^{-1}$, we have
\begin{align*}
E_{i}\left(  u_{-}u_{0}\right)   &  =\left(  \mu\circ\left(  \varepsilon
_{i}\otimes\operatorname*{id}\right)  \circ\rho^{-1}\right)  \left(
u_{-}u_{0}\right)  =\left(  \mu\circ\left(  \varepsilon_{i}\otimes
\operatorname*{id}\right)  \right)  \left(  \underbrace{\rho^{-1}\left(
u_{-}u_{0}\right)  }_{\substack{=u_{-}\otimes u_{0}\\\text{(since the
definition of }\rho\text{ yields}\\\rho\left(  u_{-}\otimes u_{0}\right)
=u_{-}u_{0}\text{)}}}\right) \\
&  =\left(  \mu\circ\left(  \varepsilon_{i}\otimes\operatorname*{id}\right)
\right)  \left(  u_{-}\otimes u_{0}\right)  =\mu\left(  \underbrace{\left(
\varepsilon_{i}\otimes\operatorname*{id}\right)  \left(  u_{-}\otimes
u_{0}\right)  }_{=\varepsilon_{i}\left(  u_{-}\right)  \otimes u_{0}}\right)
=\mu\left(  \varepsilon_{i}\left(  u_{-}\right)  \otimes u_{0}\right)
=\varepsilon_{i}\left(  u_{-}\right)  u_{0}%
\end{align*}
(since $\mu$ is the multiplication map), qed.}.
\end{verlong}

For every $i\in\left\{  1,2,...,n\right\}  $, define a linear map
$F_{i}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ by%
\[
\left(  F_{i}\left(  u\right)  =f_{i}u\ \ \ \ \ \ \ \ \ \ \text{for every
}u\in U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \right)  .
\]
Clearly, $F_{i}$ is a right $U\left(  \widetilde{\mathfrak{h}}\right)
$-module homomorphism.

For every $i\in\left\{  1,2,...,n\right\}  $, define a linear map
$H_{i}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ by%
\[
\left(  H_{i}\left(  u\right)  =h_{i}u\ \ \ \ \ \ \ \ \ \ \text{for every
}u\in U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \right)  .
\]
Clearly, $H_{i}$ is a right $U\left(  \widetilde{\mathfrak{h}}\right)
$-module homomorphism.

Our next goal is to prove the relations%
\begin{equation}
\left\{
\begin{array}
[c]{l}%
\left[  H_{i},H_{j}\right]  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  H_{i},E_{j}\right]  =a_{i,j}E_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  H_{i},F_{j}\right]  =-a_{i,j}F_{j}\ \ \ \ \ \ \ \ \ \ \text{for all
}i,j\in\left\{  1,2,...,n\right\}  ;\\
\left[  E_{i},F_{j}\right]  =\delta_{i,j}H_{i}\ \ \ \ \ \ \ \ \ \ \text{for
all }i,j\in\left\{  1,2,...,n\right\}
\end{array}
\right.  \label{pf.gtilde.NONSERRE}%
\end{equation}
in $\operatorname*{End}\left(  U\left(  \widetilde{\mathfrak{h}}%
\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  $. Once these relations
are proven, it will follow that a Lie algebra homomorphism
$\widetilde{\mathfrak{g}}\rightarrow\operatorname*{End}\left(  U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  $
mapping $h_{i}$, $e_{i}$, $f_{i}$ to $H_{i}$, $E_{i}$, $F_{i}$ for all $i$
exists (and is unique), and this map will make $U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ into a
$\widetilde{\mathfrak{g}}$-module. This $\widetilde{\mathfrak{g}}$-module
structure will then yield Theorem \ref{thm.gtilde} \textbf{(b)} by a rather
simple argument. But we must first verify (\ref{pf.gtilde.NONSERRE}).

\bigskip

\underline{\textit{5th step: Verifying the relations (\ref{pf.gtilde.NONSERRE}%
).}}

We will verify the four relations (\ref{pf.gtilde.NONSERRE}) one after the other:

\bigskip

\textit{Proof of the relation }$\left[  H_{i},H_{j}\right]  =0$ \textit{for
all } $i,j\in\left\{  1,2,...,n\right\}  $\textit{:}

Let $i$ and $j$ be two elements of $\left\{  1,2,...,n\right\}  $. Every $u\in
U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $
satisfies%
\begin{align*}
\underbrace{\left[  H_{i},H_{j}\right]  }_{=H_{i}\circ H_{j}-H_{j}\circ H_{i}%
}u  &  =\left(  H_{i}\circ H_{j}-H_{j}\circ H_{i}\right)  \left(  u\right)
=H_{i}\underbrace{\left(  H_{j}u\right)  }_{\substack{=h_{j}u\\\text{(by the
definition}\\\text{of }H_{j}\text{)}}}-H_{j}\underbrace{\left(  H_{i}u\right)
}_{\substack{=h_{i}u\\\text{(by the definition}\\\text{of }H_{i}\text{)}}}\\
&  =\underbrace{H_{i}\left(  h_{j}u\right)  }_{\substack{=h_{i}\left(
h_{j}u\right)  \\\text{(by the definition}\\\text{of }H_{i}\text{)}%
}}-\underbrace{H_{j}\left(  h_{i}u\right)  }_{\substack{=h_{j}\left(
h_{i}u\right)  \\\text{(by the definition}\\\text{of }H_{j}\text{)}}}\\
&  =h_{i}\left(  h_{j}u\right)  -h_{j}\left(  h_{i}u\right)
=\underbrace{\left(  h_{i}h_{j}-h_{j}h_{i}\right)  }_{\substack{=\left[
h_{i},h_{j}\right]  =0\\\text{in }U\left(  \widetilde{\mathfrak{h}}%
\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \\\text{(since }\left[
h_{i},h_{j}\right]  =0\text{ in }\widetilde{\mathfrak{h}}\text{)}}}u=0.
\end{align*}
Thus, $\left[  H_{i},H_{j}\right]  =0$.

Now forget that we fixed $i$ and $j$. We have thus proven the relation
$\left[  H_{i},H_{j}\right]  =0$ for all $i,j\in\left\{  1,2,...,n\right\}  $.

\bigskip

\textit{Proof of the relation }$\left[  H_{i},E_{j}\right]  =a_{i,j}E_{j}$
\textit{for all } $i,j\in\left\{  1,2,...,n\right\}  $\textit{:}

This will be the most difficult among the four relations that we must prove.

Applying Corollary \ref{cor.derivation.Lie.semidir} to
$\widetilde{\mathfrak{h}}$ and $\widetilde{\mathfrak{n}}_{-}$ instead of
$\mathfrak{g}$ and $\mathfrak{h}$, we obtain $\left[  \widetilde{\mathfrak{h}%
},U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \right]  \subseteq U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $ in $U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $.

Let us consider $U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ as
$\widetilde{\mathfrak{n}}_{-}$-module via the adjoint action. Then,
$\widetilde{\mathfrak{n}}_{-}\subseteq U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  $ as $\widetilde{\mathfrak{n}}_{-}$-modules.

Let $i$ be any element of $\left\{  1,2,...,n\right\}  $. Define a map
$\zeta_{i}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ by%
\[
\left(  \zeta_{i}\left(  u\right)  =\left[  h_{i},u\right]
\ \ \ \ \ \ \ \ \ \ \text{for every }u\in U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  .
\]
Clearly, $\zeta_{i}$ is a derivation of algebras.

Now, using the relation $\left[  \widetilde{\mathfrak{h}},U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \right]  \subseteq U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $, it is easy to check that $\zeta
_{i}\left(  U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \right)  \subseteq
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $%
\ \ \ \ \footnote{\textit{Proof.} Every $u\in U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ satisfies%
\[
\zeta_{i}\left(  u\right)  =\left[  \underbrace{h_{i}}_{\in
\widetilde{\mathfrak{h}}},\underbrace{u}_{\in U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  }\right]  \in\left[  \widetilde{\mathfrak{h}},U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \right]  \subseteq U\left(
\widetilde{\mathfrak{n}}_{-}\right)  .
\]
In other words, $\zeta_{i}\left(  U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  \right)  \subseteq U\left(  \widetilde{\mathfrak{n}}_{-}\right)
$, qed.}.

Now, let $j\in\left\{  1,2,...,n\right\}  $ be arbitrary. Recall that
$\zeta_{i}:U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ and $\varepsilon_{j}:U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \rightarrow U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ are
derivations satisfying $\zeta_{i}\left(  U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  \right)  \subseteq U\left(  \widetilde{\mathfrak{n}}_{-}\right)
$. Thus, Proposition \ref{prop.commutator.derivs.alg.2} (applied to $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $, $U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $, $\varepsilon_{j}$ and
$\zeta_{i}$ instead of $A$, $B$, $f$ and $g$) yields that $\varepsilon
_{j}\circ\left(  \zeta_{i}\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)
}\right)  -\zeta_{i}\circ\varepsilon_{j}:U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ is a derivation (of algebras).

On the other hand, $-a_{i,j}\varepsilon_{j}:U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ is also a derivation (of algebras),
since $\varepsilon_{j}$ is a derivation.

We will now prove that%
\begin{equation}
\varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon_{j}=-a_{i,j}\varepsilon
_{j}. \label{pf.gtilde.dercomm1}%
\end{equation}
\footnote{Note that the term $\varepsilon_{j}\circ\left(  \zeta_{i}%
\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  $ in this
equality is well-defined because $\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  \left(  U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \right)  =\zeta_{i}\left(  U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \right)  \subseteq U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $.} This will bring us very close to the
proof of the relation $\left[  H_{i},E_{j}\right]  =a_{i,j}E_{j}$.

\begin{vershort}
\textit{Proof of (\ref{pf.gtilde.dercomm1}):} Every $k\in\left\{
1,2,...,n\right\}  $ satisfies%
\begin{align*}
&  \left(  \left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}\right)  \left(  f_{k}\right) \\
&  =\varepsilon_{j}\left(  \underbrace{\zeta_{i}\left(  f_{k}\right)
}_{\substack{=\left[  h_{i},f_{k}\right]  \\\text{(by the definition of }%
\zeta_{i}\text{)}}}\right)  -\underbrace{\zeta_{i}\left(  \varepsilon
_{j}\left(  f_{k}\right)  \right)  }_{\substack{=\left[  h_{i},\varepsilon
_{j}\left(  f_{k}\right)  \right]  \\\text{(by the definition of }\zeta
_{i}\text{)}}}\\
&  =\varepsilon_{j}\left(  \underbrace{\left[  h_{i},f_{k}\right]
}_{\substack{=-a_{i,k}f_{k}\\\text{(by (\ref{pf.gtilde.b.semidir.ij}), applied
to}\\k\text{ instead of }j\text{)}}}\right)  -\left[  h_{i}%
,\underbrace{\varepsilon_{j}\left(  f_{k}\right)  }_{\substack{=\delta
_{j,k}h_{j}\\\text{(by the definition of }\varepsilon_{j}\text{)}}}\right] \\
&  =\underbrace{\varepsilon_{j}\left(  -a_{i,k}f_{k}\right)  }_{=-a_{i,k}%
\varepsilon_{j}\left(  f_{k}\right)  }-\underbrace{\left[  h_{i},\delta
_{j,k}h_{j}\right]  }_{\substack{=0\\\text{(since }\widetilde{\mathfrak{h}%
}\text{ is an abelian Lie algebra)}}}=-a_{i,k}\underbrace{\varepsilon
_{j}\left(  f_{k}\right)  }_{\substack{=\delta_{j,k}h_{j}\\\text{(by the
definition of }\varepsilon_{j}\text{)}}}\\
&  =-\underbrace{a_{i,k}\delta_{j,k}}_{=a_{i,j}\delta_{j,k}}h_{j}%
=-a_{i,j}\underbrace{\delta_{j,k}h_{j}}_{\substack{=\varepsilon_{j}\left(
f_{k}\right)  \\\text{(by the definition of }\varepsilon_{j}\text{)}%
}}=-a_{i,j}\varepsilon_{j}\left(  f_{k}\right)  =\left(  \left(
-a_{i,j}\varepsilon_{j}\right)  \mid_{N_{-}}\right)  \left(  f_{k}\right)  .
\end{align*}
In other words, the maps $\left(  \varepsilon_{j}\circ\left(  \zeta_{i}%
\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}%
\circ\varepsilon_{j}\right)  \mid_{N_{-}}$ and $\left(  -a_{i,j}%
\varepsilon_{j}\right)  \mid_{N_{-}}$ are equal to each other on each of the
elements $f_{1}$, $f_{2}$, $...$, $f_{n}$ of $N_{-}$. Since $\left(
f_{1},f_{2},...,f_{n}\right)  $ is a basis of $N_{-}$, this yields that
\[
\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}=\left(  -a_{i,j}\varepsilon_{j}\right)  \mid_{N_{-}}%
\]
(because the maps $\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}$ and $\left(  -a_{i,j}\varepsilon_{j}\right)
\mid_{N_{-}}$ are linear). Hence, since the set $N_{-}$ generates $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $ as an algebra (because $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  =T\left(  N_{-}\right)  $), Proposition
\ref{prop.derivation.unique} (applied to $U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  $, $N_{-}$, $U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $, $\varepsilon_{j}\circ\left(  \zeta
_{i}\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta
_{i}\circ\varepsilon_{j}$ and $-a_{i,j}\varepsilon_{j}$ instead of $A$, $S$,
$M$, $d$ and $e$) yields that $\varepsilon_{j}\circ\left(  \zeta_{i}%
\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}%
\circ\varepsilon_{j}=-a_{i,j}\varepsilon_{j}$ (since $\varepsilon_{j}%
\circ\left(  \zeta_{i}\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)
}\right)  -\zeta_{i}\circ\varepsilon_{j}$ and $-a_{i,j}\varepsilon_{j}$ are
derivations). This proves (\ref{pf.gtilde.dercomm1}).
\end{vershort}

\begin{verlong}
\textit{Proof of (\ref{pf.gtilde.dercomm1}):} Every $k\in\left\{
1,2,...,n\right\}  $ satisfies%
\begin{align*}
&  \left(  \left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}\right)  \left(  f_{k}\right) \\
&  =\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \left(  f_{k}\right) \\
&  =\varepsilon_{j}\left(  \underbrace{\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  \left(  f_{k}\right)
}_{\substack{=\zeta_{i}\left(  f_{k}\right)  =\left[  h_{i},f_{k}\right]
\\\text{(by the definition of }\zeta_{i}\text{)}}}\right)  -\underbrace{\zeta
_{i}\left(  \varepsilon_{j}\left(  f_{k}\right)  \right)  }%
_{\substack{=\left[  h_{i},\varepsilon_{j}\left(  f_{k}\right)  \right]
\\\text{(by the definition of }\zeta_{i}\text{)}}}\\
&  =\varepsilon_{j}\left(  \underbrace{\left[  h_{i},f_{k}\right]
}_{\substack{=-a_{i,k}f_{k}\\\text{(by (\ref{pf.gtilde.b.semidir.ij}), applied
to}\\k\text{ instead of }j\text{)}}}\right)  -\left[  h_{i}%
,\underbrace{\varepsilon_{j}\left(  f_{k}\right)  }_{\substack{=\delta
_{j,k}h_{j}\\\text{(by (\ref{pf.gtilde.b.epsilon.fj}), applied to}\\j\text{
and }k\text{ instead of }i\text{ and }j\text{)}}}\right] \\
&  =\underbrace{\varepsilon_{j}\left(  -a_{i,k}f_{k}\right)  }_{=-a_{i,k}%
\varepsilon_{j}\left(  f_{k}\right)  }-\underbrace{\left[  h_{i},\delta
_{j,k}h_{j}\right]  }_{\substack{=0\\\text{(since }\widetilde{\mathfrak{h}%
}\text{ is an abelian Lie algebra)}}}=-a_{i,k}\underbrace{\varepsilon
_{j}\left(  f_{k}\right)  }_{\substack{=\delta_{j,k}h_{j}\\\text{(by
(\ref{pf.gtilde.b.epsilon.fj}), applied to}\\j\text{ and }k\text{ instead of
}i\text{ and }j\text{)}}}\\
&  =-a_{i,k}\underbrace{\delta_{j,k}}_{=\left\{
\begin{array}
[c]{c}%
1,\text{ if }j=k\\
0,\text{ if }j\neq k
\end{array}
\right.  }h_{j}=-\underbrace{a_{i,k}\left\{
\begin{array}
[c]{c}%
1,\text{ if }j=k\\
0,\text{ if }j\neq k
\end{array}
\right.  }_{=\left\{
\begin{array}
[c]{c}%
a_{i,k}\cdot1,\text{ if }j=k\\
a_{i,k}\cdot0,\text{ if }j\neq k
\end{array}
\right.  }h_{j}\\
&  =-\left\{
\begin{array}
[c]{c}%
a_{i,k}\cdot1,\text{ if }j=k\\
a_{i,k}\cdot0,\text{ if }j\neq k
\end{array}
\right.  h_{j}=-\left\{
\begin{array}
[c]{c}%
a_{i,j}\cdot1,\text{ if }j=k\\
a_{i,k}\cdot0,\text{ if }j\neq k
\end{array}
\right.  h_{j}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }a_{i,k}=a_{i,j}\text{ if
}j=k\text{ (because }k=j\text{ if }j=k\text{)}\right) \\
&  =-\underbrace{\left\{
\begin{array}
[c]{c}%
a_{i,j}\cdot1,\text{ if }j=k\\
a_{i,j}\cdot0,\text{ if }j\neq k
\end{array}
\right.  }_{=a_{i,j}\cdot\left\{
\begin{array}
[c]{c}%
1,\text{ if }j=k\\
0,\text{ if }j\neq k
\end{array}
\right.  }h_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }a_{i,k}\cdot
0=a_{i,j}\cdot0\text{ if }j\neq k\right) \\
&  =-a_{i,j}\cdot\underbrace{\left\{
\begin{array}
[c]{c}%
1,\text{ if }j=k\\
0,\text{ if }j\neq k
\end{array}
\right.  }_{=\delta_{j,k}}h_{j}=-a_{i,j}\delta_{j,k}h_{j}%
\end{align*}
and%
\[
\left(  \left(  -a_{i,j}\varepsilon_{j}\right)  \mid_{N_{-}}\right)  \left(
f_{k}\right)  =\left(  -a_{i,j}\varepsilon_{j}\right)  \left(  f_{k}\right)
=-a_{i,j}\underbrace{\varepsilon_{j}\left(  f_{k}\right)  }_{\substack{=\delta
_{j,k}h_{j}\\\text{(by (\ref{pf.gtilde.b.epsilon.fj}), applied to}\\j\text{
and }k\text{ instead of }i\text{ and }j\text{)}}}=-a_{i,j}\delta_{j,k}h_{j}.
\]
Hence, every $k\in\left\{  1,2,...,n\right\}  $ satisfies%
\[
\left(  \left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}\right)  \left(  f_{k}\right)  =-a_{i,j}\delta
_{j,k}h_{j}=\left(  \left(  -a_{i,j}\varepsilon_{j}\right)  \mid_{N_{-}%
}\right)  \left(  f_{k}\right)  .
\]
In other words, the maps $\left(  \varepsilon_{j}\circ\left(  \zeta_{i}%
\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}%
\circ\varepsilon_{j}\right)  \mid_{N_{-}}$ and $\left(  -a_{i,j}%
\varepsilon_{j}\right)  \mid_{N_{-}}$ are equal to each other on each of the
elements $f_{1}$, $f_{2}$, $...$, $f_{n}$ of $N_{-}$. Since $\left(
f_{1},f_{2},...,f_{n}\right)  $ is a basis of $N_{-}$, this yields that
\[
\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}=\left(  -a_{i,j}\varepsilon_{j}\right)  \mid_{N_{-}}%
\]
(because the maps $\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \mid_{N_{-}}$ and $\left(  -a_{i,j}\varepsilon_{j}\right)
\mid_{N_{-}}$ are linear). Hence, since the set $N_{-}$ generates $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $ as an algebra (because $U\left(
\widetilde{\mathfrak{n}}_{-}\right)  =T\left(  N_{-}\right)  $), Proposition
\ref{prop.derivation.unique} (applied to $U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  $, $N_{-}$, $U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $, $\varepsilon_{j}\circ\left(  \zeta
_{i}\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta
_{i}\circ\varepsilon_{j}$ and $-a_{i,j}\varepsilon_{j}$ instead of $A$, $S$,
$M$, $d$ and $e$) yields that $\varepsilon_{j}\circ\left(  \zeta_{i}%
\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}%
\circ\varepsilon_{j}=-a_{i,j}\varepsilon_{j}$ (since $\varepsilon_{j}%
\circ\left(  \zeta_{i}\mid_{U\left(  \widetilde{\mathfrak{n}}_{-}\right)
}\right)  -\zeta_{i}\circ\varepsilon_{j}$ and $-a_{i,j}\varepsilon_{j}$ are
derivations). This proves (\ref{pf.gtilde.dercomm1}).
\end{verlong}

Now, we will show that
\begin{equation}
\left[  h_{i},\varepsilon_{j}\left(  u_{-}\right)  \right]  -\varepsilon
_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  =a_{i,j}\varepsilon
_{j}\left(  u_{-}\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }u_{-}\in
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  . \label{pf.gtilde.dercomm2}%
\end{equation}


\textit{Proof of (\ref{pf.gtilde.dercomm2}):} Let $u_{-}\in U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $. Then,%
\begin{align*}
\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  \left(  u_{-}\right)   &  =\varepsilon_{j}\left(
\underbrace{\left(  \zeta_{i}\mid_{U\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  }\right)  \left(  u_{-}\right)  }_{\substack{=\zeta_{i}\left(
u_{-}\right)  =\left[  h_{i},u_{-}\right]  \\\text{(by the definition of
}\zeta_{i}\text{)}}}\right)  -\underbrace{\zeta_{i}\left(  \varepsilon
_{j}\left(  u_{-}\right)  \right)  }_{\substack{=\left[  h_{i},\varepsilon
_{j}\left(  u_{-}\right)  \right]  \\\text{(by the definition of }\zeta
_{i}\text{)}}}\\
&  =\varepsilon_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  -\left[
h_{i},\varepsilon_{j}\left(  u_{-}\right)  \right]  .
\end{align*}
Comparing this with%
\[
\underbrace{\left(  \varepsilon_{j}\circ\left(  \zeta_{i}\mid_{U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right)  -\zeta_{i}\circ\varepsilon
_{j}\right)  }_{\substack{=-a_{i,j}\varepsilon_{j}\\\text{(by
(\ref{pf.gtilde.dercomm1}))}}}\left(  u_{-}\right)  =-a_{i,j}\varepsilon
_{j}\left(  u_{-}\right)  ,
\]
we obtain $-a_{i,j}\varepsilon_{j}\left(  u_{-}\right)  =\varepsilon
_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  -\left[  h_{i},\varepsilon
_{j}\left(  u_{-}\right)  \right]  $. In other words, $\left[  h_{i}%
,\varepsilon_{j}\left(  u_{-}\right)  \right]  -\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  =a_{i,j}\varepsilon_{j}\left(  u_{-}\right)  $.
This proves (\ref{pf.gtilde.dercomm2}).

Now, let us finally prove that $\left[  H_{i},E_{j}\right]  =a_{i,j}E_{j}$.

\begin{vershort}
Indeed, let $u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and
$u_{0}\in U\left(  \widetilde{\mathfrak{h}}\right)  $. Then, $\left[
\underbrace{h_{i}}_{\in\mathfrak{h}},\underbrace{u_{-}}_{\in U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right]  \in\left[
\widetilde{\mathfrak{h}},U\left(  \widetilde{\mathfrak{n}}_{-}\right)
\right]  \subseteq U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $. Thus,
(\ref{pf.gtilde.b.Ei.short}) (applied to $\left[  h_{i},u_{-}\right]  $ and
$j$ instead of $u_{-}$ and $i$) yields%
\[
E_{j}\left(  \left[  h_{i},u_{-}\right]  u_{0}\right)  =\varepsilon_{j}\left(
\left[  h_{i},u_{-}\right]  \right)  u_{0}.
\]
On the other hand, $\underbrace{h_{i}}_{\in\widetilde{\mathfrak{h}}%
}\underbrace{u_{0}}_{\in U\left(  \widetilde{\mathfrak{h}}\right)  }%
\in\widetilde{\mathfrak{h}}U\left(  \widetilde{\mathfrak{h}}\right)  \subseteq
U\left(  \widetilde{\mathfrak{h}}\right)  $. Hence,
(\ref{pf.gtilde.b.Ei.short}) (applied to $h_{i}u_{0}$ and $j$ instead of
$u_{0}$ and $i$) yields%
\[
E_{j}\left(  u_{-}h_{i}u_{0}\right)  =\varepsilon_{j}\left(  u_{-}\right)
h_{i}u_{0}.
\]
But $\underbrace{h_{i}u_{-}}_{=\left[  h_{i},u_{-}\right]  +u_{-}h_{i}}%
u_{0}=\left[  h_{i},u_{-}\right]  u_{0}+u_{-}h_{i}u_{0}$, so that
\begin{align*}
E_{j}\left(  h_{i}u_{-}u_{0}\right)   &  =E_{j}\left(  \left[  h_{i}%
,u_{-}\right]  u_{0}+u_{-}h_{i}u_{0}\right)  =\underbrace{E_{j}\left(  \left[
h_{i},u_{-}\right]  u_{0}\right)  }_{=\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  u_{0}}+\underbrace{E_{j}\left(  u_{-}h_{i}%
u_{0}\right)  }_{=\varepsilon_{j}\left(  u_{-}\right)  h_{i}u_{0}}\\
&  =\varepsilon_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  u_{0}%
+\varepsilon_{j}\left(  u_{-}\right)  h_{i}u_{0}.
\end{align*}


On the other hand,%
\begin{align*}
&  \underbrace{\left[  H_{i},E_{j}\right]  }_{=H_{i}\circ E_{j}-E_{j}\circ
H_{i}}\left(  u_{-}u_{0}\right)  =\left(  H_{i}\circ E_{j}-E_{j}\circ
H_{i}\right)  \left(  u_{-}u_{0}\right) \\
&  =H_{i}\left(  \underbrace{E_{j}\left(  u_{-}u_{0}\right)  }%
_{\substack{=\varepsilon_{j}\left(  u_{-}\right)  u_{0}\\\text{(by
(\ref{pf.gtilde.b.Ei.short}), applied}\\\text{to }j\text{ instead of
}i\text{)}}}\right)  -E_{j}\left(  \underbrace{H_{i}\left(  u_{-}u_{0}\right)
}_{\substack{=h_{i}u_{-}u_{0}\\\text{(by the definition of }H_{i}\text{)}%
}}\right) \\
&  =\underbrace{H_{i}\left(  \varepsilon_{j}\left(  u_{-}\right)
u_{0}\right)  }_{\substack{=h_{i}\varepsilon_{j}\left(  u_{-}\right)
u_{0}\\\text{(by the definition of }H_{i}\text{)}}}-\underbrace{E_{j}\left(
h_{i}u_{-}u_{0}\right)  }_{\substack{=\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  u_{0}+\varepsilon_{j}\left(  u_{-}\right)
h_{i}u_{0}\\\text{(as we saw above)}}}\\
&  =h_{i}\varepsilon_{j}\left(  u_{-}\right)  u_{0}-\left(  \varepsilon
_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  u_{0}+\varepsilon_{j}\left(
u_{-}\right)  h_{i}u_{0}\right)  =h_{i}\varepsilon_{j}\left(  u_{-}\right)
u_{0}-\varepsilon_{j}\left(  u_{-}\right)  h_{i}u_{0}-\varepsilon_{j}\left(
\left[  h_{i},u_{-}\right]  \right)  u_{0}\\
&  =\left(  \underbrace{h_{i}\varepsilon_{j}\left(  u_{-}\right)
-\varepsilon_{j}\left(  u_{-}\right)  h_{i}}_{=\left[  h_{i},\varepsilon
_{j}\left(  u_{-}\right)  \right]  }-\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  \right)  u_{0}=\underbrace{\left(  \left[
h_{i},\varepsilon_{j}\left(  u_{-}\right)  \right]  -\varepsilon_{j}\left(
\left[  h_{i},u_{-}\right]  \right)  \right)  }_{\substack{=a_{i,j}%
\varepsilon_{j}\left(  u_{-}\right)  \\\text{(by (\ref{pf.gtilde.dercomm2}))}%
}}u_{0}\\
&  =a_{i,j}\underbrace{\varepsilon_{j}\left(  u_{-}\right)  u_{0}%
}_{\substack{=E_{j}\left(  u_{-}u_{0}\right)  \\\text{(since
(\ref{pf.gtilde.b.Ei.short}) (applied to }j\text{ instead of }i\text{)}%
\\\text{yields }E_{j}\left(  u_{-}u_{0}\right)  =\varepsilon_{j}\left(
u_{-}\right)  u_{0}\text{)}}}=a_{i,j}E_{j}\left(  u_{-}u_{0}\right)  .
\end{align*}


Now, forget that we fixed $u_{-}$ and $u_{0}$. We thus have proven that%
\[
\left[  H_{i},E_{j}\right]  \left(  u_{-}u_{0}\right)  =\left(  a_{i,j}%
E_{j}\right)  \left(  u_{-}u_{0}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \text{ and }u_{0}\in
U\left(  \widetilde{\mathfrak{h}}\right)  .
\]
Since the vector space $U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ is generated by products $u_{-}u_{0}$
with $u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and $u_{0}\in
U\left(  \widetilde{\mathfrak{h}}\right)  $ (this is because $\rho:U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(  \widetilde{\mathfrak{h}%
}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ is an isomorphism), this yields that
$\left[  H_{i},E_{j}\right]  =a_{i,j}E_{j}$.
\end{vershort}

\begin{verlong}
Indeed, let $u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and
$u_{0}\in U\left(  \widetilde{\mathfrak{h}}\right)  $. Then, $\left[
\underbrace{h_{i}}_{\in\mathfrak{h}},\underbrace{u_{-}}_{\in U\left(
\widetilde{\mathfrak{n}}_{-}\right)  }\right]  \in\left[
\widetilde{\mathfrak{h}},U\left(  \widetilde{\mathfrak{n}}_{-}\right)
\right]  \subseteq U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $. Thus,
(\ref{pf.gtilde.b.Ei}) (applied to $\left[  h_{i},u_{-}\right]  $ and $j$
instead of $u_{-}$ and $i$) yields%
\begin{equation}
E_{j}\left(  \left[  h_{i},u_{-}\right]  u_{0}\right)  =\varepsilon_{j}\left(
\left[  h_{i},u_{-}\right]  \right)  u_{0}. \label{pf.gtilde.dercomm3}%
\end{equation}
On the other hand, $\underbrace{h_{i}}_{\in\widetilde{\mathfrak{h}}%
}\underbrace{u_{0}}_{\in U\left(  \widetilde{\mathfrak{h}}\right)  }%
\in\widetilde{\mathfrak{h}}U\left(  \widetilde{\mathfrak{h}}\right)  \subseteq
U\left(  \widetilde{\mathfrak{h}}\right)  $. Hence, (\ref{pf.gtilde.b.Ei})
(applied to $h_{i}u_{0}$ and $j$ instead of $u_{0}$ and $i$) yields%
\begin{equation}
E_{j}\left(  u_{-}h_{i}u_{0}\right)  =\varepsilon_{j}\left(  u_{-}\right)
h_{i}u_{0}. \label{pf.gtilde.dercomm4}%
\end{equation}
But $\underbrace{h_{i}u_{-}}_{=\left[  h_{i},u_{-}\right]  +u_{-}h_{i}}%
u_{0}=\left[  h_{i},u_{-}\right]  u_{0}+u_{-}h_{i}u_{0}$, so that
\begin{align}
E_{j}\left(  h_{i}u_{-}u_{0}\right)   &  =E_{j}\left(  \left[  h_{i}%
,u_{-}\right]  u_{0}+u_{-}h_{i}u_{0}\right)  =\underbrace{E_{j}\left(  \left[
h_{i},u_{-}\right]  u_{0}\right)  }_{\substack{=\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  u_{0}\\\text{(by (\ref{pf.gtilde.dercomm3}))}%
}}+\underbrace{E_{j}\left(  u_{-}h_{i}u_{0}\right)  }_{\substack{=\varepsilon
_{j}\left(  u_{-}\right)  h_{i}u_{0}\\\text{(by (\ref{pf.gtilde.dercomm4}))}%
}}\nonumber\\
&  =\varepsilon_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  u_{0}%
+\varepsilon_{j}\left(  u_{-}\right)  h_{i}u_{0}. \label{pf.gtilde.dercomm5}%
\end{align}


On the other hand, $\rho\left(  u_{-}\otimes u_{0}\right)  =u_{-}u_{0}$ (by
the definition of $\rho$), and%
\begin{align*}
&  \left(  \left[  H_{i},E_{j}\right]  \circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right) \\
&  =\underbrace{\left[  H_{i},E_{j}\right]  }_{=H_{i}\circ E_{j}-E_{j}\circ
H_{i}}\left(  \underbrace{\rho\left(  u_{-}\otimes u_{0}\right)  }%
_{=u_{-}u_{0}}\right)  =\left(  H_{i}\circ E_{j}-E_{j}\circ H_{i}\right)
\left(  u_{-}u_{0}\right) \\
&  =H_{i}\left(  \underbrace{E_{j}\left(  u_{-}u_{0}\right)  }%
_{\substack{=\varepsilon_{j}\left(  u_{-}\right)  u_{0}\\\text{(by
(\ref{pf.gtilde.b.Ei}), applied}\\\text{to }j\text{ instead of }i\text{)}%
}}\right)  -E_{j}\left(  \underbrace{H_{i}\left(  u_{-}u_{0}\right)
}_{\substack{=h_{i}u_{-}u_{0}\\\text{(by the definition of }H_{i}\text{)}%
}}\right) \\
&  =\underbrace{H_{i}\left(  \varepsilon_{j}\left(  u_{-}\right)
u_{0}\right)  }_{\substack{=h_{i}\varepsilon_{j}\left(  u_{-}\right)
u_{0}\\\text{(by the definition of }H_{i}\text{)}}}-\underbrace{E_{j}\left(
h_{i}u_{-}u_{0}\right)  }_{\substack{=\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  u_{0}+\varepsilon_{j}\left(  u_{-}\right)
h_{i}u_{0}\\\text{(by (\ref{pf.gtilde.dercomm5}))}}}\\
&  =h_{i}\varepsilon_{j}\left(  u_{-}\right)  u_{0}-\left(  \varepsilon
_{j}\left(  \left[  h_{i},u_{-}\right]  \right)  u_{0}+\varepsilon_{j}\left(
u_{-}\right)  h_{i}u_{0}\right)  =h_{i}\varepsilon_{j}\left(  u_{-}\right)
u_{0}-\varepsilon_{j}\left(  u_{-}\right)  h_{i}u_{0}-\varepsilon_{j}\left(
\left[  h_{i},u_{-}\right]  \right)  u_{0}\\
&  =\left(  \underbrace{h_{i}\varepsilon_{j}\left(  u_{-}\right)
-\varepsilon_{j}\left(  u_{-}\right)  h_{i}}_{=\left[  h_{i},\varepsilon
_{j}\left(  u_{-}\right)  \right]  }-\varepsilon_{j}\left(  \left[
h_{i},u_{-}\right]  \right)  \right)  u_{0}=\underbrace{\left(  \left[
h_{i},\varepsilon_{j}\left(  u_{-}\right)  \right]  -\varepsilon_{j}\left(
\left[  h_{i},u_{-}\right]  \right)  \right)  }_{\substack{=a_{i,j}%
\varepsilon_{j}\left(  u_{-}\right)  \\\text{(by (\ref{pf.gtilde.dercomm2}))}%
}}u_{0}\\
&  =a_{i,j}\underbrace{\varepsilon_{j}\left(  u_{-}\right)  u_{0}%
}_{\substack{=E_{j}\left(  u_{-}u_{0}\right)  \\\text{(since
(\ref{pf.gtilde.b.Ei}) (applied to }j\text{ instead of }i\text{)}%
\\\text{yields }E_{j}\left(  u_{-}u_{0}\right)  =\varepsilon_{j}\left(
u_{-}\right)  u_{0}\text{)}}}=a_{i,j}E_{j}\left(  \underbrace{u_{-}u_{0}%
}_{=\rho\left(  u_{-}\otimes u_{0}\right)  }\right)  =a_{i,j}E_{j}\left(
\rho\left(  u_{-}\otimes u_{0}\right)  \right) \\
&  =\left(  a_{i,j}E_{j}\circ\rho\right)  \left(  u_{-}\otimes u_{0}\right)  .
\end{align*}


Now, forget that we fixed $u_{-}$ and $u_{0}$. We thus have proven that%
\[
\left(  \left[  H_{i},E_{j}\right]  \circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right)  =\left(  a_{i,j}E_{j}\circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }u_{-}\in U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \text{ and }u_{0}\in U\left(
\widetilde{\mathfrak{h}}\right)  .
\]
In other words, the two maps $\left[  H_{i},E_{j}\right]  \circ\rho$ and
$a_{i,j}E_{j}\circ\rho$ are equal to each other on each pure tensor in the
tensor product $U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(
\widetilde{\mathfrak{h}}\right)  $. Since these two maps are linear, this
yields that these two maps must be identical (because whenever two linear maps
from a tensor product are equal to each other on each pure tensor, these maps
must be identical). In other words, $\left[  H_{i},E_{j}\right]  \circ
\rho=a_{i,j}E_{j}\circ\rho$. Since we can cancel the $\rho$ from this equation
(because $\rho$ is an isomorphism), this yields $\left[  H_{i},E_{j}\right]
=a_{i,j}E_{j}$.
\end{verlong}

Now forget that we fixed $i$ and $j$. We have thus proven the relation
$\left[  H_{i},E_{j}\right]  =a_{i,j}E_{j}$ for all $i,j\in\left\{
1,2,...,n\right\}  $.

\bigskip

\textit{Proof of the relation }$\left[  H_{i},F_{j}\right]  =-a_{i,j}F_{j}$
\textit{for all }$i,j\in\left\{  1,2,...,n\right\}  $\textit{:}

\begin{vershort}
The proof of the relation $\left[  H_{i},F_{j}\right]  =-a_{i,j}F_{j}$ for all
$i,j\in\left\{  1,2,...,n\right\}  $ is analogous to the above-given proof of
the relation $\left[  H_{i},H_{j}\right]  =0$ for all $i,j\in\left\{
1,2,...,n\right\}  $ (except that this time, instead of using the equality
$\left[  h_{i},h_{j}\right]  =0$ in $\widetilde{\mathfrak{h}}$, need to apply
the equality $\left[  h_{i},f_{j}\right]  =-a_{i,j}f_{j}$ in
$\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}$; the latter
equality is a consequence of (\ref{pf.gtilde.b.semidir.ij})).
\end{vershort}

\begin{verlong}
Let $i$ and $j$ be two elements of $\left\{  1,2,...,n\right\}  $. Every $u\in
U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $
satisfies%
\begin{align*}
\underbrace{\left[  H_{i},F_{j}\right]  }_{=H_{i}\circ F_{j}-F_{j}\circ H_{i}%
}u  &  =\left(  H_{i}\circ F_{j}-F_{j}\circ H_{i}\right)  \left(  u\right)
=H_{i}\underbrace{\left(  F_{j}u\right)  }_{\substack{=f_{j}u\\\text{(by the
definition}\\\text{of }F_{j}\text{)}}}-F_{j}\underbrace{\left(  H_{i}u\right)
}_{\substack{=h_{i}u\\\text{(by the definition}\\\text{of }H_{i}\text{)}}}\\
&  =\underbrace{H_{i}\left(  f_{j}u\right)  }_{\substack{=h_{i}\left(
f_{j}u\right)  \\\text{(by the definition}\\\text{of }H_{i}\text{)}%
}}-\underbrace{F_{j}\left(  h_{i}u\right)  }_{\substack{=f_{j}\left(
h_{i}u\right)  \\\text{(by the definition}\\\text{of }F_{j}\text{)}}}\\
&  =h_{i}\left(  f_{j}u\right)  -f_{j}\left(  h_{i}u\right)
=\underbrace{\left(  h_{i}f_{j}-f_{j}h_{i}\right)  }_{\substack{=\left[
h_{i},f_{j}\right]  =-a_{i,j}f_{j}\\\text{in }U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \\\text{(since
(\ref{pf.gtilde.b.semidir.ij}) yields }\left[  h_{i},f_{j}\right]
=-a_{i,j}f_{j}\text{ in }\widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\text{)}}}u\\
&  =-a_{i,j}f_{j}u
\end{align*}
and $-a_{i,j}F_{j}u=-a_{i,j}f_{j}u$ (because the definition of $F_{j}$ yields
$F_{j}u=f_{j}u$). Thus, every $u\in U\left(  \widetilde{\mathfrak{h}}%
\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ satisfies $\left[  H_{i}%
,F_{j}\right]  u=-a_{i,j}F_{j}u$. Hence, $\left[  H_{i},F_{j}\right]
=-a_{i,j}F_{j}$.

Now forget that we fixed $i$ and $j$. We have thus proven the relation
$\left[  H_{i},F_{j}\right]  =-a_{i,j}F_{j}$ for all $i,j\in\left\{
1,2,...,n\right\}  $.
\end{verlong}

\bigskip

\textit{Proof of the relation }$\left[  E_{i},F_{j}\right]  =\delta_{i,j}%
H_{i}$ \textit{for all }$i,j\in\left\{  1,2,...,n\right\}  $\textit{:}

\begin{vershort}
Let $i$ and $j$ be two elements of $\left\{  1,2,...,n\right\}  $. Let
$u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and $u_{0}\in
U\left(  \widetilde{\mathfrak{h}}\right)  $. Since $f_{j}\in
\widetilde{\mathfrak{n}}_{-}$ and $u_{-}\in U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  $, we have $f_{j}u_{-}\in\widetilde{\mathfrak{n}}_{-}\cdot
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \subseteq U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $. Thus, we can apply
(\ref{pf.gtilde.b.Ei.short}) to $f_{j}u_{-}$ instead of $u_{-}$, and obtain%
\begin{align*}
E_{i}\left(  f_{j}u_{-}u_{0}\right)   &  =\underbrace{\varepsilon_{i}\left(
f_{j}u_{-}\right)  }_{\substack{=\varepsilon_{i}\left(  f_{j}\right)
u_{-}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  \\\text{(since }%
\varepsilon_{i}\text{ is a derivation)}}}u_{0}=\left(  \varepsilon_{i}\left(
f_{j}\right)  u_{-}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  \right)  u_{0}\\
&  =\underbrace{\varepsilon_{i}\left(  f_{j}\right)  }_{\substack{=\delta
_{i,j}h_{i}\\\text{(by the definition of }\varepsilon_{i}\text{)}}}u_{-}%
u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}=\delta_{i,j}h_{i}%
u_{-}u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}.
\end{align*}

\end{vershort}

\begin{verlong}
Let $i$ and $j$ be two elements of $\left\{  1,2,...,n\right\}  $. Let
$u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and $u_{0}\in
U\left(  \widetilde{\mathfrak{h}}\right)  $. Since $f_{j}\in
\widetilde{\mathfrak{n}}_{-}$ and $u_{-}\in U\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  $, we have $f_{j}u_{-}\in\widetilde{\mathfrak{n}}_{-}\cdot
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \subseteq U\left(
\widetilde{\mathfrak{n}}_{-}\right)  $. Thus, we can apply
(\ref{pf.gtilde.b.Ei}) to $f_{j}u_{-}$ instead of $u_{-}$, and obtain%
\begin{align}
E_{i}\left(  f_{j}u_{-}u_{0}\right)   &  =\underbrace{\varepsilon_{i}\left(
f_{j}u_{-}\right)  }_{\substack{=\varepsilon_{i}\left(  f_{j}\right)
u_{-}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  \\\text{(since }%
\varepsilon_{i}\text{ is a derivation)}}}u_{0}=\left(  \varepsilon_{i}\left(
f_{j}\right)  u_{-}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  \right)
u_{0}\nonumber\\
&  =\underbrace{\varepsilon_{i}\left(  f_{j}\right)  }_{\substack{=\delta
_{i,j}h_{i}\\\text{(by (\ref{pf.gtilde.b.epsilon.fj}))}}}u_{-}u_{0}%
+f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}\nonumber\\
&  =\delta_{i,j}h_{i}u_{-}u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)
u_{0}. \label{pf.gtilde.dercomm7}%
\end{align}

\end{verlong}

\begin{vershort}
But%
\begin{align*}
\underbrace{\left[  E_{i},F_{j}\right]  }_{=E_{i}\circ F_{j}-F_{j}\circ E_{i}%
}\left(  u_{-}u_{0}\right)   &  =\left(  E_{i}\circ F_{j}-F_{j}\circ
E_{i}\right)  \left(  u_{-}u_{0}\right) \\
&  =E_{i}\left(  \underbrace{F_{j}\left(  u_{-}u_{0}\right)  }%
_{\substack{=f_{j}u_{-}u_{0}\\\text{(by the definition of }F_{j}\text{)}%
}}\right)  -F_{j}\left(  \underbrace{E_{i}\left(  u_{-}u_{0}\right)
}_{\substack{=\varepsilon_{i}\left(  u_{-}\right)  u_{0}\\\text{(by
(\ref{pf.gtilde.b.Ei.short}))}}}\right) \\
&  =\underbrace{E_{i}\left(  f_{j}u_{-}u_{0}\right)  }_{\substack{=\delta
_{i,j}h_{i}u_{-}u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}%
\\\text{(as we have proven above)}}}-\underbrace{F_{j}\left(  \varepsilon
_{i}\left(  u_{-}\right)  u_{0}\right)  }_{\substack{=f_{j}\varepsilon
_{i}\left(  u_{-}\right)  u_{0}\\\text{(by the definition of }F_{j}\text{)}%
}}\\
&  =\delta_{i,j}h_{i}u_{-}u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)
u_{0}-f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}=\delta_{i,j}h_{i}%
u_{-}u_{0}\\
&  =\delta_{i,j}\underbrace{h_{i}u_{-}u_{0}}_{\substack{=H_{i}\left(
u_{-}u_{0}\right)  \\\text{(since the definition of }H_{i}\text{
yields}\\H_{i}\left(  u_{-}u_{0}\right)  =h_{i}u_{-}u_{0}\text{)}}%
}=\delta_{i,j}H_{i}\left(  u_{-}u_{0}\right)  .
\end{align*}


Now, forget that we fixed $u_{-}$ and $u_{0}$. We thus have proven that%
\[
\left[  E_{i},F_{j}\right]  \left(  u_{-}u_{0}\right)  =\delta_{i,j}%
H_{i}\left(  u_{-}u_{0}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }u_{-}\in
U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \text{ and }u_{0}\in U\left(
\widetilde{\mathfrak{h}}\right)  \text{.}%
\]
Since the vector space $U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ is generated by products $u_{-}u_{0}$
with $u_{-}\in U\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ and $u_{0}\in
U\left(  \widetilde{\mathfrak{h}}\right)  $ (this is because $\rho:U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \otimes U\left(  \widetilde{\mathfrak{h}%
}\right)  \rightarrow U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ is an isomorphism), this yields that
$\left[  E_{i},F_{j}\right]  =\delta_{i,j}H_{i}$.
\end{vershort}

\begin{verlong}
But $\rho\left(  u_{-}\otimes u_{0}\right)  =u_{-}u_{0}$ (by the definition of
$\rho$), and%
\begin{align*}
&  \left(  \left[  E_{i},F_{j}\right]  \circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right) \\
&  =\underbrace{\left[  E_{i},F_{j}\right]  }_{=E_{i}\circ F_{j}-F_{j}\circ
E_{i}}\left(  \underbrace{\rho\left(  u_{-}\otimes u_{0}\right)  }%
_{=u_{-}u_{0}}\right)  =\left(  E_{i}\circ F_{j}-F_{j}\circ E_{i}\right)
\left(  u_{-}u_{0}\right) \\
&  =E_{i}\left(  \underbrace{F_{j}\left(  u_{-}u_{0}\right)  }%
_{\substack{=f_{j}u_{-}u_{0}\\\text{(by the definition of }F_{j}\text{)}%
}}\right)  -F_{j}\left(  \underbrace{E_{i}\left(  u_{-}u_{0}\right)
}_{\substack{=\varepsilon_{i}\left(  u_{-}\right)  u_{0}\\\text{(by
(\ref{pf.gtilde.b.Ei}))}}}\right) \\
&  =\underbrace{E_{i}\left(  f_{j}u_{-}u_{0}\right)  }_{\substack{=\delta
_{i,j}h_{i}u_{-}u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}%
\\\text{(by (\ref{pf.gtilde.dercomm7}))}}}-\underbrace{F_{j}\left(
\varepsilon_{i}\left(  u_{-}\right)  u_{0}\right)  }_{\substack{=f_{j}%
\varepsilon_{i}\left(  u_{-}\right)  u_{0}\\\text{(by the definition of }%
F_{j}\text{)}}}\\
&  =\delta_{i,j}h_{i}u_{-}u_{0}+f_{j}\varepsilon_{i}\left(  u_{-}\right)
u_{0}-f_{j}\varepsilon_{i}\left(  u_{-}\right)  u_{0}=\delta_{i,j}%
h_{i}\underbrace{u_{-}u_{0}}_{=\rho\left(  u_{-}\otimes u_{0}\right)  }\\
&  =\delta_{i,j}\underbrace{h_{i}\rho\left(  u_{-}\otimes u_{0}\right)
}_{\substack{=H_{i}\left(  \rho\left(  u_{-}\otimes u_{0}\right)  \right)
\\\text{(since the definition of }H_{i}\text{ yields}\\H_{i}\left(
\rho\left(  u_{-}\otimes u_{0}\right)  \right)  =h_{i}\rho\left(  u_{-}\otimes
u_{0}\right)  \text{)}}}=\delta_{i,j}H_{i}\left(  \rho\left(  u_{-}\otimes
u_{0}\right)  \right) \\
&  =\left(  \delta_{i,j}H_{i}\circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right)  .
\end{align*}


Now, forget that we fixed $u_{-}$ and $u_{0}$. We thus have proven that%
\[
\left(  \left[  E_{i},F_{j}\right]  \circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right)  =\left(  \delta_{i,j}H_{i}\circ\rho\right)  \left(  u_{-}\otimes
u_{0}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }u_{-}\in U\left(
\widetilde{\mathfrak{n}}_{-}\right)  \text{ and }u_{0}\in U\left(
\widetilde{\mathfrak{h}}\right)  .
\]
In other words, the two maps $\left[  E_{i},F_{j}\right]  \circ\rho$ and
$\delta_{i,j}H_{i}\circ\rho$ are equal to each other on each pure tensor in
the tensor product $U\left(  \widetilde{\mathfrak{n}}_{-}\right)  \otimes
U\left(  \widetilde{\mathfrak{h}}\right)  $. Since these two maps are linear,
this yields that these two maps must be identical (because whenever two linear
maps from a tensor product are equal to each other on each pure tensor, these
maps must be identical). In other words, $\left[  E_{i},F_{j}\right]
\circ\rho=\delta_{i,j}H_{i}\circ\rho$. Since we can cancel the $\rho$ from
this equation (because $\rho$ is an isomorphism), this yields $\left[
E_{i},F_{j}\right]  =\delta_{i,j}H_{i}$.
\end{verlong}

Now forget that we fixed $i$ and $j$. We have thus proven the relation
$\left[  E_{i},F_{j}\right]  =\delta_{i,j}H_{i}$ for all $i,j\in\left\{
1,2,...,n\right\}  $.

\bigskip

Altogether, we have thus verified all four relations (\ref{pf.gtilde.NONSERRE}%
). Now, let us define a Lie algebra homomorphism $\xi^{\prime}%
:\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \rightarrow\operatorname*{End}\left(  U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  $
by the relations%
\[
\left\{
\begin{array}
[c]{c}%
\xi^{\prime}\left(  e_{i}\right)  =E_{i}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\left\{  1,2,...,n\right\}  ;\\
\xi^{\prime}\left(  f_{i}\right)  =F_{i}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\left\{  1,2,...,n\right\}  ;\\
\xi^{\prime}\left(  h_{i}\right)  =H_{i}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\left\{  1,2,...,n\right\}
\end{array}
\right.  .
\]
This $\xi^{\prime}$ is clearly well-defined (because a Lie algebra
homomorphism from a free Lie algebra over a set can be defined by arbitrarily
choosing its values at the elements of this set). This homomorphism
$\xi^{\prime}$ clearly maps the four relations (\ref{nonserre-relations}) to
the four relations (\ref{pf.gtilde.NONSERRE}). Since we know that the four
relations (\ref{pf.gtilde.NONSERRE}) are satisfied in $\operatorname*{End}%
\left(  U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \right)  $, we conclude that the homomorphism $\xi^{\prime}$
factors through the Lie algebra $\operatorname*{FreeLie}\left(  h_{i}%
,f_{i},e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  \diagup\left(
\text{the relations (\ref{nonserre-relations})}\right)
=\widetilde{\mathfrak{g}}$. In other words, there exists a Lie algebra
homomorphism $\xi:\widetilde{\mathfrak{g}}\rightarrow\operatorname*{End}%
\left(  U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}%
_{-}\right)  \right)  $ such that%
\[
\left\{
\begin{array}
[c]{c}%
\xi\left(  e_{i}\right)  =E_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\xi\left(  f_{i}\right)  =F_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\xi\left(  h_{i}\right)  =H_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}
\end{array}
\right.  .
\]
Consider this $\xi$. Clearly, the Lie algebra homomorphism $\xi
:\widetilde{\mathfrak{g}}\rightarrow\operatorname*{End}\left(  U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  $
makes the vector space $U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $ into a $\widetilde{\mathfrak{g}}$-module.

\bigskip

\underline{\textit{6th step: Proving the injectivity of }$\iota_{-}$%
\textit{.}}

We are very close to proving Theorem \ref{thm.gtilde} \textbf{(b)} now.

Let $\xi_{-}$ be the map $\xi\circ\iota_{-}:\widetilde{\mathfrak{n}}%
_{-}\rightarrow\operatorname*{End}\left(  U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  $. Then, $\xi_{-}$ is a
Lie algebra homomorphism (since $\xi$ and $\iota_{-}$ are Lie algebra homomorphisms).

Every $i\in\left\{  1,2,...,n\right\}  $ satisfies $\underbrace{\xi_{-}}%
_{=\xi\circ\iota_{-}}\left(  f_{i}\right)  =\left(  \xi\circ\iota_{-}\right)
\left(  f_{i}\right)  =\xi\left(  \underbrace{\iota_{-}\left(  f_{i}\right)
}_{\substack{=f_{i}\\\text{(by the definition of }\iota_{-}\text{)}}}\right)
=\xi\left(  f_{i}\right)  =F_{i}$ (by the definition of $\xi$).

Let $\mathfrak{s}$ be the subset%
\[
\left\{  s\in\widetilde{\mathfrak{n}}_{-}\ \mid\ \left(  \xi_{-}\left(
s\right)  \right)  \left(  u\right)  =su\text{ for all }u\in U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right\}
\]
of $\widetilde{\mathfrak{n}}_{-}$. Every $i\in\left\{  1,2,...,n\right\}  $
satisfies%
\[
\underbrace{\left(  \xi_{-}\left(  f_{i}\right)  \right)  }_{=F_{i}}\left(
u\right)  =F_{i}\left(  u\right)  =f_{i}u\ \ \ \ \ \ \ \ \ \ \left(  \text{by
the definition of }F_{i}\right)
\]
for all $u\in U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  $, and therefore%
\[
f_{i}\in\left\{  s\in\widetilde{\mathfrak{n}}_{-}\ \mid\ \left(  \xi
_{-}\left(  s\right)  \right)  \left(  u\right)  =su\text{ for all }u\in
U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)
\right\}  =\mathfrak{s}.
\]
In other words, $\mathfrak{s}$ contains the elements $f_{1}$, $f_{2}$, $...$,
$f_{n}$.

\begin{vershort}
On the other hand, it is very easy to see that $\mathfrak{s}$ is a Lie
subalgebra of $\widetilde{\mathfrak{n}}_{-}$. (In fact, all that is needed to
prove this is knowing that $\xi_{-}$ is a Lie algebra homomorphism. The
details are left to the reader.)
\end{vershort}

\begin{verlong}
Now, we will show that $\mathfrak{s}$ is a Lie subalgebra of
$\widetilde{\mathfrak{n}}_{-}$.

\textit{Proof that $\mathfrak{s}$ is a Lie subalgebra of }%
$\widetilde{\mathfrak{n}}_{-}$\textit{:}

The reader can easily verify that $\mathfrak{s}$ is a vector subspace of
$\widetilde{\mathfrak{n}}_{-}$ (because for any fixed $u\in U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $, the
equation $\left(  \xi_{-}\left(  s\right)  \right)  \left(  u\right)  =su$ is
linear in $s$). Now, let $s_{1}\in\mathfrak{s}$ and $s_{2}\in\mathfrak{s}$ be
arbitrary. Then,%
\[
s_{1}\in\mathfrak{s}=\left\{  s\in\widetilde{\mathfrak{n}}_{-}\ \mid\ \left(
\xi_{-}\left(  s\right)  \right)  \left(  u\right)  =su\text{ for all }u\in
U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)
\right\}  ,
\]
so that%
\begin{equation}
\left(  \xi_{-}\left(  s_{1}\right)  \right)  \left(  u\right)  =s_{1}%
u\ \ \ \ \ \ \ \ \ \ \text{for all }u\in U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  . \label{pf.gtilde.b.step6.1}%
\end{equation}
Similarly,%
\begin{equation}
\left(  \xi_{-}\left(  s_{2}\right)  \right)  \left(  u\right)  =s_{2}%
u\ \ \ \ \ \ \ \ \ \ \text{for all }u\in U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  . \label{pf.gtilde.b.step6.2}%
\end{equation}
Now, since $\xi_{-}$ is a Lie algebra homomorphism, we have $\xi_{-}\left(
\left[  s_{1},s_{2}\right]  \right)  =\left[  \xi_{-}\left(  s_{1}\right)
,\xi_{-}\left(  s_{2}\right)  \right]  =\xi_{-}\left(  s_{1}\right)  \circ
\xi_{-}\left(  s_{2}\right)  -\xi_{-}\left(  s_{2}\right)  \circ\xi_{-}\left(
s_{1}\right)  $. Thus, every $u\in U\left(  \widetilde{\mathfrak{h}}%
\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $ satisfies%
\begin{align*}
\left(  \xi_{-}\left(  \left[  s_{1},s_{2}\right]  \right)  \right)  \left(
u\right)   &  =\left(  \xi_{-}\left(  s_{1}\right)  \circ\xi_{-}\left(
s_{2}\right)  -\xi_{-}\left(  s_{2}\right)  \circ\xi_{-}\left(  s_{1}\right)
\right)  \left(  u\right) \\
&  =\left(  \xi_{-}\left(  s_{1}\right)  \right)  \left(  \underbrace{\left(
\xi_{-}\left(  s_{2}\right)  \right)  \left(  u\right)  }_{\substack{=s_{2}%
u\\\text{(by (\ref{pf.gtilde.b.step6.2}))}}}\right)  -\left(  \xi_{-}\left(
s_{2}\right)  \right)  \left(  \underbrace{\left(  \xi_{-}\left(
s_{1}\right)  \right)  \left(  u\right)  }_{\substack{=s_{1}u\\\text{(by
(\ref{pf.gtilde.b.step6.1}))}}}\right) \\
&  =\underbrace{\left(  \xi_{-}\left(  s_{1}\right)  \right)  \left(
s_{2}u\right)  }_{\substack{=s_{1}s_{2}u\\\text{(by (\ref{pf.gtilde.b.step6.1}%
), applied to}\\s_{2}u\text{ instead of }u\text{)}}}-\underbrace{\left(
\xi_{-}\left(  s_{2}\right)  \right)  \left(  s_{1}u\right)  }%
_{\substack{=s_{2}s_{1}u\\\text{(by (\ref{pf.gtilde.b.step6.2}), applied
to}\\s_{1}u\text{ instead of }u\text{)}}}\\
&  =s_{1}s_{2}u-s_{2}s_{1}u=\underbrace{\left(  s_{1}s_{2}-s_{2}s_{1}\right)
}_{=\left[  s_{1},s_{2}\right]  }u=\left[  s_{1},s_{2}\right]  u.
\end{align*}
Hence,%
\[
\left[  s_{1},s_{2}\right]  \in\left\{  s\in\widetilde{\mathfrak{n}}_{-}%
\ \mid\ \left(  \xi_{-}\left(  s\right)  \right)  \left(  u\right)  =su\text{
for all }u\in U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  \right\}  =\mathfrak{s}.
\]
Now, forget that we fixed $s_{1}$ and $s_{2}$. We thus have proven that every
$s_{1}\in\mathfrak{s}$ and $s_{2}\in\mathfrak{s}$ satisfy $\left[  s_{1}%
,s_{2}\right]  \in\mathfrak{s}$. Since $\mathfrak{s}$ is a vector subspace of
$\widetilde{\mathfrak{n}}_{-}$, this yields that $\mathfrak{s}$ is a Lie
subalgebra of $\widetilde{\mathfrak{n}}_{-}$.
\end{verlong}

But now recall that $\widetilde{\mathfrak{n}}_{-}=\operatorname*{FreeLie}%
\left(  f_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  $. Hence, the
elements $f_{1}$, $f_{2}$, $...$, $f_{n}$ generate $\widetilde{\mathfrak{n}%
}_{-}$ as a Lie algebra. Thus, every Lie subalgebra of
$\widetilde{\mathfrak{n}}_{-}$ which contains the elements $f_{1}$, $f_{2}$,
$...$, $f_{n}$ must be $\widetilde{\mathfrak{n}}_{-}$ itself. Since we know
that $\mathfrak{s}$ is a Lie subalgebra of $\widetilde{\mathfrak{n}}_{-}$ and
contains the elements $f_{1}$, $f_{2}$, $...$, $f_{n}$, this yields that
$\mathfrak{s}$ must be $\widetilde{\mathfrak{n}}_{-}$ itself. In other words,
$\mathfrak{s}=\widetilde{\mathfrak{n}}_{-}$.

Now, let $s^{\prime}\in\widetilde{\mathfrak{n}}_{-}$ be such that $\iota
_{-}\left(  s^{\prime}\right)  =0$. Then, $\underbrace{\xi_{-}}_{=\xi
\circ\iota_{-}}\left(  s^{\prime}\right)  =\left(  \xi\circ\iota_{-}\right)
\left(  s^{\prime}\right)  =\xi\left(  \underbrace{\iota_{-}\left(  s^{\prime
}\right)  }_{=0}\right)  =\xi\left(  0\right)  =0$. But since%
\[
s^{\prime}\in\widetilde{\mathfrak{n}}_{-}=\mathfrak{s}=\left\{  s\in
\widetilde{\mathfrak{n}}_{-}\ \mid\ \left(  \xi_{-}\left(  s\right)  \right)
\left(  u\right)  =su\text{ for all }u\in U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right\}  ,
\]
we have $\left(  \xi_{-}\left(  s^{\prime}\right)  \right)  \left(  u\right)
=s^{\prime}u$ for all $u\in U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $. Applied to $u=1$, this yields $\left(
\xi_{-}\left(  s^{\prime}\right)  \right)  \left(  1\right)  =s^{\prime}%
\cdot1=s^{\prime}$. Compared with $\underbrace{\left(  \xi_{-}\left(
s^{\prime}\right)  \right)  }_{=0}\left(  1\right)  =0$, this yields
$s^{\prime}=0$.

Now forget that we fixed $s^{\prime}$. We have thus shown that every
$s^{\prime}\in\widetilde{\mathfrak{n}}_{-}$ such that $\iota_{-}\left(
s^{\prime}\right)  =0$ must satisfy $s^{\prime}=0$. In other words, $\iota
_{-}$ is injective.

\bigskip

\underline{\textit{7th step: Proving the injectivity of }$\iota_{0}$%
\textit{.}}

\begin{vershort}
A similar, but even simpler, argument shows that $\iota_{0}$ is injective.
Again, the reader can fill in the details.
\end{vershort}

\begin{verlong}
The proof of the injectivity of $\iota_{0}$ is similar but even simpler.

Let $\xi_{0}$ be the map $\xi\circ\iota_{0}:\widetilde{\mathfrak{h}%
}\rightarrow\operatorname*{End}\left(  U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right)  $.

Every $i\in\left\{  1,2,...,n\right\}  $ satisfies $\underbrace{\xi_{0}}%
_{=\xi\circ\iota_{0}}\left(  h_{i}\right)  =\left(  \xi\circ\iota_{0}\right)
\left(  h_{i}\right)  =\xi\left(  \underbrace{\iota_{0}\left(  h_{i}\right)
}_{\substack{=h_{i}\\\text{(by the definition of }\iota_{0}\text{)}}}\right)
=\xi\left(  h_{i}\right)  =H_{i}$ (by the definition of $\xi$).

Let $\mathfrak{t}$ be the subset%
\[
\left\{  s\in\widetilde{\mathfrak{h}}\ \mid\ \left(  \xi_{0}\left(  s\right)
\right)  \left(  u\right)  =su\text{ for all }u\in U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right\}
\]
of $\widetilde{\mathfrak{h}}$. Every $i\in\left\{  1,2,...,n\right\}  $
satisfies%
\[
\underbrace{\left(  \xi_{0}\left(  h_{i}\right)  \right)  }_{=H_{i}}\left(
u\right)  =H_{i}\left(  u\right)  =h_{i}u\ \ \ \ \ \ \ \ \ \ \left(  \text{by
the definition of }H_{i}\right)
\]
for all $u\in U\left(  \widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}\right)  $, and therefore%
\[
h_{i}\in\left\{  s\in\widetilde{\mathfrak{h}}\ \mid\ \left(  \xi_{0}\left(
s\right)  \right)  \left(  u\right)  =su\text{ for all }u\in U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right\}
=\mathfrak{t}.
\]
In other words, $\mathfrak{t}$ contains the elements $h_{1}$, $h_{2}$, $...$,
$h_{n}$.

On the other hand, it is easy to see that $\mathfrak{t}$ is a vector subspace
of $\widetilde{\mathfrak{h}}$ (because for any fixed $u\in U\left(
\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  $, the
equation $\left(  \xi_{0}\left(  s\right)  \right)  \left(  u\right)  =su$ is
linear in $s$).

But now recall that $\widetilde{\mathfrak{h}}$ is the free vector space with
basis $h_{1},h_{2},...,h_{n}$. Thus, the elements $h_{1}$, $h_{2}$, $...$,
$h_{n}$ span the vector space $\widetilde{\mathfrak{h}}$. Thus, every vector
subspace of $\widetilde{\mathfrak{h}}$ which contains the elements $h_{1}$,
$h_{2}$, $...$, $h_{n}$ must be $\widetilde{\mathfrak{h}}$ itself. Since we
know that $\mathfrak{t}$ is a vector subspace of $\widetilde{\mathfrak{h}}$
and contains the elements $h_{1}$, $h_{2}$, $...$, $h_{n}$, this yields that
$\mathfrak{t}$ must be $\widetilde{\mathfrak{h}}$ itself. In other words,
$\mathfrak{t}=\widetilde{\mathfrak{h}}$.

Now, let $s^{\prime}\in\widetilde{\mathfrak{h}}$ be such that $\iota
_{0}\left(  s^{\prime}\right)  =0$. Then, $\underbrace{\xi_{0}}_{=\xi
\circ\iota_{0}}\left(  s^{\prime}\right)  =\left(  \xi\circ\iota_{0}\right)
\left(  s^{\prime}\right)  =\xi\left(  \underbrace{\iota_{0}\left(  s^{\prime
}\right)  }_{=0}\right)  =\xi\left(  0\right)  =0$. But since%
\[
s^{\prime}\in\widetilde{\mathfrak{h}}=\mathfrak{t}=\left\{  s\in
\widetilde{\mathfrak{h}}\ \mid\ \left(  \xi_{0}\left(  s\right)  \right)
\left(  u\right)  =su\text{ for all }u\in U\left(  \widetilde{\mathfrak{h}%
}\ltimes\widetilde{\mathfrak{n}}_{-}\right)  \right\}  ,
\]
we have $\left(  \xi_{0}\left(  s^{\prime}\right)  \right)  \left(  u\right)
=s^{\prime}u$ for all $u\in U\left(  \widetilde{\mathfrak{h}}\ltimes
\widetilde{\mathfrak{n}}_{-}\right)  $. Applied to $u=1$, this yields $\left(
\xi_{0}\left(  s^{\prime}\right)  \right)  \left(  1\right)  =s^{\prime}%
\cdot1=s^{\prime}$. Compared with $\underbrace{\left(  \xi_{0}\left(
s^{\prime}\right)  \right)  }_{=0}\left(  1\right)  =0$, this yields
$s^{\prime}=0$.

Now forget that we fixed $s^{\prime}$. We have thus shown that every
$s^{\prime}\in\widetilde{\mathfrak{h}}$ such that $\iota_{0}\left(  s^{\prime
}\right)  =0$ must satisfy $s^{\prime}=0$. In other words, $\iota_{0}$ is injective.
\end{verlong}

\bigskip

\underline{\textit{8th step: Proving the injectivity of }$\iota_{+}$%
\textit{.}}

\begin{vershort}
We have proven the injectivity of the maps $\iota_{-}$ and $\iota_{0}$ above.
The proof of the injectivity of the map $\iota_{+}$ is analogous to the above
proof of the injectivity of the map $\iota_{-}$. (Alternately, the injectivity
of $\iota_{+}$ can be obtained from that of $\iota_{-}$ using the involutive
Lie algebra automorphism constructed in Theorem \ref{thm.gtilde} \textbf{(f)}.)
\end{vershort}

\begin{verlong}
We have proven the injectivity of the maps $\iota_{-}$ and $\iota_{0}$ above.
The proof of the injectivity of the map $\iota_{+}$ is very similar to the
above proof of the injectivity of the map $\iota_{-}$. More precisely, in
order to obtain a proof of the injectivity of the map $\iota_{+}$, it is
enough to apply the following changes to our above proof of the injectivity of
the map $\iota_{-}$:

\begin{itemize}
\item replace every $e_{i}$ by $f_{i}$, and simultaneously replace every
$f_{i}$ by $e_{i}$;

\item replace every $h_{i}$ by $-h_{i}$ (this is allowed since
$\widetilde{\mathfrak{h}}$ is the free vector space with basis $-h_{1}%
,-h_{2},...,-h_{n}$);

\item replace $\widetilde{\mathfrak{n}}_{-}$ by $\widetilde{\mathfrak{n}}_{+}$;

\item replace every reference to (\ref{nonserre-relations}) by a reference to
(\ref{nonserre-relations2}) (this is allowed since we know that the relations
(\ref{nonserre-relations2}) are satisfied in $\widetilde{\mathfrak{g}}$).
\end{itemize}

We have thus proven that the maps $\iota_{+}$, $\iota_{-}$ and $\iota_{0}$ are
injective. Moreover, $\iota_{+}$ and $\iota_{-}$ are Lie algebra homomorphisms
(by definition), and $\iota_{0}$ is a Lie algebra homomorphism as well
(because any $i,j\in\left\{  1,2,...,n\right\}  $ satisfy $\left[  h_{i}%
,h_{j}\right]  =0$ in $\widetilde{\mathfrak{h}}$ (since
$\widetilde{\mathfrak{h}}$ is an abelian Lie algebra) and $\left[  h_{i}%
,h_{j}\right]  =0$ in $\widetilde{\mathfrak{g}}$ (due to the relations
(\ref{nonserre-relations}))). This completes the proof of Theorem
\ref{thm.gtilde} \textbf{(b)}.
\end{verlong}

\bigskip

\textbf{(c)} \underline{\textit{1st step: The existence of the direct sum in
question.}}

Define a relation $\leq$ on $Q$ by positing that two $n$-tuples $\left(
\lambda_{1},\lambda_{2},...,\lambda_{n}\right)  \in\mathbb{Z}^{n}$ and
$\left(  \mu_{1},\mu_{2},...,\mu_{n}\right)  \in\mathbb{Z}^{n}$ satisfy
$\lambda_{1}\alpha_{1}+\lambda_{2}\alpha_{2}+...+\lambda_{n}\alpha_{n}\leq
\mu_{1}\alpha_{1}+\mu_{2}\alpha_{2}+...+\mu_{n}\alpha_{n}$ if and only if
every $i\in\left\{  1,2,...,n\right\}  $ satisfies $\lambda_{i}\leq\mu_{i}$.
It is clear that this relation $\leq$ is a non-strict partial order. Define
$\geq$ to be the opposite of $\leq$. Define $>$ and $<$ to be the strict
versions of the relations $\geq$ and $\leq$, respectively; thus, any
$\alpha\in Q$ and $\beta\in Q$ satisfy $\alpha>\beta$ if and only if $\left(
\alpha\neq\beta\text{ and }\alpha\geq\beta\right)  $.

The elements $\alpha$ of $Q$ satisfying $\alpha>0$ are exactly the nonzero
sums $\lambda_{1}\alpha_{1}+\lambda_{2}\alpha_{2}+...+\lambda_{n}\alpha_{n}$
with $\lambda_{1}$, $\lambda_{2}$, $...$, $\lambda_{n}$ being nonnegative
integers. The elements $\alpha$ of $Q$ satisfying $\alpha<0$ are exactly the
nonzero sums $\lambda_{1}\alpha_{1}+\lambda_{2}\alpha_{2}+...+\lambda
_{n}\alpha_{n}$ with $\lambda_{1}$, $\lambda_{2}$, $...$, $\lambda_{n}$ being
nonpositive integers.

Let $\widetilde{\mathfrak{g}}\left[  <0\right]  =\bigoplus
\limits_{\substack{\alpha\in Q;\\\alpha<0}}\widetilde{\mathfrak{g}}\left[
\alpha\right]  $ and $\widetilde{\mathfrak{g}}\left[  >0\right]
=\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha>0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]  $. Then, $\widetilde{\mathfrak{g}}\left[  0\right]  $,
$\widetilde{\mathfrak{g}}\left[  <0\right]  $ and $\widetilde{\mathfrak{g}%
}\left[  >0\right]  $ are $Q$-graded Lie subalgebras of
$\widetilde{\mathfrak{g}}$ (this is easy to see from the fact that
$\widetilde{\mathfrak{g}}$ is a $Q$-graded Lie algebra).

It is easy to see that the (internal) direct sum $\widetilde{\mathfrak{g}%
}\left[  >0\right]  \oplus\widetilde{\mathfrak{g}}\left[  <0\right]
\oplus\widetilde{\mathfrak{g}}\left[  0\right]  $ is
well-defined.\footnote{\textit{Proof.} We have $\widetilde{\mathfrak{g}%
}=\bigoplus\limits_{\alpha\in Q}\widetilde{\mathfrak{g}}\left[  \alpha\right]
$ (since $\widetilde{\mathfrak{g}}$ is $Q$-graded). But every $\alpha\in Q$
satisfies \textbf{exactly one} of the four assertions $\alpha>0$, $\alpha<0$,
$\alpha=0$ and $\left(  \text{neither }\alpha<0\text{ nor }\alpha>0\text{ nor
}\alpha=0\right)  $. Thus,%
\begin{align*}
\bigoplus\limits_{\alpha\in Q}\widetilde{\mathfrak{g}}\left[  \alpha\right]
&  =\underbrace{\left(  \bigoplus\limits_{\substack{\alpha\in Q;\\\alpha
>0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  \right)  }%
_{=\widetilde{\mathfrak{g}}\left[  >0\right]  }\oplus\underbrace{\left(
\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha<0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]  \right)  }_{=\widetilde{\mathfrak{g}}\left[
<0\right]  }\oplus\underbrace{\left(  \bigoplus\limits_{\substack{\alpha\in
Q;\\\alpha=0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  \right)
}_{=\widetilde{\mathfrak{g}}\left[  0\right]  }\oplus\left(  \bigoplus
\limits_{\substack{\alpha\in Q;\\\text{neither }\alpha<0\\\text{nor }%
\alpha>0\text{ nor }\alpha=0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]
\right) \\
&  =\widetilde{\mathfrak{g}}\left[  >0\right]  \oplus\widetilde{\mathfrak{g}%
}\left[  <0\right]  \oplus\widetilde{\mathfrak{g}}\left[  0\right]
\oplus\left(  \bigoplus\limits_{\substack{\alpha\in Q;\\\text{neither }%
\alpha<0\\\text{nor }\alpha>0\text{ nor }\alpha=0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]  \right)  .
\end{align*}
Thus, the (internal) direct sum $\widetilde{\mathfrak{g}}\left[  >0\right]
\oplus\widetilde{\mathfrak{g}}\left[  <0\right]  \oplus\widetilde{\mathfrak{g}%
}\left[  0\right]  $ is well-defined (because it is a partial sum of the
direct sum $\widetilde{\mathfrak{g}}\left[  >0\right]  \oplus
\widetilde{\mathfrak{g}}\left[  <0\right]  \oplus\widetilde{\mathfrak{g}%
}\left[  0\right]  \oplus\left(  \bigoplus\limits_{\substack{\alpha\in
Q;\\\text{neither }\alpha<0\\\text{nor }\alpha>0\text{ nor }\alpha
=0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  \right)  $).}

Every $i\in\left\{  1,2,...,n\right\}  $ satisfies
\begin{align*}
f_{i}  &  \in\widetilde{\mathfrak{g}}\left[  -\alpha_{i}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\deg\left(  f_{i}\right)
=-\alpha_{i}\right) \\
&  \subseteq\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha<0}%
}\widetilde{\mathfrak{g}}\left[  \alpha\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }-\alpha_{i}<0\right) \\
&  =\widetilde{\mathfrak{g}}\left[  <0\right]  .
\end{align*}
Hence, the Lie algebra $\widetilde{\mathfrak{g}}\left[  <0\right]  $ contains
the elements $f_{1}$, $f_{2}$, $...$, $f_{n}$. But now, recall that
$\widetilde{\mathfrak{n}}_{-}=\operatorname*{FreeLie}\left(  f_{i}\ \mid
\ i\in\left\{  1,2,...,n\right\}  \right)  $. Hence, the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{n}}_{-}$ generate
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra. Thus, the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{g}}$ generate $\iota
_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  $ as a Lie algebra (because
the elements $f_{1}$, $f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{g}}$
are the images of the elements $f_{1}$, $f_{2}$, $...$, $f_{n}$ of
$\widetilde{\mathfrak{n}}_{-}$ under the map $\iota_{-}$). Thus, every Lie
subalgebra of $\widetilde{\mathfrak{g}}$ which contains the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ must contain $\iota_{-}\left(  \widetilde{\mathfrak{n}%
}_{-}\right)  $ as a subset. Since we know that $\widetilde{\mathfrak{g}%
}\left[  <0\right]  $ is a Lie subalgebra of $\widetilde{\mathfrak{g}}$ and
contains the elements $f_{1}$, $f_{2}$, $...$, $f_{n}$, this yields that
$\widetilde{\mathfrak{g}}\left[  <0\right]  $ must contain $\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  $ as a subset. In other words, $\iota
_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  \subseteq
\widetilde{\mathfrak{g}}\left[  <0\right]  $. Similarly (by considering the
elements $e_{1}$, $e_{2}$, $...$, $e_{n}$ instead of $f_{1}$, $f_{2}$, $...$,
$f_{n}$), we can show $\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
\subseteq\widetilde{\mathfrak{g}}\left[  >0\right]  $.

\begin{vershort}
A similar argument proves $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
\subseteq\widetilde{\mathfrak{g}}\left[  0\right]  $.
\end{vershort}

\begin{verlong}
Finally, every $i\in\left\{  1,2,...,n\right\}  $ satisfies $h_{i}%
\in\widetilde{\mathfrak{g}}\left[  0\right]  $ (since $\deg\left(
h_{i}\right)  =0$). In other words, the vector space $\widetilde{\mathfrak{g}%
}\left[  0\right]  $ contains the elements $h_{1}$, $h_{2}$, $...$, $h_{n}$.

But now, recall that $\widetilde{\mathfrak{h}}$ is the free vector space with
basis $h_{1},h_{2},...,h_{n}$. Thus, the elements $h_{1}$, $h_{2}$, $...$,
$h_{n}$ of $\widetilde{\mathfrak{h}}$ span the vector space
$\widetilde{\mathfrak{h}}$. Consequently, the elements $h_{1}$, $h_{2}$,
$...$, $h_{n}$ of $\widetilde{\mathfrak{g}}$ span the vector space $\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ (because the elements $h_{1}$,
$h_{2}$, $...$, $h_{n}$ of $\widetilde{\mathfrak{g}}$ are the images of the
elements $h_{1}$, $h_{2}$, $...$, $h_{n}$ of $\widetilde{\mathfrak{h}}$ under
the map $\iota_{0}$). Hence, every vector subspace of $\widetilde{\mathfrak{g}%
}$ which contains the elements $h_{1}$, $h_{2}$, $...$, $h_{n}$ must contain
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ as a subset. Since we
know that $\widetilde{\mathfrak{g}}\left[  0\right]  $ is a vector subspace of
$\widetilde{\mathfrak{g}}$ and contains the elements $h_{1}$, $h_{2}$, $...$,
$h_{n}$, this yields that $\widetilde{\mathfrak{g}}\left[  0\right]  $ must
contain $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ as a subset. In
other words, $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  \subseteq
\widetilde{\mathfrak{g}}\left[  0\right]  $.
\end{verlong}

Since the internal direct sum $\widetilde{\mathfrak{g}}\left[  <0\right]
\oplus\widetilde{\mathfrak{g}}\left[  >0\right]  \oplus\widetilde{\mathfrak{g}%
}\left[  0\right]  $ is well-defined, the internal direct sum $\iota
_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)  \oplus\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ must also be well-defined (because
$\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)  \subseteq
\widetilde{\mathfrak{g}}\left[  >0\right]  $, $\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \subseteq\widetilde{\mathfrak{g}}\left[
<0\right]  $ and $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
\subseteq\widetilde{\mathfrak{g}}\left[  0\right]  $). We now must prove that
this direct sum is $\widetilde{\mathfrak{g}}$.

\bigskip

\underline{\textit{2nd step: Identifications.}}

Since the maps $\iota_{+}$, $\iota_{-}$ and $\iota_{0}$ are injective Lie
algebra homomorphisms, and since their images are linearly disjoint (because
the direct sum $\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
\oplus\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ is well-defined), we can regard
these maps $\iota_{+}$, $\iota_{-}$ and $\iota_{0}$ as inclusions of Lie
algebras. Let us do this from now on. Thus, $\widetilde{\mathfrak{n}}_{+}$,
$\widetilde{\mathfrak{n}}_{-}$ and $\widetilde{\mathfrak{h}}$ are Lie
subalgebras of $\widetilde{\mathfrak{g}}$. The identification of
$\widetilde{\mathfrak{n}}_{-}$ with the Lie subalgebra $\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  $ of $\widetilde{\mathfrak{g}}$
eliminates the need of distinguishing between the elements $f_{i}$ of
$\widetilde{\mathfrak{n}}_{-}$ and the elements $f_{i}$ of
$\widetilde{\mathfrak{g}}$ (because for every $i\in\left\{  1,2,...,n\right\}
$, the element $f_{i}$ of $\widetilde{\mathfrak{g}}$ is the image of the
element $f_{i}$ of $\widetilde{\mathfrak{n}}_{-}$ under the map $\iota_{-}$,
and since we regard this map $\iota_{-}$ as inclusion, these two elements
$f_{i}$ are therefore equal). Similarly, we don't have to distinguish between
the elements $e_{i}$ of $\widetilde{\mathfrak{n}}_{+}$ and the elements
$e_{i}$ of $\widetilde{\mathfrak{g}}$, nor is it necessary to distinguish
between the elements $h_{i}$ of $\widetilde{\mathfrak{h}}$ and the elements
$h_{i}$ of $\widetilde{\mathfrak{g}}$.

Since we regard the maps $\iota_{+}$, $\iota_{-}$ and $\iota_{0}$ as
inclusions, we have $\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
=\widetilde{\mathfrak{n}}_{+}$, $\iota_{-}\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  =\widetilde{\mathfrak{n}}_{-}$ and $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{h}}$. Hence, $\iota
_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)  \oplus\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{n}}_{+}\oplus
\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$. This shows that
the internal direct sums $\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}$ and $\widetilde{\mathfrak{n}}_{+}\oplus
\widetilde{\mathfrak{h}}$ are well-defined (since they are partial sums of the
direct sum $\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}$).

\bigskip

\underline{\textit{3rd step: Proving that }$\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}$\textit{ is a Lie subalgebra of }%
$\widetilde{\mathfrak{g}}$\textit{.}}

We now will prove part \textbf{(d)} of Theorem \ref{thm.gtilde} before we come
back and finish the proof of part \textbf{(c)}.

\begin{vershort}
Indeed, let us first prove that $\left[  \widetilde{\mathfrak{h}%
},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq\widetilde{\mathfrak{n}}_{-}$.

In fact, in order to prove this, it is enough to show that $\left[
h_{i},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq\widetilde{\mathfrak{n}%
}_{-}$ for every $i\in\left\{  1,2,...,n\right\}  $ (since the elements
$h_{1}$, $h_{2}$, $...$, $h_{n}$ of $\widetilde{\mathfrak{h}}$ span the vector
space $\widetilde{\mathfrak{h}}$). So let $i\in\left\{  1,2,...,n\right\}  $.
Let $\xi_{i}:\widetilde{\mathfrak{g}}\rightarrow\widetilde{\mathfrak{g}}$ be
the map defined by%
\[
\left(  \xi_{i}\left(  x\right)  =\left[  h_{i},x\right]
\ \ \ \ \ \ \ \ \ \ \text{for any }x\in\widetilde{\mathfrak{g}}\right)  .
\]
Then, $\xi_{i}$ is a Lie derivation of the Lie algebra
$\widetilde{\mathfrak{g}}$. On the other hand, the subset $\left\{
f_{1},f_{2},...,f_{n}\right\}  $ of $\widetilde{\mathfrak{n}}_{-}$ generates
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra (since the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{n}}_{-}$ generate
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra), and we can easily check that
$\xi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)
\subseteq\widetilde{\mathfrak{n}}_{-}$\ \ \ \ \footnote{\textit{Proof.} For
every $j\in\left\{  1,2,...,n\right\}  $, we have%
\begin{align*}
\xi_{i}\left(  f_{j}\right)   &  =\left[  h_{i},f_{j}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\xi_{i}\right) \\
&  =-a_{i,j}\underbrace{f_{j}}_{\in\widetilde{\mathfrak{n}}_{-}}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the relations (\ref{nonserre-relations}%
)}\right) \\
&  \in-a_{i,j}\widetilde{\mathfrak{n}}_{-}\subseteq\widetilde{\mathfrak{n}%
}_{-}.
\end{align*}
Thus, $\xi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)
\subseteq\widetilde{\mathfrak{n}}_{-}$, qed.}. Hence, Corollary
\ref{cor.derivation.Lie.unique.ihg} (applied to $\widetilde{\mathfrak{g}}$,
$\widetilde{\mathfrak{n}}_{-}$, $\widetilde{\mathfrak{n}}_{-}$, $\xi_{i}$ and
$\left\{  f_{1},f_{2},...,f_{n}\right\}  $ instead of $\mathfrak{g}$,
$\mathfrak{h}$, $\mathfrak{i}$, $d$ and $S$) yields that $\xi_{i}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \subseteq\widetilde{\mathfrak{n}}_{-}$.
But by the definition of $\xi_{i}$, we have $\xi_{i}\left(
\widetilde{\mathfrak{n}}_{-}\right)  =\left[  h_{i},\widetilde{\mathfrak{n}%
}_{-}\right]  $. Hence, $\left[  h_{i},\widetilde{\mathfrak{n}}_{-}\right]
=\xi_{i}\left(  \widetilde{\mathfrak{n}}_{-}\right)  \subseteq
\widetilde{\mathfrak{n}}_{-}$. Now forget that we fixed $i$. We thus have
proven that $\left[  h_{i},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq
\widetilde{\mathfrak{n}}_{-}$ for every $i\in\left\{  1,2,...,n\right\}  $. As
explained above, this yields $\left[  \widetilde{\mathfrak{h}}%
,\widetilde{\mathfrak{n}}_{-}\right]  \subseteq\widetilde{\mathfrak{n}}_{-}$.
\end{vershort}

\begin{verlong}
Indeed, we know that both $\widetilde{\mathfrak{n}}_{-}$ and
$\widetilde{\mathfrak{h}}$ are Lie subalgebras of $\widetilde{\mathfrak{g}}$.
Thus, $\left[  \widetilde{\mathfrak{n}}_{-},\widetilde{\mathfrak{n}}%
_{-}\right]  \subseteq\widetilde{\mathfrak{n}}_{-}$ and $\left[
\widetilde{\mathfrak{h}},\widetilde{\mathfrak{h}}\right]  \subseteq
\widetilde{\mathfrak{h}}$. We will now show that $\left[
\widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq
\widetilde{\mathfrak{n}}_{-}$.

\textit{Proof of }$\left[  \widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}%
}_{-}\right]  \subseteq\widetilde{\mathfrak{n}}_{-}$\textit{:}

Let $i\in\left\{  1,2,...,n\right\}  $. Let $\xi_{i}:\widetilde{\mathfrak{g}%
}\rightarrow\widetilde{\mathfrak{g}}$ be the map defined by%
\[
\left(  \xi_{i}\left(  x\right)  =\left[  h_{i},x\right]
\ \ \ \ \ \ \ \ \ \ \text{for any }x\in\widetilde{\mathfrak{g}}\right)  .
\]
Then, $\xi_{i}$ is a Lie derivation of the Lie algebra
$\widetilde{\mathfrak{g}}$. On the other hand, the subset $\left\{
f_{1},f_{2},...,f_{n}\right\}  $ of $\widetilde{\mathfrak{n}}_{-}$ generates
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra (since the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{n}}_{-}$ generate
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra), and we can easily check that
$\xi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)
\subseteq\widetilde{\mathfrak{n}}_{-}$\ \ \ \ \footnote{\textit{Proof.} For
every $j\in\left\{  1,2,...,n\right\}  $, we have%
\begin{align*}
\xi_{i}\left(  f_{j}\right)   &  =\left[  h_{i},f_{j}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\xi_{i}\right) \\
&  =-a_{i,j}\underbrace{f_{j}}_{\in\widetilde{\mathfrak{n}}_{-}}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the relations (\ref{nonserre-relations}%
)}\right) \\
&  \in-a_{i,j}\widetilde{\mathfrak{n}}_{-}\subseteq\widetilde{\mathfrak{n}%
}_{-}.
\end{align*}
Thus, $\left\{  \xi_{i}\left(  f_{1}\right)  ,\xi_{i}\left(  f_{2}\right)
,...,\xi_{i}\left(  f_{n}\right)  \right\}  \subseteq\widetilde{\mathfrak{n}%
}_{-}$. Since $\left\{  \xi_{i}\left(  f_{1}\right)  ,\xi_{i}\left(
f_{2}\right)  ,...,\xi_{i}\left(  f_{n}\right)  \right\}  =\xi_{i}\left(
\left\{  f_{1},f_{2},...,f_{n}\right\}  \right)  $, this rewrites as $\xi
_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)  \subseteq
\widetilde{\mathfrak{n}}_{-}$, qed.}. Hence, Corollary
\ref{cor.derivation.Lie.unique.ihg} (applied to $\widetilde{\mathfrak{g}}$,
$\widetilde{\mathfrak{n}}_{-}$, $\widetilde{\mathfrak{n}}_{-}$, $\xi_{i}$ and
$\left\{  f_{1},f_{2},...,f_{n}\right\}  $ instead of $\mathfrak{g}$,
$\mathfrak{h}$, $\mathfrak{i}$, $d$ and $S$) yields that $\xi_{i}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \subseteq\widetilde{\mathfrak{n}}_{-}$.
But%
\begin{align*}
\xi_{i}\left(  \widetilde{\mathfrak{n}}_{-}\right)   &  =\left\{
\underbrace{\xi_{i}\left(  x\right)  }_{=\left[  h_{i},x\right]  }\mid
x\in\widetilde{\mathfrak{n}}_{-}\right\}  =\left\{  \left[  h_{i},x\right]
\mid x\in\widetilde{\mathfrak{n}}_{-}\right\}  =\left[  h_{i}%
,\widetilde{\mathfrak{n}}_{-}\right]  =\left[  h_{i},\widetilde{\mathfrak{n}%
}_{-}\right]  \mathbb{C}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left[  h_{i}%
,\widetilde{\mathfrak{n}}_{-}\right]  \text{ is a vector space}\right) \\
&  =\left[  h_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since the Lie bracket is bilinear}\right)  .
\end{align*}
Thus, $\left[  h_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\subseteq\widetilde{\mathfrak{n}}_{-}$. Now, forget that we fixed $i$. We thus
have shown that $\left[  h_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\subseteq\widetilde{\mathfrak{n}}_{-}$ for every $i\in\left\{
1,2,...,n\right\}  $.

But the elements $h_{1}$, $h_{2}$, $...$, $h_{n}$ of $\widetilde{\mathfrak{h}%
}$ span the vector space $\widetilde{\mathfrak{h}}$. Thus,
$\widetilde{\mathfrak{h}}=\sum\limits_{i=1}^{n}\left(  h_{i}\mathbb{C}\right)
$, so that%
\begin{align*}
\left[  \widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}_{-}\right]   &
=\left[  \sum\limits_{i=1}^{n}\left(  h_{i}\mathbb{C}\right)
,\ \widetilde{\mathfrak{n}}_{-}\right]  =\sum\limits_{i=1}^{n}%
\underbrace{\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]
}_{\subseteq\widetilde{\mathfrak{n}}_{-}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since the Lie bracket is bilinear}\right) \\
&  \subseteq\sum\limits_{i=1}^{n}\widetilde{\mathfrak{n}}_{-}\subseteq
\widetilde{\mathfrak{n}}_{-}.
\end{align*}
This proves $\left[  \widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}%
_{-}\right]  \subseteq\widetilde{\mathfrak{n}}_{-}$.
\end{verlong}

\begin{vershort}
Now, $\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}%
=\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}$, so that%
\begin{align*}
\left[  \widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}%
},\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}\right]   &
=\left[  \widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}%
,\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}\right] \\
&  =\underbrace{\left[  \widetilde{\mathfrak{n}}_{-},\widetilde{\mathfrak{n}%
}_{-}\right]  }_{\substack{\subseteq\widetilde{\mathfrak{n}}_{-}\\\text{(since
}\widetilde{\mathfrak{n}}_{-}\text{ is a Lie algebra)}}}+\underbrace{\left[
\widetilde{\mathfrak{n}}_{-},\widetilde{\mathfrak{h}}\right]  }_{=-\left[
\widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq\left[
\widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq
\widetilde{\mathfrak{n}}_{-}}+\underbrace{\left[  \widetilde{\mathfrak{h}%
},\widetilde{\mathfrak{n}}_{-}\right]  }_{\subseteq\widetilde{\mathfrak{n}%
}_{-}}+\underbrace{\left[  \widetilde{\mathfrak{h}},\widetilde{\mathfrak{h}%
}\right]  }_{\substack{\subseteq\widetilde{\mathfrak{h}}\\\text{(since
}\widetilde{\mathfrak{h}}\text{ is a Lie algebra)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the Lie bracket is bilinear}\right)
\\
&  \subseteq\underbrace{\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{n}%
}_{-}+\widetilde{\mathfrak{n}}_{-}}_{\subseteq\widetilde{\mathfrak{n}}_{-}%
}+\widetilde{\mathfrak{h}}\subseteq\widetilde{\mathfrak{n}}_{-}%
+\widetilde{\mathfrak{h}}=\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}.
\end{align*}
Thus, $\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$ is a Lie
subalgebra of $\widetilde{\mathfrak{g}}$.
\end{vershort}

\begin{verlong}
Now, $\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}%
=\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}$ (since direct sums are
sums), so that
\begin{align*}
\left[  \widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}%
},\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}\right]   &
=\left[  \widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}%
,\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}\right]
=\underbrace{\left[  \widetilde{\mathfrak{n}}_{-},\widetilde{\mathfrak{n}}%
_{-}\right]  }_{\subseteq\widetilde{\mathfrak{n}}_{-}}+\underbrace{\left[
\widetilde{\mathfrak{n}}_{-},\widetilde{\mathfrak{h}}\right]  }_{=-\left[
\widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq\left[
\widetilde{\mathfrak{h}},\widetilde{\mathfrak{n}}_{-}\right]  \subseteq
\widetilde{\mathfrak{n}}_{-}}+\underbrace{\left[  \widetilde{\mathfrak{h}%
},\widetilde{\mathfrak{n}}_{-}\right]  }_{\subseteq\widetilde{\mathfrak{n}%
}_{-}}+\underbrace{\left[  \widetilde{\mathfrak{h}},\widetilde{\mathfrak{h}%
}\right]  }_{\subseteq\widetilde{\mathfrak{h}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the Lie bracket is bilinear}\right)
\\
&  \subseteq\underbrace{\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{n}%
}_{-}+\widetilde{\mathfrak{n}}_{-}}_{\subseteq\widetilde{\mathfrak{n}}_{-}%
}+\widetilde{\mathfrak{h}}\subseteq\widetilde{\mathfrak{n}}_{-}%
+\widetilde{\mathfrak{h}}=\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}.
\end{align*}
Thus, $\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$ is a Lie
subalgebra of $\widetilde{\mathfrak{g}}$.
\end{verlong}

(Note that the map $\left(  \iota_{-},\iota_{0}\right)
:\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}\rightarrow
\widetilde{\mathfrak{g}}$ is actually a Lie algebra isomorphism from the
semidirect product $\widetilde{\mathfrak{h}}\ltimes\widetilde{\mathfrak{n}%
}_{-}$ (which was constructed during our proof of Theorem \ref{thm.gtilde}
\textbf{(b)}) to $\widetilde{\mathfrak{g}}$. But we will not need this fact,
so we will not prove it either.)

So we have shown that $\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}$ is a Lie subalgebra of $\widetilde{\mathfrak{g}}$. A
similar argument (but with $\widetilde{\mathfrak{n}}_{-}$ replaced by
$\widetilde{\mathfrak{n}}_{+}$, and with $f_{j}$ replaced by $e_{j}$, and with
$-a_{i,j}$ replaced by $a_{i,j}$) shows that $\widetilde{\mathfrak{n}}%
_{+}\oplus\widetilde{\mathfrak{h}}$ is a Lie subalgebra of
$\widetilde{\mathfrak{g}}$.

We now know that $\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$
and $\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}$ are Lie
subalgebras of $\widetilde{\mathfrak{g}}$. Since $\widetilde{\mathfrak{n}}%
_{-}=\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  $,
$\widetilde{\mathfrak{n}}_{+}=\iota_{+}\left(  \widetilde{\mathfrak{n}}%
_{+}\right)  $ and $\widetilde{\mathfrak{h}}=\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, this rewrites as follows: $\iota
_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ and $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ are Lie subalgebras of
$\widetilde{\mathfrak{g}}$. This proves Theorem \ref{thm.gtilde} \textbf{(d)}.

\bigskip

\underline{\textit{4th step: Finishing the proof of Theorem \ref{thm.gtilde}
\textbf{(c)}.}}

We know that the internal direct sum $\widetilde{\mathfrak{n}}_{+}%
\oplus\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$ makes sense.
Denote this direct sum $\widetilde{\mathfrak{n}}_{+}\oplus
\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$ as $V$. We know
that $V$ is a vector subspace of $\widetilde{\mathfrak{g}}$. We need to prove
that $V=\widetilde{\mathfrak{g}}$.

\begin{vershort}
Let $N$ be the vector subspace of $\widetilde{\mathfrak{g}}$ spanned by the
$3n$ elements $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$. Then, $\widetilde{\mathfrak{g}}$ is
generated by $N$ as a Lie algebra (because the elements $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$ generate $\widetilde{\mathfrak{g}}$ as a Lie algebra).
\end{vershort}

\begin{verlong}
Let $N$ be the vector subspace of $\widetilde{\mathfrak{g}}$ spanned by the
$3n$ elements $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$,
$f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$. Then, $\widetilde{\mathfrak{g}}$ is
generated by $N$ as a Lie algebra (because the elements $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$ generate $\widetilde{\mathfrak{g}}$ as a Lie algebra\footnote{This is
because $\widetilde{\mathfrak{g}}=\operatorname*{FreeLie}\left(  h_{i}%
,f_{i},e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  \diagup\left(
\text{the relations (\ref{nonserre-relations})}\right)  $.}).
\end{verlong}

We will now prove that $\left[  N,V\right]  \subseteq V$.

Indeed, since $N=\sum\limits_{i=1}^{n}\left(  e_{i}\mathbb{C}\right)
+\sum\limits_{i=1}^{n}\left(  f_{i}\mathbb{C}\right)  +\sum\limits_{i=1}%
^{n}\left(  h_{i}\mathbb{C}\right)  $ (because $N$ is the vector subspace of
$\widetilde{\mathfrak{g}}$ spanned by the $3n$ elements $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$) and $V=\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}=\widetilde{\mathfrak{n}}_{+}%
+\widetilde{\mathfrak{n}}_{-}+\widetilde{\mathfrak{h}}$ (since direct sums are
sums), we have%
\begin{align}
\left[  N,V\right]   &  =\left[  \sum\limits_{i=1}^{n}\left(  e_{i}%
\mathbb{C}\right)  +\sum\limits_{i=1}^{n}\left(  f_{i}\mathbb{C}\right)
+\sum\limits_{i=1}^{n}\left(  h_{i}\mathbb{C}\right)
,\ \widetilde{\mathfrak{n}}_{+}+\widetilde{\mathfrak{n}}_{-}%
+\widetilde{\mathfrak{h}}\right] \nonumber\\
&  \subseteq\sum\limits_{i=1}^{n}\left[  e_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{+}\right]  +\sum\limits_{i=1}^{n}\left[
e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  +\sum\limits_{i=1}%
^{n}\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right] \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{i=1}^{n}\left[  f_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{+}\right]  +\sum\limits_{i=1}^{n}\left[
f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  +\sum\limits_{i=1}%
^{n}\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right] \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{i=1}^{n}\left[  h_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{+}\right]  +\sum\limits_{i=1}^{n}\left[
h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  +\sum\limits_{i=1}%
^{n}\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]
\label{pf.gtilde.c.1}%
\end{align}
(since the Lie bracket is bilinear).

We will now prove that each summand of each of the nine sums on the right hand
side of (\ref{pf.gtilde.c.1}) is $\subseteq V$.

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq
V$\textit{:}

For every $i\in\left\{  1,2,...,n\right\}  $, we have $e_{i}\in
\widetilde{\mathfrak{n}}_{+}$ and thus $e_{i}\mathbb{C}\subseteq
\widetilde{\mathfrak{n}}_{+}$, so that%
\begin{align*}
\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]   &
\subseteq\left[  \widetilde{\mathfrak{n}}_{+},\ \widetilde{\mathfrak{n}}%
_{+}\right]  \subseteq\widetilde{\mathfrak{n}}_{+}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }\widetilde{\mathfrak{n}}_{+}\text{ is a Lie algebra}\right) \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}+\widetilde{\mathfrak{n}}%
_{-}+\widetilde{\mathfrak{h}}=V.
\end{align*}
We have thus proven that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq V$.

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq
V$\textit{:}

\begin{vershort}
Let $i\in\left\{  1,2,...,n\right\}  $. Define a map $\psi_{i}%
:\widetilde{\mathfrak{g}}\rightarrow\widetilde{\mathfrak{g}}$ by%
\[
\left(  \psi_{i}\left(  x\right)  =\left[  e_{i},x\right]
\ \ \ \ \ \ \ \ \ \ \text{for every }x\in\widetilde{\mathfrak{g}}\right)  .
\]
Then, $\psi_{i}$ is a Lie derivation of the Lie algebra
$\widetilde{\mathfrak{g}}$. On the other hand, the subset $\left\{
f_{1},f_{2},...,f_{n}\right\}  $ of $\widetilde{\mathfrak{n}}_{-}$ generates
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra (since the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{n}}_{-}$ generate
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra), and we can easily check that
$\psi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)
\subseteq\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}%
$\ \ \ \ \footnote{\textit{Proof.} For every $j\in\left\{  1,2,...,n\right\}
$, we have%
\begin{align*}
\psi_{i}\left(  f_{j}\right)   &  =\left[  e_{i},f_{j}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\psi_{i}\right) \\
&  =\delta_{i,j}\underbrace{h_{i}}_{\in\widetilde{\mathfrak{h}}}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the relations (\ref{nonserre-relations}%
)}\right) \\
&  \in\widetilde{\mathfrak{h}}\subseteq\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}.
\end{align*}
Thus, $\psi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)
\subseteq\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$, qed.}.
Hence, Corollary \ref{cor.derivation.Lie.unique.ihg} (applied to
$\widetilde{\mathfrak{g}}$, $\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}$, $\widetilde{\mathfrak{n}}_{-}$, $\psi_{i}$ and
$\left\{  f_{1},f_{2},...,f_{n}\right\}  $ instead of $\mathfrak{g}$,
$\mathfrak{h}$, $\mathfrak{i}$, $d$ and $S$) yields that $\psi_{i}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \subseteq\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}$ (since $\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}$ is a Lie subalgebra of
$\widetilde{\mathfrak{g}}$). But by the definition of $\psi_{i}$, we have%
\begin{align*}
\psi_{i}\left(  \widetilde{\mathfrak{n}}_{-}\right)   &  =\left[
e_{i},\widetilde{\mathfrak{n}}_{-}\right]  =\left[  e_{i}%
,\widetilde{\mathfrak{n}}_{-}\right]  \mathbb{C}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }\left[  e_{i},\widetilde{\mathfrak{n}}_{-}\right]  \text{ is a
vector space}\right) \\
&  =\left[  e_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since the Lie bracket is bilinear}\right)  .
\end{align*}
Thus, $\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]
\subseteq\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}%
\subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}=V$. Now, forget that we fixed $i$. We thus have
shown that $\left[  e_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\subseteq V$ for every $i\in\left\{  1,2,...,n\right\}  $.
\end{vershort}

\begin{verlong}
Let $i\in\left\{  1,2,...,n\right\}  $. Define a map $\psi_{i}%
:\widetilde{\mathfrak{g}}\rightarrow\widetilde{\mathfrak{g}}$ by%
\[
\left(  \psi_{i}\left(  x\right)  =\left[  e_{i},x\right]
\ \ \ \ \ \ \ \ \ \ \text{for every }x\in\widetilde{\mathfrak{g}}\right)  .
\]
Then, $\psi_{i}$ is a Lie derivation of the Lie algebra
$\widetilde{\mathfrak{g}}$. On the other hand, the subset $\left\{
f_{1},f_{2},...,f_{n}\right\}  $ of $\widetilde{\mathfrak{n}}_{-}$ generates
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra (since the elements $f_{1}$,
$f_{2}$, $...$, $f_{n}$ of $\widetilde{\mathfrak{n}}_{-}$ generate
$\widetilde{\mathfrak{n}}_{-}$ as a Lie algebra), and we can easily check that
$\psi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}\right\}  \right)
\subseteq\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}%
$\ \ \ \ \footnote{\textit{Proof.} For every $j\in\left\{  1,2,...,n\right\}
$, we have%
\begin{align*}
\psi_{i}\left(  f_{j}\right)   &  =\left[  e_{i},f_{j}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\psi_{i}\right) \\
&  =\delta_{i,j}\underbrace{h_{i}}_{\in\widetilde{\mathfrak{h}}}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the relations (\ref{nonserre-relations}%
)}\right) \\
&  \in\delta_{i,j}\widetilde{\mathfrak{h}}\subseteq\widetilde{\mathfrak{h}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widetilde{\mathfrak{h}}\text{ is a
vector space}\right) \\
&  \subseteq\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}.
\end{align*}
Thus, $\left\{  \psi_{i}\left(  f_{1}\right)  ,\psi_{i}\left(  f_{2}\right)
,...,\psi_{i}\left(  f_{n}\right)  \right\}  \subseteq\widetilde{\mathfrak{n}%
}_{-}\oplus\widetilde{\mathfrak{h}}$. Since $\left\{  \psi_{i}\left(
f_{1}\right)  ,\psi_{i}\left(  f_{2}\right)  ,...,\psi_{i}\left(
f_{n}\right)  \right\}  =\psi_{i}\left(  \left\{  f_{1},f_{2},...,f_{n}%
\right\}  \right)  $, this rewrites as $\psi_{i}\left(  \left\{  f_{1}%
,f_{2},...,f_{n}\right\}  \right)  \subseteq\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}$, qed.}. Hence, Corollary
\ref{cor.derivation.Lie.unique.ihg} (applied to $\widetilde{\mathfrak{g}}$,
$\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}$,
$\widetilde{\mathfrak{n}}_{-}$, $\psi_{i}$ and $\left\{  f_{1},f_{2}%
,...,f_{n}\right\}  $ instead of $\mathfrak{g}$, $\mathfrak{h}$,
$\mathfrak{i}$, $d$ and $S$) yields that $\psi_{i}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \subseteq\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}$ (since $\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}$ is a Lie subalgebra of
$\widetilde{\mathfrak{g}}$). But%
\begin{align*}
\psi_{i}\left(  \widetilde{\mathfrak{n}}_{-}\right)   &  =\left\{
\underbrace{\psi_{i}\left(  x\right)  }_{=\left[  e_{i},x\right]  }\mid
x\in\widetilde{\mathfrak{n}}_{-}\right\}  =\left\{  \left[  e_{i},x\right]
\mid x\in\widetilde{\mathfrak{n}}_{-}\right\}  =\left[  e_{i}%
,\widetilde{\mathfrak{n}}_{-}\right]  =\left[  e_{i},\widetilde{\mathfrak{n}%
}_{-}\right]  \mathbb{C}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left[  e_{i}%
,\widetilde{\mathfrak{n}}_{-}\right]  \text{ is a vector space}\right) \\
&  =\left[  e_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\ \ \ \ \ \ \ \ \ \ \left(  \text{since the Lie bracket is bilinear}\right)  .
\end{align*}
Thus, $\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]
\subseteq\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}%
\subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}_{-}%
\oplus\widetilde{\mathfrak{h}}=V$. Now, forget that we fixed $i$. We thus have
shown that $\left[  e_{i}\mathbb{C},\widetilde{\mathfrak{n}}_{-}\right]
\subseteq V$ for every $i\in\left\{  1,2,...,n\right\}  $.
\end{verlong}

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]  \subseteq
V$\textit{:}

Every $i\in\left\{  1,2,...,n\right\}  $ satisfies $e_{i}\mathbb{C}%
\subseteq\widetilde{\mathfrak{n}}_{+}$ (since $e_{i}\in\widetilde{\mathfrak{n}%
}_{+}$). Thus, every $i\in\left\{  1,2,...,n\right\}  $ satisfies%
\begin{align*}
\left[  \underbrace{e_{i}\mathbb{C}}_{\subseteq\widetilde{\mathfrak{n}}%
_{+}\subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}%
},\ \underbrace{\widetilde{\mathfrak{h}}}_{\subseteq\widetilde{\mathfrak{n}%
}_{+}\oplus\widetilde{\mathfrak{h}}}\right]   &  \subseteq\left[
\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}%
,\ \widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}\right] \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widetilde{\mathfrak{n}}_{+}%
\oplus\widetilde{\mathfrak{h}}\text{ is a Lie subalgebra of }%
\widetilde{\mathfrak{g}}\right) \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}=V.
\end{align*}


\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq
V$\textit{:}

\begin{vershort}
We have proven above that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq V$.
An analogous argument (or an invocation of the automorphism guaranteed by
Theorem \ref{thm.gtilde} \textbf{(f)}) shows that every $i\in\left\{
1,2,...,n\right\}  $ satisfies $\left[  f_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq V$.
\end{vershort}

\begin{verlong}
We have proven above that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq V$.
A similar argument (but with $\widetilde{\mathfrak{n}}_{-}$ replaced by
$\widetilde{\mathfrak{n}}_{+}$, and with $e_{i}$ replaced by $f_{i}$, and with
$f_{j}$ replaced by $e_{j}$, and with $h_{i}$ replaced by $-h_{i}$, and with
(\ref{nonserre-relations}) replaced by (\ref{nonserre-relations2})) shows that
every $i\in\left\{  1,2,...,n\right\}  $ satisfies $\left[  f_{i}%
\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq V$.
\end{verlong}

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq
V$\textit{:}

We have proven above that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq V$.
A similar argument (but with $\widetilde{\mathfrak{n}}_{+}$ replaced by
$\widetilde{\mathfrak{n}}_{-}$, and with $e_{i}$ replaced by $f_{i}$) shows
that every $i\in\left\{  1,2,...,n\right\}  $ satisfies $\left[
f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq V$.

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]  \subseteq
V$\textit{:}

We have proven above that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]  \subseteq V$. A
similar argument (but with $\widetilde{\mathfrak{n}}_{+}$ replaced by
$\widetilde{\mathfrak{n}}_{-}$, and with $e_{i}$ replaced by $f_{i}$) shows
that every $i\in\left\{  1,2,...,n\right\}  $ satisfies $\left[
f_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]  \subseteq V$.

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq
V$\textit{:}

Every $i\in\left\{  1,2,...,n\right\}  $ satisfies $h_{i}\mathbb{C}%
\subseteq\widetilde{\mathfrak{h}}$ (since $h_{i}\in\widetilde{\mathfrak{h}}$).
Thus, every $i\in\left\{  1,2,...,n\right\}  $ satisfies%
\begin{align*}
\left[  \underbrace{h_{i}\mathbb{C}}_{\subseteq\widetilde{\mathfrak{n}}%
_{+}\subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}%
},\ \underbrace{\widetilde{\mathfrak{n}}_{+}}_{\subseteq
\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}}\right]   &
\subseteq\left[  \widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}%
},\ \widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}\right] \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widetilde{\mathfrak{n}}_{+}%
\oplus\widetilde{\mathfrak{h}}\text{ is a Lie subalgebra of }%
\widetilde{\mathfrak{g}}\right) \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}=V.
\end{align*}


\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq
V$\textit{:}

We have proven above that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  \subseteq V$.
A similar argument (but with $\widetilde{\mathfrak{n}}_{+}$ replaced by
$\widetilde{\mathfrak{n}}_{-}$) shows that every $i\in\left\{
1,2,...,n\right\}  $ satisfies $\left[  h_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{-}\right]  \subseteq V$.

\textit{Proof that every }$i\in\left\{  1,2,...,n\right\}  $\textit{ satisfies
}$\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]  \subseteq
V$\textit{:}

Every $i\in\left\{  1,2,...,n\right\}  $ satisfies $h_{i}\mathbb{C}%
\subseteq\widetilde{\mathfrak{h}}$ (since $h_{i}\in\widetilde{\mathfrak{h}}$).
Thus, every $i\in\left\{  1,2,...,n\right\}  $ satisfies%
\begin{align*}
\left[  \underbrace{h_{i}\mathbb{C}}_{\subseteq\widetilde{\mathfrak{n}}%
_{+}\subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}%
},\ \underbrace{\widetilde{\mathfrak{h}}}_{\subseteq\widetilde{\mathfrak{n}%
}_{+}\oplus\widetilde{\mathfrak{h}}}\right]   &  \subseteq\left[
\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}%
,\ \widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}}\right] \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{h}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widetilde{\mathfrak{n}}_{+}%
\oplus\widetilde{\mathfrak{h}}\text{ is a Lie subalgebra of }%
\widetilde{\mathfrak{g}}\right) \\
&  \subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}=V.
\end{align*}


Thus, we have proven that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
the nine relations $\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}%
_{+}\right]  \subseteq V$, $\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}%
}_{-}\right]  \subseteq V$, $\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{h}%
}\right]  \subseteq V$, $\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}%
}_{+}\right]  \subseteq V$, $\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}%
}_{-}\right]  \subseteq V$, $\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{h}%
}\right]  \subseteq V$, $\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}%
}_{+}\right]  \subseteq V$, $\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}%
}_{-}\right]  \subseteq V$, and $\left[  h_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{h}}\right]  \subseteq V$. Thus, (\ref{pf.gtilde.c.1})
becomes%
\begin{align*}
\left[  N,V\right]   &  \subseteq\sum\limits_{i=1}^{n}\underbrace{\left[
e_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  }_{\subseteq V}%
+\sum\limits_{i=1}^{n}\underbrace{\left[  e_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{-}\right]  }_{\subseteq V}+\sum\limits_{i=1}%
^{n}\underbrace{\left[  e_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]
}_{\subseteq V}\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{i=1}^{n}\underbrace{\left[
f_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  }_{\subseteq V}%
+\sum\limits_{i=1}^{n}\underbrace{\left[  f_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{-}\right]  }_{\subseteq V}+\sum\limits_{i=1}%
^{n}\underbrace{\left[  f_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]
}_{\subseteq V}\\
&  \ \ \ \ \ \ \ \ \ \ +\sum\limits_{i=1}^{n}\underbrace{\left[
h_{i}\mathbb{C},\ \widetilde{\mathfrak{n}}_{+}\right]  }_{\subseteq V}%
+\sum\limits_{i=1}^{n}\underbrace{\left[  h_{i}\mathbb{C}%
,\ \widetilde{\mathfrak{n}}_{-}\right]  }_{\subseteq V}+\sum\limits_{i=1}%
^{n}\underbrace{\left[  h_{i}\mathbb{C},\ \widetilde{\mathfrak{h}}\right]
}_{\subseteq V}\\
&  \subseteq\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}%
^{n}V+\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}%
^{n}V+\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}^{n}V\\
&  \subseteq V
\end{align*}
(since $V$ is a vector space). This proves $\left[  N,V\right]  \subseteq V$.

Moreover,
\begin{align*}
N  &  =\sum\limits_{i=1}^{n}\underbrace{\left(  e_{i}\mathbb{C}\right)
}_{\substack{\subseteq V\\\text{(since }e_{i}\in\widetilde{\mathfrak{n}}%
_{+}\subseteq\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}%
_{-}\oplus\widetilde{\mathfrak{h}}=V\text{)}}}+\sum\limits_{i=1}%
^{n}\underbrace{\left(  f_{i}\mathbb{C}\right)  }_{\substack{\subseteq
V\\\text{(since }f_{i}\in\widetilde{\mathfrak{n}}_{-}\subseteq
\widetilde{\mathfrak{n}}_{+}\oplus\widetilde{\mathfrak{n}}_{-}\oplus
\widetilde{\mathfrak{h}}=V\text{)}}}+\sum\limits_{i=1}^{n}\underbrace{\left(
h_{i}\mathbb{C}\right)  }_{\substack{\subseteq V\\\text{(since }h_{i}%
\in\widetilde{\mathfrak{h}}\subseteq\widetilde{\mathfrak{n}}_{+}%
\oplus\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}=V\text{)}}}\\
&  \subseteq\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}^{n}V+\sum\limits_{i=1}%
^{n}V\subseteq V
\end{align*}
(since $V$ is a vector space).

So we know that $N$ and $V$ are vector subspaces of $\widetilde{\mathfrak{g}}$
such that $\widetilde{\mathfrak{g}}$ is generated by $N$ as a Lie algebra and
such that $N\subseteq V$ and $\left[  N,V\right]  \subseteq V$. Hence, Lemma
\ref{lem.generation.1} (applied to $\widetilde{\mathfrak{g}}$, $N$ and $V$
instead of $\mathfrak{g}$, $T$ and $U$) yields $V=\widetilde{\mathfrak{g}}$.
Thus, $\widetilde{\mathfrak{g}}=V=\widetilde{\mathfrak{n}}_{+}\oplus
\widetilde{\mathfrak{n}}_{-}\oplus\widetilde{\mathfrak{h}}=\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  \oplus\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ (since $\widetilde{\mathfrak{n}}_{-}%
=\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  $,
$\widetilde{\mathfrak{n}}_{+}=\iota_{+}\left(  \widetilde{\mathfrak{n}}%
_{+}\right)  $ and $\widetilde{\mathfrak{h}}=\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $). This proves Theorem \ref{thm.gtilde}
\textbf{(c)}.

\bigskip

\textbf{(d)} During the proof of Theorem \ref{thm.gtilde} \textbf{(c)}, we
have already proven Theorem \ref{thm.gtilde} \textbf{(d)}.

\bigskip

\textbf{(e)} We will use the notations we introduced in our proof of Theorem
\ref{thm.gtilde} \textbf{(d)}. During this proof, we have shown that
$\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)  \subseteq
\widetilde{\mathfrak{g}}\left[  >0\right]  $, $\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \subseteq\widetilde{\mathfrak{g}}\left[
<0\right]  $ and $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
\subseteq\widetilde{\mathfrak{g}}\left[  0\right]  $. Also, we know that
$\widetilde{\mathfrak{g}}=\iota_{+}\left(  \widetilde{\mathfrak{n}}%
_{+}\right)  \oplus\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
\oplus\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. Finally, we know
that the internal direct sum $\widetilde{\mathfrak{g}}\left[  >0\right]
\oplus\widetilde{\mathfrak{g}}\left[  <0\right]  \oplus\widetilde{\mathfrak{g}%
}\left[  0\right]  $ is well-defined.

\begin{vershort}
Now, a simple fact from linear algebra says the following: If $U_{1}$, $U_{2}%
$, $U_{3}$, $V_{1}$, $V_{2}$, $V_{3}$ are six vector subspaces of a vector
space $V$ satisfying the four relations $U_{1}\subseteq V_{1}$, $U_{2}%
\subseteq V_{2}$, $U_{3}\subseteq V_{3}$ and $V=U_{1}\oplus U_{2}\oplus U_{3}%
$, and if the internal direct sum $V_{1}\oplus V_{2}\oplus V_{3}$ is
well-defined, then we must have $U_{1}=V_{1}$, $U_{2}=V_{2}$ and $U_{3}=V_{3}$.
\end{vershort}

\begin{verlong}
Now, a simple fact from linear algebra says the following: If $U_{1}$, $U_{2}%
$, $U_{3}$, $V_{1}$, $V_{2}$, $V_{3}$ are six vector subspaces of a vector
space $V$ satisfying the four relations $U_{1}\subseteq V_{1}$, $U_{2}%
\subseteq V_{2}$, $U_{3}\subseteq V_{3}$ and $V=U_{1}\oplus U_{2}\oplus U_{3}%
$, and if the internal direct sum $V_{1}\oplus V_{2}\oplus V_{3}$ is
well-defined, then we must have $U_{1}=V_{1}$, $U_{2}=V_{2}$ and $U_{3}=V_{3}%
$\ \ \ \ \footnote{\textit{Proof.} Let $U_{1}$, $U_{2}$, $U_{3}$, $V_{1}$,
$V_{2}$, $V_{3}$ be six vector subspaces of a vector space $V$ satisfying the
four relations $U_{1}\subseteq V_{1}$, $U_{2}\subseteq V_{2}$, $U_{3}\subseteq
V_{3}$ and $V=V_{1}\oplus V_{2}\oplus V_{3}$. Assume that the internal direct
sum $V_{1}\oplus V_{2}\oplus V_{3}$ is well-defined.
\par
Let $x\in V_{1}$. Then, $x\in V_{1}\subseteq V=U_{1}\oplus U_{2}\oplus U_{3}$.
Hence, there exist $x_{1}\in U_{1}$, $x_{2}\in U_{2}$ and $x_{3}\in U_{3}$
such that $x=x_{1}+x_{2}+x_{3}$. Consider these $x_{1}$, $x_{2}$ and $x_{3}$.
Since $x=x_{1}+x_{2}+x_{3}$, we have $x-x_{1}=\underbrace{x_{2}}_{\in
U_{2}\subseteq V_{2}}+\underbrace{x_{3}}_{\in U_{3}\subseteq V_{3}}\subseteq
V_{2}+V_{3}$. Combined with $\underbrace{x}_{\in V_{1}}-\underbrace{x_{1}%
}_{\in U_{1}\subseteq V_{1}}\in V_{1}-V_{1}\subseteq V_{1}$, this yields
\[
x-x_{1}\in\left(  V_{2}+V_{3}\right)  \cap V_{1}.
\]
\par
On the other hand, the internal direct sum $V_{1}\oplus V_{2}\oplus V_{3}$ is
well-defined. This direct sum rewrites as $V_{1}\oplus V_{2}\oplus
V_{3}=\underbrace{V_{2}\oplus V_{3}}_{\substack{=V_{2}+V_{3}\\\text{(since
direct sums are sums)}}}\oplus V_{1}=\left(  V_{2}+V_{3}\right)  \oplus V_{1}%
$. Hence, the direct sum $\left(  V_{2}+V_{3}\right)  \oplus V_{1}$ is
well-defined. Thus, $\left(  V_{2}+V_{3}\right)  \cap V_{1}=0$.
\par
But we have $x-x_{1}\in\left(  V_{2}+V_{3}\right)  \cap V_{1}$. In view of
$\left(  V_{2}+V_{3}\right)  \cap V_{1}=0$, this rewrites as $x-x_{1}\in0$.
Hence, $x-x_{1}=0$, so that $x=x_{1}\in U_{1}$.
\par
Now forget that we fixed $x$. We have thus proven that $x\in U_{1}$ for every
$x\in V_{1}$. In other words, $V_{1}\subseteq U_{1}$. Combined with
$U_{1}\subseteq V_{1}$, this yields $U_{1}=V_{1}$. Similarly, $U_{2}=V_{2}$
and $U_{3}=V_{3}$, qed.}.
\end{verlong}

If we apply this fact to $\widetilde{\mathfrak{g}}$, $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  $, $\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  $, $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, $\widetilde{\mathfrak{g}}\left[
>0\right]  $, $\widetilde{\mathfrak{g}}\left[  <0\right]  $,
$\widetilde{\mathfrak{g}}\left[  0\right]  $ instead of $V$, $U_{1}$, $U_{2}$,
$U_{3}$, $V_{1}$, $V_{2}$, $V_{3}$, then we obtain that $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  =\widetilde{\mathfrak{g}}\left[
>0\right]  $, $\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
=\widetilde{\mathfrak{g}}\left[  <0\right]  $ and $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{g}}\left[  0\right]  $
(because we know that $\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
$, $\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  $, $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, $\widetilde{\mathfrak{g}}\left[
>0\right]  $, $\widetilde{\mathfrak{g}}\left[  <0\right]  $,
$\widetilde{\mathfrak{g}}\left[  0\right]  $ are six vector subspaces of
$\widetilde{\mathfrak{g}}$ satisfying the four relations $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  \subseteq\widetilde{\mathfrak{g}}\left[
>0\right]  $, $\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
\subseteq\widetilde{\mathfrak{g}}\left[  <0\right]  $, $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  \subseteq\widetilde{\mathfrak{g}}\left[
0\right]  $ and $\widetilde{\mathfrak{g}}=\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  \oplus\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  \oplus\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, and we know that the internal direct sum
$\widetilde{\mathfrak{g}}\left[  >0\right]  \oplus\widetilde{\mathfrak{g}%
}\left[  <0\right]  \oplus\widetilde{\mathfrak{g}}\left[  0\right]  $ is well-defined).

So we have proven that $\widetilde{\mathfrak{g}}\left[  0\right]  =\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. In other words, the $0$-th
homogeneous component of $\widetilde{\mathfrak{g}}$ (in the $Q$-grading) is
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $.

On the other hand, we have proven that $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  =\widetilde{\mathfrak{g}}\left[
>0\right]  $. Thus,%
\[
\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)  =\widetilde{\mathfrak{g}%
}\left[  >0\right]  =\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha
>0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  =\bigoplus
\limits_{\substack{\alpha\text{ is a }\mathbb{Z}\text{-linear combination}%
\\\text{of }\alpha_{1}\text{, }\alpha_{2}\text{, }...\text{, }\alpha_{n}\text{
with nonnegative}\\\text{coefficients; }\alpha\neq0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]
\]
(since an element $\alpha\in Q$ satisfies $\alpha>0$ if and only if $\alpha$
is a $\mathbb{Z}$-linear combination of $\alpha_{1}$, $\alpha_{2}$, $...$,
$\alpha_{n}$ with nonnegative coefficients such that $\alpha\neq0$).

\begin{vershort}
Similarly, $\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
=\bigoplus\limits_{\substack{\alpha\text{ is a }\mathbb{Z}\text{-linear
combination}\\\text{of }\alpha_{1}\text{, }\alpha_{2}\text{, }...\text{,
}\alpha_{n}\text{ with nonpositive}\\\text{coefficients; }\alpha\neq
0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  $.
\end{vershort}

\begin{verlong}
Also, we have proven that $\iota_{-}\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  =\widetilde{\mathfrak{g}}\left[  <0\right]  $. Hence,%
\[
\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)  =\widetilde{\mathfrak{g}%
}\left[  <0\right]  =\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha
<0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  =\bigoplus
\limits_{\substack{\alpha\text{ is a }\mathbb{Z}\text{-linear combination}%
\\\text{of }\alpha_{1}\text{, }\alpha_{2}\text{, }...\text{, }\alpha_{n}\text{
with nonpositive}\\\text{coefficients; }\alpha\neq0}}\widetilde{\mathfrak{g}%
}\left[  \alpha\right]
\]
(since an element $\alpha\in Q$ satisfies $\alpha<0$ if and only if $\alpha$
is a $\mathbb{Z}$-linear combination of $\alpha_{1}$, $\alpha_{2}$, $...$,
$\alpha_{n}$ with nonpositive coefficients such that $\alpha\neq0$).
\end{verlong}

This completes the proof of Theorem \ref{thm.gtilde} \textbf{(e)}.

\bigskip

\textbf{(g)} Define a $\mathbb{Z}$-linear map $\ell:Q\rightarrow\mathbb{Z}$ by%
\[
\left(  \ell\left(  \alpha_{i}\right)  =1\text{ for every }i\in\left\{
1,2,...,n\right\}  \right)  .
\]
(This is well-defined since $Q$ is a free abelian group with generators
$\alpha_{1}$, $\alpha_{2}$, $...$, $\alpha_{n}$.) Then, $\ell$ is a group homomorphism.

We will use the notations we introduced in our proof of Theorem
\ref{thm.gtilde} \textbf{(c)}. As shown in the proof of Theorem
\ref{thm.gtilde} \textbf{(e)}, we have $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  =\widetilde{\mathfrak{g}}\left[
>0\right]  $, $\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
=\widetilde{\mathfrak{g}}\left[  <0\right]  $ and $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{g}}\left[  0\right]  $.

Just as in the proof of Theorem \ref{thm.gtilde} \textbf{(c)}, we will regard
the maps $\iota_{+}$, $\iota_{-}$ and $\iota_{0}$ as inclusions. Thus,
$\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
=\widetilde{\mathfrak{n}}_{+}$, $\iota_{-}\left(  \widetilde{\mathfrak{n}}%
_{-}\right)  =\widetilde{\mathfrak{n}}_{-}$ and $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{h}}$.

From the proof of Theorem \ref{thm.gtilde} \textbf{(c)}, we know that
$\widetilde{\mathfrak{g}}\left[  0\right]  $, $\widetilde{\mathfrak{g}}\left[
<0\right]  $ and $\widetilde{\mathfrak{g}}\left[  >0\right]  $ are $Q$-graded
Lie subalgebras of $\widetilde{\mathfrak{g}}$. Since $\widetilde{\mathfrak{g}%
}\left[  0\right]  =\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
=\widetilde{\mathfrak{h}}$, $\widetilde{\mathfrak{g}}\left[  <0\right]
=\iota_{-}\left(  \widetilde{\mathfrak{n}}_{-}\right)
=\widetilde{\mathfrak{n}}_{-}$ and $\widetilde{\mathfrak{g}}\left[  >0\right]
=\iota_{+}\left(  \widetilde{\mathfrak{n}}_{+}\right)
=\widetilde{\mathfrak{n}}_{+}$, this rewrites as follows:
$\widetilde{\mathfrak{h}}$, $\widetilde{\mathfrak{n}}_{-}$ and
$\widetilde{\mathfrak{n}}_{+}$ are $Q$-graded Lie subalgebras of
$\widetilde{\mathfrak{g}}$.

Fix $i\in\left\{  1,2,...,n\right\}  $. Since $\alpha_{i}>0$, the space
$\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  $ is an addend in the
direct sum $\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha>0}%
}\widetilde{\mathfrak{g}}\left[  \alpha\right]  $ (namely, the addend for
$\alpha=\alpha_{i}$). Hence, $\widetilde{\mathfrak{g}}\left[  \alpha
_{i}\right]  \subseteq\bigoplus\limits_{\substack{\alpha\in Q;\\\alpha
>0}}\widetilde{\mathfrak{g}}\left[  \alpha\right]  =\widetilde{\mathfrak{g}%
}\left[  >0\right]  =\widetilde{\mathfrak{n}}_{+}$. But since
$\widetilde{\mathfrak{n}}_{+}$ is a $Q$-graded vector subspace of
$\widetilde{\mathfrak{g}}$, we have $\widetilde{\mathfrak{n}}_{+}\left[
\alpha_{i}\right]  =\left(  \widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]
\right)  \cap\widetilde{\mathfrak{n}}_{+}=\widetilde{\mathfrak{g}}\left[
\alpha_{i}\right]  $ (since $\widetilde{\mathfrak{g}}\left[  \alpha
_{i}\right]  \subseteq\widetilde{\mathfrak{n}}_{+}$).

\begin{vershort}
Now, $\widetilde{\mathfrak{n}}_{+}$ is a $Q$-graded Lie algebra, and $\ell$ is
a group homomorphism. Hence, we can apply Proposition
\ref{prop.Q-graded.principal} to $\widetilde{\mathfrak{n}}_{+}$ instead of
$\widetilde{\mathfrak{g}}$. Applying Proposition \ref{prop.Q-graded.principal}
\textbf{(a)} to $\widetilde{\mathfrak{n}}_{+}$ instead of $\mathfrak{g}$, we
see that for every $m\in\mathbb{Z}$, the internal direct sum $\bigoplus
\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m}%
}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]  $ is well-defined. Denote
this internal direct sum $\bigoplus\limits_{\substack{\alpha\in Q;\\\ell
\left(  \alpha\right)  =m}}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]
$ by $\widetilde{\mathfrak{n}}_{+\left[  m\right]  }$. Applying Proposition
\ref{prop.Q-graded.principal} \textbf{(b)} to $\widetilde{\mathfrak{n}}_{+}$
instead of $\mathfrak{g}$, we see that the Lie algebra
$\widetilde{\mathfrak{n}}_{+}$ equipped with the grading $\left(
\widetilde{\mathfrak{n}}_{+\left[  m\right]  }\right)  _{m\in\mathbb{Z}}$ is a
$\mathbb{Z}$-graded Lie algebra.

Let $N_{+}$ be the free vector space with basis $e_{1},e_{2},...,e_{n}$. Since
$\widetilde{\mathfrak{n}}_{+}=\operatorname*{FreeLie}\left(  e_{i}\ \mid
\ i\in\left\{  1,2,...,n\right\}  \right)  $, we then have a canonical
isomorphism $\widetilde{\mathfrak{n}}_{+}\cong\operatorname*{FreeLie}\left(
N_{+}\right)  $ (where $\operatorname*{FreeLie}\left(  N_{+}\right)  $ means
the free Lie algebra over the vector space (not the set) $N_{+}$). We identify
$\widetilde{\mathfrak{n}}_{+}$ with $\operatorname*{FreeLie}\left(
N_{+}\right)  $ along this isomorphism. Due to the construction of the free
Lie algebra, we have a canonical injection $N_{+}\rightarrow
\operatorname*{FreeLie}\left(  N_{+}\right)  =\widetilde{\mathfrak{n}}_{+}$.
We will regard this injection as an inclusion (so that $N_{+}\subseteq
\widetilde{\mathfrak{n}}_{+}$).

Since $\widetilde{\mathfrak{n}}_{+}=\operatorname*{FreeLie}\left(
N_{+}\right)  $, it is clear that $\widetilde{\mathfrak{n}}_{+}$ is generated
by $N_{+}$ as a Lie algebra.

Clearly, $e_{j}\in\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{j}\right]
\subseteq\widetilde{\mathfrak{n}}_{+\left[  1\right]  }$ for every
$j\in\left\{  1,2,...,n\right\}  $. Thus, $N_{+}\subseteq
\widetilde{\mathfrak{n}}_{+\left[  1\right]  }$. Combining this with the fact
that $\widetilde{\mathfrak{n}}_{+}$ is generated by $N_{+}$ as a Lie algebra,
we see that we can apply Theorem \ref{thm.FreeLie.grading1} to the Lie algebra
$\widetilde{\mathfrak{n}}_{+}$ (with the $\mathbb{Z}$-grading $\left(
\widetilde{\mathfrak{n}}_{+\left[  m\right]  }\right)  _{m\in\mathbb{Z}}$, not
with the original $Q$-grading) and $N_{+}$ instead of the Lie algebra
$\mathfrak{g}$ and $T$. As a result, we obtain $N_{+}=\widetilde{\mathfrak{n}%
}_{+\left[  1\right]  }$. Since $\widetilde{\mathfrak{g}}\left[  \alpha
_{i}\right]  =\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{i}\right]
\subseteq\widetilde{\mathfrak{n}}_{+\left[  1\right]  }=N_{+}$, we have
$\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  =N_{+}\left[  \alpha
_{i}\right]  $ (since $N_{+}$ is a $Q$-graded subspace of
$\widetilde{\mathfrak{g}}$). But $N_{+}\left[  \alpha_{i}\right]
=\mathbb{C}e_{i}$ (this is clear from the fact that $N_{+}$ has basis
$e_{1},e_{2},...,e_{n}$, and each of the vectors in this basis has a different
degree in the $Q$-grading). Hence, $\widetilde{\mathfrak{g}}\left[  \alpha
_{i}\right]  =N_{+}\left[  \alpha_{i}\right]  =\mathbb{C}e_{i}$. A similar
argument (with $-\ell$ taking the role of $\ell$) shows that
$\widetilde{\mathfrak{g}}\left[  -\alpha_{i}\right]  =\mathbb{C}f_{i}$. This
proves Theorem \ref{thm.gtilde} \textbf{(g)}.
\end{vershort}

\begin{verlong}
Now, $\widetilde{\mathfrak{n}}_{+}$ is a $Q$-graded Lie algebra, and $\ell$ is
a group homomorphism. Hence, we can apply Proposition
\ref{prop.Q-graded.principal} to $\widetilde{\mathfrak{n}}_{+}$ instead of
$\widetilde{\mathfrak{g}}$. Applying Proposition \ref{prop.Q-graded.principal}
\textbf{(a)} to $\widetilde{\mathfrak{n}}_{+}$ instead of $\mathfrak{g}$, we
see that for every $m\in\mathbb{Z}$, the internal direct sum $\bigoplus
\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =m}%
}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]  $ is well-defined. Denote
this internal direct sum $\bigoplus\limits_{\substack{\alpha\in Q;\\\ell
\left(  \alpha\right)  =m}}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]
$ by $\widetilde{\mathfrak{n}}_{+\left[  m\right]  }$. Applying Proposition
\ref{prop.Q-graded.principal} \textbf{(b)} to $\widetilde{\mathfrak{n}}_{+}$
instead of $\mathfrak{g}$, we see that the Lie algebra
$\widetilde{\mathfrak{n}}_{+}$ equipped with the grading $\left(
\widetilde{\mathfrak{n}}_{+\left[  m\right]  }\right)  _{m\in\mathbb{Z}}$ is a
$\mathbb{Z}$-graded Lie algebra. Denote this $\mathbb{Z}$-graded Lie algebra
by $\widetilde{\mathfrak{n}}_{+}^{\operatorname*{principal}}$. Then,
$\widetilde{\mathfrak{n}}_{+}^{\operatorname*{principal}}\left[  m\right]
=\widetilde{\mathfrak{n}}_{+\left[  m\right]  }$ for every $m\in\mathbb{Z}$.
Applied to $m=1$, this yields $\widetilde{\mathfrak{n}}_{+}%
^{\operatorname*{principal}}\left[  1\right]  =\widetilde{\mathfrak{n}%
}_{+\left[  1\right]  }$.

We have $\widetilde{\mathfrak{n}}_{+\left[  1\right]  }=\bigoplus
\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)  =1}%
}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]  $ (by the definition of
$\widetilde{\mathfrak{n}}_{+\left[  1\right]  }$).

For every $j\in\left\{  1,2,...,n\right\}  $, the vector space
$\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{j}\right]  $ is an addend in the
direct sum $\bigoplus\limits_{\substack{\alpha\in Q;\\\ell\left(
\alpha\right)  =1}}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]  $
(namely, the addend for $\alpha=\alpha_{j}$), because $\ell\left(  \alpha
_{j}\right)  =1$. Thus, for every $j\in\left\{  1,2,...,n\right\}  $, we have
$\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{j}\right]  \subseteq
\bigoplus\limits_{\substack{\alpha\in Q;\\\ell\left(  \alpha\right)
=1}}\widetilde{\mathfrak{n}}_{+}\left[  \alpha\right]
=\widetilde{\mathfrak{n}}_{+\left[  1\right]  }$. Applied to $j=i$, this
yields $\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{i}\right]  \subseteq
\widetilde{\mathfrak{n}}_{+\left[  1\right]  }$.

Let $N_{+}$ be the free vector space with basis $e_{1},e_{2},...,e_{n}$. Since
$\widetilde{\mathfrak{n}}_{+}=\operatorname*{FreeLie}\left(  e_{i}\ \mid
\ i\in\left\{  1,2,...,n\right\}  \right)  $, we then have a canonical
isomorphism $\widetilde{\mathfrak{n}}_{+}\cong\operatorname*{FreeLie}\left(
N_{+}\right)  $ (where $\operatorname*{FreeLie}\left(  N_{+}\right)  $ means
the free Lie algebra over the vector space (not the set) $N_{+}$). We identify
$\widetilde{\mathfrak{n}}_{+}$ with $\operatorname*{FreeLie}\left(
N_{+}\right)  $ along this isomorphism. Due to the construction of the free
Lie algebra, we have a canonical injection $N_{+}\rightarrow
\operatorname*{FreeLie}\left(  N_{+}\right)  =\widetilde{\mathfrak{n}}_{+}$.
We will regard this injection as an inclusion (so that $N_{+}\subseteq
\widetilde{\mathfrak{n}}_{+}$).

Since $\widetilde{\mathfrak{n}}_{+}=\operatorname*{FreeLie}\left(
N_{+}\right)  $, it is clear that $\widetilde{\mathfrak{n}}_{+}$ is generated
by $N_{+}$ as a Lie algebra. In other words, $\widetilde{\mathfrak{n}}%
_{+}^{\operatorname*{principal}}$ is generated by $N_{+}$ as a Lie algebra
(since $\widetilde{\mathfrak{n}}_{+}^{\operatorname*{principal}}%
=\widetilde{\mathfrak{n}}_{+}$ as Lie algebra).

Since $N_{+}$ is the free vector space with basis $e_{1},e_{2},...,e_{n}$, we
have $N_{+}=\bigoplus\limits_{j=1}^{n}e_{j}\mathbb{C}$.

For every $j\in\left\{  1,2,...,n\right\}  $, we have $\deg\left(
e_{j}\right)  =\alpha_{j}$ (by the definition of the $Q$-grading on
$\widetilde{\mathfrak{g}}$) and thus $e_{j}\in\widetilde{\mathfrak{n}}%
_{+}\left[  \alpha_{j}\right]  $ (since $e_{j}\in\widetilde{\mathfrak{n}}_{+}%
$). Hence, for every $j\in\left\{  1,2,...,n\right\}  $, we have
$e_{j}\mathbb{C}\subseteq\widetilde{\mathfrak{n}}_{+}\left[  \alpha
_{j}\right]  $. Thus, for every $j\in\left\{  1,2,...,n\right\}  $, the vector
subspace $e_{j}\mathbb{C}$ of $\widetilde{\mathfrak{n}}_{+}$ lies entirely
within one homogeneous component of $\widetilde{\mathfrak{n}}_{+}$. Thus, for
every $j\in\left\{  1,2,...,n\right\}  $, the vector subspace $e_{j}%
\mathbb{C}$ is a $Q$-graded vector subspace of $\widetilde{\mathfrak{n}}_{+}$.
Therefore, the internal direct sum $\bigoplus\limits_{j=1}^{n}e_{j}\mathbb{C}$
also is a $Q$-graded vector subspace of $\widetilde{\mathfrak{n}}_{+}$
(because any internal direct sum of $Q$-graded vector subspaces of a
$Q$-graded vector space must itself be a $Q$-graded vector subspace). Since
$\bigoplus\limits_{j=1}^{n}e_{j}\mathbb{C}=N_{+}$, this means that $N_{+}$ is
a $Q$-graded vector subspace of $\widetilde{\mathfrak{n}}_{+}$.

For every $j\in\left\{  1,2,...,n\right\}  $ satisfying $j\neq i$, we have
$\left(  e_{j}\mathbb{C}\right)  \left[  \alpha_{i}\right]  =0$ (because
\begin{align*}
\left(  e_{j}\mathbb{C}\right)  \left[  \alpha_{i}\right]   &
=\underbrace{\left(  e_{j}\mathbb{C}\right)  }_{\subseteq
\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{j}\right]  }\cap\left(
\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{i}\right]  \right)  \subseteq
\left(  \widetilde{\mathfrak{n}}_{+}\left[  \alpha_{j}\right]  \right)
\cap\left(  \widetilde{\mathfrak{n}}_{+}\left[  \alpha_{i}\right]  \right)
=0\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }j\neq i\text{, so that }\alpha_{j}\neq\alpha_{i}\text{, and thus
the }\alpha_{j}\text{-th and the}\\
\alpha_{i}\text{-th homogeneous components of }\widetilde{\mathfrak{n}}%
_{+}\text{ are linearly}\\
\text{disjoint, i. e., they satisfy }\left(  \widetilde{\mathfrak{n}}%
_{+}\left[  \alpha_{j}\right]  \right)  \cap\left(  \widetilde{\mathfrak{n}%
}_{+}\left[  \alpha_{i}\right]  \right)  =0
\end{array}
\right)
\end{align*}
and thus $\left(  e_{j}\mathbb{C}\right)  \left[  \alpha_{i}\right]  =0$).
Moreover, we know that for every $j\in\left\{  1,2,...,n\right\}  $, we have
$e_{j}\mathbb{C}\subseteq\widetilde{\mathfrak{n}}_{+}\left[  \alpha
_{j}\right]  $. Applied to $j=i$, this yields $e_{i}\mathbb{C}\subseteq
\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{i}\right]  $. Now, $\left(
e_{i}\mathbb{C}\right)  \left[  \alpha_{i}\right]  =\left(  e_{i}%
\mathbb{C}\right)  \cap\left(  \widetilde{\mathfrak{n}}_{+}\left[  \alpha
_{i}\right]  \right)  =e_{i}\mathbb{C}$ (since $e_{i}\mathbb{C}\subseteq
\widetilde{\mathfrak{n}}_{+}\left[  \alpha_{i}\right]  $).

Now,
\begin{align*}
N_{+}\left[  \alpha_{i}\right]   &  =\left(  \bigoplus\limits_{j=1}^{n}%
e_{j}\mathbb{C}\right)  \left[  \alpha_{i}\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }N_{+}=\bigoplus\limits_{j=1}^{n}e_{j}\mathbb{C}\right) \\
&  =\bigoplus\limits_{j=1}^{n}\left(  \left(  e_{j}\mathbb{C}\right)  \left[
\alpha_{i}\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }e_{j}\mathbb{C}\text{ is a
}Q\text{-graded vector subspace of }\widetilde{\mathfrak{n}}_{+}\text{ for
every }j\in\left\{  1,2,...,n\right\}  \right) \\
&  =\bigoplus\limits_{j\in\left\{  1,2,...,n\right\}  }\left(  \left(
e_{j}\mathbb{C}\right)  \left[  \alpha_{i}\right]  \right)  =\left(
\underbrace{\left(  e_{i}\mathbb{C}\right)  \left[  \alpha_{i}\right]
}_{=e_{i}\mathbb{C}}\right)  \oplus\bigoplus\limits_{\substack{j\in\left\{
1,2,...,n\right\}  ;\\j\neq i}}\left(  \underbrace{\left(  e_{j}%
\mathbb{C}\right)  \left[  \alpha_{i}\right]  }_{\substack{=0\\\text{(since
}j\neq i\text{)}}}\right) \\
&  =\left(  e_{i}\mathbb{C}\right)  \oplus\underbrace{\bigoplus
\limits_{\substack{j\in\left\{  1,2,...,n\right\}  ;\\j\neq i}}0}_{=0}%
=e_{i}\mathbb{C}.
\end{align*}


On the other hand,%
\begin{align*}
N_{+}  &  =\bigoplus\limits_{j=1}^{n}e_{j}\mathbb{C}=\sum\limits_{j=1}%
^{n}\underbrace{e_{j}\mathbb{C}}_{\subseteq\widetilde{\mathfrak{n}}_{+}\left[
\alpha_{j}\right]  \subseteq\widetilde{\mathfrak{n}}_{+\left[  1\right]  }%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{since direct sums are sums}\right) \\
&  \subseteq\sum\limits_{j=1}^{n}\widetilde{\mathfrak{n}}_{+\left[  1\right]
}\subseteq\widetilde{\mathfrak{n}}_{+\left[  1\right]  }%
=\widetilde{\mathfrak{n}}_{+}^{\operatorname*{principal}}\left[  1\right]  .
\end{align*}
Since $\widetilde{\mathfrak{n}}_{+}^{\operatorname*{principal}}$ is generated
by $N_{+}$ as a Lie algebra, this yields that we can apply Theorem
\ref{thm.FreeLie.grading1} to $\widetilde{\mathfrak{n}}_{+}%
^{\operatorname*{principal}}$ and $N_{+}$ instead of $\mathfrak{g}$ and $T$.
As a result, we obtain that $N_{+}=\widetilde{\mathfrak{n}}_{+}%
^{\operatorname*{principal}}\left[  1\right]  =\widetilde{\mathfrak{n}%
}_{+\left[  1\right]  }$. Now,%
\[
\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  =\widetilde{\mathfrak{n}%
}_{+}\left[  \alpha_{i}\right]  \subseteq\widetilde{\mathfrak{n}}_{+\left[
1\right]  }=N_{+},
\]
so that%
\begin{align*}
\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]   &  =\left(
\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  \right)  \cap N_{+}%
=N_{+}\left[  \alpha_{i}\right]  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}N_{+}\text{ is a }Q\text{-graded vector subspace of }\widetilde{\mathfrak{g}%
}\right) \\
&  =e_{i}\mathbb{C}.
\end{align*}


Now, notice that $Q$ is a free abelian group with generators $-\alpha_{1}$,
$-\alpha_{2}$, $...$, $-\alpha_{n}$. Hence, we can prove
$\widetilde{\mathfrak{g}}\left[  -\alpha_{i}\right]  =f_{i}\mathbb{C}$ by
means of making the following modifications to the above proof of
$\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  =e_{i}\mathbb{C}$:

\begin{itemize}
\item Replace every $>$ sign by a $<$ sign, and vice versa.

\item Replace every $\alpha_{j}$ by $-\alpha_{j}$ (this includes replacing
every $\alpha_{i}$ by $-\alpha_{i}$).

\item Replace every $\widetilde{\mathfrak{n}}_{+}$ by $\widetilde{\mathfrak{n}%
}_{-}$ and vice versa.

\item Replace every $\iota_{+}$ by $\iota_{-}$ and vice versa.

\item Replace every $e_{j}$ by $f_{j}$ (this includes replacing every $e_{i}$
by $f_{i}$).

\item Replace every $N_{+}$ by $N_{-}$.

\item Replace $\widetilde{\mathfrak{n}}_{+}^{\operatorname*{principal}}$ by
$\widetilde{\mathfrak{n}}_{-}^{\operatorname*{principal}}$.
\end{itemize}

Thus we have proven both $\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]
=e_{i}\mathbb{C}$ and $\widetilde{\mathfrak{g}}\left[  -\alpha_{i}\right]
=f_{i}\mathbb{C}$. This proves Theorem \ref{thm.gtilde} \textbf{(g)}.
\end{verlong}

\bigskip

\textbf{(h)} It is clear that $I$ (being a sum of $Q$-graded ideals) is a
$Q$-graded ideal. We only need to prove that $I$ has zero intersection with
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $.

Let $\pi_{0}:\widetilde{\mathfrak{g}}\rightarrow\widetilde{\mathfrak{g}%
}\left[  0\right]  $ be the canonical projection from the $Q$-graded vector
space $\widetilde{\mathfrak{g}}$ on its $0$-th homogeneous component
$\widetilde{\mathfrak{g}}\left[  0\right]  $.

\begin{vershort}
For every $Q$-graded vector subspace $M$ of $\widetilde{\mathfrak{g}}$, we
have $\pi_{0}\left(  M\right)  =M\cap\left(  \widetilde{\mathfrak{g}}\left[
0\right]  \right)  $ (this is just an elementary property of $Q$-graded vector
spaces). Since $\widetilde{\mathfrak{g}}\left[  0\right]  =\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ (by Theorem \ref{thm.gtilde} \textbf{(e)}),
this rewrites as follows: For every $Q$-graded vector subspace $M$ of
$\widetilde{\mathfrak{g}}$, we have $\pi_{0}\left(  M\right)  =M\cap\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. Thus, every $Q$-graded ideal
$\mathfrak{i}$ of $\widetilde{\mathfrak{g}}$ which has zero intersection with
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ satisfies $\pi_{0}\left(
\mathfrak{i}\right)  =\mathfrak{i}\cap\iota_{0}\left(  \widetilde{\mathfrak{h}%
}\right)  =0$. Therefore, the sum $I$ of all such ideals also satisfies
$\pi_{0}\left(  I\right)  =0$ (since $\pi_{0}$ is linear). But since $\pi
_{0}\left(  I\right)  =I\cap\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
$ (because for every $Q$-graded vector subspace $M$ of
$\widetilde{\mathfrak{g}}$, we have $\pi_{0}\left(  M\right)  =M\cap\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $), this rewrites as $I\cap
\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  =0$. In other words, $I$ has
zero intersection with $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $.
Theorem \ref{thm.gtilde} \textbf{(h)} is proven.
\end{vershort}

\begin{verlong}
For every $Q$-graded vector subspace $M$ of $\widetilde{\mathfrak{g}}$, we
have%
\begin{equation}
M\cap\left(  \widetilde{\mathfrak{g}}\left[  0\right]  \right)  =\pi
_{0}\left(  M\right)  \label{pf.gtilde.g.1}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.gtilde.g.1}):} Let $M$ be a $Q$-graded
vector subspace of $\widetilde{\mathfrak{g}}$. Then, we have $M=\bigoplus
\limits_{\alpha\in Q}M\left[  \alpha\right]  $, and every $\alpha\in Q$
satisfies $M\left[  \alpha\right]  =M\cap\left(  \widetilde{\mathfrak{g}%
}\left[  \alpha\right]  \right)  $.
\par
Now, $M=\bigoplus\limits_{\alpha\in Q}M\left[  \alpha\right]  =\sum
\limits_{\alpha\in Q}M\left[  \alpha\right]  $ (since direct sums are sums),
so that%
\[
\pi_{0}\left(  M\right)  =\pi_{0}\left(  \sum\limits_{\alpha\in Q}M\left[
\alpha\right]  \right)  =\sum\limits_{\alpha\in Q}\pi_{0}\left(  M\left[
\alpha\right]  \right)  =\pi_{0}\left(  M\left[  0\right]  \right)
+\sum\limits_{\substack{\alpha\in Q;\\\alpha\neq0}}\pi_{0}\left(  M\left[
\alpha\right]  \right)  .
\]
\par
But now, let $\alpha\in Q$ be such that $\alpha\neq0$. Then, $0$ and $\alpha$
are two distinct elements of $Q$. Whenever $\beta$ and $\gamma$ are two
distinct elements of $Q$, the projection from the $Q$-graded vector space
$\widetilde{\mathfrak{g}}$ on its $\beta$-th homogeneous component
$\widetilde{\mathfrak{g}}\left[  \beta\right]  $ sends
$\widetilde{\mathfrak{g}}\left[  \gamma\right]  $ to zero. Applied to
$\beta=0$ and $\gamma=\alpha$, this yields that the projection from the
$Q$-graded vector space $\widetilde{\mathfrak{g}}$ on its $0$-th homogeneous
component $\widetilde{\mathfrak{g}}\left[  0\right]  $ sends
$\widetilde{\mathfrak{g}}\left[  \alpha\right]  $ to $0$ (since $0$ and
$\alpha$ are two distinct elements of $Q$). Since the projection from the
$Q$-graded vector space $\widetilde{\mathfrak{g}}$ on its $0$-th homogeneous
component $\widetilde{\mathfrak{g}}\left[  0\right]  $ is the map $\pi_{0}$,
this rewrites as follows: The map $\pi_{0}$ sends $\widetilde{\mathfrak{g}%
}\left[  \alpha\right]  $ to $0$. Thus, $\pi_{0}\left(
\widetilde{\mathfrak{g}}\left[  \alpha\right]  \right)  =0$. Since $M\left[
\alpha\right]  \subseteq\widetilde{\mathfrak{g}}\left[  \alpha\right]  $, we
have $\pi_{0}\left(  M\left[  \alpha\right]  \right)  \subseteq\pi_{0}\left(
\widetilde{\mathfrak{g}}\left[  \alpha\right]  \right)  =0$, so that $\pi
_{0}\left(  M\left[  \alpha\right]  \right)  =0$.
\par
Now forget that we fixed $\alpha$. We thus have shown that every $\alpha\in Q$
such that $\alpha\neq0$ satisfies $\pi_{0}\left(  M\left[  \alpha\right]
\right)  =0$. Hence, $\sum\limits_{\substack{\alpha\in Q;\\\alpha\neq
0}}\underbrace{\pi_{0}\left(  M\left[  \alpha\right]  \right)  }_{=0}%
=\sum\limits_{\substack{\alpha\in Q;\\\alpha\neq0}}0=0$.
\par
On the other hand, $\pi_{0}$ is a projection on $\widetilde{\mathfrak{g}%
}\left[  0\right]  $, and therefore leaves every subset of
$\widetilde{\mathfrak{g}}\left[  0\right]  $ invariant. Since $M\left[
0\right]  $ is a subset of $\widetilde{\mathfrak{g}}\left[  0\right]  $, this
yields that $\pi_{0}$ leaves $M\left[  0\right]  $ invariant. Hence, $\pi
_{0}\left(  M\left[  0\right]  \right)  =M\left[  0\right]  $.
\par
Now,%
\[
\pi_{0}\left(  M\right)  =\underbrace{\pi_{0}\left(  M\left[  0\right]
\right)  }_{=M\left[  0\right]  }+\underbrace{\sum\limits_{\substack{\alpha\in
Q;\\\alpha\neq0}}\pi_{0}\left(  M\left[  \alpha\right]  \right)  }%
_{=0}=M\left[  0\right]  =M\cap\left(  \widetilde{\mathfrak{g}}\left[
0\right]  \right)
\]
(since every $\alpha\in Q$ satisfies $M\left[  \alpha\right]  =M\cap\left(
\widetilde{\mathfrak{g}}\left[  \alpha\right]  \right)  $). This proves
(\ref{pf.gtilde.g.1}).}. As a consequence, every $Q$-graded vector subspace
$M$ of $\widetilde{\mathfrak{g}}$ satisfies%
\begin{equation}
M\cap\underbrace{\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
}_{\substack{=\widetilde{\mathfrak{g}}\left[  0\right]  \\\text{(by Theorem
\ref{thm.gtilde} \textbf{(e)})}}}=M\cap\left(  \widetilde{\mathfrak{g}}\left[
0\right]  \right)  =\pi_{0}\left(  M\right)  \label{pf.gtilde.g.2}%
\end{equation}
(by (\ref{pf.gtilde.g.1})).

Now, $I$ is the sum of all $Q$-graded ideals in $\widetilde{\mathfrak{g}}$
which have zero intersection with $\iota_{0}\left(  \widetilde{\mathfrak{h}%
}\right)  $. In other words,%
\begin{align*}
I  &  =\sum\limits_{\substack{\mathfrak{i}\text{ is a }Q\text{-graded ideal in
}\widetilde{\mathfrak{g}}\\\text{such that }\mathfrak{i}\cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =0}}\mathfrak{i}=\sum
\limits_{\substack{\mathfrak{i}\text{ is a }Q\text{-graded ideal in
}\widetilde{\mathfrak{g}}\\\text{such that }\pi_{0}\left(  \mathfrak{i}%
\right)  =0}}\mathfrak{i}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because every }Q\text{-graded ideal }\mathfrak{i}\text{ in
}\widetilde{\mathfrak{g}}\text{ satisfies }\mathfrak{i}\cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\pi_{0}\left(  \mathfrak{i}\right) \\
\text{(by (\ref{pf.gtilde.g.2}), applied to }M=\mathfrak{i}\text{)}%
\end{array}
\right)  .
\end{align*}
Thus,%
\[
\pi_{0}\left(  I\right)  =\pi_{0}\left(  \sum\limits_{\substack{\mathfrak{i}%
\text{ is a }Q\text{-graded ideal in }\widetilde{\mathfrak{g}}\\\text{such
that }\pi_{0}\left(  \mathfrak{i}\right)  =0}}\mathfrak{i}\right)
=\sum\limits_{\substack{\mathfrak{i}\text{ is a }Q\text{-graded ideal in
}\widetilde{\mathfrak{g}}\\\text{such that }\pi_{0}\left(  \mathfrak{i}%
\right)  =0}}\underbrace{\pi_{0}\left(  \mathfrak{i}\right)  }_{=0}%
=\sum\limits_{\substack{\mathfrak{i}\text{ is a }Q\text{-graded ideal in
}\widetilde{\mathfrak{g}}\\\text{such that }\pi_{0}\left(  \mathfrak{i}%
\right)  =0}}0=0.
\]
But $I$ is $Q$-graded. Thus, (\ref{pf.gtilde.g.2}) (applied to $M=I$) yields
$I\cap\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  =\pi_{0}\left(
I\right)  =0$. In other words, $I$ has zero intersection with $\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. This proves Theorem
\ref{thm.gtilde} \textbf{(h)}.
\end{verlong}

\bigskip

\textbf{(i)} First, we notice that the Lie algebra $\widetilde{\mathfrak{g}}$
is generated by its elements $e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$,
$f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$ (since
\[
\widetilde{\mathfrak{g}}=\operatorname*{FreeLie}\left(  h_{i},f_{i}%
,e_{i}\ \mid\ i\in\left\{  1,2,...,n\right\}  \right)  \diagup\left(
\text{the relations (\ref{nonserre-relations})}\right)
\]
). Hence, the Lie algebra $\mathfrak{g}$ is generated by its elements $e_{1}$,
$e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$,
$...$, $h_{n}$ as well (since $\mathfrak{g}=\widetilde{\mathfrak{g}}\diagup I$).

In order to prove that $\mathfrak{g}$ is a contragredient Lie algebra
corresponding to $A$, we must prove that it satisfies the conditions
\textbf{(1)}, \textbf{(2)} and \textbf{(3)} of Definition
\ref{def.contragredient}.

\textit{Proof of condition \textbf{(1)}:} The relations
(\ref{nonserre-relations}) are satisfied in $\widetilde{\mathfrak{g}}$ (by the
definition of $\widetilde{\mathfrak{g}}$ as the quotient Lie algebra
$\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\right)  \diagup\left(
\text{the relations (\ref{nonserre-relations})}\right)  $) and thus also in
$\mathfrak{g}$ (since $\mathfrak{g}$ is a quotient Lie algebra of
$\widetilde{\mathfrak{g}}$). This proves condition \textbf{(1)} for our
$Q$-graded Lie algebra $\mathfrak{g}$.

\textit{Proof of condition \textbf{(2)}:} By Theorem \ref{thm.gtilde}
\textbf{(e)}, we have $\widetilde{\mathfrak{g}}\left[  0\right]  =\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. We know that $h_{1}%
,h_{2},...,h_{n}$ is a basis of the vector space $\widetilde{\mathfrak{h}}$
(since $\widetilde{\mathfrak{h}}$ was defined as the free vector space with
basis $h_{1},h_{2},...,h_{n}$). Since $\iota_{0}$ is injective, this yields
that $h_{1},h_{2},...,h_{n}$ is a basis of $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ (because we identify the images of the
vectors $h_{1}$, $h_{2}$, $...$, $h_{n}$ under $\iota_{0}$ with $h_{1}$,
$h_{2}$, $...$, $h_{n}$). Thus, in particular, the vectors $h_{1}%
,h_{2},...,h_{n}$ in $\widetilde{\mathfrak{g}}$ span the vector space
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{g}%
}\left[  0\right]  $. As a consequence, the vectors $h_{1}$, $h_{2}$, $...$,
$h_{n}$ in $\mathfrak{g}$ span the vector space $\mathfrak{g}\left[  0\right]
$ (because $\mathfrak{g}=\widetilde{\mathfrak{g}}\diagup I$).

The vectors $h_{1}$, $h_{2}$, $...$, $h_{n}$ in $\mathfrak{g}$ are linearly
independent\footnote{\textit{Proof.} Let $\left(  \lambda_{1},\lambda
_{2},...,\lambda_{n}\right)  \in\mathbb{C}^{n}$ be such that $\lambda_{1}%
h_{1}+\lambda_{2}h_{2}+...+\lambda_{n}h_{n}=0$ in $\mathfrak{g}$. Then,
$\lambda_{1}h_{1}+\lambda_{2}h_{2}+...+\lambda_{n}h_{n}\in I$ in
$\widetilde{\mathfrak{g}}$ (since $\mathfrak{g}=\widetilde{\mathfrak{g}%
}\diagup I$). Combined with $\lambda_{1}h_{1}+\lambda_{2}h_{2}+...+\lambda
_{n}h_{n}\in\widetilde{\mathfrak{g}}\left[  0\right]  =\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, this yields $\lambda_{1}h_{1}+\lambda
_{2}h_{2}+...+\lambda_{n}h_{n}\in I\cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =0$ (since Theorem \ref{thm.gtilde}
\textbf{(h)} yields that $I$ has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $). Thus, $\lambda_{1}h_{1}+\lambda_{2}%
h_{2}+...+\lambda_{n}h_{n}=0$ in $\iota_{0}\left(  \widetilde{\mathfrak{h}%
}\right)  $. Since $h_{1},h_{2},...,h_{n}$ is a basis of $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, this yields $\lambda_{1}=\lambda
_{2}=...=\lambda_{n}=0$.
\par
Now forget that we fixed $\left(  \lambda_{1},\lambda_{2},...,\lambda
_{n}\right)  $. We have thus shown that every $\left(  \lambda_{1},\lambda
_{2},...,\lambda_{n}\right)  \in\mathbb{C}^{n}$ such that $\lambda_{1}%
h_{1}+\lambda_{2}h_{2}+...+\lambda_{n}h_{n}=0$ in $\mathfrak{g}$ satisfies
$\lambda_{1}=\lambda_{2}=...=\lambda_{n}=0$. In other words, the vectors
$h_{1}$, $h_{2}$, $...$, $h_{n}$ in $\mathfrak{g}$ are linearly independent,
qed.}. Hence, $h_{1},h_{2},...,h_{n}$ is a basis of the vector space
$\mathfrak{g}\left[  0\right]  $ (since the vectors $h_{1}$, $h_{2}$, $...$,
$h_{n}$ in $\mathfrak{g}$ span the vector space $\mathfrak{g}\left[  0\right]
$ and are linearly independent). In other words, the vector space
$\mathfrak{g}\left[  0\right]  $ has $\left(  h_{1},h_{2},...,h_{n}\right)  $
as a $\mathbb{C}$-vector space basis.

Let $i\in\left\{  1,2,...,n\right\}  $. Theorem \ref{thm.gtilde} \textbf{(g)}
yields $\widetilde{\mathfrak{g}}\left[  \alpha_{i}\right]  =\mathbb{C}e_{i}$.
Projecting this onto $\widetilde{\mathfrak{g}}\diagup I=\mathfrak{g}$, we
obtain $\mathfrak{g}\left[  \alpha_{i}\right]  =\mathbb{C}e_{i}$ (since the
projection of $e_{i}$ onto $\mathfrak{g}$ is also called $e_{i}$). Similarly,
$\mathfrak{g}\left[  -\alpha_{i}\right]  =\mathbb{C}f_{i}$.

Condition \textbf{(2)} is thus verified for our $Q$-graded Lie algebra
$\mathfrak{g}$.

\textit{Proof of condition \textbf{(3)}:} Let $J$ be a nonzero $Q$-graded
ideal in $\mathfrak{g}$. Assume that $J\cap\left(  \mathfrak{g}\left[
0\right]  \right)  =0$.

Recall that $I$ has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $. That is, $I\cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =0$.

Let $\operatorname*{proj}:\widetilde{\mathfrak{g}}\rightarrow
\widetilde{\mathfrak{g}}\diagup I=\mathfrak{g}$ be the canonical projection.
Then, $\operatorname*{proj}$ is a $Q$-graded Lie algebra homomorphism, so that
$\operatorname*{proj}\nolimits^{-1}\left(  J\right)  $ is a $Q$-graded ideal
of $\widetilde{\mathfrak{g}}$ (since $J$ is a $Q$-graded ideal of
$\mathfrak{g}$). Also, $\operatorname*{Ker}\operatorname*{proj}=I$ (since
$\operatorname*{proj}$ is the canonical projection $\widetilde{\mathfrak{g}%
}\rightarrow\widetilde{\mathfrak{g}}\diagup I$).

Let $x\in\operatorname*{proj}\nolimits^{-1}\left(  J\right)  \cap\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. Then, $x\in
\operatorname*{proj}\nolimits^{-1}\left(  J\right)  $ and $x\in\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. Since $x\in
\operatorname*{proj}\nolimits^{-1}\left(  J\right)  $, we have
$\operatorname*{proj}\left(  x\right)  \in J$. Since $x\in\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =\widetilde{\mathfrak{g}}\left[  0\right]  $
(by Theorem \ref{thm.gtilde} \textbf{(e)}), we have $\operatorname*{proj}%
\left(  x\right)  \in\mathfrak{g}\left[  0\right]  $ (since
$\operatorname*{proj}$ is $Q$-graded). Combined with $\operatorname*{proj}%
\left(  x\right)  \in J$, this yields $\operatorname*{proj}\left(  x\right)
\in J\cap\left(  \mathfrak{g}\left[  0\right]  \right)  =0$, so that
$\operatorname*{proj}\left(  x\right)  =0$, thus $x\in\operatorname*{Ker}%
\operatorname*{proj}=I$. Combined with $x\in\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, this yields $x\in I\cap\left(  \iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  \right)  =0$, so that $x=0$.

Forget that we fixed $x$. We thus have proven that every $x\in
\operatorname*{proj}\nolimits^{-1}\left(  J\right)  \cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $ satisfies $x=0$. Hence,
$\operatorname*{proj}\nolimits^{-1}\left(  J\right)  \cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =0$. Thus, $\operatorname*{proj}%
\nolimits^{-1}\left(  J\right)  $ is a $Q$-graded ideal in
$\widetilde{\mathfrak{g}}$ which has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $. Hence,%
\[
\operatorname*{proj}\nolimits^{-1}\left(  J\right)  \subseteq\left(  \text{sum
of all }Q\text{-graded ideals in }\widetilde{\mathfrak{g}}\text{ which have
zero intersection with }\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
\right)  =I.
\]


Now let $y\in J$ be arbitrary. Since $y\in J\subseteq\mathfrak{g}%
=\widetilde{\mathfrak{g}}\diagup I$, there exists a $y^{\prime}\in
\widetilde{\mathfrak{g}}$ such that $y=\operatorname*{proj}\left(  y^{\prime
}\right)  $. Consider this $y$. Since $\operatorname*{proj}\left(  y^{\prime
}\right)  =y\in J$, we have $y^{\prime}\in\operatorname*{proj}\nolimits^{-1}%
\left(  J\right)  \subseteq I=\operatorname*{Ker}\operatorname*{proj}$, so
that $\operatorname*{proj}\left(  y^{\prime}\right)  =0$. Thus,
$y=\operatorname*{proj}\left(  y^{\prime}\right)  =0$. Now, forget that we
fixed $y$. We thus have proven that every $y\in J$ satisfies $y=0$. Thus,
$J=0$, contradicting to the fact that $J$ is nonzero.

This contradiction shows that our assumption (that $J\cap\left(
\mathfrak{g}\left[  0\right]  \right)  =0$) was wrong. In other words,
$J\cap\left(  \mathfrak{g}\left[  0\right]  \right)  \neq0$.

Now forget that we fixed $J$. We thus have proven that every nonzero
$Q$-graded ideal $J$ in $\mathfrak{g}$ satisfies $J\cap\left(  \mathfrak{g}%
\left[  0\right]  \right)  \neq0$. In other words, every nonzero $Q$-graded
ideal in $\mathfrak{g}$ has a nonzero intersection with $\mathfrak{g}\left[
0\right]  $. This proves that Condition \textbf{(3)} holds for our $Q$-graded
Lie algebra $\mathfrak{g}$.

Now that we have checked all three conditions \textbf{(1)}, \textbf{(2)} and
\textbf{(3)} for our $Q$-graded Lie algebra $\mathfrak{g}$, we conclude that
$\mathfrak{g}$ indeed is a contragredient Lie algebra corresponding to $A$.
Theorem \ref{thm.gtilde} \textbf{(i)} is proven.

\bigskip

\textit{Proof of Theorem \ref{thm.g(A).exuni}.} \textbf{(a)} Let the
$Q$-graded Lie algebra $\mathfrak{g}$ be defined as in Theorem
\ref{thm.gtilde}. According to Theorem \ref{thm.gtilde} \textbf{(i)}, this
$\mathfrak{g}$ is a contragredient Lie algebra corresponding to $A$. Thus,
there exists at least one contragredient Lie algebra corresponding to $A$,
namely this $\mathfrak{g}$. Now, it only remains to prove that it is the only
such Lie algebra (up to isomorphism). In other words, it remains to prove that
whenever $\mathfrak{g}^{\prime}$ is a contragredient Lie algebra corresponding
to $A$, then there exists a $Q$-graded Lie algebra isomorphism $\mathfrak{g}%
\rightarrow\mathfrak{g}^{\prime}$ which sends the generators $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$ of $\mathfrak{g}$ to the respective generators $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$ of $\mathfrak{g}^{\prime}$.

So let $\mathfrak{g}^{\prime}$ be a contragredient Lie algebra. Then,
condition \textbf{(1)} of Definition \ref{def.contragredient} is satisfied for
$\mathfrak{g}^{\prime}$. Thus, the relations (\ref{nonserre-relations}) are
satisfied in $\mathfrak{g}^{\prime}$.

Define a Lie algebra homomorphism $\psi:\widetilde{\mathfrak{g}}%
\rightarrow\mathfrak{g}^{\prime}$ by%
\[
\left\{
\begin{array}
[c]{c}%
\psi\left(  e_{i}\right)  =e_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\psi\left(  f_{i}\right)  =f_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}  ;\\
\psi\left(  h_{i}\right)  =h_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }%
i\in\left\{  1,2,...,n\right\}
\end{array}
\right.  .
\]
This $\psi$ is well-defined because the relations (\ref{nonserre-relations})
are satisfied in $\mathfrak{g}^{\prime}$ (and because $\widetilde{\mathfrak{g}%
}=\operatorname*{FreeLie}\left(  h_{i},f_{i},e_{i}\ \mid\ i\in\left\{
1,2,...,n\right\}  \right)  \diagup\left(  \text{the relations
(\ref{nonserre-relations})}\right)  $).

Since the Lie algebra $\mathfrak{g}^{\prime}$ is generated by its elements
$e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$,
$h_{2}$, $...$, $h_{n}$ (by the definition of a contragredient Lie algebra),
the homomorphism $\psi$ is surjective (since all of the elements $e_{1}$,
$e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$,
$...$, $h_{n}$ clearly lie in the image of $\psi$).

\begin{vershort}
Since $\mathfrak{g}^{\prime}$ is a contragredient Lie algebra, the condition
\textbf{(2)} of Definition \ref{def.contragredient} is satisfied for
$\mathfrak{g}^{\prime}$. In other words, the vector space $\mathfrak{g}%
^{\prime}\left[  0\right]  $ has $\left(  h_{1},h_{2},...,h_{n}\right)  $ as a
$\mathbb{C}$-vector space basis, and we have $\mathfrak{g}^{\prime}\left[
\alpha_{i}\right]  =\mathbb{C}e_{i}$ and $\mathfrak{g}^{\prime}\left[
-\alpha_{i}\right]  =\mathbb{C}f_{i}$ for all $i\in\left\{  1,2,...,n\right\}
$. This yields that the elements $e_{i}$, $f_{i}$ and $h_{i}$ of
$\mathfrak{g}^{\prime}$ satisfy%
\[
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}  .
\]
Of course, the elements $e_{i}$, $f_{i}$ and $h_{i}$ of
$\widetilde{\mathfrak{g}}$ satisfy the same relations (because of the
definition of the $Q$-grading on $\widetilde{\mathfrak{g}}$). As a
consequence, it is easy to see that Lie algebra homomorphism $\psi$ is
$Q$-graded\footnote{\textit{Proof.} Let $T$ be the vector subspace of
$\widetilde{\mathfrak{g}}$ spanned by the elements $e_{1}$, $e_{2}$, $...$,
$e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$.
Then, $\widetilde{\mathfrak{g}}$ is generated by $T$ as a Lie algebra (because
$\widetilde{\mathfrak{g}}$ is generated by the elements $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$ as a Lie algebra). Due to the relations%
\[
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}
\]
holding both in $\widetilde{\mathfrak{g}}$ and in $\mathfrak{g}^{\prime}$, it
is clear that the map $\psi\mid_{T}$ is $Q$-graded. Proposition
\ref{prop.generation.Q-gr} (applied to $\widetilde{\mathfrak{g}}$,
$\mathfrak{g}^{\prime}$ and $\psi$ instead of $\mathfrak{g}$, $\mathfrak{h}$
and $f$) now yields that $\psi$ is $Q$-graded, qed.}. As a consequence,
$\operatorname*{Ker}\psi$ is a $Q$-graded Lie ideal of
$\widetilde{\mathfrak{g}}$.
\end{vershort}

\begin{verlong}
Since $\mathfrak{g}^{\prime}$ is a contragredient Lie algebra, the condition
\textbf{(2)} of Definition \ref{def.contragredient} is satisfied for
$\mathfrak{g}^{\prime}$. In other words, the vector space $\mathfrak{g}%
^{\prime}\left[  0\right]  $ has $\left(  h_{1},h_{2},...,h_{n}\right)  $ as a
$\mathbb{C}$-vector space basis, and we have $\mathfrak{g}^{\prime}\left[
\alpha_{i}\right]  =\mathbb{C}e_{i}$ and $\mathfrak{g}^{\prime}\left[
-\alpha_{i}\right]  =\mathbb{C}f_{i}$ for all $i\in\left\{  1,2,...,n\right\}
$. This yields that the elements $e_{i}$, $f_{i}$ and $h_{i}$ of
$\mathfrak{g}^{\prime}$ satisfy%
\[
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}  .
\]
Of course, the elements $e_{i}$, $f_{i}$ and $h_{i}$ of
$\widetilde{\mathfrak{g}}$ satisfy the same relations (because of the
definition of the $Q$-grading on $\widetilde{\mathfrak{g}}$). As a
consequence, it is easy to see that Lie algebra homomorphism $\psi$ is
$Q$-graded\footnote{\textit{Proof.} Let $T$ be the vector subspace of
$\widetilde{\mathfrak{g}}$ spanned by the elements $e_{1}$, $e_{2}$, $...$,
$e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$, $h_{n}$.
Then, $\widetilde{\mathfrak{g}}$ is generated by $T$ as a Lie algebra (because
$\widetilde{\mathfrak{g}}$ is generated by the elements $e_{1}$, $e_{2}$,
$...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}$, $...$,
$h_{n}$ as a Lie algebra). Due to the relations%
\[
\deg\left(  e_{i}\right)  =\alpha_{i},\ \ \ \ \ \ \ \ \ \ \deg\left(
f_{i}\right)  =-\alpha_{i}\ \ \ \ \ \ \ \ \ \ \text{and }\deg\left(
h_{i}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\in\left\{
1,2,...,n\right\}
\]
holding in $\widetilde{\mathfrak{g}}$, the subspace $T$ is of
$\widetilde{\mathfrak{g}}$ is $Q$-graded, and its homogeneous components are%
\[
T\left[  \alpha\right]  =\left\{
\begin{array}
[c]{l}%
\mathbb{C}h_{1}+\mathbb{C}h_{2}+...+\mathbb{C}h_{n}%
,\ \ \ \ \ \ \ \ \ \ \text{if }\alpha=0;\\
\mathbb{C}e_{i},\ \ \ \ \ \ \ \ \ \ \text{if }\alpha=\alpha_{i}\text{ for some
}i\in\left\{  1,2,...,n\right\}  ;\\
\mathbb{C}f_{i},\ \ \ \ \ \ \ \ \ \ \text{if }\alpha=-\alpha_{i}\text{ for
some }i\in\left\{  1,2,...,n\right\}  ;\\
0,\ \ \ \ \ \ \ \ \ \ \text{otherwise}%
\end{array}
\right.  \ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in Q.
\]
Using this fact, it is straightforward to check that $\psi\left(  T\left[
\alpha\right]  \right)  \subseteq\mathfrak{g}^{\prime}\left[  \alpha\right]  $
for every $\alpha\in Q$. In other words, $\left(  \psi\mid_{T}\right)  \left(
T\left[  \alpha\right]  \right)  \subseteq\mathfrak{g}^{\prime}\left[
\alpha\right]  $ for every $\alpha\in Q$. Thus, the map $\psi\mid_{T}$ is
$Q$-graded. Proposition \ref{prop.generation.Q-gr} (applied to
$\widetilde{\mathfrak{g}}$, $\mathfrak{g}^{\prime}$ and $\psi$ instead of
$\mathfrak{g}$, $\mathfrak{h}$ and $f$) now yields that $\psi$ is $Q$-graded,
qed.}. As a consequence, $\operatorname*{Ker}\psi$ is a $Q$-graded Lie ideal
of $\widetilde{\mathfrak{g}}$.
\end{verlong}

Define $\widetilde{\mathfrak{h}}$, $I$ and $\iota_{0}$ as in Theorem
\ref{thm.gtilde}. Then, $\widetilde{\mathfrak{h}}$ is the free vector space
with basis $h_{1},h_{2},...,h_{n}$. Thus, the vector space
$\widetilde{\mathfrak{h}}$ is spanned by $h_{1},h_{2},...,h_{n}$. As a
consequence, the vector space $\iota_{0}\left(  \widetilde{\mathfrak{h}%
}\right)  $ is spanned by $h_{1},h_{2},...,h_{n}$ (since $\iota_{0}$ maps the
elements $h_{1},h_{2},...,h_{n}$ of $\widetilde{\mathfrak{h}}$ to the elements
$h_{1},h_{2},...,h_{n}$ of $\widetilde{\mathfrak{g}}$). Now, it is easy to see
that $\left(  \operatorname*{Ker}\psi\right)  \cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =0$\ \ \ \ \footnote{\textit{Proof.} Let
$x\in\left(  \operatorname*{Ker}\psi\right)  \cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $. Then, $x\in\operatorname*{Ker}\psi$ and
$x\in\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $. Since $x\in\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  $, there exist some elements
$\lambda_{1}$, $\lambda_{2}$, $...$, $\lambda_{n}$ of $\mathbb{C}$ such that
$x=\lambda_{1}h_{1}+\lambda_{2}h_{2}+...+\lambda_{n}h_{n}$ (since the vector
space $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ is spanned by
$h_{1},h_{2},...,h_{n}$). Consider these $\lambda_{1}$, $\lambda_{2}$, $...$,
$\lambda_{n}$. Since $x\in\operatorname*{Ker}\psi$, we have $\psi\left(
x\right)  =0$, so that%
\begin{align*}
0  &  =\psi\left(  x\right)  =\psi\left(  \lambda_{1}h_{1}+\lambda_{2}%
h_{2}+...+\lambda_{n}h_{n}\right)  =\lambda_{1}\psi\left(  h_{1}\right)
+\lambda_{2}\psi\left(  h_{2}\right)  +...+\lambda_{n}\psi\left(  h_{n}\right)
\\
&  =\lambda_{1}h_{1}+\lambda_{2}h_{2}+...+\lambda_{n}h_{n}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\psi\left(  h_{i}\right)
=h_{i}\text{ for every }i\in\left\{  1,2,...,n\right\}  \right)
\end{align*}
in $\mathfrak{g}^{\prime}$. But since the elements $h_{1}$, $h_{2}$, $...$,
$h_{n}$ of $\mathfrak{g}^{\prime}$ are linearly independent (because the
vector space $\mathfrak{g}^{\prime}\left[  0\right]  $ has $\left(
h_{1},h_{2},...,h_{n}\right)  $ as a $\mathbb{C}$-vector space basis), this
yields that $\lambda_{1}=\lambda_{2}=...=\lambda_{n}=0$. Thus, $x=\lambda
_{1}h_{1}+\lambda_{2}h_{2}+...+\lambda_{n}h_{n}$ becomes $x=0h_{1}%
+0h_{2}+...+0h_{n}=0$.
\par
Now forget that we fixed $x$. We thus have seen that every $x\in\left(
\operatorname*{Ker}\psi\right)  \cap\iota_{0}\left(  \widetilde{\mathfrak{h}%
}\right)  $ satisfies $x=0$. In other words, $\left(  \operatorname*{Ker}%
\psi\right)  \cap\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  =0$, qed.}.
Hence, $\operatorname*{Ker}\psi$ is a $Q$-graded Lie ideal of
$\widetilde{\mathfrak{g}}$ which has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $.

But $I$ is the sum of all $Q$-graded ideals in $\widetilde{\mathfrak{g}}$
which have zero intersection with $\iota_{0}\left(  \widetilde{\mathfrak{h}%
}\right)  $. Thus, every $Q$-graded ideal of $\widetilde{\mathfrak{g}}$ which
has zero intersection with $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)
$ must be a subset of $I$. Since $\operatorname*{Ker}\psi$ is a $Q$-graded Lie
ideal of $\widetilde{\mathfrak{g}}$ which has zero intersection with
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $, this yields that
$\operatorname*{Ker}\psi\subseteq I$.

We will now prove the reverse inclusion, i. e., we will show that
$I\subseteq\operatorname*{Ker}\psi$.

We know that $I$ is $Q$-graded (by Theorem \ref{thm.gtilde} \textbf{(h)}).
Since $\psi$ is $Q$-graded, this yields that $\psi\left(  I\right)  $ is a
$Q$-graded vector subspace of $\mathfrak{g}^{\prime}$. On the other hand,
since $I$ is $Q$-graded, we have $I\left[  0\right]  =I\cap\underbrace{\left(
\widetilde{\mathfrak{g}}\left[  0\right]  \right)  }_{\substack{=\iota
_{0}\left(  \widetilde{\mathfrak{h}}\right)  \\\text{(by Theorem
\ref{thm.gtilde} \textbf{(e)})}}}=I\cap\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  =0$ (since Theorem \ref{thm.gtilde}
\textbf{(h)} yields that $I$ has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $).

Since $\mathfrak{g}^{\prime}$ is a contragredient Lie algebra, the condition
\textbf{(3)} of Definition \ref{def.contragredient} is satisfied for
$\mathfrak{g}^{\prime}$. In other words, every nonzero $Q$-graded ideal in
$\mathfrak{g}^{\prime}$ has a nonzero intersection with $\mathfrak{g}^{\prime
}\left[  0\right]  $. Since $I$ is an ideal of $\widetilde{\mathfrak{g}}$, the
image $\psi\left(  I\right)  $ is an ideal of $\mathfrak{g}^{\prime}$ (because
$\psi$ is a surjective homomorphism of Lie algebras, and because the image of
an ideal under a \textbf{surjective} homomorphism of Lie algebras must always
be an ideal of the target Lie algebra). Assume that $\psi\left(  I\right)
\neq0$. Clearly, $\psi\left(  I\right)  $ is $Q$-graded (since $I$ is
$Q$-graded (by Theorem \ref{thm.gtilde} \textbf{(h)}) and since $\psi$ is
$Q$-graded). Thus, $\psi\left(  I\right)  $ is a nonzero $Q$-graded ideal in
$\mathfrak{g}^{\prime}$. Thus, $\psi\left(  I\right)  $ has a nonzero
intersection with $\mathfrak{g}^{\prime}\left[  0\right]  $ (because every
nonzero $Q$-graded ideal in $\mathfrak{g}^{\prime}$ has a nonzero intersection
with $\mathfrak{g}^{\prime}\left[  0\right]  $). In other words, $\psi\left(
I\right)  \cap\left(  \mathfrak{g}^{\prime}\left[  0\right]  \right)  \neq0$.

The following is a known and easy fact from linear algebra: If $A$ and $B$ are
two $Q$-graded vector spaces, and $\Phi:A\rightarrow B$ is a $Q$-graded linear
map, then $\Phi\left(  A\left[  \beta\right]  \right)  =\left(  \Phi\left(
A\right)  \right)  \left[  \beta\right]  $ for every $\beta\in Q$. Applying
this fact to $A=I$, $B=\mathfrak{g}^{\prime}$, $\Phi=\psi$ and $\beta=0$, we
obtain $\psi\left(  I\left[  0\right]  \right)  =\left(  \psi\left(  I\right)
\right)  \left[  0\right]  $. But since $I\left[  0\right]  =0$, this rewrites
as $\psi\left(  0\right)  =\left(  \psi\left(  I\right)  \right)  \left[
0\right]  $. Hence, $\left(  \psi\left(  I\right)  \right)  \left[  0\right]
=\psi\left(  0\right)  =0$.

But since $\psi\left(  I\right)  $ is a $Q$-graded vector subspace of
$\mathfrak{g}^{\prime}$, we have $\psi\left(  I\right)  \cap\left(
\mathfrak{g}^{\prime}\left[  0\right]  \right)  =\left(  \psi\left(  I\right)
\right)  \left[  0\right]  =0$. This contradicts the fact that $\psi\left(
I\right)  \cap\left(  \mathfrak{g}^{\prime}\left[  0\right]  \right)  \neq0$.
Hence, our assumption (that $\psi\left(  I\right)  \neq0$) must have been
wrong. In other words, $\psi\left(  I\right)  =0$, so that $I\subseteq
\operatorname*{Ker}\psi$. Combined with $\operatorname*{Ker}\psi\subseteq I$,
this yields $I=\operatorname*{Ker}\psi$.

Since the $Q$-graded Lie algebra homomorphism $\psi:\widetilde{\mathfrak{g}%
}\rightarrow\mathfrak{g}^{\prime}$ is surjective, it factors (according to the
homomorphism theorem) through a $Q$-graded Lie algebra isomorphism
$\widetilde{\mathfrak{g}}\diagup\left(  \operatorname*{Ker}\psi\right)
\rightarrow\mathfrak{g}^{\prime}$. Since $\widetilde{\mathfrak{g}}%
\diagup\underbrace{\left(  \operatorname*{Ker}\psi\right)  }_{=I}%
=\widetilde{\mathfrak{g}}\diagup I=\mathfrak{g}$, this means that $\psi$
factors through a $Q$-graded Lie algebra isomorphism $\mathfrak{g}%
\rightarrow\mathfrak{g}^{\prime}$. This $Q$-graded Lie algebra isomorphism
$\mathfrak{g}\rightarrow\mathfrak{g}^{\prime}$ clearly sends the generators
$e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$,
$h_{2}$, $...$, $h_{n}$ of $\mathfrak{g}$ to the respective generators $e_{1}%
$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}%
$, $...$, $h_{n}$ of $\mathfrak{g}^{\prime}$.

We have thus proven that there exists a $Q$-graded Lie algebra isomorphism
$\mathfrak{g}\rightarrow\mathfrak{g}^{\prime}$ which sends the generators
$e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$,
$h_{2}$, $...$, $h_{n}$ of $\mathfrak{g}$ to the respective generators $e_{1}%
$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$, $h_{2}%
$, $...$, $h_{n}$ of $\mathfrak{g}^{\prime}$. This completes the proof of
Theorem \ref{thm.g(A).exuni} \textbf{(a)}.

\textbf{(b)} Let $A$ be the Cartan matrix of a simple finite-dimensional Lie
algebra. Clearly it is enough to prove that this Lie algebra is a
contragredient Lie algebra corresponding to $A$, that is, is generated by
$e_{1}$, $e_{2}$, $...$, $e_{n}$, $f_{1}$, $f_{2}$, $...$, $f_{n}$, $h_{1}$,
$h_{2}$, $...$, $h_{n}$ as a Lie algebra and satisfies the conditions
\textbf{(1)}, \textbf{(2)} and \textbf{(3)} of Definition
\ref{def.contragredient}. But this follows from the standard theory of roots
of simple finite-dimensional Lie algebras\footnote{For instance, condition
\textbf{(3)} follows from the fact that the Lie algebra in question is simple
and thus contains no ideals other than $0$ and itself.}. Theorem
\ref{thm.g(A).exuni} \textbf{(b)} is thus proven.

\begin{remark}
Let $A=\left(  a_{i,j}\right)  _{1\leq i,j\leq n}$ be a complex $n\times n$
matrix such that every $i\in\left\{  1,2,...,n\right\}  $ satisfies
$a_{i,i}=2$. One can show that the Lie algebra $\mathfrak{g}\left(  A\right)
$ is finite-dimensional if and only if $A$ is the Cartan matrix of a
semisimple finite-dimensional Lie algebra. (In this case, $\mathfrak{g}\left(
A\right)  $ is exactly this semisimple Lie algebra, and the ideal $I$ of
Theorem \ref{thm.gtilde} is generated by the left hand sides $\left(
\operatorname*{ad}\left(  e_{i}\right)  \right)  ^{1-a_{i,j}}e_{j}$ and
$\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j}$
of the Serre relations.)
\end{remark}

[...]

[Add something about the total degree on $\widetilde{\mathfrak{g}}$, since
this will later be used for the bilinear form. $\widetilde{\mathfrak{g}%
}\left[  \operatorname*{tot}0\right]  =\widetilde{\mathfrak{g}}\left[
0\right]  =\widetilde{\mathfrak{h}}$, $\widetilde{\mathfrak{g}}\left[
\operatorname*{tot}<0\right]  ...$, $\widetilde{\mathfrak{g}}\left[  1\right]
=...$]

\begin{remark}
\label{rmk.g(A+A)}Let $A_{1}$ and $A_{2}$ be two square complex matrices. As
usual, we denote by $A_{1}\oplus A_{2}$ the block-diagonal matrix $\left(
\begin{array}
[c]{cc}%
A_{1} & 0\\
0 & A_{2}%
\end{array}
\right)  $. Then, $\mathfrak{g}\left(  A_{1}\oplus A_{2}\right)
\cong\mathfrak{g}\left(  A_{1}\right)  \oplus\mathfrak{g}\left(  A_{2}\right)
$ as Lie algebras naturally.
\end{remark}

\textit{Proof of Remark \ref{rmk.g(A+A)} (sketched).} Say $A_{1}$ is an
$\ell\times\ell$ matrix, and $A_{2}$ is an $m\times m$ matrix. Let $n=\ell+m$
and $A=A_{1}\oplus A_{2}$. Introduce the notations $\widetilde{\mathfrak{g}}$,
$\widetilde{\mathfrak{h}}$, $\widetilde{\mathfrak{n}}_{+}$,
$\widetilde{\mathfrak{n}}_{-}$, $\iota_{0}$, $\iota_{+}$, $\iota_{-}$ and $I$
as in Theorem \ref{thm.gtilde}. Let $\mathfrak{j}_{+}$ be the ideal of the Lie
algebra $\widetilde{\mathfrak{n}}_{+}$ generated by all elements of the form
$\left[  e_{i},e_{j}\right]  $ with $i\in\left\{  1,2,...,\ell\right\}  $ and
$j\in\left\{  \ell+1,\ell+2,...,n\right\}  $. Let $\mathfrak{j}_{-}$ be the
ideal of the Lie algebra $\widetilde{\mathfrak{n}}_{-}$ generated by all
elements of the form $\left[  f_{i},f_{j}\right]  $ with $i\in\left\{
1,2,...,\ell\right\}  $ and $j\in\left\{  \ell+1,\ell+2,...,n\right\}  $.
Prove that $\iota_{+}\left(  \mathfrak{j}_{+}\right)  $ and $\iota_{-}\left(
\mathfrak{j}_{-}\right)  $ are actually $Q$-graded ideals of
$\widetilde{\mathfrak{g}}$ (and not only of $\iota_{+}\left(
\widetilde{\mathfrak{n}}_{+}\right)  $ and $\iota_{-}\left(
\widetilde{\mathfrak{n}}_{-}\right)  $), so that both $\iota_{+}\left(
\mathfrak{j}_{+}\right)  $ and $\iota_{-}\left(  \mathfrak{j}_{-}\right)  $
are subsets of $I$. For every $i\in\left\{  1,2\right\}  $, let
$\widetilde{\mathfrak{g}}_{i}$ be the Lie algebra constructed analogously to
$\widetilde{\mathfrak{g}}$ but for the matrix $A_{i}$ instead of $A$. Notice
that $\widetilde{\mathfrak{g}}\diagup\left(  \iota_{+}\left(  \mathfrak{j}%
_{+}\right)  +\iota_{-}\left(  \mathfrak{j}_{-}\right)  \right)
\cong\widetilde{\mathfrak{g}}_{1}\oplus\widetilde{\mathfrak{g}}_{2}$. Conclude
the proof by noticing that if $J$ is a $Q$-graded ideal in
$\widetilde{\mathfrak{g}}$ which has zero intersection with $\iota_{0}\left(
\widetilde{\mathfrak{h}}\right)  $, and $K$ is the sum of all $Q$-graded
ideals in $\widetilde{\mathfrak{g}}\diagup J$ which have zero intersection
with the projection of $\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ on
$\widetilde{\mathfrak{g}}\diagup J$, then $\left(  \widetilde{\mathfrak{g}%
}\diagup J\right)  \diagup K\cong\widetilde{\mathfrak{g}}\diagup
I=\mathfrak{g}$. The details are left to the reader.

\subsection{\textbf{[unfinished]} Kac-Moody algebras for generalized Cartan
matrices}

For general $A$, we do not know much about $\mathfrak{g}\left(  A\right)  $;
its definition was not even constructive (find that $I$ !). It is not known in
general how to obtain generators for $I$. But for some particular cases -- not
only Cartan matrices of semisimple Lie algebras --, things behave well. Here
is the most important such case:

\begin{definition}
An $n\times n$ matrix $A=\left(  a_{i,j}\right)  _{1\leq i,j\leq n}$ of
complex numbers is said to be a \textit{generalized Cartan matrix} if it satisfies:

\textbf{(1)} We have $a_{i,i}=2$ for all $i\in\left\{  1,2,...,n\right\}  $.

\textbf{(2)} For every $i$ and $j$, the number $a_{i,j}$ is a nonpositive
integer. Also, $a_{i,j}=0$ if and only if $a_{j,i}=0$.

\textbf{(3)} The matrix $A$ is symmetrizable, i. e., there exists a diagonal
matrix $D>0$ such that $\left(  DA\right)  ^{T}=DA$.
\end{definition}

Note that a Cartan matrix is the same as a generalized Cartan matrix $A$ with
$DA>0$.

\begin{example}
Let $A=\left(
\begin{array}
[c]{cc}%
2 & -m\\
-1 & 2
\end{array}
\right)  $ for $m\geq1$. This matrix $A$ is a generalized Cartan matrix, since
$\left(
\begin{array}
[c]{cc}%
1 & 0\\
0 & m
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
2 & -m\\
-1 & 2
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
2 & -m\\
-m & 2m
\end{array}
\right)  $. Note that $\det\left(
\begin{array}
[c]{cc}%
2 & -m\\
-1 & 2
\end{array}
\right)  =4-m$.

For $m=1$, we have $\mathfrak{g}\left(  A\right)  \cong A_{2}=\mathfrak{sl}%
_{3}$.

For $m=2$, we have $\mathfrak{g}\left(  A\right)  \cong B_{2}\cong C_{2}%
\cong\mathfrak{sp}_{4}\cong\mathfrak{so}_{5}$.

For $m=3$, we have $\mathfrak{g}\left(  A\right)  \cong G_{2}$.

For $m\geq4$, the Lie algebra $\mathfrak{g}\left(  A\right)  $ is infinite-dimensional.

For $m=4$, it is a twisted version of $\widehat{\mathfrak{sl}_{2}}$, called
$A_{2}^{2}$.

For $m\geq5$, the Lie algebra $\mathfrak{g}\left(  A\right)  $ is big (in the
sense of having exponential growth).

This strange behaviour is related to the behaviour of the $m$-subspaces
problem (finite for $m\leq3$, tame for $m=4$, wild for $m\geq5$). More
generally, Kac-Moody algebras are related to representation theory of quivers.
\end{example}

\begin{definition}
A \textit{symmetrizable Kac-Moody algebra} is a Lie algebra of the form
$\mathfrak{g}\left(  A\right)  $ for a generalized Cartan matrix $A$.
\end{definition}

\begin{theorem}
[Gabber-Kac]\label{thm.g(A).gabber-kac}If $A$ is a generalized Cartan matrix,
then the ideal $I\subseteq\widetilde{\mathfrak{g}}\left(  A\right)  $ is
generated by the Serre relations (where the notation $I$ comes from Theorem
\ref{thm.gtilde}).
\end{theorem}

\textit{Partial proof of Theorem \ref{thm.g(A).gabber-kac}.} Proving this
theorem requires showing two assertions: first, that the Serre relations are
contained in $I$; second, that they actually generate $I$. We will only prove
the first of these two assertions.

Set $I_{+}=I\cap\widetilde{\mathfrak{n}}_{+}$ and $I_{-}=I\cap
\widetilde{\mathfrak{n}}_{-}$. Denote $\widetilde{\mathfrak{g}}\left(
A\right)  $ by $\widetilde{\mathfrak{g}}$ as in Theorem \ref{thm.gtilde}.

We know (from Theorem \ref{thm.gtilde} \textbf{(h)}) that $I$ is a $Q$-graded
ideal in $\widetilde{\mathfrak{g}}$ which has zero intersection with
$\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ (where the notations are
those of Theorem \ref{thm.gtilde}). Since $\widetilde{\mathfrak{g}}\left[
0\right]  =\iota_{0}\left(  \widetilde{\mathfrak{h}}\right)  $ (by Theorem
\ref{thm.gtilde} \textbf{(e)}), this rewrites as follows: $I$ is a $Q$-graded
ideal in $\widetilde{\mathfrak{g}}$ which has zero intersection with
$\widetilde{\mathfrak{g}}\left[  0\right]  $. Thus, $I=I_{+}\oplus I_{-}$.

Let us show that $\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)
^{1-a_{i,j}}f_{j}\in I_{-}$.

To do that, it is sufficient to show that $\left[  e_{k},\left(
\operatorname*{ad}\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j}\right]  =0$
for all $k$. (If we grade $\widetilde{\mathfrak{g}}$ by setting $\deg\left(
f_{i}\right)  =-1$, $\deg\left(  e_{i}\right)  =1$ and $\deg\left(
h_{i}\right)  =0$ (this is called the \textit{principal grading}), then
$f_{k}$ can only lower degree, so that the Lie ideal generated by $\left(
\operatorname*{ad}\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j}$ will lie
entirely in negative degrees, and thus $\left(  \operatorname*{ad}\left(
f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j}$ will lie in $I_{-}$.)

\textit{Case 1:} We have $k\neq i,j$. This case is clear since $e_{k}$
commutes with $f_{i}$ and $f_{j}$ (by our relations).

\textit{Case 2:} We have $k=j$. In this case,
\begin{align*}
\left[  e_{k},\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)
^{1-a_{i,j}}f_{j}\right]   &  =\left[  e_{j},\left(  \operatorname*{ad}\left(
f_{i}\right)  \right)  ^{1-a_{i,j}}f_{j}\right]  =\left(  \operatorname*{ad}%
\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}\left(  \left[  e_{j},f_{j}\right]
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\operatorname*{ad}\left(
f_{i}\right)  \text{ and }\operatorname*{ad}\left(  e_{j}\right)  \text{
commute, due to }i\neq j\right) \\
&  =\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)  ^{1-a_{i,j}}%
h_{j}.
\end{align*}
We now distinguish between two cases according to whether $a_{i,j}$ is $=0$ or
$<0$:

\textit{Case 2a:} We have $a_{i,j}=0$. Then, $a_{j,i}=0$ by the definition of
generalized Cartan matrices. Thus, $\left[  f_{i},h_{j}\right]  =-\left[
h_{j},f_{i}\right]  =-a_{j,i}f_{i}=0$, and we are done.

\textit{Case 2b:} We have $a_{i,j}<0$. Then, $1-a_{i,j}\geq2$. Now, $\left(
\operatorname*{ad}\left(  f_{i}\right)  \right)  ^{2}h_{j}=\left(
\operatorname*{ad}\left(  f_{i}\right)  \right)  \left(  cf_{i}\right)  =0$
for some constant $c$.

\textit{Case 3:} We have $k=i$. Let $\left(  \mathfrak{sl}_{2}\right)
_{i}=\left\langle e_{i},f_{i},h_{i}\right\rangle $. Let $M$ be the $\left(
\mathfrak{sl}_{2}\right)  _{i}$-submodule in $\widetilde{\mathfrak{g}}\left(
A\right)  $ generated by $f_{j}$.

We have $\left[  h_{i},f_{j}\right]  =-a_{i,j}f_{j}=mf_{j}$, where
$m=-a_{i,j}\geq0$. Together with $\left[  e_{i},f_{j}\right]  =0$, this shows
that $f_{j}=:v$ is a highest-weight vector of $M$ with weight $m$. Thus,
$f_{i}^{m+1}v=\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)
^{1-a_{i,j}}f_{j}$ is a singular vector for $\left(  \mathfrak{sl}_{2}\right)
_{i}$ (by representation theory of $\mathfrak{sl}_{2}$\ \ \ \ \footnote{What
we are using is the following: Consider the module $M_{\lambda}=\mathbb{C}%
\left[  f\right]  v$ over $\mathfrak{sl}_{2}$. Then, $ef^{n}v=n\left(
\lambda-n+1\right)  f^{n-1}v$. Thus, when $n=m+1$ and $\lambda=m$, we get
$ef^{n}v=0$.}).

So much for our part of the proof of Theorem \ref{thm.g(A).gabber-kac}.

Of course, simple Lie algebras are Kac-Moody algebras. The next class of
Kac-Moody algebras we are interested in is the \textit{affine Lie algebras}:

\begin{remark}
Let $\sigma\in S_{n}$ be a permutation, and $A$ be an $n\times n$ complex
matrix. Then, $\mathfrak{g}\left(  A\right)  \cong\mathfrak{g}\left(  \sigma
A\sigma^{-1}\right)  $.
\end{remark}

\begin{definition}
A generalized Cartan matrix $A$ is said to be \textit{indecomposable} if it
cannot be written in the form $\sigma\left(  A_{1}\oplus A_{2}\right)
\sigma^{-1}$ for some permutation $\sigma$ and nontrivial square matrices
$A_{1}$ and $A_{2}$. Due to the above remark and to Remark \ref{rmk.g(A+A)},
we need to only consider indecomposable generalized Cartan matrices.
\end{definition}

\begin{definition}
A generalized Cartan matrix $A$ is said to be \textit{affine} if $DA\geq0$ but
$DA\not >  0$ (thus, $\det\left(  DA\right)  =0$).
\end{definition}

\begin{definition}
If $A$ is an affine generalized Cartan matrix, then $\mathfrak{g}\left(
A\right)  $ is called an \textit{affine Kac-Moody algebra}.
\end{definition}

Now let $A$ be the (usual) Cartan matrix of a simple Lie algebra, and let
$\mathfrak{g}=\mathfrak{g}\left(  A\right)  $ be this simple Lie algebra. Let
$L\mathfrak{g}=\mathfrak{g}\left[  t,t^{-1}\right]  $, and let
$\widehat{\mathfrak{g}}=L\mathfrak{g}\oplus\mathbb{C}K$ as defined long ago.

\begin{theorem}
This $\widehat{\mathfrak{g}}$ is an affine Kac-Moody algebra with generalized
Cartan matrix $\widetilde{A}$ whose $\left(  1,1\right)  $-entry is $2$ and
whose submatrix obtained by omitting the first row and the first column is
$A$. (We do not yet say what the remaining entries are.)
\end{theorem}

\textit{Proof of Theorem.} Let $\mathfrak{h}$ be the Cartan subalgebra of
$\mathfrak{g}$. Let $r=\dim\mathfrak{h}$; thus, $r$ is the rank of
$\mathfrak{g}$. Let $\left(  h_{1},h_{2},...,h_{r}\right)  $ be a
corresponding basis of $\mathfrak{h}$, and let $e_{i},f_{i}$ be standard
generators for every $i\in\left\{  1,2,...,r\right\}  $.

Let $\theta$ be the maximal root.

Let us now define elements $e_{0}=f_{\theta}\cdot t$, $f_{0}=e_{\theta}\cdot
t^{-1}$ and $h_{0}=\left[  e_{0},f_{0}\right]  =-h_{\theta}%
+\underbrace{\left(  f_{\theta},e_{\theta}\right)  }_{=1\text{ (due to our
normalization)}}K=K-h_{\theta}$ of $\widehat{\mathfrak{g}}$ (the commutator is
computed in $\widehat{\mathfrak{g}}$, not in $L\mathfrak{g}$).

Add these elements to our system of generators.

Why do we then get a system of generators of $\widehat{\mathfrak{g}}$ ?

First, $h_{i}$ for $i\in\left\{  0,1,...,r\right\}  $ are a basis of
$\widehat{\mathfrak{h}}=\mathfrak{h}\oplus\mathbb{C}K$.

Also, $\mathfrak{g}t^{0}$ is generated by $e_{i},f_{i},h_{i}$ for
$i\in\left\{  1,2,...,r\right\}  $. Now, $\mathfrak{g}t^{1}$ is an irreducible
$\mathfrak{g}$-module with lowest-weight vector $f_{\theta}\cdot t$.

$\Longrightarrow$ $U\left(  \mathfrak{g}\right)  \cdot f_{\theta
}t=\mathfrak{g}t$. Now, $\mathfrak{g}t$ generates $\mathfrak{g}t\mathbb{C}%
\left[  t\right]  $ (since $\left[  \mathfrak{g},\mathfrak{g}\right]
=\mathfrak{g}$). Similarly, $U\left(  \mathfrak{g}\right)  \cdot e_{\theta
}t^{-1}=\mathfrak{g}t^{-1}$, and $\mathfrak{g}t^{-1}$ generates $\mathfrak{g}%
t^{-1}\mathbb{C}\left[  t^{-1}\right]  $. $\Longrightarrow$ our $e_{i}$,
$f_{i}$, $h_{i}$ (including $i=0$) generate all of $\widehat{\mathfrak{g}}$.

Now to the relations.

$\left[  h_{i},h_{j}\right]  =0$ is clear for all $\left(  i,j\right)
\in\left\{  0,1,...,r\right\}  ^{2}$.

We have $\left[  h_{0},e_{0}\right]  =\left[  K-h_{\theta},f_{\theta}t\right]
=-\left[  h_{\theta},f_{\theta}\right]  t=2f_{\theta}t=2e_{0}$.

We have $\left[  h_{0},f_{0}\right]  =-2f_{0}$ similarly.

We have $\left[  e_{0},f_{0}\right]  =h_{0}$.

We have $\left[  h_{0},e_{i}\right]  =\left[  K-h_{\theta},e_{i}\right]
=-\alpha_{i}\left(  h_{\theta}\right)  e_{i}=-\left(  \alpha_{i}%
,\theta\right)  e_{i}$ $\Longrightarrow$ $a_{0,i}=-\left(  \alpha_{i}%
,\theta\right)  =\left(  \text{some nonpositive integer}\right)  $.

We have $\left[  h_{0},f_{i}\right]  =\left(  \alpha_{i},\theta\right)  f_{i}%
$, same argument.

We have $\left[  h_{i},e_{0}\right]  =\left[  h_{i},f_{\theta}t\right]
=-\theta\left(  h_{i}\right)  f_{\theta}t=-\theta\left(  h_{i}\right)
e_{0}=-\left(  \alpha_{i}^{\vee},\theta\right)  e_{0}$ (where $\alpha
_{i}^{\vee}=\dfrac{2\alpha_{i}}{\left(  \alpha_{i},\alpha_{i}\right)  }$)
$\Longrightarrow$ $a_{i,0}=-\left(  \alpha_{i}^{\vee},\theta\right)  $.

We have $\left[  h_{i},f_{0}\right]  =\left(  \alpha_{i}^{\vee},\theta\right)
f_{0}$, same argument.

We have $\left[  e_{0},f_{i}\right]  =\left[  f_{\theta}t,f_{i}\right]  =0$.

We have $\left[  e_{i},f_{0}\right]  =\left[  e_{i},e_{\theta}t^{-1}\right]
=0$.

Thus, all basic relations are satisfied.

Now let us define a grading: $\widehat{Q}=Q\oplus\mathbb{Z}\delta$, where $Q$
is the root lattice of $\mathfrak{g}$. Define $\alpha_{0}=\delta-\theta$.
$\delta\mid_{\widehat{\mathfrak{h}}}=0$. So if we think of $\alpha_{0}$ as an
element of $\widehat{\mathfrak{h}}^{\ast}$, then $\alpha_{0},\alpha
_{1},...,\alpha_{r}$ is neither linearly independent nor spanning. So the
direct sum $Q\oplus\mathbb{Z}\delta$ is an external direct sum, not an
internal one!!

$\widehat{Q}$-grading: $\deg\left(  e_{i}\right)  =\alpha_{i}$, $\deg\left(
f_{i}\right)  =-\alpha_{i}$ and $\deg\left(  h_{i}\right)  =0$ for
$i=0,1,...,r$. Also $\deg\left(  at^{k}\right)  =\deg a+k\delta$ (so, so to
speak, ``$\deg t=\delta$'').

So we have $\widehat{\mathfrak{g}}\left[  0\right]  =\widehat{\mathfrak{h}}$
and $\widehat{\mathfrak{g}}\left[  \alpha_{i}\right]  =\left\langle
e_{i}\right\rangle $ and $\widehat{\mathfrak{g}}\left[  -\alpha_{i}\right]
=\left\langle f_{i}\right\rangle $.

Note (which we won't use): $\left[  h,a\right]  =\alpha\left(  h\right)  a$,
$a\in\widehat{\mathfrak{g}}\left[  \alpha\right]  $ ``if you define things
this way''.

The only thing we now have to do is to show that $I=0$ in
$\widehat{\mathfrak{g}}$.

Let $\overline{I}$ be the projection of $I$ to $L\mathfrak{g}%
=\widehat{\mathfrak{g}}\diagup\left(  K\right)  $. Clearly, $\overline{I}%
\cap\mathfrak{h}=0$.

We must prove that $\overline{I}=0$.

But there is a \textbf{claim} that any $\widehat{Q}$-graded ideal in
$L\mathfrak{g}$ is $0$ or $L\mathfrak{g}$. (\textit{Proof:} If $J$ is a
$\widehat{Q}$-graded ideal of $L\mathfrak{g}$ different from $0$, then there
exists a nonzero $a\in\mathfrak{g}$ and an $m\in\mathbb{Z}$ such that
$at^{m}\in J$. But $at^{m}$ generates $L\mathfrak{g}$ under the action of
$L\mathfrak{g}$, since $\left[  bt^{n-m},at^{m}\right]  =\left[  b,a\right]
t^{n}$ and $\mathfrak{g}=\left[  \mathfrak{g},\mathfrak{g}\right]  $.)

Proof of Theorem complete.

Let us show how Dynkin diagrams look like for these affine Kac-Moody algebras.

Consider the case of $A_{n-1}=\mathfrak{sl}_{n}$. Then, $\theta=\left(
1,0,0,...,0,-1\right)  $. Also, $\alpha_{1}=\left(  1,-1,0,0,...,0\right)  $,
$\alpha_{2}=\left(  0,1,-1,0,0,...,0\right)  $, $...$, $\alpha_{n-1}=\left(
0,0,...,0,1,-1\right)  $. Also, $\alpha=\alpha^{\vee}$ for all simple roots
$\alpha$. We thus have $\left(  \theta,\alpha_{i}\right)  =1$ if $\alpha
\in\left\{  1,n-1\right\}  $ and $=0$ otherwise. The Dynkin diagram of
$\widehat{A_{n-1}}=A_{n-1}^{1}=\widehat{\mathfrak{sl}_{n}}$ (these are just
three notations for one and the same thing) is thus $%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
%{-}[r] & \circ\ar@{-}[r] & \circ}}}%
%BeginExpansion
\xymatrix{
\circ\ar@{-}[r] & \circ\ar@{-}[r] & \circ\ar@{}[r]|-{...} & \circ\ar@
{-}[r] & \circ\ar@{-}[r] & \circ}%
%EndExpansion
$ with a cyclically connected dot underneath.

The case $n=2$ is special: double link. $\circ=\circ$ double link.

Now let us consider other types. Suppose that $\theta$ is a fundamental
weight, i. e., satisfies $\left(  \theta,\alpha_{i}^{\vee}\right)  =1$ for
some $i$ and satisfies $\left(  \theta,\alpha_{i}^{\vee}\right)  =0$ for all
other $i$. (This happens for a lot of simple Lie algebras.)

To get $\widehat{D_{n}}=\widehat{\mathfrak{so}_{2n}}$, need to attach a new
vertex to the second vertex from the left.

To get $\widehat{C_{n}}=\widehat{\mathfrak{sp}_{2n}}$, need to attach a new
vertex \textbf{doubly-linked} to the first vertex from the left. (The arrow
points to the right, i. e., to the $C_{n}$ diagram.)

For $\widehat{G_{2}}$, attach a vertex on the left (where the arrow points to
the right).

For $\widehat{F_{4}}$, attach a vertex on the left (where the arrow points to
the right).

For $\widehat{E_{6}}$, attach a vertex to the ``bottom'' (the vertex off the line).

For $\widehat{E_{7}}$, attach a vertex to the short leg (to make the graph symmetric).

For $\widehat{E_{8}}$, attach a vertex to the long leg.

These are untwisted affine Lie algebras ($\widehat{\mathfrak{g}}$).

There are also twisted ones: $A_{2}^{2}$ with Cartan matrix $\left(
\begin{array}
[c]{cc}%
2 & -4\\
-1 & 2
\end{array}
\right)  $ and Dynkin diagram $\circ\left(  4\text{ arrows pointing
rightward}\right)  \circ$. We will not discuss this kind of Lie algebras here.

\subsection{\textbf{[unfinished]} Representation theory of
\texorpdfstring{$\mathfrak{g}\left(  A\right)  $}{g(A)}}

We will now work out the representation theory of $\mathfrak{g}\left(
A\right)  $.

Let us start with the case of $\mathfrak{g}\left(  A\right)  $ being
finite-dimensional. In contrast with usual courses on Lie algebras, we will
not restrict ourselves to finite-dimensional representations. We define a
Category $\mathcal{O}$ which is analogous but (in its details) somewhat
different from the one we defined above. In future, we will use only the new definition.

\begin{definition}
\label{def.O}The objects of \textit{category }$\mathcal{O}$ will be
$\mathfrak{g}$-modules $M$ such that:

\textbf{1)} The module $M$ is $\mathfrak{h}$-diagonalizable. By this we mean
that $M=\bigoplus\limits_{\mu\in\mathfrak{h}^{\ast}}M\left[  \mu\right]  $
(where $M\left[  \mu\right]  $ means the $\mu$-weight space of $M$), and every
$\mu\in\mathfrak{h}^{\ast}$ satisfies $\dim\left(  M\left[  \mu\right]
\right)  <\infty$.

\textbf{2)} Let $\operatorname*{Supp}M$ denote the set of all $\mu
\in\mathfrak{h}^{\ast}$ such that $M\left[  \mu\right]  \neq0$. Then, there
exist finitely many $\lambda_{1},\lambda_{2},...,\lambda_{n}\in\mathfrak{h}%
^{\ast}$ such that $\operatorname*{Supp}M\subseteq D\left(  \lambda
_{1}\right)  \cup D\left(  \lambda_{2}\right)  \cup...\cup D\left(
\lambda_{n}\right)  $, where for every $\lambda\in\mathfrak{h}^{\ast}$, we
denote by $D\left(  \lambda\right)  $ the subset%
\[
\left\{  \lambda-k_{1}\alpha_{1}-k_{2}\alpha_{2}-...-k_{r}\alpha_{r}%
\ \mid\ \left(  k_{1},k_{2},...,k_{r}\right)  \in\mathbb{N}^{r}\right\}
\ \ \ \ \ \ \ \ \ \ \text{of }\mathfrak{h}^{\ast}.
\]


The \textit{morphisms of category }$\mathcal{O}$ will be $\mathfrak{g}$-module homomorphisms.
\end{definition}

Examples of modules in Category $\mathcal{O}$ are Verma modules $M_{\lambda
}=M_{\lambda}^{+}$ and their irreducible quotients $L_{\lambda}$ (and all of
their quotients). Category $\mathcal{O}$ is an abelian category (in our case,
this simply means it is closed under taking subquotients and direct sums).

\begin{definition}
Let $M\in\mathcal{O}$ be a $\mathfrak{g}$-module. Then, the \textit{formal
character} of $M$ denotes the sum $\operatorname*{ch}M=\sum\limits_{\mu
\in\mathfrak{h}^{\ast}}\dim\left(  M\left[  \mu\right]  \right)  e^{\mu}$.
Here $\mathbb{C}\left[  \mathfrak{h}^{\ast}\right]  $ denotes the group
algebra of the additive group $\mathfrak{h}^{\ast}$, where this additive group
$\mathfrak{h}^{\ast}$ is written multiplicatively and every $\mu
\in\mathfrak{h}^{\ast}$ is renamed as $e^{\mu}$.

Where does this sum $\sum\limits_{\mu\in\mathfrak{h}^{\ast}}\dim\left(
M\left[  \mu\right]  \right)  e^{\mu}$ lie?

Let $\Gamma$ be a coset of $Q$ (the root lattice) in $\mathfrak{h}^{\ast}$.
Then, let $R_{\Gamma}$ denote the space $\lim\limits_{\mu\in\Gamma}e^{\mu
}\mathbb{C}\left[  \left[  e^{-\alpha_{1}},e^{-\alpha_{2}},...,e^{-\alpha_{r}%
}\right]  \right]  $ (this is a union, but not a disjoint union, since
$R_{\mu}\subseteq R_{\mu+\alpha_{i}}$ for all $i$ and $\mu$). Let
$R=\bigoplus\limits_{\Gamma\in\mathfrak{h}^{\ast}\diagup Q}R_{\Gamma}$. This
$R$ is a ring. We view $\operatorname*{ch}M$ as an element of $R$.
\end{definition}

Now, for an example, let us compute the formal character $\operatorname*{ch}%
\left(  M_{\lambda}\right)  $ of the Verma module $M_{\lambda}=U\left(
\mathfrak{n}_{-}\right)  v_{\lambda}$.

Recall that $U\left(  \mathfrak{n}_{-}\right)  $ has a
Poincar\'{e}-Birkhoff-Witt basis consisting of all elements of the form
$f_{\alpha^{\left(  1\right)  }}^{m_{1}}f_{\alpha^{\left(  2\right)  }}%
^{m_{2}}...f_{\alpha^{\left(  \ell\right)  }}^{m_{\ell}}$ where $\alpha
^{\left(  1\right)  },\alpha^{\left(  2\right)  },...,\alpha^{\left(
\ell\right)  }$ are all positive roots of $\mathfrak{g}$, and $\ell
=\dim\left(  \mathfrak{n}_{-}\right)  $. The weight of this element
$f_{\alpha^{\left(  1\right)  }}^{m_{1}}f_{\alpha^{\left(  2\right)  }}%
^{m_{2}}...f_{\alpha^{\left(  \ell\right)  }}^{m_{\ell}}$ is $-\left(
m_{1}\alpha^{\left(  1\right)  }+m_{2}\alpha^{\left(  2\right)  }+...+m_{\ell
}\alpha^{\left(  \ell\right)  }\right)  $. Thus, the weight of $f_{\alpha
^{\left(  1\right)  }}^{m_{1}}f_{\alpha^{\left(  2\right)  }}^{m_{2}%
}...f_{\alpha^{\left(  \ell\right)  }}^{m_{\ell}}v_{\lambda}$ is
$\lambda-\left(  m_{1}\alpha^{\left(  1\right)  }+m_{2}\alpha^{\left(
2\right)  }+...+m_{\ell}\alpha^{\left(  \ell\right)  }\right)  $.

Thus, $\dim\left(  M_{\lambda}\left[  \lambda-\beta\right]  \right)  $ is the
number of partitions of $\beta$ into positive roots. We denote this by
$p\left(  \beta\right)  $, and call $p$ the \textit{Kostant partition
function}.

Now, it is very easy (using geometric series) to see that%
\[
\sum\limits_{\beta\in Q_{+}}p\left(  \beta\right)  e^{-\beta}=\prod
\limits_{\substack{\alpha\text{ root;}\\a>0}}\dfrac{1}{1-e^{-\alpha}}.
\]
Thus,%
\[
\operatorname*{ch}\left(  M_{\lambda}\right)  =\sum\limits_{\beta\in Q_{+}%
}p\left(  \beta\right)  e^{\lambda-\beta}=e^{\lambda}\underbrace{\sum
\limits_{\beta\in Q_{+}}p\left(  \beta\right)  e^{-\beta}}_{=\prod
\limits_{\substack{\alpha\text{ root;}\\a>0}}\dfrac{1}{1-e^{-\alpha}}%
}=e^{\lambda}\prod\limits_{\substack{\alpha\text{ root;}\\a>0}}\dfrac
{1}{1-e^{-\alpha}}.
\]


\textbf{Example:} Let $\mathfrak{g}=\mathfrak{sl}_{2}$. Then,%
\[
\operatorname*{ch}\left(  M_{\lambda}\right)  =\dfrac{e^{\lambda}%
}{1-e^{-\alpha}}=e^{\lambda}+e^{\lambda-\alpha}+e^{\lambda-2\alpha}+....
\]
Classically, one identifies weights of $\mathfrak{sl}_{2}$ with elements of
$\mathbb{C}$ (by $\omega_{1}\mapsto1$ and thus $\alpha\mapsto2$). Write $x$
for $e^{\omega_{1}}$. Then,%
\[
\operatorname*{ch}\left(  M_{\lambda}\right)  =\dfrac{x^{\lambda}}{1-x^{-2}%
}=x^{\lambda}+x^{\lambda-2}+x^{\lambda-4}+....
\]
The quotient $L_{\lambda}$ has weights $\lambda$, $\lambda-2$, $...$,
$-\lambda$ and thus satisfies%
\[
\operatorname*{ch}\left(  L_{\lambda}\right)  =x^{\lambda}+x^{\lambda
-2}+...+x^{-\lambda}=\dfrac{x^{\lambda+1}-x^{-\lambda-1}}{x-x^{-1}}.
\]


Back to the general case of finite-dimensional $\mathfrak{g}\left(  A\right)
$. First of all, category $\mathcal{O}$ has tensor products, and they make it
into a tensor category.

\begin{proposition}
\textbf{1)} We have $\operatorname*{ch}\left(  M_{1}\otimes M_{2}\right)
=\operatorname*{ch}\left(  M_{1}\right)  \cdot\operatorname*{ch}\left(
M_{2}\right)  $.

\textbf{2)} If $N\subseteq M$ are both in $\mathcal{O}$, then
$\operatorname*{ch}M=\operatorname*{ch}N+\operatorname*{ch}\left(  M\diagup
N\right)  $.
\end{proposition}

\textit{Proof of Proposition.} \textbf{1)}
\[
\left(  M_{1}\otimes M_{2}\right)  \left[  \mu\right]  =\bigoplus
\limits_{\mu_{1}+\mu_{2}=\mu}M_{1}\left[  \mu_{1}\right]  \otimes M_{2}\left[
\mu_{2}\right]  .
\]


\textbf{2)}
\[
\left(  M\diagup N\right)  \left[  \mu\right]  =M\left[  \mu\right]  \diagup
N\left[  \mu\right]  .
\]


Now, let us generalize to the case of Kac-Moody Lie algebras (or
$\mathfrak{g}\left(  A\right)  $ for general $A$). Here we run into troubles:
For example, for $\widehat{\mathfrak{sl}_{2}}$, we have $M_{\lambda}=U\left(
\widetilde{\mathfrak{n}}_{-}\right)  v_{\lambda}$, and the vectors
$ht^{-1}v_{\lambda},ht^{-2}v_{\lambda},...$ all have weight $\lambda$ with
respect to $\widehat{\mathfrak{h}}=\left\langle h_{0},h_{1}\right\rangle $
with $h_{1}=h,$ $h_{0}=K-h$. This yields that weight spaces are
infinite-dimensional, and we cannot define characters.

Let us work around this by adding derivations.

Assume that $A$ is an $r\times r$ complex matrix. Let $\mathfrak{g}%
_{\operatorname*{ext}}\left(  A\right)  =\mathfrak{g}\left(  A\right)
\oplus\bigoplus\limits_{i=1}^{r}\mathbb{C}D_{i}$ with new relations%
\begin{align*}
\left[  D_{i},D_{j}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i,j;\\
\left[  D_{i},e_{j}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\neq
j;\\
\left[  D_{i},f_{j}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\neq
j;\\
\left[  D_{i},h_{j}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for all }i\neq
j;\\
\left[  D_{i},e_{i}\right]   &  =e_{i};\\
\left[  D_{i},f_{i}\right]   &  =-f_{i};\\
\left[  D_{i},h_{i}\right]   &  =0.
\end{align*}
Note that this definition is equivalent to making $\mathfrak{g}%
_{\operatorname*{ext}}\left(  A\right)  $ a semidirect product, so there is no
cancellation here.

We have $\mathfrak{g}_{\operatorname*{ext}}\left(  A\right)  =\mathfrak{n}%
_{+}\oplus\mathfrak{h}_{\operatorname*{ext}}\oplus\mathfrak{n}_{-}$ where
$\mathfrak{h}_{\operatorname*{ext}}=\mathbb{C}^{r}\oplus\mathfrak{h}$ (here
the $\mathbb{C}^{r}$ is spanned by the $\mathbb{C}D_{i}$).

Consider $\alpha_{i}$ as maps $\mathfrak{h}_{\operatorname*{ext}}%
\rightarrow\mathbb{C}$ given by $\alpha_{i}\left(  h_{j}\right)  =a_{j,i}$ and
$\alpha_{i}\left(  D_{j}\right)  =\delta_{i,j}$.

Then, for every $h\in\mathfrak{h}_{\operatorname*{ext}}$, we have $\left[
h,e_{i}\right]  =\alpha_{i}\left(  h\right)  e_{i}$ and $\left[
h,f_{i}\right]  =-\alpha_{i}\left(  h\right)  f_{i}$.

Let $F=Q\otimes_{\mathbb{Z}}\mathbb{C}$ and $P=\mathfrak{h}^{\ast}\oplus F$.

Let $\varphi:P\rightarrow\mathfrak{h}_{\operatorname*{ext}}^{\ast}$ be given
by $\varphi\left(  h_{i}^{\ast}\right)  \left(  D_{j}\right)  =0$,
$\varphi\left(  h_{i}^{\ast}\right)  \left(  h_{j}\right)  =\delta_{i,j}$,
$\varphi\left(  \alpha_{i}\right)  \left(  D_{j}\right)  =\delta_{i,j}$,
$\varphi\left(  \alpha_{i}\right)  \left(  h_{j}\right)  =a_{j,i}$.

Easy to see $\varphi$ is an iso.

Now the trouble disappears. Do the same as for simple Lie algebras. Now
weights lie in $\mathfrak{h}_{\operatorname*{ext}}^{\ast}$.

Annoying fact: Now, even when $A$ is a Cartan matrix and $\mathfrak{g}$ is
simple finite-dimensional, this is not the same as the usual theory [what?].
But it is equivalent. Namely: Suppose $\chi\in\mathfrak{h}%
_{\operatorname*{ext}}^{\ast}$. Let $\mathcal{O}_{\chi}$ be the category of
modules whose weights lie in $\chi+F$. Therefore, $\mathcal{O}=\bigoplus
\limits_{\chi\in\mathfrak{h}^{\ast}}\mathcal{O}_{\chi}$.

\begin{proposition}
If $\chi_{1}-\chi_{2}\in\operatorname*{Im}\left(  F\rightarrow\mathfrak{h}%
^{\ast}\right)  $, then $\mathcal{O}_{\chi_{1}}\cong\mathcal{O}_{\chi_{2}}$.
\end{proposition}

(See Feigin-Zelevinsky paper for proof.)

If $A$ is invertible (in particular, for simple $\mathfrak{g}$), all
$\mathcal{O}_{\chi}$ are the same and we just have a single category
$\mathcal{O}$ (which is the category $\mathcal{O}$ we defined).

Affine case: $\operatorname*{Coker}\left(  F\rightarrow\mathfrak{h}^{\ast
}\right)  $ is $1$-dimensional, so $\chi$ has one essential parameter (namely,
the image $k$ of $\chi$ in this $\operatorname*{Coker}$). So we get a
$1$-parameter category of categories, $\mathcal{O}\left(  k\right)  $,
parametrized by a complex number $k$. In our old approach to
$\widehat{\mathfrak{g}}$, this $k$ is the level of representations (i. e., the
eigenvalue of the action of $K$). So we did not get anything new, but we have
got a uniform way to treat all cases of this kind.

\subsection{\textbf{[unfinished]} Invariant bilinear forms}

Now let us start developing the theory of invariant bilinear forms on
$\mathfrak{g}\left(  A\right)  $ and $\widetilde{\mathfrak{g}}\left(
A\right)  $.

[We denote $\mathfrak{g}\left[  \alpha\right]  $ as $\mathfrak{g}_{\alpha}$.]

Let $A$ be an indecomposable complex matrix. We want to see when we can have
nontrivial nonzero invariant symmetric bilinear forms on
$\widetilde{\mathfrak{g}}\left(  A\right)  $ and $\mathfrak{g}\left(
A\right)  $. Let us only care about forms of degree $0$, which means that they
send $\mathfrak{g}_{\alpha}\times\mathfrak{g}_{\beta}$ to $0$ unless
$\alpha+\beta=0$. It also sounds like a good goal to have the forms
nondegenerate, but this cannot always be reached. Let us impose the weaker
condition that, if $e_{i}$ and $f_{i}$ denote generators of $\mathfrak{g}%
_{\alpha_{i}}$ and $\mathfrak{g}_{-\alpha_{i}}$, respectively, then $\left(
e_{i},f_{i}\right)  =d_{i}$ for some $d_{i}\neq0$.

These conditions already force some properties upon $\mathfrak{g}\left(
A\right)  $: First,
\[
\left(  h_{i},h_{j}\right)  =\left(  h_{i},\left[  e_{j},f_{j}\right]
\right)  =-\left(  \left[  h_{i},f_{j}\right]  ,e_{j}\right)  =a_{i,j}\left(
f_{j},e_{j}\right)  =a_{i,j}d_{j},
\]
so that the symmetry of our form (and the condition $d_{i}\neq0$) enforces
$a_{i,j}d_{j}=a_{j,i}d_{i}$. Thus, if $D$ denotes the matrix
$\operatorname*{diag}\left(  d_{1},d_{2},...,d_{r}\right)  $, then $\left(
AD\right)  ^{T}=AD$. This means that $A$ is symmetrizable. (Our definition of
``symmetrizable'' spoke of $DA$ instead of $AD$, but this is simply a matter
of replacing $D$ by $D^{-1}$.)

\begin{lemma}
Let $A$ be an indecomposable symmetrizable matrix. Then, there is a unique
diagonal matrix $D$ satisfying $\left(  AD\right)  ^{T}=AD$ up to scaling.
\end{lemma}

This lemma is purely combinatorial and more or less trivial.

\begin{proposition}
Let $A$ be an indecomposable symmetrizable matrix. Then, there is at most one
invariant symmetric bilinear form of degree $0$ on $\widetilde{\mathfrak{g}%
}\left(  A\right)  $ up to scaling.
\end{proposition}

Note that the degree in ``degree $0$'' is the degree with respect to
$Q$-grading; this is a tuple.

\textit{Proof of Proposition.} Let $B$ be such a form. Then, we can view $B$
as a $\mathfrak{g}$-module homomorphism $B^{\vee}:\mathfrak{g}\rightarrow
\mathfrak{g}^{\ast}$. If we fix $d_{i}$ (uniquely up to scaling, as we know
from Lemma), then we know $B^{\vee}\left(  h_{i}\right)  $, $B^{\vee}\left(
f_{i}\right)  $ and $B^{\vee}\left(  e_{i}\right)  $ (because the form is of
degree $0$, and thus the linear maps $B^{\vee}\left(  h_{i}\right)  $,
$B^{\vee}\left(  f_{i}\right)  $ and $B^{\vee}\left(  e_{i}\right)  $ are
determined by what they do to the corresponding elements of the corresponding
degree). But $\mathfrak{g}$ is generated as a $\mathfrak{g}$-module by
$e_{i},f_{i},h_{i}$, so $B$ is uniquely determined if it exists. Proposition
is proven.

\begin{theorem}
Let $A$ be a symmetrizable matrix. Then, there is a nonzero invariant bilinear
symmetric form of degree $0$ on $\widetilde{\mathfrak{g}}\left(  A\right)  $.
(We know from the previous proposition that this form is unique up to scaling
if $A$ is indecomposable.)
\end{theorem}

\textit{Proof of Theorem (incomplete, as we will skip some steps).} First, fix
the $d_{i}$. Then, we can calculate the form by%
\begin{align*}
&  \left(  \underbrace{\left[  e_{i_{1}},\left[  e_{i_{2}},...\left[
e_{i_{n-1}},e_{i_{n}}\right]  ...\right]  \right]  }_{\in\mathfrak{g}_{\alpha
}},\underbrace{\left[  f_{j_{1}},\left[  f_{j_{2}},...\left[  f_{j_{n-1}%
},f_{j_{n}}\right]  ...\right]  \right]  }_{\in\mathfrak{g}_{-\alpha}}\right)
\\
&  =-\left(  \left[  e_{i_{1}},...\right]  ,\underbrace{\left[  \left[
e_{i_{2}},\left[  e_{i_{3}},...\left[  e_{i_{n-1}},e_{i_{n}}\right]
...\right]  \right]  ,\left[  f_{j_{1}},\left[  f_{j_{2}},...\left[
f_{j_{n-1}},f_{j_{n}}\right]  ...\right]  \right]  \right]  }_{\in
\mathfrak{g}_{-\alpha}}\right) \\
&  +...
\end{align*}
induction on $\alpha$. For details and well-definedness, see page 51 of the
Feigin-Zelevinsky paper.

Also, $\widetilde{\mathfrak{g}}\left(  A\right)  $ has such a form by pullback.

As usual, denote these forms by $\left(  \cdot,\cdot\right)  $.

\begin{proposition}
The kernel $I$ of the canonical projection $\widetilde{\mathfrak{g}}\left(
A\right)  \rightarrow\mathfrak{g}\left(  A\right)  $ is a subset of
$\operatorname*{Ker}\left(  \left(  \cdot,\cdot\right)  \right)  $.
\end{proposition}

\textit{Proof of Proposition.} We defined the form $\left(  \cdot
,\cdot\right)  $ on $\widetilde{\mathfrak{g}}\left(  A\right)  \times
\widetilde{\mathfrak{g}}\left(  A\right)  $ as the pullback of the form
$\left(  \cdot,\cdot\right)  :\mathfrak{g}\left(  A\right)  \times
\mathfrak{g}\left(  A\right)  \rightarrow\mathbb{C}$ through the canonical
projection $\widetilde{\mathfrak{g}}\left(  A\right)  \times
\widetilde{\mathfrak{g}}\left(  A\right)  \rightarrow\mathfrak{g}\left(
A\right)  \times\mathfrak{g}\left(  A\right)  $. Thus, it is clear that the
kernel of the former form contains the kernel of the canonical projection
$\widetilde{\mathfrak{g}}\left(  A\right)  \rightarrow\mathfrak{g}\left(
A\right)  $. Proposition proven.

\begin{lemma}
\textbf{1)} The center $Z$ of $\mathfrak{g}\left(  A\right)  $ is contained in
$\mathfrak{h}$, and is%
\[
Z=\left\{  \sum\limits_{i}\beta_{i}h_{i}\ \mid\ \beta_{i}\in\mathbb{C}\text{
for all }i\text{, and }\sum\limits_{i}\beta_{i}a_{i,j}=0\text{ for all
}j\right\}  .
\]


\textbf{2)} If $A$ is an indecomposable symmetrizable matrix, and $A\neq0$,
then any graded proper ideal in $\mathfrak{g}\left(  A\right)  $ is contained
in $Z$.

\textbf{3)} If $a_{i,i}\neq0$ for all $i$, then $\left[  \mathfrak{g}\left(
A\right)  ,\mathfrak{g}\left(  A\right)  \right]  =\mathfrak{g}\left(
A\right)  $.
\end{lemma}

\textit{Proof of Lemma.} \textbf{1)} Let $z$ be a nonzero central element of
$\mathfrak{g}\left(  A\right)  $. We can WLOG assume that $z$ is homogeneous.
Then, $\mathbb{C}z$ is a graded nonzero ideal of $\mathfrak{g}\left(
A\right)  $, so that $\deg z$ must be $0$, and thus $z\in\mathfrak{h}$. If
$z=\sum\limits_{i}\beta_{i}h_{i}$, then every $j$ satisfies $0=\left[
z,e_{j}\right]  =\left[  \sum\limits_{i}\beta_{i}h_{i},e_{j}\right]  =\left(
\sum\limits_{i}\beta_{i}a_{i,j}\right)  e_{j}$, so that $\sum\limits_{i}%
\beta_{i}a_{i,j}=0$.

This proves that $Z\subseteq\left\{  \sum\limits_{i}\beta_{i}h_{i}%
\ \mid\ \beta_{i}\in\mathbb{C}\text{ for all }i\text{, and }\sum
\limits_{i}\beta_{i}a_{i,j}=0\text{ for all }j\right\}  $. The reverse
inclusion is easy to see (using $\left[  h_{i},f_{j}\right]  =-a_{i,j}f_{j}$).

\textbf{2)} Let $I\neq0$ be a graded ideal. Then, $I\cap\mathfrak{h}\neq0$. So
$I=I_{+}\oplus I_{0}\oplus I_{-}$ with $I_{0}$ being a nonzero subspace of
$\mathfrak{h}$. Assume $I\not \subseteq Z$. Then we claim that $I_{+}\neq0$ or
$I_{-}\neq0$.

(In fact, otherwise, we would have $I_{+}=0$ and $I_{-}=0$, so that
$I\subseteq\mathfrak{h}$, so that there exists some $h\in I\subseteq
\mathfrak{h}$ with $h\notin Z$, so that $\left[  h,e_{j}\right]  =\lambda
e_{j}$ for some $j$ and some $\lambda\neq0$, so that $e_{j}\in I_{+}$,
contradicting $I_{+}=0$ and $I_{-}=0$.)

Let $\mathfrak{G}$ be the subset $\left\{  e_{1},e_{2},...,e_{n},f_{1}%
,f_{2},...,f_{n},h_{1},h_{2},...,h_{n}\right\}  $ of $\mathfrak{g}\left(
A\right)  $. As we know, this subset $\mathfrak{G}$ generates the Lie algebra
$\mathfrak{g}\left(  A\right)  $.

So let us WLOG assume $I_{+}\neq0$. Then there exists a nonzero $a\in
I_{+}\left[  \alpha\right]  $ for some $\alpha\neq0$. Set $J$ be the ideal
generated by $a$. In other words, $J=U\left(  \mathfrak{g}\left(  A\right)
\right)  \cdot a$. This $J$ is a graded ideal. Thus, $J\cap\mathfrak{h}\neq0$.
Hence, there exists $x\in U\left(  \mathfrak{g}\left(  A\right)  \right)  $
such that $x\rightharpoonup a\in\mathfrak{h}$ and $x\rightharpoonup a\neq0$.
We can WLOG assume that $x$ has degree $-\alpha$ and is a product of some
elements of the set $\mathfrak{G}$ (with repetitions allowed). Of course, this
product is nonempty (otherwise, $a$ itself would be in $I_{0}$, not in $I_{+}%
$), and hence (by splitting off its first factor) can be written as $\xi
\cdot\eta$ with $\xi$ being an element of the set $\mathfrak{G}$ and $\eta$
being a product of elements of $\mathfrak{G}$. Consider these $\xi$ and $\eta
$. We assume WLOG that $\eta$ is a product of elements of $\mathfrak{G}$ with
a minimum possible number of factors. Then, $\xi\notin\left\{  h_{1}%
,h_{2},...,h_{n}\right\}  $ (because otherwise, we could replace $x$ by $\eta
$, and would then, by splitting off the first factor, obtain a new $\eta$ with
an even smaller number of factors). So we have either $\xi=e_{i}$ for some
$i$, or $\xi=f_{i}$ for some $i$. Let us WLOG assume that we are in the first
case, i. e., we have $\xi=e_{i}$ for some $i$.

Let $y=\eta\rightharpoonup a$. Then, $y\in I$ (since $a\in I$ and since $I$ is
an ideal) and
\begin{align*}
\left[  \xi,y\right]   &  =\xi\rightharpoonup\underbrace{y}_{=\eta
\rightharpoonup a}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\xi\in
\mathfrak{G}\subseteq\mathfrak{g}\left(  A\right)  \right) \\
&  =\xi\rightharpoonup\left(  \eta\rightharpoonup a\right)
=\underbrace{\left(  \xi\cdot\eta\right)  }_{=x}\rightharpoonup
a=x\rightharpoonup a\in\mathfrak{h}%
\end{align*}
and $\left[  \xi,y\right]  =x\rightharpoonup a\neq0$. Since $\xi=e_{i}%
\in\mathfrak{g}_{\alpha_{i}}$ and $y$ is homogeneous, this yields that
$y\in\mathfrak{g}_{-\alpha_{i}}$. Thus, $y=\chi\cdot f_{i}$ for some $\chi
\in\mathbb{C}$. This $\chi$ is nonzero, since $y$ is nonzero (since $\left[
\xi,y\right]  \neq0$).

Since $y=\chi\cdot f_{i}$, we have $\left[  e_{i},y\right]  =\chi
\cdot\underbrace{\left[  e_{i},f_{i}\right]  }_{=h_{i}}=\chi h_{i}$. Since
$\left[  e_{i},y\right]  \in I$ (because $I$ is an ideal and $y\in I$), this
becomes $\chi h_{i}\in I$, so that $h_{i}\in I$ (since $\chi$ is nonzero).
Moreover, since $\chi\cdot f_{i}=y\in I$, we have $f_{i}\in I$ (since $\chi$
is nonzero). Altogether, we now know that $h_{i}\in I$ and $f_{i}\in I$.

If $A$ is an $1\times1$ matrix, then $a_{i,i}\neq0$ (since $A\neq0$), so that
$e_{i}=\dfrac{\left[  h_{i},e_{i}\right]  }{a_{i,i}}\in I$ (because $h_{i}\in
I$). Hence, if $A$ is an $1\times1$ matrix, then all of $e_{i}$, $f_{i}$ and
$h_{i}$ lie in $I$, so that $I=\mathfrak{g}\left(  A\right)  $ (because there
exists only one $i$).

If the size of $A$ is $>1$, there exists some $j\neq i$ such that $a_{i,j}%
\neq0$ and $a_{j,i}\neq0$ (since $A$ is indecomposable and symmetrizable), so
that $e_{j}=\dfrac{\left[  h_{i},e_{j}\right]  }{a_{i,j}}\in I$ (since
$h_{i}\in I$), furthermore $f_{j}=-\dfrac{\left[  h_{i},f_{j}\right]
}{a_{i,j}}\in I$, therefore $h_{j}=\left[  e_{j},f_{j}\right]  \in I$, and
finally $e_{i}=\dfrac{\left[  h_{j},e_{i}\right]  }{a_{j,i}}\in I$. And for
every $k\neq i$ with $a_{i,k}\neq0$ and $a_{k,i}\neq0$, we similarly get
$h_{k}$, $f_{k}$, $e_{k}$ $\in I$ etc.. By repeating this argument, we
conclude that $e_{\ell},f_{\ell},h_{\ell}\in I$ for all $\ell$ (since $A$ is
indecomposable). That is, $\mathfrak{G}\subseteq I$. Since $\mathfrak{G}$ is a
generating set of the Lie algebra $\mathfrak{g}\left(  A\right)  $, this
entails $I=\mathfrak{g}\left(  A\right)  $.

\textbf{3)} If $a_{i,i}\neq0$, then the relations (\ref{nonserre-relations})
imply that all generators are in $\left[  \mathfrak{g}\left(  A\right)
,\mathfrak{g}\left(  A\right)  \right]  $.

Qed.

\begin{proposition}
Assume that $A$ is symmetrizable. We have $\operatorname*{Ker}\left(  \left(
\cdot,\cdot\right)  \mid_{\mathfrak{g}\left(  A\right)  }\right)  =Z\left(
\mathfrak{g}\left(  A\right)  \right)  $.
\end{proposition}

\textit{Proof of Proposition.} Assume WLOG that $A$ is indecomposable.

\textbf{1)} $1\times1$ case, $A=0$ trivial: $\left[  e,f\right]  =h$, $\left[
h,e\right]  =\left[  h,f\right]  =0$, $\left(  e,f\right)  =1$. Then the
kernel of this form is a graded ideal and is not $\mathfrak{g}\left(
A\right)  $. Hence, it must be contained in $Z$ by the lemma. But
$Z\subseteq\operatorname*{Ker}\left(  \left(  \cdot,\cdot\right)
\mid_{\mathfrak{g}\left(  A\right)  }\right)  $ is easy (because $\left(
\sum\limits_{i}\beta_{i}h_{i},h_{j}\right)  =\sum\limits_{i}\beta_{i}%
a_{i,j}d_{j}=0$).

Let $F=Q\otimes_{\mathbb{Z}}\mathbb{C}=\bigoplus_{i=1}^{r}\mathbb{C}\alpha
_{i}$.

Define $\gamma:F\rightarrow\mathfrak{h}$ isomorphism by $\gamma\left(
\alpha_{i}\right)  =d_{i}^{-1}h_{i}=:h_{\alpha_{i}}$. Extend by linearity:
$\gamma\left(  \alpha\right)  $ will be called $h_{\alpha}$, $\alpha\in F$.

\textbf{Claim:} $\left(  h_{\alpha},h\right)  =\overline{\alpha}\left(
h\right)  $, where $\overline{\alpha}$ is the image of $\alpha$ in
$\mathfrak{h}^{\ast}$.

Proof: $\left(  h_{\alpha_{i}},h_{j}\right)  =d_{i}^{-1}\left(  h_{i}%
,h_{j}\right)  =d_{i}^{-1}a_{i,j}d_{j}=d_{i}^{-1}a_{j,i}d_{i}=a_{j,i}%
=\overline{\alpha_{i}}\left(  h_{j}\right)  \ \ \ \ $ ($\left[  h_{j}%
,e_{i}\right]  =a_{j,i}e_{i}$).

\begin{proposition}
If $x\in\mathfrak{g}_{\alpha}$ and $y\in\mathfrak{g}_{-\alpha}$, then $\left[
x,y\right]  =\left(  x,y\right)  h_{\alpha}$.
\end{proposition}

\textit{Proof of Proposition.} By induction over $\left\vert \alpha\right\vert
$, where $\left\vert \alpha\right\vert $ means the sum of the coordinates of
$\alpha$.

\textit{Base:} $\left\vert \alpha\right\vert =1$, $\alpha=\alpha_{i}$. Want to
prove $\left[  e_{i},f_{i}\right]  =^{?}\left(  e_{i},f_{i}\right)
h_{\alpha_{i}}$. But $\left[  e_{i},f_{i}\right]  =h_{i}$ and $\left(
e_{i},f_{i}\right)  h_{\alpha_{i}}=d_{i}d_{i}^{-1}h_{i}$, so we are done with
the base.

\textit{Step:} For $x\in\mathfrak{g}_{\alpha-\alpha_{i}}$ and $y\in
\mathfrak{g}_{\alpha-\alpha_{j}}$, we have
\begin{align*}
&  \left[  \left[  e_{i},x\right]  ,\left[  f_{j},y\right]  \right] \\
&  =\left[  \left[  e_{i},\left[  f_{j},y\right]  \right]  ,x\right]  +\left[
e_{i},\left[  x,\left[  f_{j},y\right]  \right]  \right] \\
&  =-\left(  \left[  e_{i},\left[  f_{j},y\right]  \right]  ,x\right)
h_{\alpha-\alpha_{i}}+\left(  e_{i},\left[  x,\left[  f_{j},y\right]  \right]
\right)  h_{\alpha_{i}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the induction assumption}\right) \\
&  =\left(  \left[  f_{j},y\right]  ,\left[  e_{i},x\right]  \right)  \left(
h_{\alpha-\alpha_{i}}+h_{\alpha_{i}}\right)  =\left(  \left[  e_{i},x\right]
,\left[  f_{j},y\right]  \right)  h_{\alpha}.
\end{align*}
Induction step complete. Proposition proven.

\begin{corollary}
If we give $\mathfrak{g}\left(  A\right)  $ the principal $\mathbb{Z}$-grading
(so that $\mathfrak{g}\left(  A\right)  \left[  n\right]  =\bigoplus
\limits_{\substack{\alpha\in Q;\\\left\vert \alpha\right\vert =n}%
}\mathfrak{g}\left(  A\right)  \left[  \alpha\right]  $), then $\mathfrak{g}%
\left(  A\right)  $ is a nondegenerate Lie algebra.
\end{corollary}

\textit{Proof.} If $\lambda\in\mathfrak{h}^{\ast}$ is such that $\lambda
\left(  h_{\alpha}\right)  \neq0$, then $\lambda\left(  \left[  x,y\right]
\right)  $ is a nondegenerate form $\mathfrak{g}_{\alpha}\times\mathfrak{g}%
_{-\alpha}\rightarrow\mathbb{C}$. Qed.

Recall $P=\mathfrak{h}^{\ast}\oplus F\cong\mathfrak{h}_{\operatorname*{ext}%
}^{\ast}$.

$\left(  \cdot,\cdot\right)  $ on $P$: $\left(  \underbrace{\varphi}%
_{\in\mathfrak{h}^{\ast}}\oplus\underbrace{\alpha}_{\in F},\underbrace{\psi
}_{\in\mathfrak{h}^{\ast}}\oplus\underbrace{\beta}_{\in F}\right)
=\psi\left(  h_{\alpha}\right)  +\varphi\left(  h_{\beta}\right)  +\left(
h_{\alpha},h_{\beta}\right)  $

$\left(  h_{\alpha_{i}},h_{\alpha_{j}}\right)  =d_{i}^{-1}d_{j}^{-1}\left(
h_{i},h_{j}\right)  =d_{i}^{-1}d_{j}^{-1}a_{i,j}d_{j}=d_{i}^{-1}a_{i,j}$.

Basis $h_{\alpha_{i}}^{\ast}\in\mathfrak{h}^{\ast}$, $\alpha_{i}\in F$
$\Longrightarrow$ matrix of the form $\left(
\begin{array}
[c]{cc}%
0 & 1\\
1 & D^{-1}A
\end{array}
\right)  $.

Inverse form on $\mathfrak{h}_{\operatorname*{ext}}$: dual basis:
$h_{\alpha_{i}},D_{i}$.

$\left(  D_{i},D_{j}\right)  =0$, $\left(  D_{i},h_{\alpha_{j}}\right)
=\delta_{i,j}$, $\left(  h_{\alpha_{i}},h_{\alpha_{j}}\right)  =d_{i}%
^{-1}a_{i,j}$.

\begin{proposition}
The form on $\mathfrak{g}_{\operatorname*{ext}}\left(  A\right)
=\mathfrak{g}\left(  A\right)  \oplus\mathbb{C}D_{1}\oplus\mathbb{C}%
D_{2}\oplus...\oplus\mathbb{C}D_{r}$ defined by this is a nondegenerate
symmetric invariant form.
\end{proposition}

\subsection{\textbf{[unfinished]} Casimir element}

We now define the Casimir element. The problem with the classical ``sum of
squares of orthonormal basis'' construction which works well in the
finite-dimensional case is that now we are infinite-dimensional and such a sum
needs to be defined.

Note that it will be a generalization of the $L_{0}$ of the Sugawara construction.

Define $\rho\in\mathfrak{h}^{\ast}$ by $\rho\left(  h_{i}\right)
=\dfrac{a_{i,i}}{2}$ (in the Kac-Moody case, this becomes $\rho\left(
h_{i}\right)  =1$).

$\left(  \rho,\rho\right)  =0$.

Case of a finite-dimensional simple Lie algebra: $\Delta=\sum\limits_{a\in
B}a^{2}=\sum\limits_{i=1}^{r}x_{i}^{2}+2h_{\rho}+2\sum\limits_{\alpha
>0}f_{\alpha}e_{\alpha}$ where $\left(  x_{i}\right)  _{i=1,...,r}$ is an
orthonormal basis of $\mathfrak{h}$.

In the infinite-dimensional case, we fix a basis $\left(  e_{\alpha}%
^{i}\right)  _{i}$ of $\mathfrak{g}_{\alpha}$ for every $\alpha$, and a dual
basis $\left(  f_{\alpha}^{i}\right)  _{i}$ of $\mathfrak{g}_{-\alpha}$ under
the inner product. Then define $\Delta_{+}=2\sum\limits_{\alpha>0}%
\sum\limits_{i}f_{\alpha}^{i}e_{\alpha}^{i}$ and $\Delta_{0}=\sum
\limits_{j}x_{j}^{2}+2h_{\rho}$ (where $\left(  x_{j}\right)  $ is an
orthonormal basis of $\mathfrak{h}_{\operatorname*{ext}}$). We set
$\Delta=\Delta_{+}+\Delta_{0}$.

Note that $\Delta_{+}$ is an infinite sum and not in $U\left(  \mathfrak{g}%
\left(  A\right)  \right)  $. But it becomes finite after applying to any
vector in a module in category $\mathcal{O}$.

\begin{theorem}
\textbf{1)} The operator $\Delta$ commutes with $\mathfrak{g}\left(  A\right)
$.

\textbf{2)} We have $\Delta\mid_{M_{\lambda}}=\left(  \lambda,\lambda
+2\rho\right)  \operatorname*{id}$.
\end{theorem}

\textit{Proof of Theorem.} Let us first prove \textbf{2)} using \textbf{1)}:

\textbf{2)} We have $\Delta v_{\lambda}=\Delta_{0}v_{\lambda}=\left(
\sum\limits_{j}\lambda\left(  x_{j}\right)  ^{2}+2\lambda\left(  h_{\rho
}\right)  \right)  v_{\lambda}=\left(  \left(  \lambda,\lambda\right)
+2\left(  \lambda,\rho\right)  \right)  v_{\lambda}=\left(  \lambda
,\lambda+2\rho\right)  v_{\lambda}$.

From \textbf{1)}, we see that every $a\in U\left(  \mathfrak{g}\left(
A\right)  \right)  $ satisfies $\Delta av_{\lambda}=a\Delta v_{\lambda
}=\left(  \lambda,\lambda+2\rho\right)  av_{\lambda}$. This proves \textbf{2)}
since $M_{\lambda}=U\left(  \mathfrak{g}\left(  A\right)  \right)  v_{\lambda
}$.

\textbf{1)} We need to show that $\left[  \Delta,e_{i}\right]  =\left[
\Delta,f_{i}\right]  =0$.

Let us prove $\left[  \Delta,e_{i}\right]  =0$ (the proof of $\left[
\Delta,f_{i}\right]  =0$ is similar).

We have $\left[  \Delta_{0},e_{i}\right]  =\left[  \sum x_{j}^{2}+2h\rho
,e_{i}\right]  =\sum x_{j}\left[  x_{j},e_{i}\right]  +\sum\left[  x_{j}%
,e_{i}\right]  x_{j}+2\left(  \alpha_{i},\rho\right)  e_{i}$

$=\sum x_{j}\underbrace{\alpha_{i}\left(  x_{j}\right)  }_{=\left(
h_{\alpha_{i}},x_{j}\right)  }e_{i}+\sum\alpha_{i}\left(  x_{j}\right)
e_{i}x_{j}+2\left(  \alpha_{i},\rho\right)  e_{i}$

$=2h_{\alpha_{i}}e_{i}-\sum\underbrace{\alpha_{i}\left(  x_{j}\right)
}_{=\left(  \alpha_{i},\alpha_{i}\right)  e_{i}}\alpha_{i}\left(
x_{j}\right)  e_{i}+2\left(  \alpha_{i},\rho\right)  e_{i}=2h_{\alpha}e_{i}$

$\Longrightarrow$ Our job is to show $\left[  \Delta_{+},e_{i}\right]
=-2h_{\alpha_{i}}e_{i}$. But

$\left[  \Delta_{+},e_{i}\right]  =2\sum\limits_{\alpha>0}f_{\alpha}%
^{j}\left[  e_{\alpha}^{j},e_{i}\right]  +2\underbrace{\sum\limits_{\alpha
>0}\left[  f_{\alpha}^{j},e_{i}\right]  e_{\alpha}^{j}}_{\substack{\text{for
}\alpha=\alpha_{i}\text{ the addend is}\\-2h_{\alpha_{i}}e_{i}\\\text{because
}f_{\alpha_{i}}=d_{i}^{-1}f_{i}\text{, }e_{\alpha_{i}}=e_{i}\text{,}\\\left[
d_{i}^{-1}f_{i},e_{i}\right]  e_{i}=-d_{i}^{-1}h_{i}e_{i}=-h_{\alpha_{i}}%
e_{i}}}$.

So we need to show that%
\[
\sum\limits_{\alpha>0}f_{\alpha}^{j}\left[  e_{\alpha}^{j},e_{i}\right]
+2\sum\limits_{\substack{\alpha>0;\\\alpha\neq\alpha_{i}}}\left[  f_{\alpha
}^{j},e_{i}\right]  e_{\alpha}^{j}=0.
\]
For this it is enough to check%
\[
\sum\limits_{\alpha>0}f_{\alpha}^{j}\otimes\left[  e_{\alpha}^{j}%
,e_{i}\right]  +2\sum\limits_{\substack{\alpha>0;\\\alpha\neq\alpha_{i}%
}}\left[  f_{\alpha}^{j},e_{i}\right]  \otimes e_{\alpha}^{j}=0.
\]
For this it is enough to check that $\left[  e_{i},e_{\alpha}^{k}\right]
=\sum\left(  e_{\beta}^{k},\left[  f_{\alpha}^{j},e_{i}\right]  \right)
e_{\alpha}^{j}$. This is somehow obvious. Proof complete.

\textbf{Exercise:} for $\widehat{\mathfrak{g}}$ (affine), $\Delta=\left(
k+h^{\vee}\right)  \left(  L_{0}-d\right)  $ (Sugawara).

\subsection{\textbf{[unfinished]} Preparations for the Weyl-Kac character
formula}

Let $A$ be a symmetrizable generalized Cartan matrix, WLOG indecomposable.

We consider the Kac-Moody algebra $\mathfrak{g}=\mathfrak{g}\left(  A\right)
\subseteq\mathfrak{g}_{\operatorname*{ext}}\left(  A\right)  $.

\begin{proposition}
The Serre relations $\left(  \operatorname*{ad}\left(  e_{i}\right)  \right)
^{1-a_{i,j}}e_{j}=\left(  \operatorname*{ad}\left(  f_{i}\right)  \right)
^{1-a_{i,j}}f_{j}=0$ hold in $\mathfrak{g}\left(  A\right)  $.
\end{proposition}

This is a part of Theorem \ref{thm.g(A).gabber-kac} (actually, the part that
we proved above).

\begin{definition}
Let $A$ be an associative algebra (with $1$, as always). Let $V$ be an $A$-module.

\textbf{(a)} Let $v\in V$. Then, the vector $v$ is said to be \textit{of
finite type} if $\dim\left(  Av\right)  <\infty$.

\textbf{(b)} The $A$-module $V$ is said to be \textit{locally finite} if every
$v\in V$ is of finite type.
\end{definition}

It is very easy to check that:

\begin{proposition}
\label{prop.locfin.equiv}Let $A$ be an associative algebra (with $1$, as
always). Let $V$ be an $A$-module. Then, $V$ is locally finite if and only if
$V$ is a sum of finite-dimensional $A$-modules.
\end{proposition}

\textit{Proof of Proposition \ref{prop.locfin.equiv} (sketched).}
$\Longrightarrow:$ Assume that $V$ is locally finite. Then, for every $v\in
V$, we have $\dim\left(  Av\right)  <\infty$ (since $v$ is of finite type), so
that $Av$ is a finite-dimensional $A$-module. Thus, $V=\sum\limits_{v\in V}Av$
is a sum of finite-dimensional $A$-modules.

$\Longleftarrow:$ Assume that $V$ is a sum of finite-dimensional $A$-modules.
Then, for every $v\in V$, the vector $v$ belongs to a sum of \textbf{finitely
many} finite-dimensional $A$-modules. But such a sum is finite-dimensional as
well. As a consequence, for every $v\in V$, the vector $v$ belongs to a
finite-dimensional $A$-module, and thus $\dim\left(  Av\right)  <\infty$, so
that $v$ is of finite type. Thus, $V$ is locally finite.

Proposition \ref{prop.locfin.equiv} is proven.

\begin{Convention}
If $\mathfrak{g}$ is a Lie algebra, then ``locally finite'' and ``of finite
type'' with respect to $\mathfrak{g}$ mean locally finite resp. of finite type
with respect to $U\left(  \mathfrak{g}\right)  $.
\end{Convention}

In the following, let $A=U\left(  \mathfrak{g}\right)  $ for $\mathfrak{g}%
=\mathfrak{g}\left(  A\right)  $.

\begin{definition}
Let $V$ be a $\mathfrak{g}\left(  A\right)  $-module. We say that $V$ is
\textit{integrable} if $V$ is locally finite under the $\mathfrak{sl}_{2}%
$-subalgebra $\left(  \mathfrak{sl}_{2}\right)  _{i}=\left\langle e_{i}%
,f_{i},h_{i}\right\rangle $ for every $i\in\left\{  1,2,...,r\right\}  $.
\end{definition}

To motivate the terminology ``integrable'', let us notice:

\begin{proposition}
If $V$ is a $\mathfrak{sl}_{2}$-module, then $V$ is locally finite if and only
if $V$ is isomorphic to a direct sum $\bigoplus\limits_{n=0}^{\infty}%
W_{n}\otimes V_{n}$, where $W_{n}$ are vector spaces and $V_{n}$ is the
irreducible representation of $\mathfrak{sl}_{2}$ of highest weight $n$ (so
that $\dim\left(  V_{n}\right)  =n+1$) for every $n\in\mathbb{N}$. (In such a
direct sum, we have $W_{n}\cong\operatorname*{Hom}\nolimits_{\mathfrak{sl}%
_{2}}\left(  V_{n},V\right)  $.)

Locally-finite $\mathfrak{sl}_{2}$-modules can be lifted to modules over the
\textbf{algebraic group} $\operatorname*{SL}\nolimits_{2}\left(
\mathbb{C}\right)  $.
\end{proposition}

Since lifting is called ``integrating'' (in analogy to geometry, where an
action of a Lie group gives rise to an action of the corresponding of the Lie
algebra by ``differentiation'', and thus the converse operation, when it makes
sense, is called ``integration''), the last sentence of this proposition
explains the name ``integrable''.

\begin{proposition}
\label{prop.weylkac.gint}The $\mathfrak{g}$-module $\mathfrak{g}%
=\mathfrak{g}\left(  A\right)  $ itself is integrable.
\end{proposition}

The proof of this proposition is based on the following lemma:

\begin{lemma}
\label{lem.weylkac.fintypfintyp}Let $\mathfrak{a}$ be a Lie algebra, and
$\mathfrak{b}$ be another Lie algebra. Assume that we are given a Lie algebra
homomorphism $\mathfrak{b}\rightarrow\operatorname*{Der}\mathfrak{a}$; this
makes $\mathfrak{a}$ into a $\mathfrak{b}$-module. Then, if $x,y\in
\mathfrak{a}$ are of finite type for $\mathfrak{b}$, then so is $\left[
x,y\right]  $.
\end{lemma}

\textit{Proof of Lemma \ref{lem.weylkac.fintypfintyp}.} In $\mathfrak{a}$ (not
in $U\left(  \mathfrak{a}\right)  $), we have%
\[
U\left(  \mathfrak{b}\right)  \cdot\left[  x,y\right]  \subseteq\left[
\underbrace{U\left(  \mathfrak{b}\right)  \cdot x}_{\text{finite dimensional}%
},\underbrace{U\left(  \mathfrak{b}\right)  \cdot y}_{\text{finite
dimensional}}\right]  .
\]
Hence, $U\left(  \mathfrak{b}\right)  \cdot\left[  x,y\right]  $ is
finite-dimensional. Hence, $\left[  x,y\right]  $ is of finite type for
$\mathfrak{b}$. Lemma \ref{lem.weylkac.fintypfintyp} is proven.

\textit{Proof of Proposition \ref{prop.weylkac.gint}.} We know that $e_{i}$ is
of finite type under $\left(  \mathfrak{sl}_{2}\right)  _{i}$ (in fact,
$e_{i}$ generates a $3$-dimensional representation of $\left(  \mathfrak{sl}%
_{2}\right)  _{i}$), and that $e_{j}$ is of finite type under $\left(
\mathfrak{sl}_{2}\right)  _{i}$ for every $j\neq i$ (in fact, $e_{j}$
generates a representation of dimension $1-a_{i,j}$). The same applies to
$f_{j}$, and hence also to $h_{j}$ (by Lemma \ref{lem.weylkac.fintypfintyp}).
Hence (again using Lemma \ref{lem.weylkac.fintypfintyp}), the whole
$\mathfrak{g}\left(  A\right)  $ is locally finite under $\left(
\mathfrak{sl}_{2}\right)  _{i}$. [Fix some stuff here.] Proposition
\ref{prop.weylkac.gint} is proven.

\begin{proposition}
If $V$ is a $\mathfrak{g}\left(  A\right)  $-module, then $V$ is integrable if
and only if there exists a generating family $\left(  v_{\alpha}\right)
_{\alpha\in\mathfrak{A}}$ of the $\mathfrak{g}\left(  A\right)  $-module $V$
such that each $v_{\alpha}$ is of finite type under $\left(  \mathfrak{sl}%
_{2}\right)  _{i}$ for each $i$.
\end{proposition}

Note that this proposition could just as well be formulated for every Lie
algebra $\mathfrak{g}$ instead of $\mathfrak{g}\left(  A\right)  $.

\textit{Proof of Proposition.} $\Longleftarrow:$ Let $v\in V$. We need to show
that $v$ is of finite type under $\left(  \mathfrak{sl}_{2}\right)  _{i}$ for
all $i$.

Pick some $i\in\left\{  1,2,...,r\right\}  $. Let $\mathfrak{g}=\mathfrak{g}%
\left(  A\right)  $.

Fix some $i$. Then, there exist $i_{1},i_{2},...,i_{m}\in\mathfrak{A}$ such
that $v\in U\left(  \mathfrak{g}\right)  \cdot v_{i_{1}}+U\left(
\mathfrak{g}\right)  \cdot v_{i_{2}}+...+U\left(  \mathfrak{g}\right)  \cdot
v_{i_{m}}$. WLOG assume that $i_{1}=1$, $i_{2}=2$, $...$, $i_{m}=m$, and
denote the $\mathfrak{g}$-submodule $U\left(  \mathfrak{g}\right)  \cdot
v_{1}+U\left(  \mathfrak{g}\right)  \cdot v_{2}+...+U\left(  \mathfrak{g}%
\right)  \cdot v_{m}$ of $V$ by $V^{\prime}$. Then, $v\in U\left(
\mathfrak{g}\right)  \cdot v_{i_{1}}+U\left(  \mathfrak{g}\right)  \cdot
v_{i_{2}}+...+U\left(  \mathfrak{g}\right)  \cdot v_{i_{m}}=U\left(
\mathfrak{g}\right)  \cdot v_{1}+U\left(  \mathfrak{g}\right)  \cdot
v_{2}+...+U\left(  \mathfrak{g}\right)  \cdot v_{m}=V^{\prime}\subseteq V$.

Pick a finite-dimensional $\left(  \mathfrak{sl}_{2}\right)  _{i}%
$-subrepresentation $W$ of $V^{\prime}$ such that $v_{1},v_{2},...,v_{m}\in
W$. (This is possible because $v_{1},v_{2},...,v_{m}$ are of finite type under
$\left(  \mathfrak{sl}_{2}\right)  _{i}$.) Then we have a surjective
homomorphism of $\left(  \mathfrak{sl}_{2}\right)  _{i}$-modules $U\left(
\mathfrak{g}\right)  \otimes W\rightarrow V^{\prime}$ (namely, the
homomorphism sending $x\otimes w$ to $xw$), where $\mathfrak{g}$ acts on
$U\left(  \mathfrak{g}\right)  $ by adjoint action, and where $\left(
\mathfrak{sl}_{2}\right)  _{i}$ acts on $U\left(  \mathfrak{g}\right)  $ by
restricting the $\mathfrak{g}$-action on $U\left(  \mathfrak{g}\right)  $ to
$\left(  \mathfrak{sl}_{2}\right)  _{i}$. So it suffices to show that
$U\left(  \mathfrak{g}\right)  $ is integrable for the adjoint action of
$\mathfrak{g}$. But by the symmetrization map (which is an isomorphism by
PBW), we have $U\left(  \mathfrak{g}\right)  \cong S\left(  \mathfrak{g}%
\right)  =\bigoplus\limits_{m\in\mathbb{N}}S^{m}\left(  \mathfrak{g}\right)  $
(as $\mathfrak{g}$-modules) (this is true for every Lie algebra over a field
of characteristic $0$). Since $S^{m}\left(  \mathfrak{g}\right)  $ injects
into $\mathfrak{g}^{\otimes m}$, and since $\mathfrak{g}^{\otimes m}$ is
integrable (because $\mathfrak{g}$ is (in fact, it is easy to see that if $X$
and $Y$ are locally finite $\mathfrak{a}$-modules, then so is $X\otimes Y$)),
this yields that $U\left(  \mathfrak{g}\right)  $ is integrable. Hence,
$U\left(  \mathfrak{g}\right)  \otimes W$ is a locally finite $\left(
\mathfrak{sl}_{2}\right)  _{i}$-module, and thus $V^{\prime}$ (being a
quotient module of $U\left(  \mathfrak{g}\right)  \otimes W$) is a locally
finite $\left(  \mathfrak{sl}_{2}\right)  _{i}$-module also as well. Hence,
$v$ (being an element of $V^{\prime}$) is of finite type under $\left(
\mathfrak{sl}_{2}\right)  _{i}$.

$\Longrightarrow:$ Trivial (take all vectors of $V$ as generators).

Proposition proven.

\begin{corollary}
Let $L_{\lambda}$ be the irreducible highest-weight module for $\mathfrak{g}%
\left(  A\right)  $. Then, $L_{\lambda}$ is integrable if and only if for
every $i\in\left\{  1,2,...,r\right\}  $, the value $\lambda\left(
h_{i}\right)  $ is a nonnegative integer.
\end{corollary}

\textit{Proof of Corollary.} $\Longrightarrow:$ Assume that $L_{\lambda}$ is
integrable. Consider the element $v_{\lambda}$ of $L_{\lambda}$. Since
$L_{\lambda}$ is integrable, we know that $v_{\lambda}$ is of finite type
under $\left(  \mathfrak{sl}_{2}\right)  _{i}$. In other words, $U\left(
\left(  \mathfrak{sl}_{2}\right)  _{i}\right)  v_{\lambda}$ is a
finite-dimensional $\left(  \mathfrak{sl}_{2}\right)  _{i}$-module. Also, we
know that $v_{\lambda}\neq0$, $e_{i}v_{\lambda}=0$ and $h_{i}v_{\lambda
}=\lambda\left(  h_{i}\right)  v_{\lambda}$. Hence, Lemma
\ref{lem.serre-gen.sl2} \textbf{(c)} (applied to $\left(  \mathfrak{sl}%
_{2}\right)  _{i}$, $e_{i}$, $h_{i}$, $f_{i}$, $U\left(  \left(
\mathfrak{sl}_{2}\right)  _{i}\right)  v_{\lambda}$, $v_{\lambda}$ and
$\lambda\left(  h_{i}\right)  $ instead of $\mathfrak{sl}_{2}$, $e$, $h$, $f$,
$V$, $x$ and $\lambda$) yields that $\lambda\left(  h_{i}\right)
\in\mathbb{N}$ and $f_{i}^{\lambda\left(  h_{i}\right)  +1}v_{\lambda}=0$. In
particular, $\lambda\left(  h_{i}\right)  $ is a nonnegative integer.

$\Longleftarrow:$ We have%
\begin{align*}
e_{i}f_{i}^{\lambda\left(  h_{i}\right)  +1}v_{\lambda}  &  =\left(
\lambda\left(  h_{i}\right)  +1\right)  \underbrace{\left(  \lambda\left(
h_{i}\right)  -\left(  \lambda\left(  h_{i}\right)  +1\right)  +1\right)
}_{=0}f_{i}^{\lambda\left(  h_{i}\right)  }v_{\lambda}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the formula }e_{i}f_{i}^{m}v_{\lambda
}=m\left(  \lambda\left(  h_{i}\right)  -m+1\right)  f_{i}^{m-1}v_{\lambda
}\right) \\
&  =0.
\end{align*}
Hence, $f_{i}^{\lambda\left(  h_{i}\right)  +1}v_{\lambda}$ must also be zero
(since otherwise, this vector would generate a proper graded submodule). This
implies that $v_{\lambda}$ generates a finite-dimensional $\left(
\mathfrak{sl}_{2}\right)  _{i}$-module of dimension $\lambda\left(
h_{i}\right)  +1$ with basis $\left(  v_{\lambda},f_{i}v_{\lambda}%
,...,f_{i}^{\lambda\left(  h_{i}\right)  }v_{\lambda}\right)  $. Hence,
$v_{\lambda}$ is of finite type with respect to $\left(  \mathfrak{sl}%
_{2}\right)  _{i}$.

By the previous proposition, this yields that $L_{\lambda}$ is integrable.
Proof of Corollary complete.

\begin{remark}
Assume that for every $i\in\left\{  1,2,...,r\right\}  $, the value
$\lambda\left(  h_{i}\right)  $ is a nonnegative integer. Then, the relations
$f_{i}^{\lambda\left(  h_{i}\right)  +1}v_{\lambda}=0$ are defining for
$L_{\lambda}$.
\end{remark}

We will not prove this now, but this will follow from things we do later (from
the main theorem for the character formula).

\begin{definition}
A weight $\lambda$ for which all $\lambda\left(  h_{i}\right)  $ are
nonnegative integers is called \textit{integral} (for $\mathfrak{g}\left(
A\right)  $ or for $\mathfrak{g}_{\operatorname*{ext}}\left(  A\right)  $).
\end{definition}

Now, our next goal is to compute the character of $L_{\lambda}$ for any
dominant integral weight $\lambda$.

For finite-dimensional simple Lie algebras, these $L_{\lambda}$ are exactly
the finite-dimensional irreducible representations, and their characters can
be computed by the well-known Weyl character formula. So our goal is to
generalize this formula.

The Weyl character formula involves a summation over the Weyl group. So, first
of all, we need to define a ``Weyl group'' for Kac-Moody Lie algebras.

\subsection{\textbf{[unfinished]} Weyl group}

\begin{definition}
Consider $P=\mathfrak{h}^{\ast}\oplus F$. We know that there is a
nondegenerate form $\left(  \cdot,\cdot\right)  $ on $P$, and we have $\dim
P=2r$. Let $i\in\left\{  1,2,...,r\right\}  $. Let $r_{i}:P\rightarrow P$ be
the map given by $r_{i}\left(  \chi\right)  =\chi-\chi\left(  h_{i}\right)
\alpha_{i}$.
\end{definition}

Note that $r_{i}$ is an involution, since%
\[
r_{i}^{2}\left(  \chi\right)  =\chi-\chi\left(  h_{i}\right)  \alpha_{i}%
-\chi\left(  h_{i}\right)  \alpha_{i}+\chi\left(  h_{i}\right)
\underbrace{\alpha_{i}\left(  h_{i}\right)  }_{=2}\alpha_{i}=\chi
\]
for every $\chi\in P$. Since $r_{i}\left(  \alpha_{i}\right)  =-\alpha_{i}$,
this yields $\det\left(  r_{i}\right)  =-1$.

Easy to check that $\left(  r_{i}x,r_{i}y\right)  =\left(  x,y\right)  $ for
all $x,y\in P$.

\begin{proposition}
Let $V$ be an integrable $\mathfrak{g}\left(  A\right)  $-module. Then, for
each $i\in\left\{  1,2,...,r\right\}  $ and any $\mu\in P$, we have an
isomorphism $V\left[  \mu\right]  \rightarrow V\left[  r_{i}\mu\right]  $. In
particular, $\dim\left(  V\left[  \mu\right]  \right)  =\dim\left(  V\left[
r_{i}\mu\right]  \right)  $.
\end{proposition}

\textit{Proof of Proposition.} We have $r_{i}\mu=\mu-\mu\left(  h_{i}\right)
\alpha_{i}$. Since $V$ is integrable for $\left(  \mathfrak{sl}_{2}\right)
_{i}$, we know that $\mu\left(  h_{i}\right)  $ is an integer. We have
$\left(  r_{i}\mu\right)  \left(  h_{i}\right)  =-\mu\left(  h_{i}\right)  $.
Hence, we can assume WLOG that $\mu\left(  h_{i}\right)  $ is nonnegative
(because otherwise, we can switch $\mu$ with $r_{i}\mu$, and it will change
sign). Then we have $f_{i}^{\mu\left(  h_{i}\right)  }:V\left[  \mu\right]
\rightarrow V\left[  r_{i}\mu\right]  $.

I claim that $f_{i}^{\mu\left(  h_{i}\right)  }$ is an isomorphism.

This follows from:

\begin{lemma}
If $V$ is a locally finite $\mathfrak{sl}_{2}$-module, then $f^{m}:V\left[
m\right]  \rightarrow V\left[  -m\right]  $ is an isomorphism.
\end{lemma}

\begin{definition}
The \textit{Weyl group of} $\mathfrak{g}\left(  A\right)  $ is defined as the
subgroup of $\operatorname*{GL}\left(  P\right)  $ generated by the $r_{i}$.
This Weyl group is denoted by $W$. The elements $r_{i}$ are called
\textit{simple reflections}.
\end{definition}

We will not prove:

\begin{remark}
The Weyl group $W$ is finite if and only if $A$ is a Cartan matrix (of a
finite-dimensional Lie algebra).
\end{remark}

\begin{proposition}
\label{prop.weylkac.prop0}\textbf{1)} The form $\left(  \cdot,\cdot\right)  $
on $P$ is $W$-invariant.

\textbf{2)} There exists an isomorphism $V\left[  \mu\right]  \rightarrow
V\left[  w\mu\right]  $ for every $\mu\in P$, $w\in W$ and any integrable $V$.

\textbf{3)} The set of roots $R$ is $W$-invariant. (We recall that a
\textit{root} means a nonzero element $\alpha\in F=Q\otimes_{\mathbb{Z}%
}\mathbb{C}$ such that $\mathfrak{g}_{\alpha}\neq0$. We consider $F$ as a
subspace of $P$.)

\textbf{4)} We have $r_{i}\left(  \alpha_{i}\right)  =-\alpha_{i}$. Moreover,
$r_{i}$ induces a permutation of all positive roots except for $\alpha_{i}$.
\end{proposition}

\textit{Proof of Proposition.} \textbf{1)} and \textbf{2)} follow easily from
the corresponding statement for generators proven above.

\textbf{3)} By part \textbf{2)}, the set of weights $P\left(  V\right)  $ of
an integrable $\mathfrak{g}$-module $V$ is $W$-invariant. (Here, ``weight''
means a weight whose weight subspace is nonzero.) Applied to $V=\mathfrak{g}$,
this implies \textbf{3)} (since $P\left(  \mathfrak{g}\right)  =0\cup R$).

\textbf{4)} Proving $r_{i}\left(  \alpha_{i}\right)  =-\alpha_{i}$ is
straightforward. Now for the other part:

Any positive root can be written as $\alpha=\sum_{i}k_{i}\alpha_{i}$ where all
$k_{i}$ are $\geq0$ and $\sum_{i}k_{i}>0$.

Thus, for such a root, $r_{i}\left(  \alpha\right)  =\alpha-\alpha\left(
h_{i}\right)  \alpha_{i}=\sum_{j\neq i}k_{j}\alpha_{j}+\left(  k_{i}%
-\alpha\left(  h_{i}\right)  \right)  \alpha_{i}$.

If there exists a $j\neq i$ such that $k_{j}>0$, then $r_{i}\left(
\alpha\right)  $ must be a positive root (since there is no such thing as a
partly-negative-partly-positive root).

Alternative: $k_{j}=0$ for all $j\neq i$. But then $\alpha=k_{i}\alpha_{i}$,
so that $k_{i}=1$ (because a positive multiple of a simple root is not a root,
unless we are multiplying with $1$), but this is the case we excluded
(``except for $\alpha_{i}$''). Proposition proven.

\subsection{\textbf{[unfinished]} The Weyl-Kac character formula}

\begin{theorem}
[Kac]\label{thm.weylkac.weylkac}Denote by $P_{+}$ the set $\left\{  \chi\in
P\ \mid\ \chi\left(  h_{i}\right)  \in\mathbb{N}\text{ for all }i\in\left\{
1,2,...,r\right\}  \right\}  $.

Let $\chi$ be a dominant integral weight of $\mathfrak{g}\left(  A\right)  $.
(This means that $\chi\left(  h_{i}\right)  $ is a nonnegative integer for
every $i\in\left\{  1,2,...,r\right\}  $.) Let $V$ be an integrable
highest-weight $\mathfrak{g}_{\operatorname*{ext}}\left(  A\right)  $-module
with highest weight $\chi$. Then:

\textbf{(1)} The $\mathfrak{g}$-module $V$ is isomorphic to $L_{\chi}$. (In
other words, the $\mathfrak{g}$-module $V$ is irreducible.)

\textbf{(2)} The character of $V$ is%
\[
\operatorname*{ch}\left(  V\right)  =\dfrac{\sum\limits_{w\in W}\det\left(
w\right)  \cdot e^{w\left(  \chi+\rho\right)  -\rho}}{\prod\limits_{\alpha
>0}\left(  1-e^{-\alpha}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)
}}\ \ \ \ \ \ \ \ \ \ \text{in }R.
\]
Here, we recall that $R$ is the ring $\lim\limits_{\lambda\in P_{+}}%
e^{\lambda}\mathbb{C}\left[  \left[  e^{-\alpha_{1}},e^{-\alpha_{2}%
},...,e^{-\alpha_{r}}\right]  \right]  $ (note that this term increases when
$\lambda$ is changed to $\lambda+\alpha_{i}$) in which the characters are defined.

Here, $\rho$ is the element of $\mathfrak{h}^{\ast}$ satisfying $\rho\left(
h_{i}\right)  =1$ (as defined above). Since $\mathfrak{h}^{\ast}\subseteq P$,
this $\rho$ becomes an element of $P$.

Note that $\det\left(  w\right)  $ is always $1$ or $-1$ (and, in fact, equals
$\left(  -1\right)  ^{k}$, where $w$ is written in the form $w=r_{i_{1}%
}r_{i_{2}}...r_{i_{k}}$).
\end{theorem}

Part \textbf{(2)} of this theorem is called the \textit{Weyl-Kac character
formula}.

We want to prove this theorem.

Since $\chi$ is a dominant integral weight, we have $\chi\in P_{+}$.

Some comments on the theorem:

First of all, part \textbf{(2)} implies part \textbf{(1)}, since both $V$ and
$L_{\chi}$ satisfy the conditions of the Theorem and thus (according to part
\textbf{(2)}) share the same character, but we also have a surjective
homomorphism $\varphi:V\rightarrow L_{\chi}$, so (because of the characters
being the same) it is an isomorphism. Thus, we only need to bother about
proving part \textbf{(2)}.

Secondly, let us remark that the theorem yields $L_{\lambda}=M_{\lambda
}\diagup\left\langle f_{i}^{\lambda\left(  h_{i}\right)  +1}v_{\lambda}%
\ \mid\ i\in\left\{  1,2,...,r\right\}  \right\rangle $ for all dominant
integral weights $\lambda$. Indeed, denote $M_{\lambda}\diagup\left\langle
f_{i}^{\lambda\left(  h_{i}\right)  +1}v_{\lambda}\ \mid\ i\in\left\{
1,2,...,r\right\}  \right\rangle $ by $L_{\lambda}^{\prime}$. Then,
$L_{\lambda}^{\prime}$ is integrable (as we showed above more or less; more
precisely, we showed that $L_{\lambda}$ was integrable, but this proof went
exactly through proving that $L_{\lambda}^{\prime}$ is integrable), so that
the theorem is still applicable to $L_{\lambda}^{\prime}$ and we obtain
$L_{\lambda}^{\prime}\cong L_{\lambda}$.

Our third remark: In the case of a simple finite-dimensional Lie algebra
$\mathfrak{g}$, we have%
\[
\operatorname*{ch}\left(  M_{\lambda}\right)  =\dfrac{e^{\lambda}}%
{\prod\limits_{\alpha>0}\left(  1-e^{-\alpha}\right)  }.
\]
The denominator can be rewritten $\prod\limits_{\alpha>0}\left(  1-e^{-\alpha
}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)  }$, since $\dim\left(
\mathfrak{g}_{\alpha}\right)  =1$ for all roots $\alpha$.

In the case of Kac-Moody Lie algebras $\mathfrak{g}=\mathfrak{g}\left(
A\right)  $, we can use similar arguments to show that%
\[
\operatorname*{ch}\left(  M_{\lambda}\right)  =\dfrac{e^{\lambda}}%
{\prod\limits_{\alpha>0}\left(  1-e^{-\alpha}\right)  ^{\dim\left(
\mathfrak{g}_{\alpha}\right)  }}.
\]


So the Weyl-Kac character formula can be written as%
\[
\operatorname*{ch}\left(  V\right)  =\sum\limits_{w\in W}\det\left(  w\right)
\cdot\operatorname*{ch}\left(  M_{w\left(  \chi+\rho\right)  -\rho}\right)  .
\]


This formula can be proven using the BGG\footnote{Bernstein-Gelfand-Gelfand}
resolution (in fact, it is obtained as the Euler character of that
resolution), but we will take a different route here.

Another remark before we prove the formula. The Weyl-Kac character formula has
the following corollary:

\begin{corollary}
[Weyl-Kac denominator formula]We have $\prod\limits_{\alpha>0}\left(
1-e^{-\alpha}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)  }%
=\sum\limits_{w\in W}\det\left(  w\right)  \cdot e^{w\rho-\rho}$.
\end{corollary}

\textit{Proof of Corollary (using Weyl-Kac character formula).} Set $\chi=0$.
Then $L_{\chi}=\mathbb{C}$, so that $\operatorname*{ch}\left(  L_{\chi
}\right)  =1$ but on the other hand $\operatorname*{ch}\left(  L_{\chi
}\right)  =\dfrac{\sum\limits_{w\in W}\det\left(  w\right)  \cdot
e^{w\rho-\rho}}{\prod\limits_{\alpha>0}\left(  1-e^{-\alpha}\right)
^{\dim\left(  \mathfrak{g}_{\alpha}\right)  }}$. Thus, $\prod\limits_{\alpha
>0}\left(  1-e^{-\alpha}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)
}=\sum\limits_{w\in W}\det\left(  w\right)  \cdot e^{w\rho-\rho}$.

To prove the Weyl-Kac character formula, we will have to show several lemmas.

\begin{lemma}
\label{lem.weylkac.1}Let $\chi\in P_{+}$.

\textbf{(1)} Then, $W\chi\subseteq D\left(  \chi\right)  $ (where, as we
recall, $D\left(  \chi\right)  $ denotes the set $\left\{  \chi-\sum_{i}%
k_{i}\alpha_{i}\ \mid\ k_{i}\in\mathbb{N}\text{ for all }i\right\}  $.

\textbf{(2)} If $D\subseteq D\left(  \chi\right)  $ is a $W$-invariant subset,
then $D\cap P_{+}\neq\varnothing$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.weylkac.1}.} \textbf{(1)} Consider $L_{\chi}$.
Since $L_{\chi}$ is integrable, the set $P\left(  L_{\chi}\right)  $ is
$W$-invariant, so that $W\chi\subseteq P\left(  L_{\chi}\right)  $. But
$P\left(  L_{\chi}\right)  \subseteq D\left(  \chi\right)  $, since any weight
of $L_{\chi}$ is $\chi$ minus a sum of positive roots. Part \textbf{(1)} is proven.

\textbf{(2)} Let $\psi\in D$. Pick $w\in W$ such that $x-w\psi=\sum_{i}%
k_{i}\alpha_{i}$ with nonnegative integers $k_{i}$ and minimal $\sum_{i}k_{i}%
$. We claim that this $w$ satisfies $w\psi\in P_{+}$. This, of course, will
prove part \textbf{(2)}.

To prove $w\psi\in P_{+}$, assume that $w\psi\notin P_{+}$. Then, there exists
an $i$ such that $\left(  w\psi,\alpha_{i}\right)  =d_{i}^{-1}\left(
w\psi\right)  \left(  h_{i}\right)  <0$. (Note that all the $d_{i}$ are $>0$.)
Then, $r_{i}w\psi=w\psi-\left(  w\psi\right)  \left(  h_{i}\right)  \alpha
_{i}$, so that $\chi-r_{i}w\psi=\chi-w\psi+\left(  w\psi\right)  \left(
h_{i}\right)  \alpha_{i}=\sum_{j}k_{j}\alpha_{j}+\left(  w\psi\right)  \left(
h_{i}\right)  \alpha_{i}=\sum_{j}k_{j}^{\prime}\alpha_{j}$ and $\sum_{j}%
k_{j}^{\prime}=\sum_{j}k_{j}+\left(  w\psi\right)  \left(  h_{i}\right)
<\sum_{j}k_{j}$. This contradicts the minimality in our choice of $w$. Part
\textbf{(2)} is thus proven.

\begin{corollary}
\label{cor.weylkac.2}Let $w\in W$ satisfy $w\neq1$. Then, there exists $i$
such that $w\alpha_{i}<0$. (By $w\alpha_{i}<0$ we mean that $w\alpha_{i}$ is a
negative root.)
\end{corollary}

\textit{Proof of Corollary \ref{cor.weylkac.2}.} Choose $\chi\in P_{+}$ such
that $w\chi\neq\chi$. (Such a $\chi$ always exists, due to the definition of
$P_{+}$). Then, $w^{-1}\chi=\chi-\sum k_{i}\alpha_{i}$ for some $k_{i}%
\in\mathbb{N}$ (by Lemma \ref{lem.weylkac.1} \textbf{(1)}). Hence,%
\[
\chi=ww^{-1}\chi=w\chi-\sum k_{i}w\alpha_{i}=\left(  \chi-\sum k_{i}^{\prime
}\alpha_{i}\right)  -\sum k_{i}w\alpha_{i}.
\]
Thus, $\sum k_{i}^{\prime}\alpha_{i}+\sum k_{i}w\alpha_{i}=0$. But $\sum
k_{i}^{\prime}>0$, so there must exist an $i$ such that $w\alpha_{i}<0$.
Corollary \ref{cor.weylkac.2} is proven.

\begin{proposition}
\label{prop.weylkac.3}Let $\varphi,\psi\in P$ be such that $\varphi\left(
h_{i}\right)  >0$ and $\psi\left(  h_{i}\right)  \geq0$ for each $i$. Let
$w\in W$.

Then, $w\varphi=\psi$ if and only if $\varphi=\psi$ and $w=1$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.weylkac.3}.} For every $i$, we have
$\varphi\left(  h_{i}\right)  >0$ if and only if $\left(  \varphi,\alpha
_{i}\right)  >0$. Now suppose that there exists a $w\neq1$ such that
$w\varphi=\psi$. Then, by Corollary \ref{cor.weylkac.2}, there exists an $i$
such that $w\alpha_{i}<0$. Then, $\left(  \varphi,\alpha_{i}\right)  >0$ but
$\left(  \varphi,\alpha_{i}\right)  =\left(  w^{-1}\psi,\alpha_{i}\right)
=\left(  \psi,w\alpha_{i}\right)  \leq0$. This is a contradiction. Proposition
\ref{prop.weylkac.3} is proven.

Next, notice that $W$ acts on $R$.

\begin{proposition}
\label{prop.weylkac.4}Let $K$ denote the Weyl-Kac denominator $\prod
\limits_{\alpha>0}\left(  1-e^{-\alpha}\right)  ^{\dim\left(  \mathfrak{g}%
_{\alpha}\right)  }$. Then, $w\cdot K=\det\left(  w\right)  \cdot K$ for every
$w\in W$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.weylkac.4}.} We can WLOG take $w=r_{i}$
(since $\det$ is multiplicative). Then,%
\begin{align*}
r_{i}K  &  =e^{r_{i}\rho}\prod\limits_{\alpha>0}\left(  1-e^{-r_{i}\alpha
}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)  }=e^{r_{i}\rho}\left(
1-e^{+\alpha_{i}}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha_{i}}\right)
}\prod\limits_{\substack{\alpha>0;\\\alpha\neq\alpha_{i}}}\left(
1-e^{-\alpha}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.weylkac.prop0}%
}\right) \\
&  =e^{r_{i}\rho}\left(  1-e^{+\alpha_{i}}\right)  \prod
\limits_{\substack{\alpha>0;\\\alpha\neq\alpha_{i}}}\left(  1-e^{-\alpha
}\right)  ^{\dim\left(  \mathfrak{g}_{\alpha}\right)  }%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\dim\left(  \mathfrak{g}_{\alpha_{i}%
}\right)  =1\right) \\
&  =\dfrac{e^{r_{i}\rho}\left(  1-e^{+\alpha_{i}}\right)  }{e^{\rho}\left(
1-e^{-\alpha_{i}}\right)  }\cdot K.
\end{align*}
Thus, we must only prove that $\dfrac{e^{r_{i}\rho}\left(  1-e^{+\alpha_{i}%
}\right)  }{e^{\rho}\left(  1-e^{-\alpha_{i}}\right)  }=-1$.

But this is very easy: We have $r_{i}\rho=\rho-\underbrace{\rho\left(
h_{i}\right)  }_{=1}\alpha_{i}=\rho-\alpha_{i}$, so that
\[
\dfrac{e^{r_{i}\rho}\left(  1-e^{+\alpha_{i}}\right)  }{e^{\rho}\left(
1-e^{-\alpha_{i}}\right)  }=\dfrac{e^{\rho-\alpha_{i}}\left(  1-e^{+\alpha
_{i}}\right)  }{e^{\rho}\left(  1-e^{-\alpha_{i}}\right)  }=\dfrac
{e^{-\alpha_{i}}\left(  1-e^{+\alpha_{i}}\right)  }{1-e^{-\alpha_{i}}}%
=\dfrac{e^{-\alpha_{i}}-1}{1-e^{-\alpha_{i}}}=-1.
\]
Proposition \ref{prop.weylkac.4} is proven.

\begin{proposition}
\label{prop.weylkac.5}Let $\mu,\nu\in P_{+}$ be such that $\mu\in D\left(
\nu\right)  $ and $\mu\neq\nu$. Then, $\left(  \nu+\rho\right)  ^{2}-\left(
\mu+\rho\right)  ^{2}>0$. Here, $\lambda^{2}$ is defined to mean the inner
product $\left(  \lambda,\lambda\right)  $.
\end{proposition}

\textit{Proof of Proposition \ref{prop.weylkac.5}.} We have $\nu-\mu
=\sum\limits_{i}k_{i}\alpha_{i}$ for some $k_{i}\geq0$ (since $\mu\in D\left(
\nu\right)  $). There exists an $i$ such that $k_{i}>0$ (because $\mu\neq\nu
$). Now,%
\[
\left(  \nu+\rho\right)  ^{2}-\left(  \mu+\rho\right)  ^{2}=\left(  \nu
-\mu,\mu+\nu+2\rho\right)  =\sum\limits_{i}k_{i}\left(  \alpha_{i},\mu
+\nu+2\rho\right)  .
\]
But now use $\left(  \alpha_{i},\mu\right)  \geq0$ (since $\mu\in P_{+}$),
also $\left(  \alpha_{i},\nu\right)  \geq0$ (since $\nu\in P_{+}$) and
$\left(  \alpha_{i},\rho\right)  =d_{i}^{-1}>0$ to conclude that this is $>0$
(since there exists an $i$ such that $k_{i}>0$). Proposition
\ref{prop.weylkac.5} is proven.

\begin{proposition}
\label{prop.weylkac.6}Suppose that $V$ is a $\mathfrak{g}_{\operatorname*{ext}%
}\left(  A\right)  $-module from Category $\mathcal{O}$ such that the Casimir
$C$ satisfies $\Delta\mid_{V}=\gamma\cdot\operatorname*{id}$. Then,
$\operatorname*{ch}\left(  V\right)  =\sum c_{\lambda}\operatorname*{ch}%
\left(  M_{\lambda}\right)  $, where the sum is over all $\lambda$ satisfying
$\left(  \lambda,\lambda+2\rho\right)  =\gamma$, and $c_{\lambda}\in
\mathbb{Z}$ are some integers.
\end{proposition}

\textit{Proof of Proposition \ref{prop.weylkac.6}.} The expansion is built
inductively as follows:

Suppose $P\left(  V\right)  \subseteq D\left(  \lambda_{1}\right)  \cup
D\left(  \lambda_{2}\right)  \cup...\cup D\left(  \lambda_{m}\right)  $ for
some weights $\lambda_{1},\lambda_{2},...,\lambda_{m}$. Assume that this is a
minimal such union. Then, $\lambda_{i}+\alpha_{j}\notin P\left(  V\right)  $
for any $i,j$.

Let $d_{i}=\dim\left(  V\left[  \lambda_{i}\right]  \right)  $. Then, we have
a homomorphism $\varphi:\bigoplus_{i}d_{i}M_{\lambda_{i}}\rightarrow V$ which
is an isomorphism in weight $\lambda_{i}$. Let $K=\operatorname*{Ker}\varphi$.
Let $C=\operatorname*{Coker}\varphi$. Clearly, both $K$ and $C$ lie in
Category $\mathcal{O}$. We have an exact sequence $0\rightarrow K\rightarrow
\bigoplus_{i}d_{i}M_{\lambda_{i}}\rightarrow V\rightarrow C\rightarrow0$.
Since the alternating sum of characters in an exact sequence is $0$, this
yields $\operatorname*{ch}V=\sum_{i}d_{i}\operatorname*{ch}\left(
M_{\lambda_{i}}\right)  -\operatorname*{ch}K+\operatorname*{ch}C$.

Now we claim that $\Delta\mid_{M_{\lambda_{i}}}=\left(  \lambda_{i}%
,\lambda_{i}+2\rho\right)  =\gamma$ if $d_{i}\neq0$. (Otherwise, a
homomorphism $\varphi$ could not exist.)

Also, $\Delta\mid_{K}=\Delta\mid_{C}=\gamma$.

But if $\mu\in P\left(  K\right)  \cup P\left(  C\right)  $, then for some
$i$, we have $\lambda_{i}-\mu=\sum k_{j}\alpha_{j}$ with $\sum k_{j}\geq1$.

Next step: $\sum k_{i}\geq2$.

Etc.

If we run this procedure indefinitely, eventually every weight in this cone
will be exhausted. Then we apply the procedure to $K$ and $C$, and then to
their $K$ and $C$ etc..

\textit{Proof of Weyl-Kac character formula.} According to Proposition
\ref{prop.weylkac.6}, we have%
\[
\operatorname*{ch}\left(  V\right)  =\sum_{\psi\in D\left(  \chi\right)
}c_{\psi}\operatorname*{ch}\left(  M_{\psi}\right)
\ \ \ \ \ \ \ \ \ \ \text{with }c_{\chi}=1.
\]


We will now need:

\begin{corollary}
\label{cor.weylkac.7}If $c_{\psi}\neq0$, then $\left(  \psi+\rho\right)
^{2}=\left(  \chi+\rho\right)  ^{2}$.
\end{corollary}

\textit{Proof of Corollary \ref{cor.weylkac.7}.} This follows from Proposition
\ref{prop.weylkac.6}.

\begin{lemma}
\label{lem.weylkac.8}If $\psi+\rho=w\left(  \chi+\rho\right)  $, then
$c_{\psi}=\det\left(  w\right)  \cdot c_{\chi}$.
\end{lemma}

\textit{Proof of Lemma \ref{lem.weylkac.8}.} We have $wK=\left(  \det
w\right)  \cdot K$ and $w\cdot\operatorname*{ch}V=\operatorname*{ch}V$. Hence,
$w\left(  K\cdot\operatorname*{ch}V\right)  =\left(  \det w\right)
\cdot\left(  K\operatorname*{ch}V\right)  $. But since $\operatorname*{ch}%
\left(  M_{\psi}\right)  =\dfrac{\sum c_{\psi}e^{\psi+\rho}}{K}$, we have
$K\operatorname*{ch}V=\sum\limits_{\psi\in D\left(  \chi\right)  }c_{\psi
}e^{\psi+\rho}=\left(  \det w\right)  \cdot\sum\limits_{\psi\in D\left(
\chi\right)  }c_{\psi}e^{\psi+\rho}$. (If $\psi+\rho=w\left(  \chi
+\rho\right)  $.) Thus, $c_{\psi}=\left(  \det w\right)  \cdot c_{\chi}$.

\begin{lemma}
\label{lem.weylkac.9}Let $D=\left\{  \psi\ \mid\ c_{\psi-\rho}\neq0\right\}
$. Then, $D=W\left(  \chi+\rho\right)  $.
\end{lemma}

\textit{Proof of Lemma \ref{lem.weylkac.9}.} We have $W\left(  \chi
+\rho\right)  \subseteq D$ by Lemma \ref{lem.weylkac.8}. Also, $D$ is
$W$-invariant since $V$ is integrable.

Suppose $D\neq W\left(  \chi+\rho\right)  $. Then, $\left(  D\diagdown
W\left(  \chi+\rho\right)  \right)  \cap P_{+}\neq\varnothing$ by Lemma
\ref{lem.weylkac.1} \textbf{(2)}. Take some $\beta\in\left(  D\diagdown
W\left(  \chi+\rho\right)  \right)  \cap P_{+}$. Then, $\beta-\rho\in D\left(
\chi\right)  $, so that $\left(  \chi+\rho,\chi+\rho\right)  -\left(
\beta,\beta\right)  >0$ (by Proposition \ref{prop.weylkac.5}). Thus, $\beta$
cannot occur in the sum (by Corollary \ref{cor.weylkac.7}).

Punchline: $\operatorname*{ch}V=\sum_{w\in W}\dfrac{\left(  \det w\right)
\cdot e^{w\left(  \chi+\rho\right)  }}{K}$. This is exactly the Weyl-Kac
character formula.

\end{document}
